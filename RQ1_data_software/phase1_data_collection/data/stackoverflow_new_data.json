[
{"title": "Catkin workspace build fails on Yocto: _setup_util.py` generated with blank shebang (`#!`)", "time": 1756918472, "post_content": ["I\u2019m running ROS 1 Noetic on a Yocto-based image. I\u2019m trying to create an empty catkin workspace (catkin_init_workspace, then catkin_make).\ncatkin_make fails during configuration with errors like:\n/home/root/catkin_ws/devel/_setup_util.py: line 40: import: command not found\n/home/root/catkin_ws/devel/_setup_util.py: line 49: syntax error near unexpected token '('\n\nOn inspection, devel/_setup_util.py is generated with just:\n#!\n# -*- coding: utf-8 -*-\n\ninstead of the expected shebang:\n#!/usr/bin/env python3\n\nSo when setup.sh tries to run _setup_util.py, it gets executed by sh instead of Python, causing the syntax errors.\n\npython3 is installed and working (/usr/bin/python3, version 3.10.15).\nPYTHON_EXECUTABLE is correctly set to /usr/bin/python3 in CMakeCache.txt.\n/usr/bin/env exists and is valid.\nThis only happens on my Yocto image; on Ubuntu the same steps generate a correct shebang.\n\nWhy does Catkin generate _setup_util.py with a blank shebang on Yocto, and how can I fix or patch this so catkin_make works normally?\nWhat I\u2019ve tried\n\nVerified /usr/bin/python3 exists and works (Python 3.10.15).\n\nChecked CMakeCache.txt, PYTHON_EXECUTABLE is correctly set to /usr/bin/python3.\n\n/usr/bin/env exists and works.\n\nManually patching _setup_util.py to add #!/usr/bin/env python3 fixes the error temporarily (then python3 _setup_util.py --generate bash runs fine).\n\nManually patching devel/setup.sh to call /usr/bin/python3 _setup_util.py also works, but is overwritten every catkin_make.\n\n\n6.Forcing catkin_make -DPYTHON_EXECUTABLE=/usr/bin/python3 doesn\u2019t change the outcome \u2014 the generated _setup_util.py still has a blank shebang.\nHere is my config for the ROS1 installation:\nIMAGE_INSTALL:append = \" packagegroup-ros1-comm \"\n\n\nIMAGE_INSTALL:append = \" python3-rosdep python3-argcomplete \"\n\nIMAGE_INSTALL:append = \" \\\n  roscpp \\\n  rospy \\\n  std-msgs \\\n  sensor-msgs \\\n  nav-msgs \\\n  message-runtime \\\n  roslaunch \\\n  pcl-conversions \\\n  pcl-ros \\\n  pluginlib \\\n  class-loader \\\n  nodelet \\\n  laser-geometry \\\n  message-generation \\\n  roslaunch \\\n  jsk-recognition-msgs \\\n  visualization-msgs \\\n\"\n\nIMAGE_INSTALL:append = \" \\\n  catkin \\\n  python3-empy \\\n  python3-rospkg \\\n\"\n\nLayers:\nmeta-ros-common       \nmeta-ros1            \nmeta-ros1-noetic\n\nWhat I expected\nThat catkin_make would generate devel/_setup_util.py with a valid Python shebang (#!/usr/bin/env python3), allowing the workspace to build normally without patching."], "question_code": ["catkin_init_workspace", "catkin_make", "catkin_make", "/home/root/catkin_ws/devel/_setup_util.py: line 40: import: command not found\n/home/root/catkin_ws/devel/_setup_util.py: line 49: syntax error near unexpected token '('\n", "devel/_setup_util.py", "#!\n# -*- coding: utf-8 -*-\n", "#!/usr/bin/env python3\n", "setup.sh", "_setup_util.py", "sh", "python3", "/usr/bin/python3", "PYTHON_EXECUTABLE", "/usr/bin/python3", "CMakeCache.txt", "/usr/bin/env", "_setup_util.py", "catkin_make", "IMAGE_INSTALL:append = &quot; packagegroup-ros1-comm &quot;\n\n\nIMAGE_INSTALL:append = &quot; python3-rosdep python3-argcomplete &quot;\n\nIMAGE_INSTALL:append = &quot; \\\n  roscpp \\\n  rospy \\\n  std-msgs \\\n  sensor-msgs \\\n  nav-msgs \\\n  message-runtime \\\n  roslaunch \\\n  pcl-conversions \\\n  pcl-ros \\\n  pluginlib \\\n  class-loader \\\n  nodelet \\\n  laser-geometry \\\n  message-generation \\\n  roslaunch \\\n  jsk-recognition-msgs \\\n  visualization-msgs \\\n&quot;\n\nIMAGE_INSTALL:append = &quot; \\\n  catkin \\\n  python3-empy \\\n  python3-rospkg \\\n&quot;\n", "meta-ros-common       \nmeta-ros1            \nmeta-ros1-noetic\n"], "quote": [], "url": "https://stackoverflow.com/questions/79754886/catkin-workspace-build-fails-on-yocto-setup-util-py-generated-with-blank-sheb", "answer": [], "answer_code": []},
{"title": "/map not received with slam_toolbox (ros humble)", "time": 1753900137, "post_content": ["i am using slam toolbox with nav2 and ros humble to create a robot that autonomously navigates and maps the area. currently, I launch the robot simulation in gazebo with no problem, but the slam toolbox doesnt publish in the /map topic, making so that the nav2 cant create a costmap. i have searched this problem a lot, and most of the solutions i found are related to the tf tree. I think this might be a tf related problem, because earlier the map was being published, but because my tf tree was very wrong, when i moved the robot via teleop_twist_keyboard the map and the robot would remain static and the map would get very \"corrupt\". now that i solved the tf tree problem, the robot can move around the map transform, but i dont get the map msg. my tf tree is correct (map->odom->base_footprint->base_link->rest of the bot).\n\ni also get this error from slam_toolbox:\n[async_slam_toolbox_node-1] [INFO] [1753797759.327500274] [slam_toolbox]: Message Filter dropping message: frame 'base_footprint' at time 1753797759.302 for reason 'discarding message because the queue is full\n\nwhat i know: there is a /scan being published, as well as a /odom. i tried increasing scan_queue_size in the slam params file to 200 but it didnt work"], "question_code": ["[async_slam_toolbox_node-1] [INFO] [1753797759.327500274] [slam_toolbox]: Message Filter dropping message: frame 'base_footprint' at time 1753797759.302 for reason 'discarding message because the queue is full\n"], "quote": [], "url": "https://stackoverflow.com/questions/79720382/map-not-received-with-slam-toolbox-ros-humble", "answer": [], "answer_code": []},
{"title": "ROS 2 installation in Windows 11 with visualization", "time": 1751363220, "post_content": ["I am trying to get in the ROS 2 world and I am trying to understand how to properly install ROS 2 for my master's thesis. I am on Windows 11 machine and I am trying to decide which is the best way to install ROS 2, since I will be needing visualization and also I will need my GPU capabilities for Deep Reinforcement Learning training. Dual boot is not really an option since I am working on a laptop so I can not split the disk in partitions.\nI have shown some articles and videos talking about docker and something called Ansible but I can not really tell which of them is the best that combines all the above requirements.\nHad anyone here the same problem before?"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79685855/ros-2-installation-in-windows-11-with-visualization", "answer": [], "answer_code": []},
{"title": "What is the proper way to conver ROS std_msg types into pydrake compatible values?", "time": 1750969803, "post_content": ["I'm working on a ROS 2 node that runs a PyDrake simulation to emulate robot dynamics, intended for testing an existing ROS 2 control stack. My approach is to use drake_ros's RosSubscriberSystem to subscribe to commanded torque values published on ROS topics, and then use a LeafSystem with two AbstractValue input ports to convert and combine the Float32 messages into a 2D vector suitable for the MultibodyPlant.\nHowever, when I run the node, I receive the following repeated error in the terminal:\n[INFO] [1750968350.207715533] [simulate_ball]: Starting Simulation\nINFO:drake:Meshcat listening for connections at http://localhost:7000\n[INFO] [1750968350.229970451] [simulate_ball]: Drake simulation initialized\n[ERROR] [1750968353.460812671] [simulate_ball]: Simulation error: Tried to call pure virtual function \"SerializerInterface::Deserialize\"\n[ERROR] [1750968353.472300868] [simulate_ball]: Simulation error: Tried to call pure virtual function \"SerializerInterface::Deserialize\"\n[ERROR] [1750968353.480820201] [simulate_ball]: Simulation error: Tried to call pure virtual function \"SerializerInterface::Deserialize\"\n\nThis message occurs once the simulator begins stepping. I suspect that the error stems from an incorrect or unsupported use of AbstractValue.Make(Float32())\nHere's a minimal working example of the setup:\nclass ControlTorquesConverter(LeafSystem):\n    def __init__(self):\n        super().__init__()\n        self.inputFloat32drive = self.DeclareAbstractInputPort(\n            \"cmd_drive_torques\", AbstractValue.Make(Float32())\n        )\n        self.inputFloat32steer = self.DeclareAbstractInputPort(\n            \"cmd_steer_torques\", AbstractValue.Make(Float32())\n        )\n\n        self.DeclareVectorOutputPort(\"drive_steer_torques\", 2, self.ConvertValues)\n\n    def ConvertValues(self, context, output):\n        drive_torque_msg = self.inputFloat32drive.Eval(context)\n        steer_torque_msg = self.inputFloat32steer.Eval(context)\n\n        drive_val = drive_torque_msg.data\n        steer_val = steer_torque_msg.data\n\n        output.SetFromVector([drive_val, steer_val])\n\n\nthis leaf system is implemented in the node as follows\ndrive_control_sub = self.builder.AddSystem(RosSubscriberSystem.Make(Float32, \n                                                                            \"/cmd/drive_torque\", \n                                                                            qos, \n                                                                            self.ros_interface_system.get_ros_interface()))\n        steer_control_sub = self.builder.AddSystem(RosSubscriberSystem.Make(Float32, \n                                                                            \"/cmd/steer_torque\", \n                                                                            qos, \n                                                                            self.ros_interface_system.get_ros_interface()))\n        control_converter = self.builder.AddSystem(ControlTorquesConverter())\n\n        # connect control sub to plant\n        self.builder.Connect(drive_control_sub.get_output_port(0),\n                             control_converter.inputFloat32drive)\n        self.builder.Connect(steer_control_sub.get_output_port(0),\n                             control_converter.inputFloat32steer)\n        # self.builder.Connect(control_converter.get_output_port(),\n        #                      self.plant.get_actuation_input_port())\n\nMy main node initializes the simulation, builds the diagram, and advances the simulation in a periodic timer callback. I've confirmed that the diagram builds and the simulator initializes \u2014 the crash only occurs when stepping begins.\nIs using AbstractValue.Make(Float32()) a valid approach in a LeafSystem for RosSubscriberSystem output? Or is there a better way to do this?"], "question_code": ["[INFO] [1750968350.207715533] [simulate_ball]: Starting Simulation\nINFO:drake:Meshcat listening for connections at http://localhost:7000\n[INFO] [1750968350.229970451] [simulate_ball]: Drake simulation initialized\n[ERROR] [1750968353.460812671] [simulate_ball]: Simulation error: Tried to call pure virtual function &quot;SerializerInterface::Deserialize&quot;\n[ERROR] [1750968353.472300868] [simulate_ball]: Simulation error: Tried to call pure virtual function &quot;SerializerInterface::Deserialize&quot;\n[ERROR] [1750968353.480820201] [simulate_ball]: Simulation error: Tried to call pure virtual function &quot;SerializerInterface::Deserialize&quot;\n", "class ControlTorquesConverter(LeafSystem):\n    def __init__(self):\n        super().__init__()\n        self.inputFloat32drive = self.DeclareAbstractInputPort(\n            &quot;cmd_drive_torques&quot;, AbstractValue.Make(Float32())\n        )\n        self.inputFloat32steer = self.DeclareAbstractInputPort(\n            &quot;cmd_steer_torques&quot;, AbstractValue.Make(Float32())\n        )\n\n        self.DeclareVectorOutputPort(&quot;drive_steer_torques&quot;, 2, self.ConvertValues)\n\n    def ConvertValues(self, context, output):\n        drive_torque_msg = self.inputFloat32drive.Eval(context)\n        steer_torque_msg = self.inputFloat32steer.Eval(context)\n\n        drive_val = drive_torque_msg.data\n        steer_val = steer_torque_msg.data\n\n        output.SetFromVector([drive_val, steer_val])\n\n", "drive_control_sub = self.builder.AddSystem(RosSubscriberSystem.Make(Float32, \n                                                                            &quot;/cmd/drive_torque&quot;, \n                                                                            qos, \n                                                                            self.ros_interface_system.get_ros_interface()))\n        steer_control_sub = self.builder.AddSystem(RosSubscriberSystem.Make(Float32, \n                                                                            &quot;/cmd/steer_torque&quot;, \n                                                                            qos, \n                                                                            self.ros_interface_system.get_ros_interface()))\n        control_converter = self.builder.AddSystem(ControlTorquesConverter())\n\n        # connect control sub to plant\n        self.builder.Connect(drive_control_sub.get_output_port(0),\n                             control_converter.inputFloat32drive)\n        self.builder.Connect(steer_control_sub.get_output_port(0),\n                             control_converter.inputFloat32steer)\n        # self.builder.Connect(control_converter.get_output_port(),\n        #                      self.plant.get_actuation_input_port())\n"], "quote": [], "url": "https://stackoverflow.com/questions/79681113/what-is-the-proper-way-to-conver-ros-std-msg-types-into-pydrake-compatible-value", "answer": [], "answer_code": []},
{"title": "RobotWebTools: rosbridge - ros3djs integration on ros2", "time": 1749545549, "post_content": ["I'm unable to make ros3djs work with rosbridge on ros2 humble.\nros3djs uses roslibjs TF client which requires the rosbridge to be able to communicate TF information.\nThis is achieved by using tf2_web_repblisher but this module is supported only on ROS1.\nSo I'm trying to use tf2_web_republisher_py which is for ROS2 but I get the following error from rosbridge_server:\n\nUnable to import msg class TFSubscriptionActionGoal from package tf2_web_republisher. Caused by module 'tf2_web_republisher.msg' has no attribute 'TFSubscriptionActionGoal'\n\nSearching the web I discovered that there are many people experiencing this problem and also that most of the RWT libraries (roslibjs, rosbridge, tf2_web_republisher) have several branches for different ros version.\nIt is a total mess and a shame that RobotWebTools is unable to maintain and document the integration of its own tech stack.\nIn conclusion does exist a combination of such libraries versions/branches that in your experience works on ROS2?"], "question_code": ["ros3djs", "rosbridge", "ros2", "humble", "ros3djs", "roslibjs", "rosbridge", "tf2_web_repblisher", "rosbridge_server", "roslibjs", "rosbridge", "tf2_web_republisher"], "quote": ["Unable to import msg class TFSubscriptionActionGoal from package tf2_web_republisher. Caused by module 'tf2_web_republisher.msg' has no attribute 'TFSubscriptionActionGoal'"], "url": "https://stackoverflow.com/questions/79660105/robotwebtools-rosbridge-ros3djs-integration-on-ros2", "answer": [], "answer_code": []},
{"title": "How to implement the multiplicative extended kalman filter in opencv aruco application?", "time": 1747515655, "post_content": ["I've been looking to find a way of removing jitter from a project involving tracking two aruco marker boards. The camera is static and I have two marker boards moving with respect to one another. I have been looking at extended kalman filters and it appears that a multiplicative one could be the solution for me. The link below summarises the approach for a quaternion based approach that works on orientation using an IMU.\nhttps://matthewhampsey.github.io/blog/2020/07/18/mekf\nMy source transformations are rotation vectors and translation vectors from the opencv solvePNP function.\nI have recorded the output of the rvecs and tvecs from the two markers in lists of arrays stored in the pickle files attached ( p1 = probe 1, p2 = probe 2).\nData can be downloaded here:\nhttps://drive.google.com/drive/folders/1DL8rnc3rn4UqJUYZVHuUk2Rd4FzvYgCX?usp=sharing\nThe jitter is present in both the rvec and tvec and I am unsure how to implement the MEKF.\nThe gif below is a mockup of the two objects moving around with very visible jitter (the rvecs and tvecs are generated from a factory calibrated machine vision camera - 4k stream - the input image for opencv is as good as you can get).\n\nBelow is some boilerplate code to experiment with the dataset and see the jitter.\nimport numpy as np\nimport open3d as o3d\nimport cv2\nimport time\ndef convert_to_open3d_affine(r,t):\n    #takes rvec and tvec and converts to 4x4 affine transform with both rotation and translation\n    R, _ = cv2.Rodrigues(r)\n    bob=np.eye(4,4)\n    bob[:3,:3]=R\n    bob[:,3][:3]=t.reshape(1,3)\n    #convert from opencv format of affine to open3d\n    bob[1:3]=-bob[1:3]\n    return bob\n\n#load saved opencv tracking data\nimport pickle\nwith open('p1_rvec_store.pickle', 'rb') as handle:\n    probe_1_rvec_store = pickle.load(handle)\nwith open('p1_tvec_store.pickle', 'rb') as handle:\n    probe_1_tvec_store = pickle.load(handle)\nwith open('p2_rvec_store.pickle', 'rb') as handle:\n    probe_2_rvec_store = pickle.load(handle)\nwith open('p2_tvec_store.pickle', 'rb') as handle:\n    probe_2_tvec_store = pickle.load(handle)\nwith open('probe_1_vertices.pickle', 'rb') as handle:\n    probe_1_vertices = pickle.load(handle)\nwith open('probe_2_vertices.pickle', 'rb') as handle:\n    probe_2_vertices = pickle.load(handle)\n\n#load point clouds of tracked objects\npcd=o3d.geometry.PointCloud()\npcd.points=o3d.utility.Vector3dVector(probe_1_vertices)\npcd2=o3d.geometry.PointCloud()\npcd2.points=o3d.utility.Vector3dVector(probe_2_vertices)\n\n#setup visualiser\nvis = o3d.visualization.Visualizer()\nvis.create_window(height=480, width=640)\nvis.add_geometry(pcd)\nvis.add_geometry(pcd2)\nwhile True:\n    for pr,pt,sr,st in zip(probe_1_rvec_store,probe_1_tvec_store,probe_2_rvec_store,probe_2_tvec_store):\n        time.sleep(0.05)\n        pcd.points=o3d.utility.Vector3dVector(probe_1_vertices)\n        pcd2.points=o3d.utility.Vector3dVector(probe_2_vertices)\n\n        #need to insert kalman filter here, taking pr,pt,sr and st as input\n\n        pcd.points=pcd.transform(convert_to_open3d_affine(pr,pt)).points #open3d takes 4x4 affine as input for transforms hence conversion\n        pcd2.points=pcd2.transform(convert_to_open3d_affine(sr,st)).points #open3d takes 4x4 affine as input for transforms hence conversion\n\n\n        vis.update_geometry(pcd)\n        vis.update_geometry(pcd2)\n        vis.poll_events()\n        vis.update_renderer()\n\nAny help perhaps with python code to elaborate would be most welcome as my knowledge of code is probably less weak than my knowledge of the maths behind this!"], "question_code": ["import numpy as np\nimport open3d as o3d\nimport cv2\nimport time\ndef convert_to_open3d_affine(r,t):\n    #takes rvec and tvec and converts to 4x4 affine transform with both rotation and translation\n    R, _ = cv2.Rodrigues(r)\n    bob=np.eye(4,4)\n    bob[:3,:3]=R\n    bob[:,3][:3]=t.reshape(1,3)\n    #convert from opencv format of affine to open3d\n    bob[1:3]=-bob[1:3]\n    return bob\n\n#load saved opencv tracking data\nimport pickle\nwith open('p1_rvec_store.pickle', 'rb') as handle:\n    probe_1_rvec_store = pickle.load(handle)\nwith open('p1_tvec_store.pickle', 'rb') as handle:\n    probe_1_tvec_store = pickle.load(handle)\nwith open('p2_rvec_store.pickle', 'rb') as handle:\n    probe_2_rvec_store = pickle.load(handle)\nwith open('p2_tvec_store.pickle', 'rb') as handle:\n    probe_2_tvec_store = pickle.load(handle)\nwith open('probe_1_vertices.pickle', 'rb') as handle:\n    probe_1_vertices = pickle.load(handle)\nwith open('probe_2_vertices.pickle', 'rb') as handle:\n    probe_2_vertices = pickle.load(handle)\n\n#load point clouds of tracked objects\npcd=o3d.geometry.PointCloud()\npcd.points=o3d.utility.Vector3dVector(probe_1_vertices)\npcd2=o3d.geometry.PointCloud()\npcd2.points=o3d.utility.Vector3dVector(probe_2_vertices)\n\n#setup visualiser\nvis = o3d.visualization.Visualizer()\nvis.create_window(height=480, width=640)\nvis.add_geometry(pcd)\nvis.add_geometry(pcd2)\nwhile True:\n    for pr,pt,sr,st in zip(probe_1_rvec_store,probe_1_tvec_store,probe_2_rvec_store,probe_2_tvec_store):\n        time.sleep(0.05)\n        pcd.points=o3d.utility.Vector3dVector(probe_1_vertices)\n        pcd2.points=o3d.utility.Vector3dVector(probe_2_vertices)\n\n        #need to insert kalman filter here, taking pr,pt,sr and st as input\n\n        pcd.points=pcd.transform(convert_to_open3d_affine(pr,pt)).points #open3d takes 4x4 affine as input for transforms hence conversion\n        pcd2.points=pcd2.transform(convert_to_open3d_affine(sr,st)).points #open3d takes 4x4 affine as input for transforms hence conversion\n\n\n        vis.update_geometry(pcd)\n        vis.update_geometry(pcd2)\n        vis.poll_events()\n        vis.update_renderer()\n"], "quote": [], "url": "https://stackoverflow.com/questions/79626985/how-to-implement-the-multiplicative-extended-kalman-filter-in-opencv-aruco-appli", "answer": [], "answer_code": []},
{"title": "Lifecycle nodes loaded as composable nodes in a container are unable to communicate with the lifecycle manager", "time": 1747308430, "post_content": ["I have several lifecycle nodes loaded as composable nodes in a container. Then, I use the lifecycle manager to bring up all the nodes\n    from launch import LaunchDescription\n    from launch.actions import DeclareLaunchArgument\n    from launch.substitutions import LaunchConfiguration\n    from launch_ros.actions import ComposableNodeContainer, Node\n    from launch_ros.descriptions import ComposableNode\n\n    def generate_launch_description():\n        use_sim_time = LaunchConfiguration('use_sim_time')\n\n        return LaunchDescription([\n            DeclareLaunchArgument(\n                'use_sim_time',\n                default_value='false',\n                description='Use simulation time if true'\n            ),\n\n            # Composable Node Container\n            ComposableNodeContainer(\n                name='sensor_container',\n                namespace='',\n                package='rclcpp_components',\n                executable='component_container',\n                output='screen',\n                composable_node_descriptions=[\n                    ComposableNode(\n                        package='imu_preprocessor',\n                        plugin='aide_imu_preprocessing::ImuPreprocessor',\n                        name='imu_preprocessor_node',\n                        parameters=[{'use_sim_time': use_sim_time}]\n                    )\n                ]\n            ),\n\n            # Lifecycle Manager to manage lifecycle state transitions\n            Node(\n                package='nav2_lifecycle_manager',\n                executable='lifecycle_manager',\n                name='lifecycle_manager_sensors',\n                output='screen',\n                parameters=[\n                    {'autostart': True},\n                    {'node_names': ['sensor_container/imu_preprocessor_node']},\n                    {'bond_timeout': 10.0},\n                    {'attempt_respawn_reconnection': True},\n                    {'retry_on_failure': True}\n                ]\n            )\n        ])\n\nThose nodes start successfully, but due to namespace issues, the lifecycle manager is unable to retrieve the status of each lifecycle node\n        [INFO] [launch]: All log files can be found below /home/op/.ros/log/2025-05-15-12-11-22-609782-op-Dell-G16-7630-907199\n        [INFO] [launch]: Default logging verbosity is set to INFO\n        [INFO] [component_container-1]: process started with pid [907210]\n        [INFO] [lifecycle_manager-2]: process started with pid [907212]\n        [lifecycle_manager-2] [INFO] [1747307482.668951759] [lifecycle_manager_sensors]: Creating\n        [lifecycle_manager-2] [INFO] [1747307482.669757600] [lifecycle_manager_sensors]: Creating and initializing lifecycle service clients\n        [component_container-1] [INFO] [1747307482.909456536] [sensor_container]: Load Library: /home/op/imu_ws/install/imu_preprocessor/lib/libimu_preprocessor_component.so\n        [component_container-1] [INFO] [1747307482.915015197] [sensor_container]: Found class: rclcpp_components::NodeFactoryTemplate<aide_imu_preprocessing::ImuPreprocessor>\n        [component_container-1] [INFO] [1747307482.915051099] [sensor_container]: Instantiate class: rclcpp_components::NodeFactoryTemplate<aide_imu_preprocessing::ImuPreprocessor>\n        [component_container-1] [INFO] [1747307482.917613496] [imu_preprocessor_node]: Initializing IMU Preprocessor\n        [INFO] [launch_ros.actions.load_composable_nodes]: Loaded node '/imu_preprocessor_node' in container '/sensor_container'\n        [lifecycle_manager-2] [INFO] [1747307484.670338132] [lifecycle_manager_sensors]: Waiting for service sensor_container/imu_preprocessor_node/get_state...\n        ^C[WARNING] [launch]: user interrupted with ctrl-c (SIGINT)\n        ^C[WARNING] [launch]: user interrupted with ctrl-c (SIGINT) again, ignoring...\n        [lifecycle_manager-2] [INFO] [1747307485.688357535] [rclcpp]: signal_handler(signum=2)\n        [lifecycle_manager-2] [INFO] [1747307485.688621706] [lifecycle_manager_sensors]: Running Nav2 LifecycleManager rcl preshutdown (lifecycle_manager_sensors)\n        [lifecycle_manager-2] [INFO] [1747307485.688835270] [lifecycle_manager_sensors]: Waiting for service sensor_container/imu_preprocessor_node/get_state...\n\nWhen I check the ROS service list, the lifecycle node services are prefixed with their namespaces, but not with the container name sensor_container. As a result, the lifecycle manager is unable to communicate with the nodes.\nros2 service list\n/imu_preprocessor_node/get_state\nNow sure how to resolve this?"], "question_code": ["    from launch import LaunchDescription\n    from launch.actions import DeclareLaunchArgument\n    from launch.substitutions import LaunchConfiguration\n    from launch_ros.actions import ComposableNodeContainer, Node\n    from launch_ros.descriptions import ComposableNode\n\n    def generate_launch_description():\n        use_sim_time = LaunchConfiguration('use_sim_time')\n\n        return LaunchDescription([\n            DeclareLaunchArgument(\n                'use_sim_time',\n                default_value='false',\n                description='Use simulation time if true'\n            ),\n\n            # Composable Node Container\n            ComposableNodeContainer(\n                name='sensor_container',\n                namespace='',\n                package='rclcpp_components',\n                executable='component_container',\n                output='screen',\n                composable_node_descriptions=[\n                    ComposableNode(\n                        package='imu_preprocessor',\n                        plugin='aide_imu_preprocessing::ImuPreprocessor',\n                        name='imu_preprocessor_node',\n                        parameters=[{'use_sim_time': use_sim_time}]\n                    )\n                ]\n            ),\n\n            # Lifecycle Manager to manage lifecycle state transitions\n            Node(\n                package='nav2_lifecycle_manager',\n                executable='lifecycle_manager',\n                name='lifecycle_manager_sensors',\n                output='screen',\n                parameters=[\n                    {'autostart': True},\n                    {'node_names': ['sensor_container/imu_preprocessor_node']},\n                    {'bond_timeout': 10.0},\n                    {'attempt_respawn_reconnection': True},\n                    {'retry_on_failure': True}\n                ]\n            )\n        ])\n", "        [INFO] [launch]: All log files can be found below /home/op/.ros/log/2025-05-15-12-11-22-609782-op-Dell-G16-7630-907199\n        [INFO] [launch]: Default logging verbosity is set to INFO\n        [INFO] [component_container-1]: process started with pid [907210]\n        [INFO] [lifecycle_manager-2]: process started with pid [907212]\n        [lifecycle_manager-2] [INFO] [1747307482.668951759] [lifecycle_manager_sensors]: Creating\n        [lifecycle_manager-2] [INFO] [1747307482.669757600] [lifecycle_manager_sensors]: Creating and initializing lifecycle service clients\n        [component_container-1] [INFO] [1747307482.909456536] [sensor_container]: Load Library: /home/op/imu_ws/install/imu_preprocessor/lib/libimu_preprocessor_component.so\n        [component_container-1] [INFO] [1747307482.915015197] [sensor_container]: Found class: rclcpp_components::NodeFactoryTemplate&lt;aide_imu_preprocessing::ImuPreprocessor&gt;\n        [component_container-1] [INFO] [1747307482.915051099] [sensor_container]: Instantiate class: rclcpp_components::NodeFactoryTemplate&lt;aide_imu_preprocessing::ImuPreprocessor&gt;\n        [component_container-1] [INFO] [1747307482.917613496] [imu_preprocessor_node]: Initializing IMU Preprocessor\n        [INFO] [launch_ros.actions.load_composable_nodes]: Loaded node '/imu_preprocessor_node' in container '/sensor_container'\n        [lifecycle_manager-2] [INFO] [1747307484.670338132] [lifecycle_manager_sensors]: Waiting for service sensor_container/imu_preprocessor_node/get_state...\n        ^C[WARNING] [launch]: user interrupted with ctrl-c (SIGINT)\n        ^C[WARNING] [launch]: user interrupted with ctrl-c (SIGINT) again, ignoring...\n        [lifecycle_manager-2] [INFO] [1747307485.688357535] [rclcpp]: signal_handler(signum=2)\n        [lifecycle_manager-2] [INFO] [1747307485.688621706] [lifecycle_manager_sensors]: Running Nav2 LifecycleManager rcl preshutdown (lifecycle_manager_sensors)\n        [lifecycle_manager-2] [INFO] [1747307485.688835270] [lifecycle_manager_sensors]: Waiting for service sensor_container/imu_preprocessor_node/get_state...\n", "ros2 service list", "/imu_preprocessor_node/get_state"], "quote": [], "url": "https://stackoverflow.com/questions/79623217/lifecycle-nodes-loaded-as-composable-nodes-in-a-container-are-unable-to-communic", "answer": [], "answer_code": []},
{"title": "Couldn't find executable named imu_tf_pose below /home/slam/catkin_ws/src/imu_path", "time": 1747273905, "post_content": ["I create a new package IMU_path\nthe following step is the create process.\nmkdir -p catkin_ws/src\ncd catkin_ws/src\ncatkin_create_pkg imu_path roscpp rospy tf nav_msgs\ncd ..\n\nput the imu_tf_pose.cpp in src/imu_path/src\nadd the following order in file src/imu_path/CMakeLists.txt:\nadd_executable(imu_tf_pose src/imu_tf_pose.cpp)\ntarget_link_libraries( imu_tf_pose ${catkin_LIBRARIES})# ${SERIAL_LIB}\n\nthen I catkin_make the file ,show this:\nBase path: /home/slam/catkin_ws\nSource space: /home/slam/catkin_ws/src\nBuild space: /home/slam/catkin_ws/build\nDevel space: /home/slam/catkin_ws/devel\nInstall space: /home/slam/catkin_ws/install\n####\n#### Running command: \"make cmake_check_build_system\" in \"/home/slam/catkin_ws/build\"\n####\n####\n#### Running command: \"make -j4 -l4\" in \"/home/slam/catkin_ws/build\"\n####\n[  1%] Built target benchmark_publisher\n[  6%] Built target camera_model\n[ 12%] Built target camera_models\n[ 18%] Built target Calibration\n[ 20%] Built target libGeographiccc\n[ 26%] Built target Calibrations\n[ 32%] Built target pose_graph\n[ 33%] Built target imu_tf\n[ 41%] Built target vins_lib\n[ 48%] Built target vins_estimator\n[ 48%] Built target std_msgs_generate_messages_cpp\n[ 48%] Built target geometry_msgs_generate_messages_cpp\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuAllData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuSlaveGnssData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuSensorData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuEulerAngle\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuMasterGnssData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuVelocity\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuLocation\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuCmdResp\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuGpsData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuInertialData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuUtcTime\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuGnssData\n[ 48%] Built target tf2_msgs_generate_messages_nodejs\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuNavData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuStatus\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuQuaternion\n[ 48%] Built target tf2_msgs_generate_messages_lisp\n[ 48%] Built target tf2_msgs_generate_messages_py\n[ 48%] Built target tf2_msgs_generate_messages_eus\n[ 48%] Built target tf2_msgs_generate_messages_cpp\n[ 48%] Built target actionlib_msgs_generate_messages_nodejs\n[ 48%] Built target actionlib_msgs_generate_messages_py\n[ 48%] Built target actionlib_msgs_generate_messages_lisp\n[ 48%] Built target actionlib_msgs_generate_messages_eus\n[ 48%] Built target std_msgs_generate_messages_nodejs\n[ 48%] Built target std_msgs_generate_messages_py\n[ 48%] Built target std_msgs_generate_messages_eus\n[ 48%] Built target rosgraph_msgs_generate_messages_py\n[ 48%] Built target rosgraph_msgs_generate_messages_nodejs\n[ 48%] Built target tf_generate_messages_cpp\n[ 48%] Built target sensor_msgs_generate_messages_cpp\n[ 48%] Built target std_msgs_generate_messages_lisp\n[ 48%] Built target sensor_msgs_generate_messages_eus\n[ 48%] Built target rosgraph_msgs_generate_messages_lisp\n[ 48%] Built target actionlib_msgs_generate_messages_cpp\n[ 48%] Built target rosgraph_msgs_generate_messages_eus\n[ 48%] Built target tf_generate_messages_eus\n[ 48%] Built target rosgraph_msgs_generate_messages_cpp\n[ 48%] Built target roscpp_generate_messages_lisp\n[ 48%] Built target tf_generate_messages_lisp\n[ 48%] Built target roscpp_generate_messages_py\n[ 48%] Built target geometry_msgs_generate_messages_nodejs\n[ 48%] Built target roscpp_generate_messages_nodejs\n[ 48%] Built target roscpp_generate_messages_eus\n[ 48%] Built target geometry_msgs_generate_messages_eus\n[ 48%] Built target tf_generate_messages_nodejs\n[ 48%] Built target geometry_msgs_generate_messages_lisp\n[ 48%] Built target geometry_msgs_generate_messages_py\n[ 48%] Built target actionlib_generate_messages_cpp\n[ 48%] Built target sensor_msgs_generate_messages_lisp\n[ 48%] Built target sensor_msgs_generate_messages_nodejs\n[ 48%] Built target roscpp_generate_messages_cpp\n[ 48%] Built target tf_generate_messages_py\n[ 48%] Built target actionlib_generate_messages_eus\n[ 48%] Built target actionlib_generate_messages_lisp\n[ 48%] Built target sensor_msgs_generate_messages_py\n[ 48%] Built target nav_msgs_generate_messages_eus\n[ 48%] Built target actionlib_generate_messages_py\n[ 48%] Built target actionlib_generate_messages_nodejs\n[ 48%] Built target nav_msgs_generate_messages_cpp\n[ 48%] Built target nav_msgs_generate_messages_lisp\n[ 48%] Built target nav_msgs_generate_messages_py\n[ 48%] Built target nav_msgs_generate_messages_nodejs\n[ 48%] Built target std_srvs_generate_messages_py\n[ 48%] Built target std_srvs_generate_messages_eus\n[ 48%] Built target dynamic_reconfigure_generate_messages_lisp\n[ 48%] Built target std_srvs_generate_messages_nodejs\n[ 48%] Built target std_srvs_generate_messages_cpp\n[ 48%] Built target dynamic_reconfigure_generate_messages_cpp\n[ 48%] Built target dynamic_reconfigure_generate_messages_py\n[ 48%] Built target dynamic_reconfigure_generate_messages_nodejs\n[ 48%] Built target dynamic_reconfigure_generate_messages_eus\n[ 48%] Built target dynamic_reconfigure_gencfg\n[ 48%] Built target std_srvs_generate_messages_lisp\n[ 49%] Generating dynamic reconfigure files from cfg/Yesense.cfg: /home/slam/catkin_ws/devel/include/yesense_imu/YesenseConfig.h /home/slam/catkin_ws/devel/lib/python2.7/dist-packages/yesense_imu/cfg/YesenseConfig.py\n[ 56%] Built target yesense_imu_generate_messages_nodejs\n[ 64%] Built target yesense_imu_generate_messages_eus\n[ 71%] Built target yesense_imu_generate_messages_py\n[ 77%] Built target yesense_imu_generate_messages_lisp\nGenerating reconfiguration files for YesenseNode in yesense_imu\n[ 78%] Built target ar_demo_node\nWrote header file in /home/slam/catkin_ws/devel/include/yesense_imu/YesenseNodeConfig.h\n[ 81%] Built target feature_tracker\n[ 82%] Built target global_fusion_node\n[ 89%] Built target vins_node\n[ 89%] Built target loop_fusion_node\n[ 90%] Built target kitti_odom_test\n[ 90%] Built target yesense_imu_gencfg\n[ 96%] Built target yesense_imu_generate_messages_cpp\n[ 97%] Built target kitti_gps_test\n[ 97%] Built target yesense_imu_generate_messages\n[ 97%] Built target yesense_imu_gencpp\n[100%] Built target yesense_imu_node\n\nthere is no imu_path node built target ,and how can i fixed it ?\nafter, I rosrun imu_path imu_tf_pose,it show [rosrun] Couldn't find executable named imu_tf_pose below /home/slam/catkin_ws/src/imu_path,"], "question_code": ["mkdir -p catkin_ws/src\ncd catkin_ws/src\ncatkin_create_pkg imu_path roscpp rospy tf nav_msgs\ncd ..\n", "add_executable(imu_tf_pose src/imu_tf_pose.cpp)\ntarget_link_libraries( imu_tf_pose ${catkin_LIBRARIES})# ${SERIAL_LIB}\n\nthen I catkin_make the file ,show this:\nBase path: /home/slam/catkin_ws\nSource space: /home/slam/catkin_ws/src\nBuild space: /home/slam/catkin_ws/build\nDevel space: /home/slam/catkin_ws/devel\nInstall space: /home/slam/catkin_ws/install\n####\n#### Running command: &quot;make cmake_check_build_system&quot; in &quot;/home/slam/catkin_ws/build&quot;\n####\n####\n#### Running command: &quot;make -j4 -l4&quot; in &quot;/home/slam/catkin_ws/build&quot;\n####\n[  1%] Built target benchmark_publisher\n[  6%] Built target camera_model\n[ 12%] Built target camera_models\n[ 18%] Built target Calibration\n[ 20%] Built target libGeographiccc\n[ 26%] Built target Calibrations\n[ 32%] Built target pose_graph\n[ 33%] Built target imu_tf\n[ 41%] Built target vins_lib\n[ 48%] Built target vins_estimator\n[ 48%] Built target std_msgs_generate_messages_cpp\n[ 48%] Built target geometry_msgs_generate_messages_cpp\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuAllData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuSlaveGnssData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuSensorData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuEulerAngle\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuMasterGnssData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuVelocity\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuLocation\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuCmdResp\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuGpsData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuInertialData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuUtcTime\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuGnssData\n[ 48%] Built target tf2_msgs_generate_messages_nodejs\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuNavData\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuStatus\n[ 48%] Built target _yesense_imu_generate_messages_check_deps_YesenseImuQuaternion\n[ 48%] Built target tf2_msgs_generate_messages_lisp\n[ 48%] Built target tf2_msgs_generate_messages_py\n[ 48%] Built target tf2_msgs_generate_messages_eus\n[ 48%] Built target tf2_msgs_generate_messages_cpp\n[ 48%] Built target actionlib_msgs_generate_messages_nodejs\n[ 48%] Built target actionlib_msgs_generate_messages_py\n[ 48%] Built target actionlib_msgs_generate_messages_lisp\n[ 48%] Built target actionlib_msgs_generate_messages_eus\n[ 48%] Built target std_msgs_generate_messages_nodejs\n[ 48%] Built target std_msgs_generate_messages_py\n[ 48%] Built target std_msgs_generate_messages_eus\n[ 48%] Built target rosgraph_msgs_generate_messages_py\n[ 48%] Built target rosgraph_msgs_generate_messages_nodejs\n[ 48%] Built target tf_generate_messages_cpp\n[ 48%] Built target sensor_msgs_generate_messages_cpp\n[ 48%] Built target std_msgs_generate_messages_lisp\n[ 48%] Built target sensor_msgs_generate_messages_eus\n[ 48%] Built target rosgraph_msgs_generate_messages_lisp\n[ 48%] Built target actionlib_msgs_generate_messages_cpp\n[ 48%] Built target rosgraph_msgs_generate_messages_eus\n[ 48%] Built target tf_generate_messages_eus\n[ 48%] Built target rosgraph_msgs_generate_messages_cpp\n[ 48%] Built target roscpp_generate_messages_lisp\n[ 48%] Built target tf_generate_messages_lisp\n[ 48%] Built target roscpp_generate_messages_py\n[ 48%] Built target geometry_msgs_generate_messages_nodejs\n[ 48%] Built target roscpp_generate_messages_nodejs\n[ 48%] Built target roscpp_generate_messages_eus\n[ 48%] Built target geometry_msgs_generate_messages_eus\n[ 48%] Built target tf_generate_messages_nodejs\n[ 48%] Built target geometry_msgs_generate_messages_lisp\n[ 48%] Built target geometry_msgs_generate_messages_py\n[ 48%] Built target actionlib_generate_messages_cpp\n[ 48%] Built target sensor_msgs_generate_messages_lisp\n[ 48%] Built target sensor_msgs_generate_messages_nodejs\n[ 48%] Built target roscpp_generate_messages_cpp\n[ 48%] Built target tf_generate_messages_py\n[ 48%] Built target actionlib_generate_messages_eus\n[ 48%] Built target actionlib_generate_messages_lisp\n[ 48%] Built target sensor_msgs_generate_messages_py\n[ 48%] Built target nav_msgs_generate_messages_eus\n[ 48%] Built target actionlib_generate_messages_py\n[ 48%] Built target actionlib_generate_messages_nodejs\n[ 48%] Built target nav_msgs_generate_messages_cpp\n[ 48%] Built target nav_msgs_generate_messages_lisp\n[ 48%] Built target nav_msgs_generate_messages_py\n[ 48%] Built target nav_msgs_generate_messages_nodejs\n[ 48%] Built target std_srvs_generate_messages_py\n[ 48%] Built target std_srvs_generate_messages_eus\n[ 48%] Built target dynamic_reconfigure_generate_messages_lisp\n[ 48%] Built target std_srvs_generate_messages_nodejs\n[ 48%] Built target std_srvs_generate_messages_cpp\n[ 48%] Built target dynamic_reconfigure_generate_messages_cpp\n[ 48%] Built target dynamic_reconfigure_generate_messages_py\n[ 48%] Built target dynamic_reconfigure_generate_messages_nodejs\n[ 48%] Built target dynamic_reconfigure_generate_messages_eus\n[ 48%] Built target dynamic_reconfigure_gencfg\n[ 48%] Built target std_srvs_generate_messages_lisp\n[ 49%] Generating dynamic reconfigure files from cfg/Yesense.cfg: /home/slam/catkin_ws/devel/include/yesense_imu/YesenseConfig.h /home/slam/catkin_ws/devel/lib/python2.7/dist-packages/yesense_imu/cfg/YesenseConfig.py\n[ 56%] Built target yesense_imu_generate_messages_nodejs\n[ 64%] Built target yesense_imu_generate_messages_eus\n[ 71%] Built target yesense_imu_generate_messages_py\n[ 77%] Built target yesense_imu_generate_messages_lisp\nGenerating reconfiguration files for YesenseNode in yesense_imu\n[ 78%] Built target ar_demo_node\nWrote header file in /home/slam/catkin_ws/devel/include/yesense_imu/YesenseNodeConfig.h\n[ 81%] Built target feature_tracker\n[ 82%] Built target global_fusion_node\n[ 89%] Built target vins_node\n[ 89%] Built target loop_fusion_node\n[ 90%] Built target kitti_odom_test\n[ 90%] Built target yesense_imu_gencfg\n[ 96%] Built target yesense_imu_generate_messages_cpp\n[ 97%] Built target kitti_gps_test\n[ 97%] Built target yesense_imu_generate_messages\n[ 97%] Built target yesense_imu_gencpp\n[100%] Built target yesense_imu_node\n", "rosrun imu_path imu_tf_pose"], "quote": [], "url": "https://stackoverflow.com/questions/79622509/couldnt-find-executable-named-imu-tf-pose-below-home-slam-catkin-ws-src-imu-pa", "answer": [], "answer_code": []},
{"title": "ESP32 micro-ROS RPLIDAR\u202fN10 + MPU6050 publishes /scan & /imu/data_raw but SLAM Toolbox shows \u201cNo map received\u201d", "time": 1746795198, "post_content": ["I\u2019m building a handheld mapping setup with:\n\nESP32\u2011WROVER\u2011E running micro\u2011ROS\n\nUART2 \u2192 RPLIDAR N10 \u2192 publishes /scan (sensor_msgs/LaserScan)\n\nI\u00b2C \u2192 MPU6050 \u2192 publishes /imu/data_raw (sensor_msgs/Imu)\n\nROS\u202f2 Humble on PC\n\nmicro_ros_agent (UDP4, port\u202f8888)\n\nimu_filter_madgwick \u2192 filters raw IMU\n\nrobot_localization EKF \u2192 publishes odom \u2192 base_link TF\n\nslam_toolbox \u2192 publishes map \u2192 odom TF\n\nstatic_transform_publishers for base_link \u2192 laser and base_link \u2192 imu_link\n\n\nProblem: In RViz, with Fixed Frame = map, I get \u201cNo map received\u201d and the Map display is empty. If I switch Fixed Frame to laser, I can see the live scans but still no map received\nesp32code:\n#include <WiFi.h>\n#include <HardwareSerial.h>\n#include <Wire.h>\n#include <MPU6050_tockn.h>  // Using MPU6050_tockn library\n\n#include <micro_ros_arduino.h>\n#include <rcl/rcl.h>\n#include <rclc/rclc.h>\n#include <sensor_msgs/msg/laser_scan.h>\n#include <sensor_msgs/msg/imu.h>\n#include <rosidl_runtime_c/primitives_sequence_functions.h>\n\n/* ---------------------- Wi-Fi + \u00b5ROS setup --------------------------- */\nconst char *SSID = \"4B\";\nconst char *PASS = \"88886666@feihe\";\nconst char *AGENT_IP   = \"192.168.1.192\";\nconst uint16_t AGENT_PORT = 8888;\n\n/* ---------------------- LiDAR UART ----------------------------------- */\nHardwareSerial lidar(2);           // UART2\n#define LIDAR_BAUD 230400\n#define LIDAR_RX   27\n#define LIDAR_TX   26\n\n/* ---------------------- I2C for MPU6050 ----------------------------- */\n#define IMU_SDA 21  // Adjust these pins according to your ESP32 wiring\n#define IMU_SCL 22  // Make sure these don't conflict with other used pins\nMPU6050 mpu(Wire);\nunsigned long last_imu_time = 0;\nconst int IMU_PUBLISH_INTERVAL = 10; // Publish IMU data every 10ms (100Hz)\n\n/* ---------------------- \u00b5ROS handles --------------------------------- */\nrclc_support_t  support;\nrcl_node_t      node;\nrcl_publisher_t laser_pub;\nrcl_publisher_t imu_pub;\n\n/* ROS messages (static storage) */\nsensor_msgs__msg__LaserScan scan;\nsensor_msgs__msg__Imu imu_msg;\nstatic float ranges[450];          // 0 \u2013 360\u00b0 @ 0.8\u00b0 \u2248 450 points\n\n/* ---------------------- helper macros -------------------------------- */\n#define RCCHECK(fn)  { rcl_ret_t rc = (fn); if (rc != RCL_RET_OK) { Serial.printf(\"uROS err %d @ %s:%d\\n\", rc,__FILE__,__LINE__); delay(1000); ESP.restart(); } }\n#define RCSOFTCHECK(fn)  { rcl_ret_t rc = (fn); if (rc != RCL_RET_OK) { Serial.printf(\"uROS soft-err %d @ %s:%d\\n\", rc,__FILE__,__LINE__); } }\n\n/* ---------------------- N10 packet parser state ---------------------- */\nenum { SEEK_HDR, LEN, PAYLOAD } st = SEEK_HDR;\nuint8_t pkt[58];\nuint8_t idx = 0;\nuint16_t p_idx = 0;            // ranges[] write-pointer\n\nvoid setup()\n{\n  Serial.begin(115200);\n  \n  /* I2C for IMU ---------------------------------------------------- */\n  Wire.begin(IMU_SDA, IMU_SCL);\n  mpu.begin();\n  mpu.calcGyroOffsets(true); // Calibrate gyro with output\n  Serial.println(\"MPU6050 initialized\");\n  \n  /* LiDAR UART ----------------------------------------------------- */\n  lidar.begin(LIDAR_BAUD, SERIAL_8N1, LIDAR_RX, LIDAR_TX);\n\n  /* Wi-Fi ------------------------------------------------------------- */\n  WiFi.begin(SSID, PASS);\n  while (WiFi.status() != WL_CONNECTED) { delay(200); Serial.print('.'); }\n  Serial.printf(\"\\nWi-Fi OK  %s\\n\", WiFi.localIP().toString().c_str());\n\n  /* micro-ROS transport ---------------------------------------------- */\n  set_microros_wifi_transports((char*)SSID,(char*)PASS,(char*)AGENT_IP,AGENT_PORT);\n  while (rmw_uros_ping_agent(1000,5)!=RMW_RET_OK) Serial.print('~');\n\n  /* micro-ROS init ---------------------------------------------------- */\n  rcl_allocator_t alloc = rcl_get_default_allocator();\n  RCCHECK( rclc_support_init(&support, 0, NULL, &alloc) );\n  RCCHECK( rclc_node_init_default(&node,\"n10_bridge\",\"\",&support) );\n  \n  // Initialize LiDAR publisher\n  RCCHECK( rclc_publisher_init_default(&laser_pub, &node,\n           ROSIDL_GET_MSG_TYPE_SUPPORT(sensor_msgs,msg,LaserScan),\"/scan\") );\n  \n  // Initialize IMU publisher\n  RCCHECK( rclc_publisher_init_default(&imu_pub, &node,\n           ROSIDL_GET_MSG_TYPE_SUPPORT(sensor_msgs,msg,Imu),\"/imu/data_raw\") );\n\n  /* LaserScan constant part ------------------------------------------ */\n  scan.header.frame_id.data = (char*)\"laser\";\n  scan.header.frame_id.size = 5;\n  scan.header.frame_id.capacity = 6;\n  scan.range_min = 0.05f;\n  scan.range_max = 12.0f;\n  rosidl_runtime_c__float__Sequence__init(&scan.ranges, 450);\n  \n  /* IMU message constant part ---------------------------------------- */\n  imu_msg.header.frame_id.data = (char*)\"imu_link\";\n  imu_msg.header.frame_id.size = 8;\n  imu_msg.header.frame_id.capacity = 9;\n  \n  // Initialize orientation covariance (unknown)\n  for (int i = 0; i < 9; i++) {\n    imu_msg.orientation_covariance[i] = -1.0;\n  }\n  \n  last_imu_time = millis();\n}\n\n/* helper to stamp builtin_interfaces/Time ----------------------------- */\nstatic inline void stamp_now(builtin_interfaces__msg__Time &t)\n{\n  // Just use zero for sec and increase nanosec each time\n  static uint32_t nano_count = 0;\n  nano_count += 10000000; // 10ms increment\n  \n  t.sec = nano_count / 1000000000ULL;\n  t.nanosec = nano_count % 1000000000ULL;\n}\n\n/* -------------------------------------------------------------------- */\nvoid loop()\n{\n  // Handle IMU publishing at regular intervals\n  unsigned long current_time = millis();\n  if (current_time - last_imu_time >= IMU_PUBLISH_INTERVAL) {\n    // Update IMU readings\n    mpu.update();\n    \n    // Populate IMU message\n    stamp_now(imu_msg.header.stamp);\n    \n    // Angular velocity in rad/sec (from deg/sec)\n    imu_msg.angular_velocity.x = mpu.getGyroX() * DEG_TO_RAD;\n    imu_msg.angular_velocity.y = mpu.getGyroY() * DEG_TO_RAD;\n    imu_msg.angular_velocity.z = mpu.getGyroZ() * DEG_TO_RAD;\n    \n    // Linear acceleration in m/s^2\n    imu_msg.linear_acceleration.x = mpu.getAccX() * 9.81;\n    imu_msg.linear_acceleration.y = mpu.getAccY() * 9.81;\n    imu_msg.linear_acceleration.z = mpu.getAccZ() * 9.81;\n    \n    // Publish IMU data\n    RCSOFTCHECK( rcl_publish(&imu_pub, &imu_msg, NULL) );\n    \n    last_imu_time = current_time;\n  }\n\n  // Process LiDAR data\n  while (lidar.available())\n  {\n    uint8_t b = lidar.read();\n\n    switch (st)\n    {\n      case SEEK_HDR:\n        if (idx==0 && b==0xA5) { pkt[idx++]=b; }\n        else if (idx==1 && b==0x5A) { pkt[idx++]=b; st=LEN; }\n        else idx=0;\n        break;\n\n      case LEN:\n        if (b!=58) { idx=0; st=SEEK_HDR; break; }\n        pkt[idx++]=b; st=PAYLOAD; break;\n\n      case PAYLOAD:\n        pkt[idx++]=b;\n        if (idx==58)\n        {\n          /* ----- decode one frame ---------------------------------- */\n          uint16_t start_angle = (pkt[5]<<8)|pkt[6];\n          uint16_t stop_angle  = (pkt[55]<<8)|pkt[56];\n\n          for (uint8_t i=0;i<16;i++) {\n            uint16_t dist_mm = (pkt[7+3*i]<<8)|pkt[8+3*i];\n            if (p_idx<450) ranges[p_idx++] = dist_mm * 0.001f;\n          }\n\n          /* when we wrapped \u2248360\u00b0, publish ------------------------- */\n          if (p_idx>=450) {\n            scan.angle_min = (start_angle/100.0f - (p_idx-1)*0.8f) * DEG_TO_RAD;\n            scan.angle_max = (stop_angle/100.0f) * DEG_TO_RAD;\n            scan.angle_increment = 0.8f * DEG_TO_RAD;\n            memcpy(scan.ranges.data, ranges, p_idx*sizeof(float));\n            scan.ranges.size = p_idx;\n\n            stamp_now(scan.header.stamp);\n            RCSOFTCHECK( rcl_publish(&laser_pub, &scan, NULL) );\n            p_idx = 0;\n          }\n\n          /* reset state machine ------------------------------------ */\n          idx=0; st=SEEK_HDR;\n        }\n        break;\n    }\n  }\n}\n\nslam launch file:\n# ~/lslidar_ws/src/your_package/launch/slam_with_imu.launch.py\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import ExecuteProcess\nimport os\n\ndef generate_launch_description():\n    # Paths to config files\n    slam_params_path = os.path.join(os.path.expanduser('~'), 'lslidar_ws', 'src', 'slam_params.yaml')\n    ekf_config_path = os.path.join(os.path.expanduser('~'), 'lslidar_ws', 'src', 'ekf_config.yaml')\n    \n    # IMU filter node (processes raw IMU data)\n    imu_filter_node = Node(\n        package='imu_filter_madgwick',\n        executable='imu_filter_madgwick_node',\n        name='imu_filter',\n        parameters=[{\n            'use_mag': False,\n            'publish_tf': False,\n            'world_frame': 'enu',\n            'gain': 0.1,\n            'use_sim_time': False\n        }],\n        remappings=[\n            ('imu/data_raw', 'imu/data_raw'),\n            ('imu/data', 'imu/data')\n        ]\n    )\n    \n    # Robot localization node (publishes odom \u2192 base_link transform)\n    ekf_node = Node(\n        package='robot_localization',\n        executable='ekf_node',\n        name='ekf_filter_node',\n        parameters=[ekf_config_path, {'use_sim_time': False}]\n    )\n    \n    # SLAM Toolbox (publishes map \u2192 odom transform)\n    slam_node = Node(\n        package='slam_toolbox',\n        executable='async_slam_toolbox_node',\n        name='slam_toolbox',\n        parameters=[slam_params_path, {'use_sim_time': False}]\n    )\n    \n    # Static transforms for sensors relative to base_link\n    static_tf_laser = Node(\n        package='tf2_ros',\n        executable='static_transform_publisher',\n        name='static_tf_laser',\n        arguments=['0', '0', '0', '0', '0', '0', 'base_link', 'laser']\n    )\n    \n    static_tf_imu = Node(\n        package='tf2_ros',\n        executable='static_transform_publisher',\n        name='static_tf_imu',\n        arguments=['0', '0', '0', '0', '0', '0', 'base_link', 'imu_link']\n    )\n    \n    # micro-ROS agent\n    micro_ros_agent = ExecuteProcess(\n        cmd=['ros2', 'run', 'micro_ros_agent', 'micro_ros_agent', 'udp4', '--port', '8888'],\n        output='screen'\n    )\n    \n    return LaunchDescription([\n        micro_ros_agent,\n        static_tf_laser,\n        static_tf_imu,\n        imu_filter_node,\n        ekf_node,\n        slam_node\n    ])\n\nWhat I\u2019ve tried:\n\nVerified /scan and /imu/data_raw via ros2 topic echo\n\nChecked TF tree with view_frames.py \u2014 map \u2192 odom \u2192 base_link \u2192 laser looks present\n\nRemapped topics and parameters, but map still doesn\u2019t appear in RViz under map\n\nChecked TF tree with view_frames.py \u2014 map \u2192 odom \u2192 base_link \u2192 laser looks present\n\nRemapped topics and parameters, but map still doesn\u2019t appear in RViz under map\n\n\nparamsfile:\nsolver_plugin: solver_plugins::CeresSolver\n    ceres_linear_solver: SPARSE_NORMAL_CHOLESKY\n    ceres_preconditioner: SCHUR_JACOBI\n    ceres_trust_strategy: LEVENBERG_MARQUARDT\n    ceres_dogleg_type: TRADITIONAL_DOGLEG\n    ceres_loss_function: None\n    mode: mapping\n    map_frame: map\n    odom_frame: odom\n    base_frame: base_link\n    scan_topic: /scan\n    range_data_count: 450\n    min_laser_range: 0.05\n    max_laser_range: 12.0\n    throttle_scans: 1\n    use_sim_time: false\n    use_scan_matching: true\n    use_scan_barycenter: true\n    publish_tf: true\n    transform_timeout: 0.5"], "question_code": ["#include &lt;WiFi.h&gt;\n#include &lt;HardwareSerial.h&gt;\n#include &lt;Wire.h&gt;\n#include &lt;MPU6050_tockn.h&gt;  // Using MPU6050_tockn library\n\n#include &lt;micro_ros_arduino.h&gt;\n#include &lt;rcl/rcl.h&gt;\n#include &lt;rclc/rclc.h&gt;\n#include &lt;sensor_msgs/msg/laser_scan.h&gt;\n#include &lt;sensor_msgs/msg/imu.h&gt;\n#include &lt;rosidl_runtime_c/primitives_sequence_functions.h&gt;\n\n/* ---------------------- Wi-Fi + \u00b5ROS setup --------------------------- */\nconst char *SSID = &quot;4B&quot;;\nconst char *PASS = &quot;88886666@feihe&quot;;\nconst char *AGENT_IP   = &quot;192.168.1.192&quot;;\nconst uint16_t AGENT_PORT = 8888;\n\n/* ---------------------- LiDAR UART ----------------------------------- */\nHardwareSerial lidar(2);           // UART2\n#define LIDAR_BAUD 230400\n#define LIDAR_RX   27\n#define LIDAR_TX   26\n\n/* ---------------------- I2C for MPU6050 ----------------------------- */\n#define IMU_SDA 21  // Adjust these pins according to your ESP32 wiring\n#define IMU_SCL 22  // Make sure these don't conflict with other used pins\nMPU6050 mpu(Wire);\nunsigned long last_imu_time = 0;\nconst int IMU_PUBLISH_INTERVAL = 10; // Publish IMU data every 10ms (100Hz)\n\n/* ---------------------- \u00b5ROS handles --------------------------------- */\nrclc_support_t  support;\nrcl_node_t      node;\nrcl_publisher_t laser_pub;\nrcl_publisher_t imu_pub;\n\n/* ROS messages (static storage) */\nsensor_msgs__msg__LaserScan scan;\nsensor_msgs__msg__Imu imu_msg;\nstatic float ranges[450];          // 0 \u2013 360\u00b0 @ 0.8\u00b0 \u2248 450 points\n\n/* ---------------------- helper macros -------------------------------- */\n#define RCCHECK(fn)  { rcl_ret_t rc = (fn); if (rc != RCL_RET_OK) { Serial.printf(&quot;uROS err %d @ %s:%d\\n&quot;, rc,__FILE__,__LINE__); delay(1000); ESP.restart(); } }\n#define RCSOFTCHECK(fn)  { rcl_ret_t rc = (fn); if (rc != RCL_RET_OK) { Serial.printf(&quot;uROS soft-err %d @ %s:%d\\n&quot;, rc,__FILE__,__LINE__); } }\n\n/* ---------------------- N10 packet parser state ---------------------- */\nenum { SEEK_HDR, LEN, PAYLOAD } st = SEEK_HDR;\nuint8_t pkt[58];\nuint8_t idx = 0;\nuint16_t p_idx = 0;            // ranges[] write-pointer\n\nvoid setup()\n{\n  Serial.begin(115200);\n  \n  /* I2C for IMU ---------------------------------------------------- */\n  Wire.begin(IMU_SDA, IMU_SCL);\n  mpu.begin();\n  mpu.calcGyroOffsets(true); // Calibrate gyro with output\n  Serial.println(&quot;MPU6050 initialized&quot;);\n  \n  /* LiDAR UART ----------------------------------------------------- */\n  lidar.begin(LIDAR_BAUD, SERIAL_8N1, LIDAR_RX, LIDAR_TX);\n\n  /* Wi-Fi ------------------------------------------------------------- */\n  WiFi.begin(SSID, PASS);\n  while (WiFi.status() != WL_CONNECTED) { delay(200); Serial.print('.'); }\n  Serial.printf(&quot;\\nWi-Fi OK  %s\\n&quot;, WiFi.localIP().toString().c_str());\n\n  /* micro-ROS transport ---------------------------------------------- */\n  set_microros_wifi_transports((char*)SSID,(char*)PASS,(char*)AGENT_IP,AGENT_PORT);\n  while (rmw_uros_ping_agent(1000,5)!=RMW_RET_OK) Serial.print('~');\n\n  /* micro-ROS init ---------------------------------------------------- */\n  rcl_allocator_t alloc = rcl_get_default_allocator();\n  RCCHECK( rclc_support_init(&amp;support, 0, NULL, &amp;alloc) );\n  RCCHECK( rclc_node_init_default(&amp;node,&quot;n10_bridge&quot;,&quot;&quot;,&amp;support) );\n  \n  // Initialize LiDAR publisher\n  RCCHECK( rclc_publisher_init_default(&amp;laser_pub, &amp;node,\n           ROSIDL_GET_MSG_TYPE_SUPPORT(sensor_msgs,msg,LaserScan),&quot;/scan&quot;) );\n  \n  // Initialize IMU publisher\n  RCCHECK( rclc_publisher_init_default(&amp;imu_pub, &amp;node,\n           ROSIDL_GET_MSG_TYPE_SUPPORT(sensor_msgs,msg,Imu),&quot;/imu/data_raw&quot;) );\n\n  /* LaserScan constant part ------------------------------------------ */\n  scan.header.frame_id.data = (char*)&quot;laser&quot;;\n  scan.header.frame_id.size = 5;\n  scan.header.frame_id.capacity = 6;\n  scan.range_min = 0.05f;\n  scan.range_max = 12.0f;\n  rosidl_runtime_c__float__Sequence__init(&amp;scan.ranges, 450);\n  \n  /* IMU message constant part ---------------------------------------- */\n  imu_msg.header.frame_id.data = (char*)&quot;imu_link&quot;;\n  imu_msg.header.frame_id.size = 8;\n  imu_msg.header.frame_id.capacity = 9;\n  \n  // Initialize orientation covariance (unknown)\n  for (int i = 0; i &lt; 9; i++) {\n    imu_msg.orientation_covariance[i] = -1.0;\n  }\n  \n  last_imu_time = millis();\n}\n\n/* helper to stamp builtin_interfaces/Time ----------------------------- */\nstatic inline void stamp_now(builtin_interfaces__msg__Time &amp;t)\n{\n  // Just use zero for sec and increase nanosec each time\n  static uint32_t nano_count = 0;\n  nano_count += 10000000; // 10ms increment\n  \n  t.sec = nano_count / 1000000000ULL;\n  t.nanosec = nano_count % 1000000000ULL;\n}\n\n/* -------------------------------------------------------------------- */\nvoid loop()\n{\n  // Handle IMU publishing at regular intervals\n  unsigned long current_time = millis();\n  if (current_time - last_imu_time &gt;= IMU_PUBLISH_INTERVAL) {\n    // Update IMU readings\n    mpu.update();\n    \n    // Populate IMU message\n    stamp_now(imu_msg.header.stamp);\n    \n    // Angular velocity in rad/sec (from deg/sec)\n    imu_msg.angular_velocity.x = mpu.getGyroX() * DEG_TO_RAD;\n    imu_msg.angular_velocity.y = mpu.getGyroY() * DEG_TO_RAD;\n    imu_msg.angular_velocity.z = mpu.getGyroZ() * DEG_TO_RAD;\n    \n    // Linear acceleration in m/s^2\n    imu_msg.linear_acceleration.x = mpu.getAccX() * 9.81;\n    imu_msg.linear_acceleration.y = mpu.getAccY() * 9.81;\n    imu_msg.linear_acceleration.z = mpu.getAccZ() * 9.81;\n    \n    // Publish IMU data\n    RCSOFTCHECK( rcl_publish(&amp;imu_pub, &amp;imu_msg, NULL) );\n    \n    last_imu_time = current_time;\n  }\n\n  // Process LiDAR data\n  while (lidar.available())\n  {\n    uint8_t b = lidar.read();\n\n    switch (st)\n    {\n      case SEEK_HDR:\n        if (idx==0 &amp;&amp; b==0xA5) { pkt[idx++]=b; }\n        else if (idx==1 &amp;&amp; b==0x5A) { pkt[idx++]=b; st=LEN; }\n        else idx=0;\n        break;\n\n      case LEN:\n        if (b!=58) { idx=0; st=SEEK_HDR; break; }\n        pkt[idx++]=b; st=PAYLOAD; break;\n\n      case PAYLOAD:\n        pkt[idx++]=b;\n        if (idx==58)\n        {\n          /* ----- decode one frame ---------------------------------- */\n          uint16_t start_angle = (pkt[5]&lt;&lt;8)|pkt[6];\n          uint16_t stop_angle  = (pkt[55]&lt;&lt;8)|pkt[56];\n\n          for (uint8_t i=0;i&lt;16;i++) {\n            uint16_t dist_mm = (pkt[7+3*i]&lt;&lt;8)|pkt[8+3*i];\n            if (p_idx&lt;450) ranges[p_idx++] = dist_mm * 0.001f;\n          }\n\n          /* when we wrapped \u2248360\u00b0, publish ------------------------- */\n          if (p_idx&gt;=450) {\n            scan.angle_min = (start_angle/100.0f - (p_idx-1)*0.8f) * DEG_TO_RAD;\n            scan.angle_max = (stop_angle/100.0f) * DEG_TO_RAD;\n            scan.angle_increment = 0.8f * DEG_TO_RAD;\n            memcpy(scan.ranges.data, ranges, p_idx*sizeof(float));\n            scan.ranges.size = p_idx;\n\n            stamp_now(scan.header.stamp);\n            RCSOFTCHECK( rcl_publish(&amp;laser_pub, &amp;scan, NULL) );\n            p_idx = 0;\n          }\n\n          /* reset state machine ------------------------------------ */\n          idx=0; st=SEEK_HDR;\n        }\n        break;\n    }\n  }\n}\n", "# ~/lslidar_ws/src/your_package/launch/slam_with_imu.launch.py\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import ExecuteProcess\nimport os\n\ndef generate_launch_description():\n    # Paths to config files\n    slam_params_path = os.path.join(os.path.expanduser('~'), 'lslidar_ws', 'src', 'slam_params.yaml')\n    ekf_config_path = os.path.join(os.path.expanduser('~'), 'lslidar_ws', 'src', 'ekf_config.yaml')\n    \n    # IMU filter node (processes raw IMU data)\n    imu_filter_node = Node(\n        package='imu_filter_madgwick',\n        executable='imu_filter_madgwick_node',\n        name='imu_filter',\n        parameters=[{\n            'use_mag': False,\n            'publish_tf': False,\n            'world_frame': 'enu',\n            'gain': 0.1,\n            'use_sim_time': False\n        }],\n        remappings=[\n            ('imu/data_raw', 'imu/data_raw'),\n            ('imu/data', 'imu/data')\n        ]\n    )\n    \n    # Robot localization node (publishes odom \u2192 base_link transform)\n    ekf_node = Node(\n        package='robot_localization',\n        executable='ekf_node',\n        name='ekf_filter_node',\n        parameters=[ekf_config_path, {'use_sim_time': False}]\n    )\n    \n    # SLAM Toolbox (publishes map \u2192 odom transform)\n    slam_node = Node(\n        package='slam_toolbox',\n        executable='async_slam_toolbox_node',\n        name='slam_toolbox',\n        parameters=[slam_params_path, {'use_sim_time': False}]\n    )\n    \n    # Static transforms for sensors relative to base_link\n    static_tf_laser = Node(\n        package='tf2_ros',\n        executable='static_transform_publisher',\n        name='static_tf_laser',\n        arguments=['0', '0', '0', '0', '0', '0', 'base_link', 'laser']\n    )\n    \n    static_tf_imu = Node(\n        package='tf2_ros',\n        executable='static_transform_publisher',\n        name='static_tf_imu',\n        arguments=['0', '0', '0', '0', '0', '0', 'base_link', 'imu_link']\n    )\n    \n    # micro-ROS agent\n    micro_ros_agent = ExecuteProcess(\n        cmd=['ros2', 'run', 'micro_ros_agent', 'micro_ros_agent', 'udp4', '--port', '8888'],\n        output='screen'\n    )\n    \n    return LaunchDescription([\n        micro_ros_agent,\n        static_tf_laser,\n        static_tf_imu,\n        imu_filter_node,\n        ekf_node,\n        slam_node\n    ])\n", "solver_plugin: solver_plugins::CeresSolver\n    ceres_linear_solver: SPARSE_NORMAL_CHOLESKY\n    ceres_preconditioner: SCHUR_JACOBI\n    ceres_trust_strategy: LEVENBERG_MARQUARDT\n    ceres_dogleg_type: TRADITIONAL_DOGLEG\n    ceres_loss_function: None\n    mode: mapping\n    map_frame: map\n    odom_frame: odom\n    base_frame: base_link\n    scan_topic: /scan\n    range_data_count: 450\n    min_laser_range: 0.05\n    max_laser_range: 12.0\n    throttle_scans: 1\n    use_sim_time: false\n    use_scan_matching: true\n    use_scan_barycenter: true\n    publish_tf: true\n    transform_timeout: 0.5\n"], "quote": [], "url": "https://stackoverflow.com/questions/79614155/esp32-micro-ros-rplidar-n10-mpu6050-publishes-scan-imu-data-raw-but-slam-t", "answer": [], "answer_code": []},
{"title": "Pointcloud not aligned with with map", "time": 1746714013, "post_content": ["i am new to robotics and i want to build a robot that has a lidar sensor, depth camera and which detects traversable soft objects (using yolo) and extracts only the depth image of the detected objects from the image (fusionvision) and uses the image to update the costmap of the robot. But when i try to visualize the poincloud of the detected object, the pointcloud is not aligned with the map (the detection is wrong, since it is detecting walls, which i don't want, but it is not the issue).\nHere is the code for the node that does this\n\nimport cv2\nimport struct\nimport torch\nimport random\nimport time\nimport sys\nimport numpy as np\n# open3d for generating point cloud\nimport open3d as o3d\n\nimport rclpy\nfrom rclpy.node import Node\nfrom cv_bridge import CvBridge \nfrom message_filters import ApproximateTimeSynchronizer, Subscriber \nfrom rclpy.qos import qos_profile_sensor_data \nfrom rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy, DurabilityPolicy\n\n# utils for performing yolo inference\nfrom fusionvision import utils\n\n# fastsam import for segmentation \nfrom fusionvision.fastsam import FastSAM, FastSAMPrompt\n\nfrom ultralytics import YOLO\nfrom ultralytics.yolo.utils.plotting import Annotator \n\n# Added pointcloud2 message type and header to create PointCloud2 message\nfrom sensor_msgs.msg import Image, CameraInfo, PointCloud2, PointField\nfrom std_msgs.msg import Header\n\nfrom std_srvs.srv import SetBool \n\n# imports for fixing weights only true issue\nfrom torch.nn import Sequential, Conv2d, BatchNorm2d, SiLU, ModuleList, MaxPool2d, Upsample, ConvTranspose2d\nfrom ultralytics.nn.modules.conv import Conv, Concat\nfrom ultralytics.nn.modules.block import C2f, Bottleneck, SPPF, DFL, Proto\nfrom ultralytics.nn.modules.head import Detect, Segment\nfrom ultralytics.nn.tasks import SegmentationModel\nfrom ultralytics.yolo.utils import IterableSimpleNamespace\nfrom ultralytics.yolo.utils.loss import v8DetectionLoss \nfrom torch.nn.modules.loss import BCEWithLogitsLoss\nfrom ultralytics.yolo.utils.tal import TaskAlignedAssigner \nfrom ultralytics.yolo.utils.loss import BboxLoss \nfrom ultralytics.nn.tasks import DetectionModel\n\nclass FusionVisionNode(Node):\n    def __init__(self) -> Node:\n        super().__init__(\"fusionvision_node\")\n\n        #self.declare_parameter(\"yolo_model_path\", \"/home/a/Documents/visual-traversability-task/visual-traversability-using-nav2-rgb/src/fusionvision/models/yolo_model.pt\")\n        self.declare_parameter(\"yolo_model_path\", \"/home/a/Documents/visual-traversability-task/visual-traversability-using-nav2-rgb/src/fusionvision/models/annotated-small-objects-mode_v3.pt\")\n        self.declare_parameter(\"fastsam_model_path\", \"/home/a/Documents/visual-traversability-task/visual-traversability-using-nav2-rgb/src/fusionvision/models/FastSAM-s.pt\")\n        self.declare_parameter(\"device\", \"cpu\")\n        self.declare_parameter(\"frequency\", 2.0)\n        self.declare_parameter(\"queue_size\", 30)\n        self.declare_parameter(\"delay_threshold\", 0.3)\n        self.declare_parameter(\"NN_threshold\", 0.5)\n        self.declare_parameter(\"enable\", True)\n        self.declare_parameter(\"debug\", True)\n        # confidence_threshold for the yolo and fastsam model\n        self.declare_parameter(\"confidence_threshold\", 0.5)\n        self.declare_parameter(\"iou\", 0.9)\n\n        yolo_model_path               = self.get_parameter(\"yolo_model_path\").get_parameter_value().string_value\n        fastsam_model_path            = self.get_parameter(\"fastsam_model_path\").get_parameter_value().string_value\n        device                        = self.get_parameter(\"device\").get_parameter_value().string_value\n        frequency                     = self.get_parameter(\"frequency\").get_parameter_value().double_value\n        queue_size                    = self.get_parameter(\"queue_size\").get_parameter_value().integer_value\n        delay_threshold               = self.get_parameter(\"delay_threshold\").get_parameter_value().double_value\n        self.NN_threshold             = self.get_parameter(\"NN_threshold\").get_parameter_value().double_value\n        self.enable                   = self.get_parameter(\"enable\").get_parameter_value().bool_value\n        self.debug                    = self.get_parameter(\"debug\").get_parameter_value().bool_value\n        # confidence_threshold for the yolo and fastsam model\n        self.confidence_threshold     = self.get_parameter(\"confidence_threshold\").get_parameter_value().double_value\n        self.iou                      = self.get_parameter(\"iou\").get_parameter_value().double_value\n\n        clock_type = self.get_clock().clock_type\n        self.get_logger().info(f\"Using clock type: {clock_type.name} (ROS_TIME=0, SYSTEM_TIME=1, STEADY_TIME=2)\")\n\n        # mark all these classes as safe inorder to load the model from file\n        safe_classes = [\n            DetectionModel,Sequential,Conv,Conv2d,BatchNorm2d,SiLU,ModuleList,\n            C2f,Bottleneck,SPPF,MaxPool2d,Upsample,Concat,Detect,DFL,SegmentationModel, \n            Segment,Proto,ConvTranspose2d,getattr,IterableSimpleNamespace,v8DetectionLoss,\n            BCEWithLogitsLoss,TaskAlignedAssigner,BboxLoss \n        ]\n\n        torch.serialization.add_safe_globals(safe_classes)\n        \n        self.cv_bridge = CvBridge()     \n        self.yolo_model = YOLO(yolo_model_path)   \n        self.fastsam_model = FastSAM(fastsam_model_path)   \n        self.yolo_model.to(device)           \n        self.pcd = o3d.geometry.PointCloud()\n\n        # Transformation matrix for flipping the point cloud upside down and left to right\n        self.flip_matrix = np.array([[1, 0, 0, 0],\n                            [0, -1, 0, 0],\n                            [0, 0, -1, 0],\n                            [0, 0, 0, 1]])\n\n        qos_profile = QoSProfile(\n            reliability=ReliabilityPolicy.RELIABLE,\n            history=HistoryPolicy.KEEP_LAST,\n            depth=1, # Keep only the latest message\n            durability=DurabilityPolicy.TRANSIENT_LOCAL # Match publisher, often VOLATILE\n        )\n\n\n        # Create a publisher for point cloud and camera info\n        #self._res_pub   = self.create_publisher(PointCloud2,\"/depth/pointcloud2\" , 10)\n        #self._info_pub  = self.create_publisher(CameraInfo, \"/image_seg/info\", 10)\n        self._res_pub   = self.create_publisher(PointCloud2,\"/depth/pointcloud2\" , qos_profile)\n        self._info_pub  = self.create_publisher(CameraInfo, \"/image_seg/info\", qos_profile)\n        self._color_sub = Subscriber(self, Image, \"/camera_depth_sensor/image_raw\")\n        self._depth_sub = Subscriber(self, Image, \"/camera_depth_sensor/depth/image_raw\")\n        self._info_sub  = Subscriber(self, CameraInfo, \"/camera_depth_sensor/depth/camera_info\")\n\n        # From ROS 2 message_filters, to synchronize the topics\n        self._time_sync = ApproximateTimeSynchronizer(\n            [self._color_sub, self._depth_sub, self._info_sub ], \n            queue_size,\n            delay_threshold, \n        )\n\n        self._time_sync.registerCallback(self.image_cb)\n        self._srv = self.create_service(SetBool, \"enable\", self.enable_cb)\n        self._timer_expired = True\n        self._timer = self.create_timer(1/frequency, self.timer_callback)\n\n        self.get_logger().info(\"fastsam node initialized\")\n\n\n    def enable_cb(self, req: SetBool.Request, res: SetBool.Response) -> SetBool.Response:\n        self.enable = req.data\n        res.success = True\n        return res\n\n    def timer_callback(self) -> None:\n        self._timer_expired = True\n\n    def image_cb(self, color: Image, depth: Image, info: CameraInfo) -> None:\n\n\n        if self.enable and self._timer_expired:\n            self._timer_expired = False\n            color_img = self.cv_bridge.imgmsg_to_cv2(color)\n            depth_img = self.cv_bridge.imgmsg_to_cv2(depth)\n\n            detections, predicted_boxes = utils.perform_yolo_inference(color_img, self.yolo_model, confidence_threshold=self.confidence_threshold)\n            \n            bounding_box_lines = []\n\n            if len(predicted_boxes) > 0:\n                bounding_boxes = [list(map(int, box[:4])) for box in predicted_boxes]\n\n                fastsam_results = self.fastsam_model(color_img, device='cpu', retina_masks=True, imgsz=640, conf=self.confidence_threshold,\n                                                iou=self.iou) \n\n                #self.get_logger().info(f'fastsam_results: {fastsam_results}')\n                #self.get_logger().info(f'color image: {color_img}')\n\n                if fastsam_results:\n                    prompt_process = FastSAMPrompt(color_img, fastsam_results, device='cpu') # changed device from cuda to cpu\n                    ann = prompt_process.box_prompt(bboxes=bounding_boxes) \n                    img_with_annotations = prompt_process.plot_to_result(annotations=ann)\n                    #cv2.imshow('FastSAM Inference', img_with_annotations)\n\n                    #self.get_logger().info(f'ann: {ann}')\n                    \n                    ann_mask = np.array(ann).astype(np.uint8) \n                    ann_mask_overlay = np.sum(ann_mask, axis=0) \n\n                    #ann_mask_overlay_normalized = (ann_mask_overlay / np.max(ann_mask_overlay) * 255).astype(np.uint8)\n\n                    #cv2.imshow('Annotation Mask', ann_mask_overlay_normalized)\n                    ann_mask_overlay_uint8 = ann_mask_overlay.astype(np.uint8)\n\n                    eroded_ann_mask = cv2.erode(ann_mask_overlay_uint8, kernel=np.ones((20, 20), np.uint8), iterations=1) \n                    \n                    isolated_depth = np.where((eroded_ann_mask > 0) & (depth_img < 1000), depth_img, np.nan) \n                    #isolated_depth = np.where((eroded_ann_mask > 0) & (depth_img < 1), depth_img, np.nan) \n                    non_nan_points = np.argwhere(~np.isnan(isolated_depth)) \n                    non_nan_depth_values = isolated_depth[non_nan_points[:, 0], non_nan_points[:, 1]] \n\n                   \n\n                    self.get_logger().info('---------------------------------------------------------------')\n                    self.get_logger().info(f'shape of the non nan depth value: {non_nan_depth_values.shape}')\n                    self.get_logger().info('---------------------------------------------------------------')\n                                        \n                    depth_scale = 1\n   \n                    #self.get_logger().info(f'isolated_depth: {isolated_depth}')\n                    #self.get_logger().info(f'non nan points: {non_nan_points}')\n                    self.get_logger().info(f'non nan depth values: {non_nan_depth_values}')\n                    \n                    self.pcd.points = o3d.utility.Vector3dVector(\n                        np.column_stack([non_nan_points[:, 1], non_nan_points[:, 0], non_nan_depth_values * depth_scale])\n                    )\n\n                    pcd_outlier = self.pcd.voxel_down_sample(voxel_size=2)\n                    denoised_pcd, _ = pcd_outlier.remove_statistical_outlier(nb_neighbors=300,\n                                                                            std_ratio=2.0)\n\n                    \n\n                    denoised_pcd.transform(self.flip_matrix)\n\n                    pointcloud_msg = PointCloud2()\n                    pointcloud_msg.header = Header()\n\n                    #current_ros_time = self.get_clock().now()\n                    \n                    pointcloud_msg.header.frame_id = \"camera_depth_optical_frame\"\n                    pointcloud_msg.header.stamp = depth.header.stamp\n                    #pointcloud_msg.header.stamp = current_ros_time.to_msg() \n                    \n                    points = np.asarray(denoised_pcd.points)\n\n                    colors = np.asarray(denoised_pcd.colors) if denoised_pcd.has_colors() else None\n                \n                    # Define fields based on whether colors are present\n                    fields = [\n                        PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),\n                        PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1),\n                        PointField(name='z', offset=8, datatype=PointField.FLOAT32, count=1)\n                    ]\n                    if colors is not None and colors.shape[1] == 3:\n                        fields.extend([\n                            PointField(name='rgb', offset=12, datatype=PointField.FLOAT32, count=1)\n                        ])\n                \n                    pointcloud_msg.fields = fields\n                \n                    pointcloud_msg.height = 1  \n                    pointcloud_msg.width = points.shape[0]\n                \n                    pointcloud_msg.point_step = 12 + (12 if colors is not None and colors.shape[1] == 3 else 0)\n                \n                    pointcloud_msg.row_step = pointcloud_msg.point_step * pointcloud_msg.width\n                \n                    data = []\n                    for i in range(points.shape[0]):\n                        data.extend(struct.pack('<fff', points[i, 0], points[i, 1], points[i, 2]))\n                        if colors is not None and colors.shape[1] == 3:\n                            rgb = colors[i]\n                            # Combine RGB into a single float (as often done in ROS PointCloud2)\n                            rgb_packed = struct.unpack('f', struct.pack('BBB', int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255)))[0]\n                            data.extend(struct.pack('<f', rgb_packed))\n                \n                    pointcloud_msg.data = bytes(data)\n                    pointcloud_msg.is_dense = True \n                    \n                    self._res_pub.publish(pointcloud_msg)\n\ndef main():\n   try:\n       rclpy.init()\n       node = FusionVisionNode()\n       rclpy.spin(node)\n   except KeyboardInterrupt:\n       node.get_logger().info('Ctrl+C received - exiting...')\n       sys.exit(0)\n   finally:\n       node.get_logger().info('ROS node FusionVisionNode shutdown')\n       rclpy.shutdown()\n       cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main() \n\n\ni checked the transform of the depth camera (when i try to visualize the actual pointcloud published by the camera, it is visualizing correctly on the map). What can cause this issue? Any help would be appreciated\ninitially i thought the issue was due to a transform issue, but upon close inspection, the pointcloud publishes by the camera displays correctly which suggest the issue is with the processing"], "question_code": ["\nimport cv2\nimport struct\nimport torch\nimport random\nimport time\nimport sys\nimport numpy as np\n# open3d for generating point cloud\nimport open3d as o3d\n\nimport rclpy\nfrom rclpy.node import Node\nfrom cv_bridge import CvBridge \nfrom message_filters import ApproximateTimeSynchronizer, Subscriber \nfrom rclpy.qos import qos_profile_sensor_data \nfrom rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy, DurabilityPolicy\n\n# utils for performing yolo inference\nfrom fusionvision import utils\n\n# fastsam import for segmentation \nfrom fusionvision.fastsam import FastSAM, FastSAMPrompt\n\nfrom ultralytics import YOLO\nfrom ultralytics.yolo.utils.plotting import Annotator \n\n# Added pointcloud2 message type and header to create PointCloud2 message\nfrom sensor_msgs.msg import Image, CameraInfo, PointCloud2, PointField\nfrom std_msgs.msg import Header\n\nfrom std_srvs.srv import SetBool \n\n# imports for fixing weights only true issue\nfrom torch.nn import Sequential, Conv2d, BatchNorm2d, SiLU, ModuleList, MaxPool2d, Upsample, ConvTranspose2d\nfrom ultralytics.nn.modules.conv import Conv, Concat\nfrom ultralytics.nn.modules.block import C2f, Bottleneck, SPPF, DFL, Proto\nfrom ultralytics.nn.modules.head import Detect, Segment\nfrom ultralytics.nn.tasks import SegmentationModel\nfrom ultralytics.yolo.utils import IterableSimpleNamespace\nfrom ultralytics.yolo.utils.loss import v8DetectionLoss \nfrom torch.nn.modules.loss import BCEWithLogitsLoss\nfrom ultralytics.yolo.utils.tal import TaskAlignedAssigner \nfrom ultralytics.yolo.utils.loss import BboxLoss \nfrom ultralytics.nn.tasks import DetectionModel\n\nclass FusionVisionNode(Node):\n    def __init__(self) -&gt; Node:\n        super().__init__(&quot;fusionvision_node&quot;)\n\n        #self.declare_parameter(&quot;yolo_model_path&quot;, &quot;/home/a/Documents/visual-traversability-task/visual-traversability-using-nav2-rgb/src/fusionvision/models/yolo_model.pt&quot;)\n        self.declare_parameter(&quot;yolo_model_path&quot;, &quot;/home/a/Documents/visual-traversability-task/visual-traversability-using-nav2-rgb/src/fusionvision/models/annotated-small-objects-mode_v3.pt&quot;)\n        self.declare_parameter(&quot;fastsam_model_path&quot;, &quot;/home/a/Documents/visual-traversability-task/visual-traversability-using-nav2-rgb/src/fusionvision/models/FastSAM-s.pt&quot;)\n        self.declare_parameter(&quot;device&quot;, &quot;cpu&quot;)\n        self.declare_parameter(&quot;frequency&quot;, 2.0)\n        self.declare_parameter(&quot;queue_size&quot;, 30)\n        self.declare_parameter(&quot;delay_threshold&quot;, 0.3)\n        self.declare_parameter(&quot;NN_threshold&quot;, 0.5)\n        self.declare_parameter(&quot;enable&quot;, True)\n        self.declare_parameter(&quot;debug&quot;, True)\n        # confidence_threshold for the yolo and fastsam model\n        self.declare_parameter(&quot;confidence_threshold&quot;, 0.5)\n        self.declare_parameter(&quot;iou&quot;, 0.9)\n\n        yolo_model_path               = self.get_parameter(&quot;yolo_model_path&quot;).get_parameter_value().string_value\n        fastsam_model_path            = self.get_parameter(&quot;fastsam_model_path&quot;).get_parameter_value().string_value\n        device                        = self.get_parameter(&quot;device&quot;).get_parameter_value().string_value\n        frequency                     = self.get_parameter(&quot;frequency&quot;).get_parameter_value().double_value\n        queue_size                    = self.get_parameter(&quot;queue_size&quot;).get_parameter_value().integer_value\n        delay_threshold               = self.get_parameter(&quot;delay_threshold&quot;).get_parameter_value().double_value\n        self.NN_threshold             = self.get_parameter(&quot;NN_threshold&quot;).get_parameter_value().double_value\n        self.enable                   = self.get_parameter(&quot;enable&quot;).get_parameter_value().bool_value\n        self.debug                    = self.get_parameter(&quot;debug&quot;).get_parameter_value().bool_value\n        # confidence_threshold for the yolo and fastsam model\n        self.confidence_threshold     = self.get_parameter(&quot;confidence_threshold&quot;).get_parameter_value().double_value\n        self.iou                      = self.get_parameter(&quot;iou&quot;).get_parameter_value().double_value\n\n        clock_type = self.get_clock().clock_type\n        self.get_logger().info(f&quot;Using clock type: {clock_type.name} (ROS_TIME=0, SYSTEM_TIME=1, STEADY_TIME=2)&quot;)\n\n        # mark all these classes as safe inorder to load the model from file\n        safe_classes = [\n            DetectionModel,Sequential,Conv,Conv2d,BatchNorm2d,SiLU,ModuleList,\n            C2f,Bottleneck,SPPF,MaxPool2d,Upsample,Concat,Detect,DFL,SegmentationModel, \n            Segment,Proto,ConvTranspose2d,getattr,IterableSimpleNamespace,v8DetectionLoss,\n            BCEWithLogitsLoss,TaskAlignedAssigner,BboxLoss \n        ]\n\n        torch.serialization.add_safe_globals(safe_classes)\n        \n        self.cv_bridge = CvBridge()     \n        self.yolo_model = YOLO(yolo_model_path)   \n        self.fastsam_model = FastSAM(fastsam_model_path)   \n        self.yolo_model.to(device)           \n        self.pcd = o3d.geometry.PointCloud()\n\n        # Transformation matrix for flipping the point cloud upside down and left to right\n        self.flip_matrix = np.array([[1, 0, 0, 0],\n                            [0, -1, 0, 0],\n                            [0, 0, -1, 0],\n                            [0, 0, 0, 1]])\n\n        qos_profile = QoSProfile(\n            reliability=ReliabilityPolicy.RELIABLE,\n            history=HistoryPolicy.KEEP_LAST,\n            depth=1, # Keep only the latest message\n            durability=DurabilityPolicy.TRANSIENT_LOCAL # Match publisher, often VOLATILE\n        )\n\n\n        # Create a publisher for point cloud and camera info\n        #self._res_pub   = self.create_publisher(PointCloud2,&quot;/depth/pointcloud2&quot; , 10)\n        #self._info_pub  = self.create_publisher(CameraInfo, &quot;/image_seg/info&quot;, 10)\n        self._res_pub   = self.create_publisher(PointCloud2,&quot;/depth/pointcloud2&quot; , qos_profile)\n        self._info_pub  = self.create_publisher(CameraInfo, &quot;/image_seg/info&quot;, qos_profile)\n        self._color_sub = Subscriber(self, Image, &quot;/camera_depth_sensor/image_raw&quot;)\n        self._depth_sub = Subscriber(self, Image, &quot;/camera_depth_sensor/depth/image_raw&quot;)\n        self._info_sub  = Subscriber(self, CameraInfo, &quot;/camera_depth_sensor/depth/camera_info&quot;)\n\n        # From ROS 2 message_filters, to synchronize the topics\n        self._time_sync = ApproximateTimeSynchronizer(\n            [self._color_sub, self._depth_sub, self._info_sub ], \n            queue_size,\n            delay_threshold, \n        )\n\n        self._time_sync.registerCallback(self.image_cb)\n        self._srv = self.create_service(SetBool, &quot;enable&quot;, self.enable_cb)\n        self._timer_expired = True\n        self._timer = self.create_timer(1/frequency, self.timer_callback)\n\n        self.get_logger().info(&quot;fastsam node initialized&quot;)\n\n\n    def enable_cb(self, req: SetBool.Request, res: SetBool.Response) -&gt; SetBool.Response:\n        self.enable = req.data\n        res.success = True\n        return res\n\n    def timer_callback(self) -&gt; None:\n        self._timer_expired = True\n\n    def image_cb(self, color: Image, depth: Image, info: CameraInfo) -&gt; None:\n\n\n        if self.enable and self._timer_expired:\n            self._timer_expired = False\n            color_img = self.cv_bridge.imgmsg_to_cv2(color)\n            depth_img = self.cv_bridge.imgmsg_to_cv2(depth)\n\n            detections, predicted_boxes = utils.perform_yolo_inference(color_img, self.yolo_model, confidence_threshold=self.confidence_threshold)\n            \n            bounding_box_lines = []\n\n            if len(predicted_boxes) &gt; 0:\n                bounding_boxes = [list(map(int, box[:4])) for box in predicted_boxes]\n\n                fastsam_results = self.fastsam_model(color_img, device='cpu', retina_masks=True, imgsz=640, conf=self.confidence_threshold,\n                                                iou=self.iou) \n\n                #self.get_logger().info(f'fastsam_results: {fastsam_results}')\n                #self.get_logger().info(f'color image: {color_img}')\n\n                if fastsam_results:\n                    prompt_process = FastSAMPrompt(color_img, fastsam_results, device='cpu') # changed device from cuda to cpu\n                    ann = prompt_process.box_prompt(bboxes=bounding_boxes) \n                    img_with_annotations = prompt_process.plot_to_result(annotations=ann)\n                    #cv2.imshow('FastSAM Inference', img_with_annotations)\n\n                    #self.get_logger().info(f'ann: {ann}')\n                    \n                    ann_mask = np.array(ann).astype(np.uint8) \n                    ann_mask_overlay = np.sum(ann_mask, axis=0) \n\n                    #ann_mask_overlay_normalized = (ann_mask_overlay / np.max(ann_mask_overlay) * 255).astype(np.uint8)\n\n                    #cv2.imshow('Annotation Mask', ann_mask_overlay_normalized)\n                    ann_mask_overlay_uint8 = ann_mask_overlay.astype(np.uint8)\n\n                    eroded_ann_mask = cv2.erode(ann_mask_overlay_uint8, kernel=np.ones((20, 20), np.uint8), iterations=1) \n                    \n                    isolated_depth = np.where((eroded_ann_mask &gt; 0) &amp; (depth_img &lt; 1000), depth_img, np.nan) \n                    #isolated_depth = np.where((eroded_ann_mask &gt; 0) &amp; (depth_img &lt; 1), depth_img, np.nan) \n                    non_nan_points = np.argwhere(~np.isnan(isolated_depth)) \n                    non_nan_depth_values = isolated_depth[non_nan_points[:, 0], non_nan_points[:, 1]] \n\n                   \n\n                    self.get_logger().info('---------------------------------------------------------------')\n                    self.get_logger().info(f'shape of the non nan depth value: {non_nan_depth_values.shape}')\n                    self.get_logger().info('---------------------------------------------------------------')\n                                        \n                    depth_scale = 1\n   \n                    #self.get_logger().info(f'isolated_depth: {isolated_depth}')\n                    #self.get_logger().info(f'non nan points: {non_nan_points}')\n                    self.get_logger().info(f'non nan depth values: {non_nan_depth_values}')\n                    \n                    self.pcd.points = o3d.utility.Vector3dVector(\n                        np.column_stack([non_nan_points[:, 1], non_nan_points[:, 0], non_nan_depth_values * depth_scale])\n                    )\n\n                    pcd_outlier = self.pcd.voxel_down_sample(voxel_size=2)\n                    denoised_pcd, _ = pcd_outlier.remove_statistical_outlier(nb_neighbors=300,\n                                                                            std_ratio=2.0)\n\n                    \n\n                    denoised_pcd.transform(self.flip_matrix)\n\n                    pointcloud_msg = PointCloud2()\n                    pointcloud_msg.header = Header()\n\n                    #current_ros_time = self.get_clock().now()\n                    \n                    pointcloud_msg.header.frame_id = &quot;camera_depth_optical_frame&quot;\n                    pointcloud_msg.header.stamp = depth.header.stamp\n                    #pointcloud_msg.header.stamp = current_ros_time.to_msg() \n                    \n                    points = np.asarray(denoised_pcd.points)\n\n                    colors = np.asarray(denoised_pcd.colors) if denoised_pcd.has_colors() else None\n                \n                    # Define fields based on whether colors are present\n                    fields = [\n                        PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),\n                        PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1),\n                        PointField(name='z', offset=8, datatype=PointField.FLOAT32, count=1)\n                    ]\n                    if colors is not None and colors.shape[1] == 3:\n                        fields.extend([\n                            PointField(name='rgb', offset=12, datatype=PointField.FLOAT32, count=1)\n                        ])\n                \n                    pointcloud_msg.fields = fields\n                \n                    pointcloud_msg.height = 1  \n                    pointcloud_msg.width = points.shape[0]\n                \n                    pointcloud_msg.point_step = 12 + (12 if colors is not None and colors.shape[1] == 3 else 0)\n                \n                    pointcloud_msg.row_step = pointcloud_msg.point_step * pointcloud_msg.width\n                \n                    data = []\n                    for i in range(points.shape[0]):\n                        data.extend(struct.pack('&lt;fff', points[i, 0], points[i, 1], points[i, 2]))\n                        if colors is not None and colors.shape[1] == 3:\n                            rgb = colors[i]\n                            # Combine RGB into a single float (as often done in ROS PointCloud2)\n                            rgb_packed = struct.unpack('f', struct.pack('BBB', int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255)))[0]\n                            data.extend(struct.pack('&lt;f', rgb_packed))\n                \n                    pointcloud_msg.data = bytes(data)\n                    pointcloud_msg.is_dense = True \n                    \n                    self._res_pub.publish(pointcloud_msg)\n\ndef main():\n   try:\n       rclpy.init()\n       node = FusionVisionNode()\n       rclpy.spin(node)\n   except KeyboardInterrupt:\n       node.get_logger().info('Ctrl+C received - exiting...')\n       sys.exit(0)\n   finally:\n       node.get_logger().info('ROS node FusionVisionNode shutdown')\n       rclpy.shutdown()\n       cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main() \n\n"], "quote": [], "url": "https://stackoverflow.com/questions/79612599/pointcloud-not-aligned-with-with-map", "answer": [], "answer_code": []},
{"title": "Implementation of real-time object detection and navigation on a robot using RGB-D and LiDAR data without relying on simulation", "time": 1746505635, "post_content": ["I need to implement real-time object detection and robot navigation using RGB-D and LiDAR data on a Deep Robotics Lite3 quad robot without simulation.\nI have ROS Melodic installed on its system.\nThe robot dog is equipped with ARMv8 (Tegra Xavier) and has Ubuntu 18.04 (Bionic).\nIt has also realsense RGB-D camera and i have an external RPLIDAR C1 from Slamtec.\nWhat i am trying to do, is to use SLAM with both RGB-D camera and the LIDAR to create a map where the robot dog can navigate and explore using camera to detect objects and save them in a semantic map which i want to use for creating navigation's goal(find chair).\nSo far, all the papers that I found doing these types of projects use simulations to train the robot dog, which is something I kinda find unnecessary as i want to use pre-trained models. That's why I wanted to ask in this group to know if its actually possible to do this without going into the simulation part because the robot dog's OS is too slow and weak to run those simulations and even if I do it in my workstation, I still need to deploy it on the robot dog which I think would require a more powerful OS in order to run properly.\nAlso the papers that do this kinda work, all used habitat as simulation to train the robot dog which is a simulator I have no idea about and has a last version 2023\nMy obstacle avoidance works for simple scenarios, but fails when navigating around more than two obstacles. I encountered issues with Rtabmap rendering, when I launch the roslaunch file, the Rviz window shows up and the map starts being rendered vertically to the grid map.\nThis was Rviz config file i used:\nPanels:\n  - Class: rviz/Displays\n    Name: Displays\n  - Class: rviz/Views\n    Name: Views\nVisualization Manager:\n  Views:\n    Current:\n      Class: rviz/Orbit\n      Distance: 5\n      Focal Point:\n        X: 0\n        Y: 0\n        Z: 0\n      Pitch: 0.5\n      Yaw: 0.5\n  Displays:\n    - Class: rtabmap_ros/MapCloud\n      Enabled: true\n      MapCloudTopic: /mapData\n      Name: MapCloud\n      PointSize: 1\n    - Class: rtabmap_ros/MapGraph\n      Enabled: true\n      MapGraphTopic: /mapData\n      Name: MapGraph\n    - Class: rviz/LaserScan\n      Enabled: true\n      LaserScanTopic: /scan\n      Name: LaserScan\n    - Class: rviz/TF\n      Enabled: true\n      Name: TF\n  Global Options:\n    Background Color: 0 0 0\n    Fixed Frame: map\n\nThis is the Rtabmap launch file:\n<launch>\n  <!-- TF Configuration -->\n  <node pkg=\"tf\" type=\"static_transform_publisher\" name=\"base_to_laser\"\n    args=\"0.15 0 0.1 0 0 0 base_link laser 30\"/>\n  <node pkg=\"tf\" type=\"static_transform_publisher\" name=\"base_to_camera\"\n    args=\"0 0 0 0 0 0 base_link camera_link 30\"/>\n\n  <!-- RGB-D Synchronization -->\n  <node pkg=\"nodelet\" type=\"nodelet\" name=\"rgbd_sync\" \n        args=\"standalone rtabmap_ros/rgbd_sync\" output=\"screen\">\n    <remap from=\"rgb/image\"         to=\"/camera/color/image_raw\"/>\n    <remap from=\"depth/image\"       to=\"/camera/aligned_depth_to_color/image_raw\"/>\n    <remap from=\"rgb/camera_info\"   to=\"/camera/color/camera_info\"/>\n    <remap from=\"rgbd_image\"        to=\"rgbd_image\"/>\n    \n    <param name=\"approx_sync\"       value=\"false\"/> <!-- RealSense has hardware sync -->\n    <param name=\"queue_size\"        value=\"5\"/>\n  </node>\n\n  <!-- RTAB-Map Core Node -->\n  <node name=\"rtabmap\" pkg=\"rtabmap_ros\" type=\"rtabmap\" output=\"screen\" args=\"--delete_db_on_start\">\n    <!-- Core Parameters -->\n    <param name=\"frame_id\"              value=\"base_link\"/>\n    <param name=\"odom_frame_id\"         value=\"odom\"/>\n    <param name=\"map_frame_id\"          value=\"map\"/>\n    \n    <!-- Sensor Inputs -->\n    <remap from=\"scan\"              to=\"/scan\"/>\n    <remap from=\"rgbd_image\"        to=\"rgbd_image\"/>\n    <remap from=\"odom\"              to=\"/leg_odom\"/>\n\n    <!-- Sensor Configuration -->\n    <param name=\"subscribe_rgbd\"    value=\"true\"/>\n    <param name=\"subscribe_scan\"    value=\"true\"/>\n    <param name=\"Reg/Strategy\"      value=\"1\"/> <!-- 1=ICP -->\n    <param name=\"Reg/Force3DoF\"     value=\"true\"/>\n    <param name=\"Grid/FromDepth\"    value=\"false\"/> <!-- Use laser for 2D mapping -->\n\n    <!-- ICP Parameters -->\n    <param name=\"Icp/VoxelSize\"                 value=\"0.05\"/>\n    <param name=\"Icp/MaxCorrespondenceDistance\"  value=\"0.1\"/>\n    <param name=\"Icp/PointToPlane\"               value=\"true\"/>\n    <param name=\"Icp/CorrespondenceRatio\"        value=\"0.3\"/>\n\n    <!-- Optimization Parameters -->\n    <param name=\"RGBD/NeighborLinkRefining\"      value=\"true\"/>\n    <param name=\"RGBD/ProximityBySpace\"          value=\"true\"/>\n    <param name=\"RGBD/AngularUpdate\"             value=\"0.01\"/>\n    <param name=\"RGBD/LinearUpdate\"              value=\"0.01\"/>\n    <param name=\"RGBD/OptimizeFromGraphEnd\"      value=\"false\"/>\n\n    <!-- Performance Settings -->\n    <param name=\"Mem/STMSize\"            value=\"10\"/>\n    <param name=\"Kp/MaxDepth\"            value=\"4.0\"/>\n    <param name=\"Rtabmap/DetectionRate\"  value=\"2\"/>\n    <param name=\"queue_size\"             value=\"10\"/>\n  </node>\n\n  <!-- Visualization -->\n  <node pkg=\"rviz\" type=\"rviz\" name=\"rviz\" \n    args=\"-d $(find rtabmap_ros)/launch/config/rviz_mapping.rviz\"/>\n</launch>\n\nI also used the Isaacgym legged project to train the robot dog to walk using RL training.\nI used the camera sensor of the robot dog in the simulation to test the obstacle detection. It worked and I ran Simple repulsive planner algorithm to avoid obstacles while still navigating but this was conducted in a basic map with a flat plane and 2 boxes as obstacles.\nThe semantic map logic was also implemented in the simulation part but it\u2019s effective as I need real world scenarios.\nWhat I want to reach is that I can select a goal where I need the robot dog to navigate to and find a chair\nAnd with that prompt, the robot dog starts navigating and use object detection until he find the specified object i selected for him.\nIf this could be done without using simulation, then it would be the best option for me."], "question_code": ["Panels:\n  - Class: rviz/Displays\n    Name: Displays\n  - Class: rviz/Views\n    Name: Views\nVisualization Manager:\n  Views:\n    Current:\n      Class: rviz/Orbit\n      Distance: 5\n      Focal Point:\n        X: 0\n        Y: 0\n        Z: 0\n      Pitch: 0.5\n      Yaw: 0.5\n  Displays:\n    - Class: rtabmap_ros/MapCloud\n      Enabled: true\n      MapCloudTopic: /mapData\n      Name: MapCloud\n      PointSize: 1\n    - Class: rtabmap_ros/MapGraph\n      Enabled: true\n      MapGraphTopic: /mapData\n      Name: MapGraph\n    - Class: rviz/LaserScan\n      Enabled: true\n      LaserScanTopic: /scan\n      Name: LaserScan\n    - Class: rviz/TF\n      Enabled: true\n      Name: TF\n  Global Options:\n    Background Color: 0 0 0\n    Fixed Frame: map\n", "&lt;launch&gt;\n  &lt;!-- TF Configuration --&gt;\n  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;base_to_laser&quot;\n    args=&quot;0.15 0 0.1 0 0 0 base_link laser 30&quot;/&gt;\n  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;base_to_camera&quot;\n    args=&quot;0 0 0 0 0 0 base_link camera_link 30&quot;/&gt;\n\n  &lt;!-- RGB-D Synchronization --&gt;\n  &lt;node pkg=&quot;nodelet&quot; type=&quot;nodelet&quot; name=&quot;rgbd_sync&quot; \n        args=&quot;standalone rtabmap_ros/rgbd_sync&quot; output=&quot;screen&quot;&gt;\n    &lt;remap from=&quot;rgb/image&quot;         to=&quot;/camera/color/image_raw&quot;/&gt;\n    &lt;remap from=&quot;depth/image&quot;       to=&quot;/camera/aligned_depth_to_color/image_raw&quot;/&gt;\n    &lt;remap from=&quot;rgb/camera_info&quot;   to=&quot;/camera/color/camera_info&quot;/&gt;\n    &lt;remap from=&quot;rgbd_image&quot;        to=&quot;rgbd_image&quot;/&gt;\n    \n    &lt;param name=&quot;approx_sync&quot;       value=&quot;false&quot;/&gt; &lt;!-- RealSense has hardware sync --&gt;\n    &lt;param name=&quot;queue_size&quot;        value=&quot;5&quot;/&gt;\n  &lt;/node&gt;\n\n  &lt;!-- RTAB-Map Core Node --&gt;\n  &lt;node name=&quot;rtabmap&quot; pkg=&quot;rtabmap_ros&quot; type=&quot;rtabmap&quot; output=&quot;screen&quot; args=&quot;--delete_db_on_start&quot;&gt;\n    &lt;!-- Core Parameters --&gt;\n    &lt;param name=&quot;frame_id&quot;              value=&quot;base_link&quot;/&gt;\n    &lt;param name=&quot;odom_frame_id&quot;         value=&quot;odom&quot;/&gt;\n    &lt;param name=&quot;map_frame_id&quot;          value=&quot;map&quot;/&gt;\n    \n    &lt;!-- Sensor Inputs --&gt;\n    &lt;remap from=&quot;scan&quot;              to=&quot;/scan&quot;/&gt;\n    &lt;remap from=&quot;rgbd_image&quot;        to=&quot;rgbd_image&quot;/&gt;\n    &lt;remap from=&quot;odom&quot;              to=&quot;/leg_odom&quot;/&gt;\n\n    &lt;!-- Sensor Configuration --&gt;\n    &lt;param name=&quot;subscribe_rgbd&quot;    value=&quot;true&quot;/&gt;\n    &lt;param name=&quot;subscribe_scan&quot;    value=&quot;true&quot;/&gt;\n    &lt;param name=&quot;Reg/Strategy&quot;      value=&quot;1&quot;/&gt; &lt;!-- 1=ICP --&gt;\n    &lt;param name=&quot;Reg/Force3DoF&quot;     value=&quot;true&quot;/&gt;\n    &lt;param name=&quot;Grid/FromDepth&quot;    value=&quot;false&quot;/&gt; &lt;!-- Use laser for 2D mapping --&gt;\n\n    &lt;!-- ICP Parameters --&gt;\n    &lt;param name=&quot;Icp/VoxelSize&quot;                 value=&quot;0.05&quot;/&gt;\n    &lt;param name=&quot;Icp/MaxCorrespondenceDistance&quot;  value=&quot;0.1&quot;/&gt;\n    &lt;param name=&quot;Icp/PointToPlane&quot;               value=&quot;true&quot;/&gt;\n    &lt;param name=&quot;Icp/CorrespondenceRatio&quot;        value=&quot;0.3&quot;/&gt;\n\n    &lt;!-- Optimization Parameters --&gt;\n    &lt;param name=&quot;RGBD/NeighborLinkRefining&quot;      value=&quot;true&quot;/&gt;\n    &lt;param name=&quot;RGBD/ProximityBySpace&quot;          value=&quot;true&quot;/&gt;\n    &lt;param name=&quot;RGBD/AngularUpdate&quot;             value=&quot;0.01&quot;/&gt;\n    &lt;param name=&quot;RGBD/LinearUpdate&quot;              value=&quot;0.01&quot;/&gt;\n    &lt;param name=&quot;RGBD/OptimizeFromGraphEnd&quot;      value=&quot;false&quot;/&gt;\n\n    &lt;!-- Performance Settings --&gt;\n    &lt;param name=&quot;Mem/STMSize&quot;            value=&quot;10&quot;/&gt;\n    &lt;param name=&quot;Kp/MaxDepth&quot;            value=&quot;4.0&quot;/&gt;\n    &lt;param name=&quot;Rtabmap/DetectionRate&quot;  value=&quot;2&quot;/&gt;\n    &lt;param name=&quot;queue_size&quot;             value=&quot;10&quot;/&gt;\n  &lt;/node&gt;\n\n  &lt;!-- Visualization --&gt;\n  &lt;node pkg=&quot;rviz&quot; type=&quot;rviz&quot; name=&quot;rviz&quot; \n    args=&quot;-d $(find rtabmap_ros)/launch/config/rviz_mapping.rviz&quot;/&gt;\n&lt;/launch&gt;\n"], "quote": [], "url": "https://stackoverflow.com/questions/79607971/implementation-of-real-time-object-detection-and-navigation-on-a-robot-using-rgb", "answer": [], "answer_code": []},
{"title": "Cmake: undefined reference to `rclcpp::Node::Node(std::string const&, rclcpp::NodeOptions const&)'", "time": 1745089619, "post_content": ["I'm working on a ROS2 Humble project. As always, I created the ament_cmake package, wrote a C++ node with Torch Scripts, and made Cmake - but I got this error: undefined reference to `rclcpp::Node::Node(std::string const&, rclcpp::NodeOptions const&)'. As far as I understand, it's all about the linker - for some reason it doesn't see the ROS methods. I've tried a lot, but I still don't fully understand what the problem is. Colcon build throws an error every time it is run. Here is my Cmake file:\ncmake_minimum_required(VERSION 3.10)\nproject(tinker_publisher_udp)\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n  add_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\n# Find ROS 2 packages\nfind_package(ament_cmake REQUIRED)\nfind_package(rclcpp REQUIRED)\n\nfind_package(CUDAToolkit REQUIRED)\ninclude_directories(${CUDAToolkit_INCLUDE_DIRS})\n\nset(Torch_DIR \"/home/user1/libtorch/libtorch/share/cmake/Torch\")\nlist(APPEND CMAKE_PREFIX_PATH \"${libtorch_path}\")\nfind_package(Torch REQUIRED)\n\nadd_executable(tinker_publisher_udp src/tinker_publisher_udp.cpp)\n\nament_target_dependencies(tinker_publisher_udp\n    rclcpp\n    \n)\n\ninclude_directories(\n    ${Torch_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(tinker_publisher_udp\n    \"${TORCH_LIBRARIES}\"\n    rclcpp::rclcpp  # Ensure this line is present\n)\n\ninstall(TARGETS tinker_publisher_udp\n    DESTINATION lib/${PROJECT_NAME}\n)\n\nfind_package(ament_lint_auto REQUIRED)\nament_lint_auto_find_test_dependencies()\n\nif(BUILD_TESTING)\n  find_package(ament_lint_auto REQUIRED)\n  ament_lint_auto_find_test_dependencies()\nendif()\n\nament_package()\n\nuser1@desktop:~/my_test/LocomotionWithNP3O-masteroldx/ros2$ colcon build --packages-select tinker_publisher_udp\n[0.312s] WARNING:colcon.colcon_ros.prefix_path.ament:The path '/home/user1/my_test/LocomotionWithNP3O-masteroldx/ros2/install/tinker_mujoco_sim' in the environment variable AMENT_PREFIX_PATH doesn't exist\n[0.312s] WARNING:colcon.colcon_ros.prefix_path.ament:The path '/home/user1/my_test/LocomotionWithNP3O-masteroldx/ros2/install/test' in the environment variable AMENT_PREFIX_PATH doesn't exist\n[0.313s] WARNING:colcon.colcon_ros.prefix_path.catkin:The path '/home/user1/my_test/LocomotionWithNP3O-masteroldx/ros2/install/test' in the environment variable CMAKE_PREFIX_PATH doesn't exist\nStarting >>> tinker_publisher_udp\n--- stderr: tinker_publisher_udp                                \nCMake Warning at /home/user1/libtorch/libtorch/share/cmake/Caffe2/public/cuda.cmake:140 (message):\n  Failed to compute shorthash for libnvrtc.so\nCall Stack (most recent call first):\n  /home/user1/libtorch/libtorch/share/cmake/Caffe2/Caffe2Config.cmake:86 (include)\n  /home/user1/libtorch/libtorch/share/cmake/Torch/TorchConfig.cmake:68 (find_package)\n  CMakeLists.txt:17 (find_package)\n\n\nCMake Warning (dev) at /usr/local/cmake-3.31.7/share/cmake-3.31/Modules/FindPackageHandleStandardArgs.cmake:441 (message):\n  The package name passed to `find_package_handle_standard_args` (nvtx3) does\n  not match the name of the calling package (Caffe2).  This can lead to\n  problems in calling code that expects `find_package` result variables\n  (e.g., `_FOUND`) to follow a certain pattern.\nCall Stack (most recent call first):\n  /home/user1/libtorch/libtorch/share/cmake/Caffe2/public/cuda.cmake:178 (find_package_handle_standard_args)\n  /home/user1/libtorch/libtorch/share/cmake/Caffe2/Caffe2Config.cmake:86 (include)\n  /home/user1/libtorch/libtorch/share/cmake/Torch/TorchConfig.cmake:68 (find_package)\n  CMakeLists.txt:17 (find_package)\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n\nCMake Warning at /home/user1/libtorch/libtorch/share/cmake/Caffe2/public/cuda.cmake:184 (message):\n  Cannot find NVTX3, find old NVTX instead\nCall Stack (most recent call first):\n  /home/user1/libtorch/libtorch/share/cmake/Caffe2/Caffe2Config.cmake:86 (include)\n  /home/user1/libtorch/libtorch/share/cmake/Torch/TorchConfig.cmake:68 (find_package)\n  CMakeLists.txt:17 (find_package)\n\n\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `main':\ntinker_publisher_udp.cpp:(.text+0x360): undefined reference to `rclcpp::shutdown(std::shared_ptr<rclcpp::Context>, std::string const&)'\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `rclcpp::ParameterTypeException::ParameterTypeException(rclcpp::ParameterType, rclcpp::ParameterType)':\ntinker_publisher_udp.cpp:(.text._ZN6rclcpp22ParameterTypeExceptionC2ENS_13ParameterTypeES1_[_ZN6rclcpp22ParameterTypeExceptionC5ENS_13ParameterTypeES1_]+0x3e): undefined reference to `rclcpp::to_string(rclcpp::ParameterType)'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN6rclcpp22ParameterTypeExceptionC2ENS_13ParameterTypeES1_[_ZN6rclcpp22ParameterTypeExceptionC5ENS_13ParameterTypeES1_]+0x50): undefined reference to `rclcpp::to_string(rclcpp::ParameterType)'\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `auto rclcpp::Node::declare_parameter<std::string>(std::string const&, std::string const&, rcl_interfaces::msg::ParameterDescriptor_<std::allocator<void> > const&, bool)':\ntinker_publisher_udp.cpp:(.text._ZN6rclcpp4Node17declare_parameterISsEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb[_ZN6rclcpp4Node17declare_parameterISsEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb]+0x69): undefined reference to `rclcpp::ParameterValue::ParameterValue(std::string const&)'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN6rclcpp4Node17declare_parameterISsEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb[_ZN6rclcpp4Node17declare_parameterISsEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb]+0x90): undefined reference to `rclcpp::Node::declare_parameter(std::string const&, rclcpp::ParameterValue const&, rcl_interfaces::msg::ParameterDescriptor_<std::allocator<void> > const&, bool)'\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `auto rclcpp::Node::declare_parameter<int>(std::string const&, int const&, rcl_interfaces::msg::ParameterDescriptor_<std::allocator<void> > const&, bool)':\ntinker_publisher_udp.cpp:(.text._ZN6rclcpp4Node17declare_parameterIiEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb[_ZN6rclcpp4Node17declare_parameterIiEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb]+0x8a): undefined reference to `rclcpp::Node::declare_parameter(std::string const&, rclcpp::ParameterValue const&, rcl_interfaces::msg::ParameterDescriptor_<std::allocator<void> > const&, bool)'\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `RL_Tinymal_UDP::RL_Tinymal_UDP()':\ntinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0xb7): undefined reference to `rclcpp::Node::Node(std::string const&, rclcpp::NodeOptions const&)'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x6a1): undefined reference to `rclcpp::Node::get_parameter(std::string const&) const'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x6b0): undefined reference to `rclcpp::Parameter::as_string() const'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x747): undefined reference to `rclcpp::Node::get_parameter(std::string const&) const'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x7e1): undefined reference to `rclcpp::Node::get_parameter(std::string const&) const'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x7f0): undefined reference to `rclcpp::Parameter::as_string() const'\ncollect2: error: ld returned 1 exit status\ngmake[2]: *** [CMakeFiles/tinker_publisher_udp.dir/build.make:164: tinker_publisher_udp] Error 1\ngmake[1]: *** [CMakeFiles/Makefile2:153: CMakeFiles/tinker_publisher_udp.dir/all] Error 2\ngmake: *** [Makefile:146: all] Error 2\n---\nFailed   <<< tinker_publisher_udp [25.1s, exited with code 2]\n\nI tried to change Cmake, but it seemed to have no effect.\nI also noticed one interesting feature that if you remove work with ROS2 or work with Torch from the node code and try colcon build again, everything will be copied."], "question_code": ["cmake_minimum_required(VERSION 3.10)\nproject(tinker_publisher_udp)\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES &quot;Clang&quot;)\n  add_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\n# Find ROS 2 packages\nfind_package(ament_cmake REQUIRED)\nfind_package(rclcpp REQUIRED)\n\nfind_package(CUDAToolkit REQUIRED)\ninclude_directories(${CUDAToolkit_INCLUDE_DIRS})\n\nset(Torch_DIR &quot;/home/user1/libtorch/libtorch/share/cmake/Torch&quot;)\nlist(APPEND CMAKE_PREFIX_PATH &quot;${libtorch_path}&quot;)\nfind_package(Torch REQUIRED)\n\nadd_executable(tinker_publisher_udp src/tinker_publisher_udp.cpp)\n\nament_target_dependencies(tinker_publisher_udp\n    rclcpp\n    \n)\n\ninclude_directories(\n    ${Torch_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(tinker_publisher_udp\n    &quot;${TORCH_LIBRARIES}&quot;\n    rclcpp::rclcpp  # Ensure this line is present\n)\n\ninstall(TARGETS tinker_publisher_udp\n    DESTINATION lib/${PROJECT_NAME}\n)\n\nfind_package(ament_lint_auto REQUIRED)\nament_lint_auto_find_test_dependencies()\n\nif(BUILD_TESTING)\n  find_package(ament_lint_auto REQUIRED)\n  ament_lint_auto_find_test_dependencies()\nendif()\n\nament_package()\n", "user1@desktop:~/my_test/LocomotionWithNP3O-masteroldx/ros2$ colcon build --packages-select tinker_publisher_udp\n[0.312s] WARNING:colcon.colcon_ros.prefix_path.ament:The path '/home/user1/my_test/LocomotionWithNP3O-masteroldx/ros2/install/tinker_mujoco_sim' in the environment variable AMENT_PREFIX_PATH doesn't exist\n[0.312s] WARNING:colcon.colcon_ros.prefix_path.ament:The path '/home/user1/my_test/LocomotionWithNP3O-masteroldx/ros2/install/test' in the environment variable AMENT_PREFIX_PATH doesn't exist\n[0.313s] WARNING:colcon.colcon_ros.prefix_path.catkin:The path '/home/user1/my_test/LocomotionWithNP3O-masteroldx/ros2/install/test' in the environment variable CMAKE_PREFIX_PATH doesn't exist\nStarting &gt;&gt;&gt; tinker_publisher_udp\n--- stderr: tinker_publisher_udp                                \nCMake Warning at /home/user1/libtorch/libtorch/share/cmake/Caffe2/public/cuda.cmake:140 (message):\n  Failed to compute shorthash for libnvrtc.so\nCall Stack (most recent call first):\n  /home/user1/libtorch/libtorch/share/cmake/Caffe2/Caffe2Config.cmake:86 (include)\n  /home/user1/libtorch/libtorch/share/cmake/Torch/TorchConfig.cmake:68 (find_package)\n  CMakeLists.txt:17 (find_package)\n\n\nCMake Warning (dev) at /usr/local/cmake-3.31.7/share/cmake-3.31/Modules/FindPackageHandleStandardArgs.cmake:441 (message):\n  The package name passed to `find_package_handle_standard_args` (nvtx3) does\n  not match the name of the calling package (Caffe2).  This can lead to\n  problems in calling code that expects `find_package` result variables\n  (e.g., `_FOUND`) to follow a certain pattern.\nCall Stack (most recent call first):\n  /home/user1/libtorch/libtorch/share/cmake/Caffe2/public/cuda.cmake:178 (find_package_handle_standard_args)\n  /home/user1/libtorch/libtorch/share/cmake/Caffe2/Caffe2Config.cmake:86 (include)\n  /home/user1/libtorch/libtorch/share/cmake/Torch/TorchConfig.cmake:68 (find_package)\n  CMakeLists.txt:17 (find_package)\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n\nCMake Warning at /home/user1/libtorch/libtorch/share/cmake/Caffe2/public/cuda.cmake:184 (message):\n  Cannot find NVTX3, find old NVTX instead\nCall Stack (most recent call first):\n  /home/user1/libtorch/libtorch/share/cmake/Caffe2/Caffe2Config.cmake:86 (include)\n  /home/user1/libtorch/libtorch/share/cmake/Torch/TorchConfig.cmake:68 (find_package)\n  CMakeLists.txt:17 (find_package)\n\n\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `main':\ntinker_publisher_udp.cpp:(.text+0x360): undefined reference to `rclcpp::shutdown(std::shared_ptr&lt;rclcpp::Context&gt;, std::string const&amp;)'\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `rclcpp::ParameterTypeException::ParameterTypeException(rclcpp::ParameterType, rclcpp::ParameterType)':\ntinker_publisher_udp.cpp:(.text._ZN6rclcpp22ParameterTypeExceptionC2ENS_13ParameterTypeES1_[_ZN6rclcpp22ParameterTypeExceptionC5ENS_13ParameterTypeES1_]+0x3e): undefined reference to `rclcpp::to_string(rclcpp::ParameterType)'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN6rclcpp22ParameterTypeExceptionC2ENS_13ParameterTypeES1_[_ZN6rclcpp22ParameterTypeExceptionC5ENS_13ParameterTypeES1_]+0x50): undefined reference to `rclcpp::to_string(rclcpp::ParameterType)'\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `auto rclcpp::Node::declare_parameter&lt;std::string&gt;(std::string const&amp;, std::string const&amp;, rcl_interfaces::msg::ParameterDescriptor_&lt;std::allocator&lt;void&gt; &gt; const&amp;, bool)':\ntinker_publisher_udp.cpp:(.text._ZN6rclcpp4Node17declare_parameterISsEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb[_ZN6rclcpp4Node17declare_parameterISsEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb]+0x69): undefined reference to `rclcpp::ParameterValue::ParameterValue(std::string const&amp;)'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN6rclcpp4Node17declare_parameterISsEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb[_ZN6rclcpp4Node17declare_parameterISsEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb]+0x90): undefined reference to `rclcpp::Node::declare_parameter(std::string const&amp;, rclcpp::ParameterValue const&amp;, rcl_interfaces::msg::ParameterDescriptor_&lt;std::allocator&lt;void&gt; &gt; const&amp;, bool)'\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `auto rclcpp::Node::declare_parameter&lt;int&gt;(std::string const&amp;, int const&amp;, rcl_interfaces::msg::ParameterDescriptor_&lt;std::allocator&lt;void&gt; &gt; const&amp;, bool)':\ntinker_publisher_udp.cpp:(.text._ZN6rclcpp4Node17declare_parameterIiEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb[_ZN6rclcpp4Node17declare_parameterIiEEDaRKSsRKT_RKN14rcl_interfaces3msg20ParameterDescriptor_ISaIvEEEb]+0x8a): undefined reference to `rclcpp::Node::declare_parameter(std::string const&amp;, rclcpp::ParameterValue const&amp;, rcl_interfaces::msg::ParameterDescriptor_&lt;std::allocator&lt;void&gt; &gt; const&amp;, bool)'\n/usr/bin/ld: CMakeFiles/tinker_publisher_udp.dir/src/tinker_publisher_udp.cpp.o: in function `RL_Tinymal_UDP::RL_Tinymal_UDP()':\ntinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0xb7): undefined reference to `rclcpp::Node::Node(std::string const&amp;, rclcpp::NodeOptions const&amp;)'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x6a1): undefined reference to `rclcpp::Node::get_parameter(std::string const&amp;) const'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x6b0): undefined reference to `rclcpp::Parameter::as_string() const'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x747): undefined reference to `rclcpp::Node::get_parameter(std::string const&amp;) const'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x7e1): undefined reference to `rclcpp::Node::get_parameter(std::string const&amp;) const'\n/usr/bin/ld: tinker_publisher_udp.cpp:(.text._ZN14RL_Tinymal_UDPC2Ev[_ZN14RL_Tinymal_UDPC5Ev]+0x7f0): undefined reference to `rclcpp::Parameter::as_string() const'\ncollect2: error: ld returned 1 exit status\ngmake[2]: *** [CMakeFiles/tinker_publisher_udp.dir/build.make:164: tinker_publisher_udp] Error 1\ngmake[1]: *** [CMakeFiles/Makefile2:153: CMakeFiles/tinker_publisher_udp.dir/all] Error 2\ngmake: *** [Makefile:146: all] Error 2\n---\nFailed   &lt;&lt;&lt; tinker_publisher_udp [25.1s, exited with code 2]\n"], "quote": [], "url": "https://stackoverflow.com/questions/79582746/cmake-undefined-reference-to-rclcppnodenodestdstring-const-rclcppno", "answer": [], "answer_code": []},
{"title": "eProsima node-red-ros2-plugin throws errors", "time": 1744836650, "post_content": ["I am trying to use https://github.com/eProsima/node-red-ros2-plugin to connect to ROS2 using node-red dashboard to read geometry messages. I installed the plugin and configured the IS_ROS2_PREFIX_PATH, IS_MIX_PATH, IS_WEBSOCKET_CLIENT_PREFIX_PATH and made a YAML file as well. When I start IS using the YAML file, sometimes the error was below.\nIntegration-service ~/is_ws/ros2.websocket.yaml [Integration Service][WARN] [is::core::Config] Parsing the IDL number '1' placed in the YAML config. The parsing was successful but no types were found. [Integration Service][INFO] [is::sh::ROS2] Created node '/is_ros2_node_1804289383' with Domain ID: 0 [Integration Service][INFO] [is::sh::ROS2] Configured! [Integration Service][INFO] [is::sh::WebSocket::Client] Security enabled, creating TLS endpoint... [Integration Service][INFO] [is::sh::WebSocket::Client] Configured TLS endpoint 'localhost:3000' [Integration Service][INFO] [is::sh::WebSocket::Client] Configured! Segmentation fault (core dumped)\n\nand other times it says  that the path to mix files are not found.\nI have been trying this for over a week. But, still unable to crack it properly.\nWhat is the mistake I am doing here?\nI am using ROS2 humble, node v18.20.5, nothing is installed on dockers.\nPlease assist."], "question_code": ["Integration-service ~/is_ws/ros2.websocket.yaml [Integration Service][WARN] [is::core::Config] Parsing the IDL number '1' placed in the YAML config. The parsing was successful but no types were found. [Integration Service][INFO] [is::sh::ROS2] Created node '/is_ros2_node_1804289383' with Domain ID: 0 [Integration Service][INFO] [is::sh::ROS2] Configured! [Integration Service][INFO] [is::sh::WebSocket::Client] Security enabled, creating TLS endpoint... [Integration Service][INFO] [is::sh::WebSocket::Client] Configured TLS endpoint 'localhost:3000' [Integration Service][INFO] [is::sh::WebSocket::Client] Configured! Segmentation fault (core dumped)\n"], "quote": [], "url": "https://stackoverflow.com/questions/79578093/eprosima-node-red-ros2-plugin-throws-errors", "answer": [], "answer_code": []},
{"title": "ROS SLAM_toolbox queue is full and timestamp error", "time": 1743356136, "post_content": ["Im using Ros2 humble and a ouster lidar. Im utilizing the Ros2 container ouster provides to expose the scan topics. Im attempting to use online async slam from slam tool bot but Im getting the error bellow when I run it using the command \"ros2 launch slam_toolbox online_async_launch.py\"\n[async_slam_toolbox_node-1] [INFO] [1743355473.858619647] [slam_toolbox]: Message Filter dropping message: frame 'os_lidar' at time 404.359 for reason 'discarding message because the queue is full'\nIncreasing the buffer size doe not fix the issue and after doing some research it looks like it could be a tf issue. Ive attached an image of the tee below.\ntf tree\nThis seems to be how it should be and when I add the laser scan topic to rviz the scans show up when the fixed frame is set to baselink as seen below\nrviz with robot and scan\nI also tried a work around where I just read and punlish the scan to a different scan topic at a slower rate but then I get time stamp errors as seen bellow.\n[async_slam_toolbox_node-1] [INFO] [1743355498.853598783] [slam_toolbox]: Message Filter dropping message: frame 'os_lidar' at time 429.457 for reason 'the timestamp on the message is earlier than all the data in the transform cache'\nAm a bit stumped and would really appreciate the help!"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79544954/ros-slam-toolbox-queue-is-full-and-timestamp-error", "answer": [], "answer_code": []},
{"title": "Issue with Using Pilz Industrial Motion Planner in Python Script", "time": 1742807909, "post_content": ["Hello,\nI am using ROS2 Humble to control a Fairino robot, and I can control the robot through the MoveIt2 interface using the Pilz Industrial Motion Planner.\nI wrote a Python script to move between multiple locations relative to the gripper frame (which was grasp_frame relative to robot_base_link). However, when I run the following code, the robot moves without using the Pilz Industrial Motion Planner, and its movement is very random.\nDo you have any solutions to ensure the robot moves using the Pilz Industrial Motion Planner within a Python script?\nThank you!\nPython code:\n#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom moveit_msgs.srv import GetMotionPlan\nfrom moveit_msgs.msg import MotionPlanRequest, RobotState, Constraints, PositionConstraint, OrientationConstraint, MoveItErrorCodes\nfrom geometry_msgs.msg import Pose, Point, Quaternion, Vector3\nfrom shape_msgs.msg import SolidPrimitive\nfrom sensor_msgs.msg import JointState\nfrom moveit_msgs.action import ExecuteTrajectory\nfrom rclpy.action import ActionClient\n\nclass PalletizingRobot(Node):\n    def __init__(self):\n        super().__init__('palletizing_robot')\n\n        # Service client for motion planning\n        self.client = self.create_client(GetMotionPlan, 'plan_kinematic_path')\n        while not self.client.wait_for_service(timeout_sec=1.0):\n            self.get_logger().info('Waiting for plan_kinematic_path service...')\n        self.get_logger().info('Motion planning service available!')\n\n        # Action client for trajectory execution\n        self.execute_client = ActionClient(self, ExecuteTrajectory, 'execute_trajectory')\n        while not self.execute_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().info('Waiting for execute_trajectory action server...')\n        self.get_logger().info('Trajectory execution server available!')\n\n        # Subscribe to joint states\n        self.joint_state_sub = self.create_subscription(JointState, 'joint_states', self.joint_state_callback, 10)\n        self.current_joint_state = None\n\n        # Robot configuration\n        self.group_name = \"fairino10_v6_group\"\n        self.base_frame = \"base_link\"\n        self.gripper_frame = \"grasp_frame\"\n\n        # Define target poses (gripper frame relative to base_link)\n        self.target_poses = {\n            'prepick_pos': Pose(\n                position=Point(x=0.800, y=-0.050, z=0.510),\n                orientation=Quaternion(x=0.000, y=0.000, z=0.000, w=1.000)\n            ),\n            'pick_pos': Pose(\n                position=Point(x=0.800, y=-0.050, z=0.365),  # 0.315 + 0.05\n                orientation=Quaternion(x=0.000, y=0.000, z=0.000, w=1.000)\n            ),\n            'postpick_pos': Pose(\n                position=Point(x=0.800, y=-0.050, z=0.510),\n                orientation=Quaternion(x=0.000, y=0.000, z=0.000, w=1.000)\n            ),\n            'preplace_pos': Pose(\n                position=Point(x=0.763, y=0.007, z=0.518),\n                orientation=Quaternion(x=-0.052, y=-0.009, z=0.661, w=0.748)\n            ),\n            'place_pos': Pose(\n                position=Point(x=0.799, y=-0.005, z=0.278),\n                orientation=Quaternion(x=-0.002, y=0.030, z=0.661, w=0.750)\n            ),\n            'postplace_pos': Pose(\n                position=Point(x=0.763, y=0.007, z=0.518),\n                orientation=Quaternion(x=-0.052, y=-0.009, z=0.661, w=0.748)\n            ),\n            'home_pos': Pose(\n                position=Point(x=0.092, y=-0.760, z=0.257),\n                orientation=Quaternion(x=-0.004, y=0.003, z=0.049, w=0.999)\n            )\n        }\n\n        # Motion parameters\n        self.max_velocity = 0.3  # m/s (adjustable)\n        self.max_acceleration = 0.3  # m/s^2 (adjustable)\n\n    def joint_state_callback(self, msg):\n        self.current_joint_state = msg\n\n    def plan_cartesian_motion(self, target_pose, stage_name):\n        if self.current_joint_state is None:\n            self.get_logger().error('No current joint state available!')\n            return None\n\n        # Motion plan request\n        request = GetMotionPlan.Request()\n        motion_req = request.motion_plan_request\n\n        # Configure motion request\n        motion_req.group_name = self.group_name\n        motion_req.planner_id = \"pilz_industrial_motion_planner/LIN\"\n        motion_req.num_planning_attempts = 10\n        motion_req.allowed_planning_time = 5.0\n        motion_req.max_velocity_scaling_factor = 1.0  # Adjusted in execution\n        motion_req.max_acceleration_scaling_factor = 1.0  # Adjusted in execution\n\n        # Workspace parameters\n        motion_req.workspace_parameters.header.frame_id = self.base_frame\n        motion_req.workspace_parameters.min_corner = Vector3(x=-2.0, y=-2.0, z=-2.0)\n        motion_req.workspace_parameters.max_corner = Vector3(x=2.0, y=2.0, z=2.0)\n\n        # Start state\n        motion_req.start_state.joint_state = self.current_joint_state\n\n        # Goal constraints\n        constraints = Constraints()\n\n        # Position constraint (tight tolerance for Cartesian precision)\n        pos_constraint = PositionConstraint()\n        pos_constraint.header.frame_id = self.base_frame\n        pos_constraint.link_name = self.gripper_frame\n        pos_constraint.constraint_region.primitives.append(SolidPrimitive(type=SolidPrimitive.SPHERE, dimensions=[0.001]))\n        pos_constraint.constraint_region.primitive_poses.append(target_pose)\n        pos_constraint.weight = 1.0\n        constraints.position_constraints.append(pos_constraint)\n\n        # Orientation constraint (strict to preserve gripper orientation)\n        ori_constraint = OrientationConstraint()\n        ori_constraint.header.frame_id = self.base_frame\n        ori_constraint.link_name = self.gripper_frame\n        ori_constraint.orientation = target_pose.orientation\n        ori_constraint.absolute_x_axis_tolerance = 0.005\n        ori_constraint.absolute_y_axis_tolerance = 0.005\n        ori_constraint.absolute_z_axis_tolerance = 0.005\n        ori_constraint.weight = 1.0\n        constraints.orientation_constraints.append(ori_constraint)\n\n        motion_req.goal_constraints.append(constraints)\n\n        # Call motion planning service\n        future = self.client.call_async(request)\n        rclpy.spin_until_future_complete(self, future)\n\n        if future.result() is None or future.result().motion_plan_response.error_code.val != MoveItErrorCodes.SUCCESS:\n            self.get_logger().error(f'Failed to plan motion to {stage_name}: {future.result().motion_plan_response.error_code.val if future.result() else \"No response\"}')\n            return None\n\n        self.get_logger().info(f'Successfully planned motion to {stage_name}')\n        return future.result().motion_plan_response.trajectory\n\n    def execute_trajectory(self, trajectory, stage_name):\n        # Adjust trajectory speed and acceleration\n        for point in trajectory.joint_trajectory.points:\n            if point.velocities:\n                point.velocities = [min(max(v, -self.max_velocity), self.max_velocity) for v in point.velocities]\n            if point.accelerations:\n                point.accelerations = [min(max(a, -self.max_acceleration), self.max_acceleration) for a in point.accelerations]\n\n        # Execute trajectory\n        goal_msg = ExecuteTrajectory.Goal()\n        goal_msg.trajectory = trajectory\n\n        send_goal_future = self.execute_client.send_goal_async(goal_msg)\n        rclpy.spin_until_future_complete(self, send_goal_future)\n\n        if not send_goal_future.result():\n            self.get_logger().error(f'Failed to send trajectory goal for {stage_name}')\n            return False\n\n        goal_handle = send_goal_future.result()\n        result_future = goal_handle.get_result_async()\n        rclpy.spin_until_future_complete(self, result_future)\n\n        if result_future.result():\n            self.get_logger().info(f'Successfully executed motion to {stage_name}')\n            return True\n        else:\n            self.get_logger().error(f'Trajectory execution to {stage_name} failed')\n            return False\n\n    def move_to(self, stage_name):\n        target_pose = self.target_poses[stage_name]\n        trajectory = self.plan_cartesian_motion(target_pose, stage_name)\n        if trajectory is None:\n            return False\n        return self.execute_trajectory(trajectory, stage_name)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = PalletizingRobot()\n\n    # Wait for joint state\n    while node.current_joint_state is None and rclpy.ok():\n        rclpy.spin_once(node)\n        node.get_logger().info('Waiting for joint states...')\n\n    # Palletizing sequence\n    sequence = [\n        'home_pos',\n        'prepick_pos',\n        'pick_pos',\n        'postpick_pos',\n        'preplace_pos',\n        'place_pos',\n        'postplace_pos',\n        'home_pos'\n    ] \n\n    try:\n        while rclpy.ok():\n            for stage in sequence:\n                node.get_logger().info(f'Moving to {stage}...')\n                if not node.move_to(stage):\n                    node.get_logger().error(f'Failed to complete motion to {stage}. Aborting cycle.')\n                    break\n            else:\n                node.get_logger().info('Completed one palletizing cycle. Repeating...')\n    except KeyboardInterrupt:\n        node.get_logger().info('Stopped by user.')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()"], "question_code": ["#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom moveit_msgs.srv import GetMotionPlan\nfrom moveit_msgs.msg import MotionPlanRequest, RobotState, Constraints, PositionConstraint, OrientationConstraint, MoveItErrorCodes\nfrom geometry_msgs.msg import Pose, Point, Quaternion, Vector3\nfrom shape_msgs.msg import SolidPrimitive\nfrom sensor_msgs.msg import JointState\nfrom moveit_msgs.action import ExecuteTrajectory\nfrom rclpy.action import ActionClient\n\nclass PalletizingRobot(Node):\n    def __init__(self):\n        super().__init__('palletizing_robot')\n\n        # Service client for motion planning\n        self.client = self.create_client(GetMotionPlan, 'plan_kinematic_path')\n        while not self.client.wait_for_service(timeout_sec=1.0):\n            self.get_logger().info('Waiting for plan_kinematic_path service...')\n        self.get_logger().info('Motion planning service available!')\n\n        # Action client for trajectory execution\n        self.execute_client = ActionClient(self, ExecuteTrajectory, 'execute_trajectory')\n        while not self.execute_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().info('Waiting for execute_trajectory action server...')\n        self.get_logger().info('Trajectory execution server available!')\n\n        # Subscribe to joint states\n        self.joint_state_sub = self.create_subscription(JointState, 'joint_states', self.joint_state_callback, 10)\n        self.current_joint_state = None\n\n        # Robot configuration\n        self.group_name = &quot;fairino10_v6_group&quot;\n        self.base_frame = &quot;base_link&quot;\n        self.gripper_frame = &quot;grasp_frame&quot;\n\n        # Define target poses (gripper frame relative to base_link)\n        self.target_poses = {\n            'prepick_pos': Pose(\n                position=Point(x=0.800, y=-0.050, z=0.510),\n                orientation=Quaternion(x=0.000, y=0.000, z=0.000, w=1.000)\n            ),\n            'pick_pos': Pose(\n                position=Point(x=0.800, y=-0.050, z=0.365),  # 0.315 + 0.05\n                orientation=Quaternion(x=0.000, y=0.000, z=0.000, w=1.000)\n            ),\n            'postpick_pos': Pose(\n                position=Point(x=0.800, y=-0.050, z=0.510),\n                orientation=Quaternion(x=0.000, y=0.000, z=0.000, w=1.000)\n            ),\n            'preplace_pos': Pose(\n                position=Point(x=0.763, y=0.007, z=0.518),\n                orientation=Quaternion(x=-0.052, y=-0.009, z=0.661, w=0.748)\n            ),\n            'place_pos': Pose(\n                position=Point(x=0.799, y=-0.005, z=0.278),\n                orientation=Quaternion(x=-0.002, y=0.030, z=0.661, w=0.750)\n            ),\n            'postplace_pos': Pose(\n                position=Point(x=0.763, y=0.007, z=0.518),\n                orientation=Quaternion(x=-0.052, y=-0.009, z=0.661, w=0.748)\n            ),\n            'home_pos': Pose(\n                position=Point(x=0.092, y=-0.760, z=0.257),\n                orientation=Quaternion(x=-0.004, y=0.003, z=0.049, w=0.999)\n            )\n        }\n\n        # Motion parameters\n        self.max_velocity = 0.3  # m/s (adjustable)\n        self.max_acceleration = 0.3  # m/s^2 (adjustable)\n\n    def joint_state_callback(self, msg):\n        self.current_joint_state = msg\n\n    def plan_cartesian_motion(self, target_pose, stage_name):\n        if self.current_joint_state is None:\n            self.get_logger().error('No current joint state available!')\n            return None\n\n        # Motion plan request\n        request = GetMotionPlan.Request()\n        motion_req = request.motion_plan_request\n\n        # Configure motion request\n        motion_req.group_name = self.group_name\n        motion_req.planner_id = &quot;pilz_industrial_motion_planner/LIN&quot;\n        motion_req.num_planning_attempts = 10\n        motion_req.allowed_planning_time = 5.0\n        motion_req.max_velocity_scaling_factor = 1.0  # Adjusted in execution\n        motion_req.max_acceleration_scaling_factor = 1.0  # Adjusted in execution\n\n        # Workspace parameters\n        motion_req.workspace_parameters.header.frame_id = self.base_frame\n        motion_req.workspace_parameters.min_corner = Vector3(x=-2.0, y=-2.0, z=-2.0)\n        motion_req.workspace_parameters.max_corner = Vector3(x=2.0, y=2.0, z=2.0)\n\n        # Start state\n        motion_req.start_state.joint_state = self.current_joint_state\n\n        # Goal constraints\n        constraints = Constraints()\n\n        # Position constraint (tight tolerance for Cartesian precision)\n        pos_constraint = PositionConstraint()\n        pos_constraint.header.frame_id = self.base_frame\n        pos_constraint.link_name = self.gripper_frame\n        pos_constraint.constraint_region.primitives.append(SolidPrimitive(type=SolidPrimitive.SPHERE, dimensions=[0.001]))\n        pos_constraint.constraint_region.primitive_poses.append(target_pose)\n        pos_constraint.weight = 1.0\n        constraints.position_constraints.append(pos_constraint)\n\n        # Orientation constraint (strict to preserve gripper orientation)\n        ori_constraint = OrientationConstraint()\n        ori_constraint.header.frame_id = self.base_frame\n        ori_constraint.link_name = self.gripper_frame\n        ori_constraint.orientation = target_pose.orientation\n        ori_constraint.absolute_x_axis_tolerance = 0.005\n        ori_constraint.absolute_y_axis_tolerance = 0.005\n        ori_constraint.absolute_z_axis_tolerance = 0.005\n        ori_constraint.weight = 1.0\n        constraints.orientation_constraints.append(ori_constraint)\n\n        motion_req.goal_constraints.append(constraints)\n\n        # Call motion planning service\n        future = self.client.call_async(request)\n        rclpy.spin_until_future_complete(self, future)\n\n        if future.result() is None or future.result().motion_plan_response.error_code.val != MoveItErrorCodes.SUCCESS:\n            self.get_logger().error(f'Failed to plan motion to {stage_name}: {future.result().motion_plan_response.error_code.val if future.result() else &quot;No response&quot;}')\n            return None\n\n        self.get_logger().info(f'Successfully planned motion to {stage_name}')\n        return future.result().motion_plan_response.trajectory\n\n    def execute_trajectory(self, trajectory, stage_name):\n        # Adjust trajectory speed and acceleration\n        for point in trajectory.joint_trajectory.points:\n            if point.velocities:\n                point.velocities = [min(max(v, -self.max_velocity), self.max_velocity) for v in point.velocities]\n            if point.accelerations:\n                point.accelerations = [min(max(a, -self.max_acceleration), self.max_acceleration) for a in point.accelerations]\n\n        # Execute trajectory\n        goal_msg = ExecuteTrajectory.Goal()\n        goal_msg.trajectory = trajectory\n\n        send_goal_future = self.execute_client.send_goal_async(goal_msg)\n        rclpy.spin_until_future_complete(self, send_goal_future)\n\n        if not send_goal_future.result():\n            self.get_logger().error(f'Failed to send trajectory goal for {stage_name}')\n            return False\n\n        goal_handle = send_goal_future.result()\n        result_future = goal_handle.get_result_async()\n        rclpy.spin_until_future_complete(self, result_future)\n\n        if result_future.result():\n            self.get_logger().info(f'Successfully executed motion to {stage_name}')\n            return True\n        else:\n            self.get_logger().error(f'Trajectory execution to {stage_name} failed')\n            return False\n\n    def move_to(self, stage_name):\n        target_pose = self.target_poses[stage_name]\n        trajectory = self.plan_cartesian_motion(target_pose, stage_name)\n        if trajectory is None:\n            return False\n        return self.execute_trajectory(trajectory, stage_name)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = PalletizingRobot()\n\n    # Wait for joint state\n    while node.current_joint_state is None and rclpy.ok():\n        rclpy.spin_once(node)\n        node.get_logger().info('Waiting for joint states...')\n\n    # Palletizing sequence\n    sequence = [\n        'home_pos',\n        'prepick_pos',\n        'pick_pos',\n        'postpick_pos',\n        'preplace_pos',\n        'place_pos',\n        'postplace_pos',\n        'home_pos'\n    ] \n\n    try:\n        while rclpy.ok():\n            for stage in sequence:\n                node.get_logger().info(f'Moving to {stage}...')\n                if not node.move_to(stage):\n                    node.get_logger().error(f'Failed to complete motion to {stage}. Aborting cycle.')\n                    break\n            else:\n                node.get_logger().info('Completed one palletizing cycle. Repeating...')\n    except KeyboardInterrupt:\n        node.get_logger().info('Stopped by user.')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"], "quote": [], "url": "https://stackoverflow.com/questions/79530657/issue-with-using-pilz-industrial-motion-planner-in-python-script", "answer": [], "answer_code": []},
{"title": "rplidar works from usb but does not work from raspberyy pi gpio", "time": 1742619574, "post_content": ["I have a problem, the lidar works through a TTL converter from USB to rasperri pi, but does not work through a gpio. I use ROS Kinetic and raspberry pi 4.\nPackage for rplidar. At \"rplidar_c1.launch\" file i replaced  \"serial_port\"'s value from /dev/ttyUSB0 to /dev/tty/S0.I followed all these instructions for my ROS Kinetic. I remember once everything worked, but when I turned off the robot and left, and then came back and turned it on, nothing worked.\nIf i try to start rplidar with \"roslaunch rplidar_ros rplidar_c1.launch\", I'll be stuck here.enter image description here\nEvery time I check all connections. Multimeter shows 4.69 volts on red and blue lidar wire. I read documentation and it says there that the minimum voltage should be 4.8 volts. How can i fix this problem?"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79526969/rplidar-works-from-usb-but-does-not-work-from-raspberyy-pi-gpio", "answer": [], "answer_code": []},
{"title": "Issues with SkyController Remapping on Ubuntu 22.04 & ROS 2", "time": 1740870983, "post_content": ["I am conducting research with the Bebop 2 and encountering issues with the SkyController. My goal is to remap the controller and modify the drone's command inputs. While I could use another joystick, such as a PlayStation or Xbox controller, I still need the SkyController\u2019s Wi-Fi antenna to extend the drone\u2019s range.\nI am attempting to achieve this using ROS 2 but have encountered two main problems:\nUbuntu 22.04 does not recognize the SkyController as a joystick\u2014it does not appear on any port. I've tried via USB-C and Bluetooth, but it didn't appear anything to connect.\nI need to intercept the direct commands from the controller to the drone so that they are processed only through the computer using ROS.\n\nNote: I am not using the parrot app. I want to control everything on my computer with the SkyController via ROS.\nIn summary, what I want to do is use the SkyController as a Wi-Fi range extender, prevent it from sending packets to the drone, and remap its buttons so I can send commands using ROS.\nAny help would be greatly appreciated!\nBest regards\nAbout the communication, I've tried sudo iptables -D OUTPUT -d <ID> -j DROP on Ubuntu 22.04 to interrupt it, but it didn't work. Not sure if it should work, but it was supposed to stop the controller of sending packages to the drone.\nAnd the recognition issue, the command lsusb doesn't show anything different when a plug the SkyController. I've also searched on typec folder, but nothing was found. Bluetooh scan on found nothing too. The controller should appear as js0, it works when a plug a Xbox joystick.\n`"], "question_code": ["Ubuntu 22.04 does not recognize the SkyController as a joystick\u2014it does not appear on any port. I've tried via USB-C and Bluetooth, but it didn't appear anything to connect.\nI need to intercept the direct commands from the controller to the drone so that they are processed only through the computer using ROS.\n", "sudo iptables -D OUTPUT -d &lt;ID&gt; -j DROP", "lsusb", "typec", "scan on", "js0"], "quote": [], "url": "https://stackoverflow.com/questions/79478412/issues-with-skycontroller-remapping-on-ubuntu-22-04-ros-2", "answer": [], "answer_code": []},
{"title": "Setup Nav2 with ROS jazzy on real hardware", "time": 1740859034, "post_content": ["I want to build mobile robot. I am using raspberry pi 5, YDLidar X3, ROS jazzy, slam toolbox and want to add navigation to my robot(nav2). Also I should mention that I am using motors without encoders.\nIs it possible to run nav2 without encoders? Currently I am using odometry from lidar using this package: https://github.com/MAPIRlab/rf2o_laser_odometry\nMy transforms looks like this\n\nmy xacro file looks like\n\n\n \n<robot name=\"my_robot\" xmlns:xacro=\"http://www.ros.org/wiki/xacro\">\n    <!-- Constants/Properties -->\n    <xacro:property name=\"base_width\" value=\"0.4\"/>\n    <xacro:property name=\"base_length\" value=\"0.6\"/>\n    <xacro:property name=\"base_height\" value=\"0.2\"/>\n    \n    <xacro:property name=\"wheel_radius\" value=\"0.1\"/>\n    <xacro:property name=\"wheel_length\" value=\"0.05\"/>\n    <xacro:property name=\"wheel_offset_z\" value=\"-0.1\"/>\n    <xacro:property name=\"wheel_offset_y\" value=\"0.2\"/>\n    <xacro:property name=\"wheel_offset_x\" value=\"-0.1\"/>\n    \n    <xacro:property name=\"caster_radius\" value=\"0.05\"/>\n    <xacro:property name=\"caster_offset_x\" value=\"0.2\"/>\n    <xacro:property name=\"caster_offset_z\" value=\"-0.15\"/>\n    \n    <xacro:property name=\"lidar_radius\" value=\"0.1\"/>\n    <xacro:property name=\"lidar_length\" value=\"0.06\"/>\n    <xacro:property name=\"lidar_offset_z\" value=\"0.13\"/>\n\n    <!-- Materials -->\n    <material name=\"grey\">\n        <color rgba=\"0.5 0.5 0.5 1\"/>\n    </material>\n    <material name=\"blue\">\n        <color rgba=\"0 0 0.5 1\"/>\n    </material>\n\n    <!-- Wheel macro -->\n    <xacro:macro name=\"wheel\" params=\"prefix reflect\">\n        <joint name=\"base_${prefix}_wheel_joint\" type=\"fixed\">\n            <parent link=\"base_link\"/>\n            <child link=\"${prefix}_wheel\"/>\n            <origin xyz=\"${wheel_offset_x} ${reflect * wheel_offset_y} ${wheel_offset_z}\" rpy=\"0 0 0\"/>\n        </joint>\n        <link name=\"${prefix}_wheel\">\n            <visual>\n                <geometry>\n                    <cylinder radius=\"${wheel_radius}\" length=\"${wheel_length}\"/>\n                </geometry>\n                <origin xyz=\"0 0 0\" rpy=\"1.57 0 0\"/>\n                <material name=\"grey\"/>\n            </visual>\n        </link>\n    </xacro:macro>\n\n    <!-- Base Footprint -->\n    <link name=\"base_footprint\"/>\n    \n    <joint name=\"base_joint\" type=\"fixed\">\n        <parent link=\"base_footprint\"/>\n        <child link=\"base_link\"/>\n        <origin xyz=\"0 0 ${base_height/2}\" rpy=\"0 0 0\"/>\n    </joint>\n\n    <!-- Base Link -->\n    <link name=\"base_link\">\n        <visual>\n            <geometry>\n                <box size=\"${base_length} ${base_width} ${base_height}\"/>\n            </geometry>\n            <origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n            <material name=\"blue\"/>\n        </visual>\n    </link>\n\n    <!-- LIDAR -->\n    <joint name=\"lidar_joint\" type=\"fixed\">\n        <parent link=\"base_link\"/>\n        <child link=\"lidar_link\"/>\n        <origin xyz=\"0 0 ${lidar_offset_z}\" rpy=\"0 0 0\"/>\n    </joint>\n    \n    <link name=\"lidar_link\">\n        <visual>\n            <geometry>\n                <cylinder radius=\"${lidar_radius}\" length=\"${lidar_length}\"/>\n            </geometry>\n            <origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n            <material name=\"grey\"/>\n        </visual>\n    </link>\n\n    <!-- Wheels -->\n    <xacro:wheel prefix=\"left\" reflect=\"1\"/>\n    <xacro:wheel prefix=\"right\" reflect=\"-1\"/>\n\n    <!-- Caster Wheel -->\n    <joint name=\"base_caster_wheel_joint\" type=\"fixed\">\n        <parent link=\"base_link\"/>\n        <child link=\"caster_wheel\"/>\n        <origin xyz=\"${caster_offset_x} 0 ${caster_offset_z}\" rpy=\"0 0 0\"/>\n    </joint>\n    \n    <link name=\"caster_wheel\">\n        <visual>\n            <geometry>\n                <sphere radius=\"${caster_radius}\"/>\n            </geometry>\n            <origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n            <material name=\"grey\"/>\n        </visual>\n    </link>\n</robot>\n\n\n\nI have move listener node for moving robot\n\n\nimport rclpy from rclpy.node import Node import gpiod from geometry_msgs.msg import Twist import time\n\nclass ArduinoBaseController(Node):\ndef init(self):\nsuper().init('arduino_base_controller')\n    # Define GPIO pins\n    self.motor_left_forward = 17   # Left motor forward\n    self.motor_left_backward = 27  # Left motor backward\n    self.motor_right_forward = 22  # Right motor forward\n    self.motor_right_backward = 23 # Right motor backward\n    \n    self.chip = gpiod.Chip('gpiochip4')\n\n    # Initialize GPIOs\n    self.left_forward = self.chip.get_line(self.motor_left_forward)\n    self.left_backward = self.chip.get_line(self.motor_left_backward)\n    self.right_forward = self.chip.get_line(self.motor_right_forward)\n    self.right_backward = self.chip.get_line(self.motor_right_backward)\n    \n    self.left_forward.request(consumer=\"Motor\", type=gpiod.LINE_REQ_DIR_OUT)\n    self.left_backward.request(consumer=\"Motor\", type=gpiod.LINE_REQ_DIR_OUT)\n    self.right_forward.request(consumer=\"Motor\", type=gpiod.LINE_REQ_DIR_OUT)\n    self.right_backward.request(consumer=\"Motor\", type=gpiod.LINE_REQ_DIR_OUT)\n\n    # Subscribe to /cmd_vel\n    self.create_subscription(Twist, '/cmd_vel', self.cmd_vel_callback, 10)\n    self.get_logger().info(\"Arduino Base Controller Node Initialized. Listening on /cmd_vel.\")\n\ndef stop_motors(self):\n    \"\"\" Stops all motors safely \"\"\"\n    self.left_forward.set_value(0)\n    self.left_backward.set_value(0)\n    self.right_forward.set_value(0)\n    self.right_backward.set_value(0)\n\ndef cmd_vel_callback(self, msg: Twist):\n    linear = msg.linear.x\n    angular = msg.angular.z\n    self.get_logger().info(f\"Received cmd_vel: linear.x = {linear}, angular.z = {angular}\")\n    \n    if linear > 0.05:  # Move Forward\n        self.get_logger().info(\"Command: Move Forward\")\n        self.left_forward.set_value(0)\n        self.left_backward.set_value(1)\n        self.right_forward.set_value(1)\n        self.right_backward.set_value(0)\n\n    elif linear < -0.05:  # Move Backward\n        self.get_logger().info(\"Command: Move Backward\")\n        self.left_forward.set_value(1)\n        self.left_backward.set_value(0)\n        self.right_forward.set_value(0)\n        self.right_backward.set_value(1)\n\n    elif angular > 0.05:  # Turn Left\n        self.get_logger().info(\"Command: Turn Left\")\n        self.left_forward.set_value(0)\n        self.left_backward.set_value(1)\n        self.right_forward.set_value(0)\n        self.right_backward.set_value(1)\n\n    elif angular < -0.05:  # Turn Right\n        self.get_logger().info(\"Command: Turn Right\")\n        self.left_forward.set_value(1)\n        self.left_backward.set_value(0)\n        self.right_forward.set_value(1)\n        self.right_backward.set_value(0)\n\n    else:  # Stop\n        self.get_logger().info(\"Command: Stop\")\n        self.stop_motors()\n        \n\ndef destroy_node(self):\n    \"\"\" Release GPIOs on shutdown \"\"\"\n    self.stop_motors()\n    self.left_forward.release()\n    self.left_backward.release()\n    self.right_forward.release()\n    self.right_backward.release()\n    super().destroy_node()\n\ndef main(args=None):\nrclpy.init(args=args)\nnode = ArduinoBaseController()\nrclpy.spin(node)\nnode.destroy_node()\nrclpy.shutdown()\nif name == 'main':\nmain()\n\nI start it as\nros2 run tf2_ros static_transform_publisher 0 0 0.13 0 0 0 base_link lidar_link\nros2 run move_listener move_listener   (topic is published and listen to data correctly)\nros2 run robot_state_publisher robot_state_publisher /home/dima/ros2_ws/src/my_robot.urdf\nros2 launch ydlidar_ros2_driver ydlidar_launch_view.py\nros2 launch rf2o_laser_odometry rf2o_laser_odometry.launch.py\nros2 launch nav2_bringup localization_launch.py map:=/home/dima/ros2_ws/src/maps/room.yaml (it works correctly and I can locate robot)\n\nThen I run navigation:\nros2 launch nav2_bringup navigation_launch.py use_sim_time:=False\n\nand when I setup Goal Pose in logs I receive\n[bt_navigator-5] [INFO] [1740857782.106966815] [bt_navigator]: Begin navigating from current location (0.26, -0.28) to (1.32, -0.26)\n[controller_server-1] [INFO] [1740857782.141517124] [controller_server]: Received a goal, begin computing control effort.\n[controller_server-1] [WARN] [1740857782.141642051] [controller_server]: No goal checker was specified in parameter 'current_goal_checker'. Server will use only plugin loaded general_goal_checker . This warning will appear once.\n[controller_server-1] [WARN] [1740857782.141674366] [controller_server]: No progress checker was specified in parameter 'current_progress_checker'. Server will use only plugin loaded progress_checker . This warning will appear once.\n[controller_server-1] [WARN] [1740857782.196578189] [controller_server]: Control loop missed its desired rate of 20.0000 Hz. Current loop rate is 18.2448 Hz.\n[bt_navigator-5] [WARN] [1740857782.197324103] [bt_navigator_navigate_to_pose_rclcpp_node]: Timed out while waiting for action server to acknowledge goal request for follow_path\n[bt_navigator-5] [WARN] [1740857782.197842478] [bt_navigator]: [navigate_to_pose] [ActionServer] Aborting handle.\n[bt_navigator-5] [ERROR] [1740857782.197984424] [bt_navigator]: Goal failed\n[controller_server-1] [WARN] [1740857782.269227152] [controller_server]: Control loop missed its desired rate of 20.0000 Hz. Current loop rate is 13.7792 Hz.\n[controller_server-1] [WARN] [1740857782.313207748] [controller_server]: Control loop missed its desired rate of 20.0000 Hz. Current loop rate is 22.8437 Hz.\n[collision_monitor-8] [ERROR] [1740857782.539174449] [getTransform]: Failed to get \"laser_frame\"->\"base_footprint\" frame transform: Lookup would require extrapolation into the future.  Requested time 1740857782.333532 but the latest data is at time 1740857782.161137, when looking up transform from frame [odom] to frame [base_footprint]\n[collision_monitor-8] [WARN] [1740857782.539311117] [collision_monitor]: Robot to stop due to invalid source. Either due to data not published yet, or to lack of new data received within the sensor timeout, or if impossible to transform data to base frame\n\nCould you please help me to resolve it?\nI would really appreciate any piece of advise, thank you"], "question_code": ["&lt;robot name=&quot;my_robot&quot; xmlns:xacro=&quot;http://www.ros.org/wiki/xacro&quot;&gt;\n    &lt;!-- Constants/Properties --&gt;\n    &lt;xacro:property name=&quot;base_width&quot; value=&quot;0.4&quot;/&gt;\n    &lt;xacro:property name=&quot;base_length&quot; value=&quot;0.6&quot;/&gt;\n    &lt;xacro:property name=&quot;base_height&quot; value=&quot;0.2&quot;/&gt;\n    \n    &lt;xacro:property name=&quot;wheel_radius&quot; value=&quot;0.1&quot;/&gt;\n    &lt;xacro:property name=&quot;wheel_length&quot; value=&quot;0.05&quot;/&gt;\n    &lt;xacro:property name=&quot;wheel_offset_z&quot; value=&quot;-0.1&quot;/&gt;\n    &lt;xacro:property name=&quot;wheel_offset_y&quot; value=&quot;0.2&quot;/&gt;\n    &lt;xacro:property name=&quot;wheel_offset_x&quot; value=&quot;-0.1&quot;/&gt;\n    \n    &lt;xacro:property name=&quot;caster_radius&quot; value=&quot;0.05&quot;/&gt;\n    &lt;xacro:property name=&quot;caster_offset_x&quot; value=&quot;0.2&quot;/&gt;\n    &lt;xacro:property name=&quot;caster_offset_z&quot; value=&quot;-0.15&quot;/&gt;\n    \n    &lt;xacro:property name=&quot;lidar_radius&quot; value=&quot;0.1&quot;/&gt;\n    &lt;xacro:property name=&quot;lidar_length&quot; value=&quot;0.06&quot;/&gt;\n    &lt;xacro:property name=&quot;lidar_offset_z&quot; value=&quot;0.13&quot;/&gt;\n\n    &lt;!-- Materials --&gt;\n    &lt;material name=&quot;grey&quot;&gt;\n        &lt;color rgba=&quot;0.5 0.5 0.5 1&quot;/&gt;\n    &lt;/material&gt;\n    &lt;material name=&quot;blue&quot;&gt;\n        &lt;color rgba=&quot;0 0 0.5 1&quot;/&gt;\n    &lt;/material&gt;\n\n    &lt;!-- Wheel macro --&gt;\n    &lt;xacro:macro name=&quot;wheel&quot; params=&quot;prefix reflect&quot;&gt;\n        &lt;joint name=&quot;base_${prefix}_wheel_joint&quot; type=&quot;fixed&quot;&gt;\n            &lt;parent link=&quot;base_link&quot;/&gt;\n            &lt;child link=&quot;${prefix}_wheel&quot;/&gt;\n            &lt;origin xyz=&quot;${wheel_offset_x} ${reflect * wheel_offset_y} ${wheel_offset_z}&quot; rpy=&quot;0 0 0&quot;/&gt;\n        &lt;/joint&gt;\n        &lt;link name=&quot;${prefix}_wheel&quot;&gt;\n            &lt;visual&gt;\n                &lt;geometry&gt;\n                    &lt;cylinder radius=&quot;${wheel_radius}&quot; length=&quot;${wheel_length}&quot;/&gt;\n                &lt;/geometry&gt;\n                &lt;origin xyz=&quot;0 0 0&quot; rpy=&quot;1.57 0 0&quot;/&gt;\n                &lt;material name=&quot;grey&quot;/&gt;\n            &lt;/visual&gt;\n        &lt;/link&gt;\n    &lt;/xacro:macro&gt;\n\n    &lt;!-- Base Footprint --&gt;\n    &lt;link name=&quot;base_footprint&quot;/&gt;\n    \n    &lt;joint name=&quot;base_joint&quot; type=&quot;fixed&quot;&gt;\n        &lt;parent link=&quot;base_footprint&quot;/&gt;\n        &lt;child link=&quot;base_link&quot;/&gt;\n        &lt;origin xyz=&quot;0 0 ${base_height/2}&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;/joint&gt;\n\n    &lt;!-- Base Link --&gt;\n    &lt;link name=&quot;base_link&quot;&gt;\n        &lt;visual&gt;\n            &lt;geometry&gt;\n                &lt;box size=&quot;${base_length} ${base_width} ${base_height}&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0 0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;material name=&quot;blue&quot;/&gt;\n        &lt;/visual&gt;\n    &lt;/link&gt;\n\n    &lt;!-- LIDAR --&gt;\n    &lt;joint name=&quot;lidar_joint&quot; type=&quot;fixed&quot;&gt;\n        &lt;parent link=&quot;base_link&quot;/&gt;\n        &lt;child link=&quot;lidar_link&quot;/&gt;\n        &lt;origin xyz=&quot;0 0 ${lidar_offset_z}&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;/joint&gt;\n    \n    &lt;link name=&quot;lidar_link&quot;&gt;\n        &lt;visual&gt;\n            &lt;geometry&gt;\n                &lt;cylinder radius=&quot;${lidar_radius}&quot; length=&quot;${lidar_length}&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0 0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;material name=&quot;grey&quot;/&gt;\n        &lt;/visual&gt;\n    &lt;/link&gt;\n\n    &lt;!-- Wheels --&gt;\n    &lt;xacro:wheel prefix=&quot;left&quot; reflect=&quot;1&quot;/&gt;\n    &lt;xacro:wheel prefix=&quot;right&quot; reflect=&quot;-1&quot;/&gt;\n\n    &lt;!-- Caster Wheel --&gt;\n    &lt;joint name=&quot;base_caster_wheel_joint&quot; type=&quot;fixed&quot;&gt;\n        &lt;parent link=&quot;base_link&quot;/&gt;\n        &lt;child link=&quot;caster_wheel&quot;/&gt;\n        &lt;origin xyz=&quot;${caster_offset_x} 0 ${caster_offset_z}&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;/joint&gt;\n    \n    &lt;link name=&quot;caster_wheel&quot;&gt;\n        &lt;visual&gt;\n            &lt;geometry&gt;\n                &lt;sphere radius=&quot;${caster_radius}&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0 0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;material name=&quot;grey&quot;/&gt;\n        &lt;/visual&gt;\n    &lt;/link&gt;\n&lt;/robot&gt;\n", "import rclpy from rclpy.node import Node import gpiod from geometry_msgs.msg import Twist import time\n", "    # Define GPIO pins\n    self.motor_left_forward = 17   # Left motor forward\n    self.motor_left_backward = 27  # Left motor backward\n    self.motor_right_forward = 22  # Right motor forward\n    self.motor_right_backward = 23 # Right motor backward\n    \n    self.chip = gpiod.Chip('gpiochip4')\n\n    # Initialize GPIOs\n    self.left_forward = self.chip.get_line(self.motor_left_forward)\n    self.left_backward = self.chip.get_line(self.motor_left_backward)\n    self.right_forward = self.chip.get_line(self.motor_right_forward)\n    self.right_backward = self.chip.get_line(self.motor_right_backward)\n    \n    self.left_forward.request(consumer=&quot;Motor&quot;, type=gpiod.LINE_REQ_DIR_OUT)\n    self.left_backward.request(consumer=&quot;Motor&quot;, type=gpiod.LINE_REQ_DIR_OUT)\n    self.right_forward.request(consumer=&quot;Motor&quot;, type=gpiod.LINE_REQ_DIR_OUT)\n    self.right_backward.request(consumer=&quot;Motor&quot;, type=gpiod.LINE_REQ_DIR_OUT)\n\n    # Subscribe to /cmd_vel\n    self.create_subscription(Twist, '/cmd_vel', self.cmd_vel_callback, 10)\n    self.get_logger().info(&quot;Arduino Base Controller Node Initialized. Listening on /cmd_vel.&quot;)\n\ndef stop_motors(self):\n    &quot;&quot;&quot; Stops all motors safely &quot;&quot;&quot;\n    self.left_forward.set_value(0)\n    self.left_backward.set_value(0)\n    self.right_forward.set_value(0)\n    self.right_backward.set_value(0)\n\ndef cmd_vel_callback(self, msg: Twist):\n    linear = msg.linear.x\n    angular = msg.angular.z\n    self.get_logger().info(f&quot;Received cmd_vel: linear.x = {linear}, angular.z = {angular}&quot;)\n    \n    if linear &gt; 0.05:  # Move Forward\n        self.get_logger().info(&quot;Command: Move Forward&quot;)\n        self.left_forward.set_value(0)\n        self.left_backward.set_value(1)\n        self.right_forward.set_value(1)\n        self.right_backward.set_value(0)\n\n    elif linear &lt; -0.05:  # Move Backward\n        self.get_logger().info(&quot;Command: Move Backward&quot;)\n        self.left_forward.set_value(1)\n        self.left_backward.set_value(0)\n        self.right_forward.set_value(0)\n        self.right_backward.set_value(1)\n\n    elif angular &gt; 0.05:  # Turn Left\n        self.get_logger().info(&quot;Command: Turn Left&quot;)\n        self.left_forward.set_value(0)\n        self.left_backward.set_value(1)\n        self.right_forward.set_value(0)\n        self.right_backward.set_value(1)\n\n    elif angular &lt; -0.05:  # Turn Right\n        self.get_logger().info(&quot;Command: Turn Right&quot;)\n        self.left_forward.set_value(1)\n        self.left_backward.set_value(0)\n        self.right_forward.set_value(1)\n        self.right_backward.set_value(0)\n\n    else:  # Stop\n        self.get_logger().info(&quot;Command: Stop&quot;)\n        self.stop_motors()\n        \n\ndef destroy_node(self):\n    &quot;&quot;&quot; Release GPIOs on shutdown &quot;&quot;&quot;\n    self.stop_motors()\n    self.left_forward.release()\n    self.left_backward.release()\n    self.right_forward.release()\n    self.right_backward.release()\n    super().destroy_node()\n", "ros2 run tf2_ros static_transform_publisher 0 0 0.13 0 0 0 base_link lidar_link\nros2 run move_listener move_listener   (topic is published and listen to data correctly)\nros2 run robot_state_publisher robot_state_publisher /home/dima/ros2_ws/src/my_robot.urdf\nros2 launch ydlidar_ros2_driver ydlidar_launch_view.py\nros2 launch rf2o_laser_odometry rf2o_laser_odometry.launch.py\nros2 launch nav2_bringup localization_launch.py map:=/home/dima/ros2_ws/src/maps/room.yaml (it works correctly and I can locate robot)\n", "ros2 launch nav2_bringup navigation_launch.py use_sim_time:=False\n", "[bt_navigator-5] [INFO] [1740857782.106966815] [bt_navigator]: Begin navigating from current location (0.26, -0.28) to (1.32, -0.26)\n[controller_server-1] [INFO] [1740857782.141517124] [controller_server]: Received a goal, begin computing control effort.\n[controller_server-1] [WARN] [1740857782.141642051] [controller_server]: No goal checker was specified in parameter 'current_goal_checker'. Server will use only plugin loaded general_goal_checker . This warning will appear once.\n[controller_server-1] [WARN] [1740857782.141674366] [controller_server]: No progress checker was specified in parameter 'current_progress_checker'. Server will use only plugin loaded progress_checker . This warning will appear once.\n[controller_server-1] [WARN] [1740857782.196578189] [controller_server]: Control loop missed its desired rate of 20.0000 Hz. Current loop rate is 18.2448 Hz.\n[bt_navigator-5] [WARN] [1740857782.197324103] [bt_navigator_navigate_to_pose_rclcpp_node]: Timed out while waiting for action server to acknowledge goal request for follow_path\n[bt_navigator-5] [WARN] [1740857782.197842478] [bt_navigator]: [navigate_to_pose] [ActionServer] Aborting handle.\n[bt_navigator-5] [ERROR] [1740857782.197984424] [bt_navigator]: Goal failed\n[controller_server-1] [WARN] [1740857782.269227152] [controller_server]: Control loop missed its desired rate of 20.0000 Hz. Current loop rate is 13.7792 Hz.\n[controller_server-1] [WARN] [1740857782.313207748] [controller_server]: Control loop missed its desired rate of 20.0000 Hz. Current loop rate is 22.8437 Hz.\n[collision_monitor-8] [ERROR] [1740857782.539174449] [getTransform]: Failed to get &quot;laser_frame&quot;-&gt;&quot;base_footprint&quot; frame transform: Lookup would require extrapolation into the future.  Requested time 1740857782.333532 but the latest data is at time 1740857782.161137, when looking up transform from frame [odom] to frame [base_footprint]\n[collision_monitor-8] [WARN] [1740857782.539311117] [collision_monitor]: Robot to stop due to invalid source. Either due to data not published yet, or to lack of new data received within the sensor timeout, or if impossible to transform data to base frame\n"], "quote": ["<robot name=\"my_robot\" xmlns:xacro=\"http://www.ros.org/wiki/xacro\">\n    <!-- Constants/Properties -->\n    <xacro:property name=\"base_width\" value=\"0.4\"/>\n    <xacro:property name=\"base_length\" value=\"0.6\"/>\n    <xacro:property name=\"base_height\" value=\"0.2\"/>\n    \n    <xacro:property name=\"wheel_radius\" value=\"0.1\"/>\n    <xacro:property name=\"wheel_length\" value=\"0.05\"/>\n    <xacro:property name=\"wheel_offset_z\" value=\"-0.1\"/>\n    <xacro:property name=\"wheel_offset_y\" value=\"0.2\"/>\n    <xacro:property name=\"wheel_offset_x\" value=\"-0.1\"/>\n    \n    <xacro:property name=\"caster_radius\" value=\"0.05\"/>\n    <xacro:property name=\"caster_offset_x\" value=\"0.2\"/>\n    <xacro:property name=\"caster_offset_z\" value=\"-0.15\"/>\n    \n    <xacro:property name=\"lidar_radius\" value=\"0.1\"/>\n    <xacro:property name=\"lidar_length\" value=\"0.06\"/>\n    <xacro:property name=\"lidar_offset_z\" value=\"0.13\"/>\n\n    <!-- Materials -->\n    <material name=\"grey\">\n        <color rgba=\"0.5 0.5 0.5 1\"/>\n    </material>\n    <material name=\"blue\">\n        <color rgba=\"0 0 0.5 1\"/>\n    </material>\n\n    <!-- Wheel macro -->\n    <xacro:macro name=\"wheel\" params=\"prefix reflect\">\n        <joint name=\"base_${prefix}_wheel_joint\" type=\"fixed\">\n            <parent link=\"base_link\"/>\n            <child link=\"${prefix}_wheel\"/>\n            <origin xyz=\"${wheel_offset_x} ${reflect * wheel_offset_y} ${wheel_offset_z}\" rpy=\"0 0 0\"/>\n        </joint>\n        <link name=\"${prefix}_wheel\">\n            <visual>\n                <geometry>\n                    <cylinder radius=\"${wheel_radius}\" length=\"${wheel_length}\"/>\n                </geometry>\n                <origin xyz=\"0 0 0\" rpy=\"1.57 0 0\"/>\n                <material name=\"grey\"/>\n            </visual>\n        </link>\n    </xacro:macro>\n\n    <!-- Base Footprint -->\n    <link name=\"base_footprint\"/>\n    \n    <joint name=\"base_joint\" type=\"fixed\">\n        <parent link=\"base_footprint\"/>\n        <child link=\"base_link\"/>\n        <origin xyz=\"0 0 ${base_height/2}\" rpy=\"0 0 0\"/>\n    </joint>\n\n    <!-- Base Link -->\n    <link name=\"base_link\">\n        <visual>\n            <geometry>\n                <box size=\"${base_length} ${base_width} ${base_height}\"/>\n            </geometry>\n            <origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n            <material name=\"blue\"/>\n        </visual>\n    </link>\n\n    <!-- LIDAR -->\n    <joint name=\"lidar_joint\" type=\"fixed\">\n        <parent link=\"base_link\"/>\n        <child link=\"lidar_link\"/>\n        <origin xyz=\"0 0 ${lidar_offset_z}\" rpy=\"0 0 0\"/>\n    </joint>\n    \n    <link name=\"lidar_link\">\n        <visual>\n            <geometry>\n                <cylinder radius=\"${lidar_radius}\" length=\"${lidar_length}\"/>\n            </geometry>\n            <origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n            <material name=\"grey\"/>\n        </visual>\n    </link>\n\n    <!-- Wheels -->\n    <xacro:wheel prefix=\"left\" reflect=\"1\"/>\n    <xacro:wheel prefix=\"right\" reflect=\"-1\"/>\n\n    <!-- Caster Wheel -->\n    <joint name=\"base_caster_wheel_joint\" type=\"fixed\">\n        <parent link=\"base_link\"/>\n        <child link=\"caster_wheel\"/>\n        <origin xyz=\"${caster_offset_x} 0 ${caster_offset_z}\" rpy=\"0 0 0\"/>\n    </joint>\n    \n    <link name=\"caster_wheel\">\n        <visual>\n            <geometry>\n                <sphere radius=\"${caster_radius}\"/>\n            </geometry>\n            <origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n            <material name=\"grey\"/>\n        </visual>\n    </link>\n</robot>", "import rclpy from rclpy.node import Node import gpiod from geometry_msgs.msg import Twist import time\n\nclass ArduinoBaseController(Node):\ndef init(self):\nsuper().init('arduino_base_controller')\n    # Define GPIO pins\n    self.motor_left_forward = 17   # Left motor forward\n    self.motor_left_backward = 27  # Left motor backward\n    self.motor_right_forward = 22  # Right motor forward\n    self.motor_right_backward = 23 # Right motor backward\n    \n    self.chip = gpiod.Chip('gpiochip4')\n\n    # Initialize GPIOs\n    self.left_forward = self.chip.get_line(self.motor_left_forward)\n    self.left_backward = self.chip.get_line(self.motor_left_backward)\n    self.right_forward = self.chip.get_line(self.motor_right_forward)\n    self.right_backward = self.chip.get_line(self.motor_right_backward)\n    \n    self.left_forward.request(consumer=\"Motor\", type=gpiod.LINE_REQ_DIR_OUT)\n    self.left_backward.request(consumer=\"Motor\", type=gpiod.LINE_REQ_DIR_OUT)\n    self.right_forward.request(consumer=\"Motor\", type=gpiod.LINE_REQ_DIR_OUT)\n    self.right_backward.request(consumer=\"Motor\", type=gpiod.LINE_REQ_DIR_OUT)\n\n    # Subscribe to /cmd_vel\n    self.create_subscription(Twist, '/cmd_vel', self.cmd_vel_callback, 10)\n    self.get_logger().info(\"Arduino Base Controller Node Initialized. Listening on /cmd_vel.\")\n\ndef stop_motors(self):\n    \"\"\" Stops all motors safely \"\"\"\n    self.left_forward.set_value(0)\n    self.left_backward.set_value(0)\n    self.right_forward.set_value(0)\n    self.right_backward.set_value(0)\n\ndef cmd_vel_callback(self, msg: Twist):\n    linear = msg.linear.x\n    angular = msg.angular.z\n    self.get_logger().info(f\"Received cmd_vel: linear.x = {linear}, angular.z = {angular}\")\n    \n    if linear > 0.05:  # Move Forward\n        self.get_logger().info(\"Command: Move Forward\")\n        self.left_forward.set_value(0)\n        self.left_backward.set_value(1)\n        self.right_forward.set_value(1)\n        self.right_backward.set_value(0)\n\n    elif linear < -0.05:  # Move Backward\n        self.get_logger().info(\"Command: Move Backward\")\n        self.left_forward.set_value(1)\n        self.left_backward.set_value(0)\n        self.right_forward.set_value(0)\n        self.right_backward.set_value(1)\n\n    elif angular > 0.05:  # Turn Left\n        self.get_logger().info(\"Command: Turn Left\")\n        self.left_forward.set_value(0)\n        self.left_backward.set_value(1)\n        self.right_forward.set_value(0)\n        self.right_backward.set_value(1)\n\n    elif angular < -0.05:  # Turn Right\n        self.get_logger().info(\"Command: Turn Right\")\n        self.left_forward.set_value(1)\n        self.left_backward.set_value(0)\n        self.right_forward.set_value(1)\n        self.right_backward.set_value(0)\n\n    else:  # Stop\n        self.get_logger().info(\"Command: Stop\")\n        self.stop_motors()\n        \n\ndef destroy_node(self):\n    \"\"\" Release GPIOs on shutdown \"\"\"\n    self.stop_motors()\n    self.left_forward.release()\n    self.left_backward.release()\n    self.right_forward.release()\n    self.right_backward.release()\n    super().destroy_node()\n\ndef main(args=None):\nrclpy.init(args=args)\nnode = ArduinoBaseController()\nrclpy.spin(node)\nnode.destroy_node()\nrclpy.shutdown()\nif name == 'main':\nmain()"], "url": "https://stackoverflow.com/questions/79478187/setup-nav2-with-ros-jazzy-on-real-hardware", "answer": [], "answer_code": []},
{"title": "How to move turtlebot3 without diff drive plugin? (ROS2)", "time": 1739365053, "post_content": ["I'm trying to move my turtlebot burger model on gazebo without diff_drive_controller. I commented diff drive plugin from the sdf file. I wrote a code but my robot still not moving.\nHere's my code:\n#include \"rclcpp/rclcpp.hpp\"\n#include \"geometry_msgs/msg/twist.hpp\"\n#include \"std_msgs/msg/float64.hpp\"\n#include \"sensor_msgs/msg/joint_state.hpp\"\n\nclass RobotController : public rclcpp::Node\n{\npublic:\n    RobotController() : Node(\"robot_controller\")\n    {\n        // cmd_vel subscriber\n        cmd_vel_subscriber_ = this->create_subscription<geometry_msgs::msg::Twist>(\n            \"/cmd_vel\", 10, std::bind(&RobotController::cmd_vel_callback, this, std::placeholders::_1));\n            \n        // joint_states publisher for wheels\n        joint_states_publisher_ = this->create_publisher<sensor_msgs::msg::JointState>(\"/joint_states\", 10);\n\n        // Get joint_state messages\n        joint_state_subscriber_ = this->create_subscription<sensor_msgs::msg::JointState>(\n            \"/joint_states\", 10, std::bind(&RobotController::joint_states_callback, this, std::placeholders::_1));\n    }\n\nprivate:\n    void cmd_vel_callback(const geometry_msgs::msg::Twist::SharedPtr msg)\n    {\n        double wheel_separation = 0.16;  // Distance between the wheels (m)\n        double wheel_radius = 0.03;      // Wheel radius (m)\n\n        double linear_force = msg->linear.x * 5.0;  // Converting to force with basic coef.\n        double angular_force = msg->angular.z * 2.0; // Angular force\n\n        // Calculate torques for both wheels \n        double left_wheel_effort = (linear_force - (wheel_separation / 2.0) * angular_force);\n        double right_wheel_effort = (linear_force + (wheel_separation / 2.0) * angular_force);\n\n        // Create JointState message\n        auto joint_state_msg = sensor_msgs::msg::JointState();\n        joint_state_msg.header.stamp = this->get_clock()->now();  // Zaman damgas\u0131\n        joint_state_msg.name.push_back(\"wheel_left_joint\");\n        joint_state_msg.name.push_back(\"wheel_right_joint\");\n\n        // Add position values as 0\n        joint_state_msg.position.push_back(0.0);  // Left wheel position (temp,0) \n        joint_state_msg.position.push_back(0.0);  // Right wheel positin (temp,0)\n\n        // Set the torque values of left and right wheels\n        joint_state_msg.effort.push_back(left_wheel_effort);\n        joint_state_msg.effort.push_back(right_wheel_effort);\n\n        // Publish JointState to joint_states topic\n        joint_states_publisher_->publish(joint_state_msg);\n\n        RCLCPP_INFO(this->get_logger(), \"Set Effort -> Left: %f, Right: %f\", left_wheel_effort, right_wheel_effort);\n    }\n\n    void joint_states_callback(const sensor_msgs::msg::JointState::SharedPtr msg)\n    {\n        double left_wheel_effort = 0.0;\n        double right_wheel_effort = 0.0;\n\n        // Control the torque values that come in the joint_state mesage \n        for (size_t i = 0; i < msg->name.size(); i++) {\n            if (msg->name[i] == \"wheel_left_joint\") {\n                left_wheel_effort = msg->effort[i];\n            }\n            if (msg->name[i] == \"wheel_right_joint\") {\n                right_wheel_effort = msg->effort[i];\n            }\n        }\n\n        // Log the incoming torques \n        RCLCPP_INFO(this->get_logger(), \"Effort Feedback -> Left: %f, Right: %f\", left_wheel_effort, right_wheel_effort);\n    }\n\n    rclcpp::Subscription<geometry_msgs::msg::Twist>::SharedPtr cmd_vel_subscriber_;\n    rclcpp::Publisher<sensor_msgs::msg::JointState>::SharedPtr joint_states_publisher_;\n    rclcpp::Subscription<sensor_msgs::msg::JointState>::SharedPtr joint_state_subscriber_;\n};\n\nint main(int argc, char **argv)\n{\n    rclcpp::init(argc, argv);\n    rclcpp::spin(std::make_shared<RobotController>());\n    rclcpp::shutdown();\n    return 0;\n}\n\nI wrote a code i used publishers and subscribers. In terminal i see joint states sub count 2 pub count 2. cmd vel sub count 1 pub count 1 but as i said my robot not moving"], "question_code": ["#include &quot;rclcpp/rclcpp.hpp&quot;\n#include &quot;geometry_msgs/msg/twist.hpp&quot;\n#include &quot;std_msgs/msg/float64.hpp&quot;\n#include &quot;sensor_msgs/msg/joint_state.hpp&quot;\n\nclass RobotController : public rclcpp::Node\n{\npublic:\n    RobotController() : Node(&quot;robot_controller&quot;)\n    {\n        // cmd_vel subscriber\n        cmd_vel_subscriber_ = this-&gt;create_subscription&lt;geometry_msgs::msg::Twist&gt;(\n            &quot;/cmd_vel&quot;, 10, std::bind(&amp;RobotController::cmd_vel_callback, this, std::placeholders::_1));\n            \n        // joint_states publisher for wheels\n        joint_states_publisher_ = this-&gt;create_publisher&lt;sensor_msgs::msg::JointState&gt;(&quot;/joint_states&quot;, 10);\n\n        // Get joint_state messages\n        joint_state_subscriber_ = this-&gt;create_subscription&lt;sensor_msgs::msg::JointState&gt;(\n            &quot;/joint_states&quot;, 10, std::bind(&amp;RobotController::joint_states_callback, this, std::placeholders::_1));\n    }\n\nprivate:\n    void cmd_vel_callback(const geometry_msgs::msg::Twist::SharedPtr msg)\n    {\n        double wheel_separation = 0.16;  // Distance between the wheels (m)\n        double wheel_radius = 0.03;      // Wheel radius (m)\n\n        double linear_force = msg-&gt;linear.x * 5.0;  // Converting to force with basic coef.\n        double angular_force = msg-&gt;angular.z * 2.0; // Angular force\n\n        // Calculate torques for both wheels \n        double left_wheel_effort = (linear_force - (wheel_separation / 2.0) * angular_force);\n        double right_wheel_effort = (linear_force + (wheel_separation / 2.0) * angular_force);\n\n        // Create JointState message\n        auto joint_state_msg = sensor_msgs::msg::JointState();\n        joint_state_msg.header.stamp = this-&gt;get_clock()-&gt;now();  // Zaman damgas\u0131\n        joint_state_msg.name.push_back(&quot;wheel_left_joint&quot;);\n        joint_state_msg.name.push_back(&quot;wheel_right_joint&quot;);\n\n        // Add position values as 0\n        joint_state_msg.position.push_back(0.0);  // Left wheel position (temp,0) \n        joint_state_msg.position.push_back(0.0);  // Right wheel positin (temp,0)\n\n        // Set the torque values of left and right wheels\n        joint_state_msg.effort.push_back(left_wheel_effort);\n        joint_state_msg.effort.push_back(right_wheel_effort);\n\n        // Publish JointState to joint_states topic\n        joint_states_publisher_-&gt;publish(joint_state_msg);\n\n        RCLCPP_INFO(this-&gt;get_logger(), &quot;Set Effort -&gt; Left: %f, Right: %f&quot;, left_wheel_effort, right_wheel_effort);\n    }\n\n    void joint_states_callback(const sensor_msgs::msg::JointState::SharedPtr msg)\n    {\n        double left_wheel_effort = 0.0;\n        double right_wheel_effort = 0.0;\n\n        // Control the torque values that come in the joint_state mesage \n        for (size_t i = 0; i &lt; msg-&gt;name.size(); i++) {\n            if (msg-&gt;name[i] == &quot;wheel_left_joint&quot;) {\n                left_wheel_effort = msg-&gt;effort[i];\n            }\n            if (msg-&gt;name[i] == &quot;wheel_right_joint&quot;) {\n                right_wheel_effort = msg-&gt;effort[i];\n            }\n        }\n\n        // Log the incoming torques \n        RCLCPP_INFO(this-&gt;get_logger(), &quot;Effort Feedback -&gt; Left: %f, Right: %f&quot;, left_wheel_effort, right_wheel_effort);\n    }\n\n    rclcpp::Subscription&lt;geometry_msgs::msg::Twist&gt;::SharedPtr cmd_vel_subscriber_;\n    rclcpp::Publisher&lt;sensor_msgs::msg::JointState&gt;::SharedPtr joint_states_publisher_;\n    rclcpp::Subscription&lt;sensor_msgs::msg::JointState&gt;::SharedPtr joint_state_subscriber_;\n};\n\nint main(int argc, char **argv)\n{\n    rclcpp::init(argc, argv);\n    rclcpp::spin(std::make_shared&lt;RobotController&gt;());\n    rclcpp::shutdown();\n    return 0;\n}\n"], "quote": [], "url": "https://stackoverflow.com/questions/79433139/how-to-move-turtlebot3-without-diff-drive-plugin-ros2", "answer": [], "answer_code": []},
{"title": "build target failed - DJI OSDK ROS Compiling error - catkin_make not working", "time": 1738941751, "post_content": ["I am using DJI OSDK 4.1.0 and DJI OSDK ROS 4.1.0 as well, but when after installing DJI OSDK, when I compile the DJI OSDK ROS in separate workspace, it gives me error:\n\n[ 76%] Generating Python code from SRV dji_osdk_ros/UploadWaypointV2Mission\n[ 76%] Generating Python code from SRV dji_osdk_ros/MissionStatus\n[ 76%] Generating Python code from SRV dji_osdk_ros/MissionHpUpdateRadius\n[ 76%] Generating C++ code from dji_osdk_ros/SetupCameraH264.srv\n[ 77%] Generating C++ code from dji_osdk_ros/DroneTaskControl.srv\n[ 77%] Generating C++ code from dji_osdk_ros/CameraFocusPoint.srv\n[ 77%] Generating Python code from SRV dji_osdk_ros/CameraStartShootBurstPhoto\n[ 77%] Generating Python code from SRV dji_osdk_ros/Activation\n[ 77%] Generating Python code from SRV dji_osdk_ros/SetCurrentAircraftLocAsHomePoint\n[ 78%] Generating Python code from SRV dji_osdk_ros/MissionWpSetSpeed\n[ 78%] Generating C++ code from dji_osdk_ros/SetHomePoint.srv\n[ 78%] Generating Python code from SRV dji_osdk_ros/FlightTaskControl\n[ 78%] Generating C++ code from dji_osdk_ros/InitWaypointV2Setting.srv\n[ 78%] Generating Python code from SRV dji_osdk_ros/DroneArmControl\n[ 78%] Generating C++ code from dji_osdk_ros/GetGoHomeAltitude.srv\n[ 78%] Generating C++ code from dji_osdk_ros/GetHMSData.srv\n[ 78%] Generating Python code from SRV dji_osdk_ros/GetSingleBatteryDynamicInfo\n[ 78%] Generating Python code from SRV dji_osdk_ros/GimbalAction\n[ 78%] Built target dji_osdk_ros_generate_messages_eus\n[ 78%] Generating Python code from SRV dji_osdk_ros/SetupCameraStream\n[ 79%] Generating Python code from SRV dji_osdk_ros/CameraStartShootAEBPhoto\n[ 80%] Generating C++ code from dji_osdk_ros/ResumeWaypointV2Mission.srv\n[ 80%] Generating C++ code from dji_osdk_ros/CameraAperture.srv\n[ 80%] Generating Python code from SRV dji_osdk_ros/CameraTapZoomPoint\n[ 80%] Generating C++ code from dji_osdk_ros/KillSwitch.srv\n[ 80%] Generating Python code from SRV dji_osdk_ros/MissionHpUpdateYawRate\n[ 80%] Generating Python code from SRV dji_osdk_ros/SDKControlAuthority\n[ 80%] Generating C++ code from dji_osdk_ros/MFIO.srv\n[ 80%] Generating C++ code from dji_osdk_ros/SetLocalPosRef.srv\n[ 80%] Generating Python code from SRV dji_osdk_ros/SetAvoidEnable\n[ 80%] Generating Python code from SRV dji_osdk_ros/ObtainControlAuthority\n[ 80%] Generating Python code from SRV dji_osdk_ros/SetJoystickMode\n[ 81%] Generating Python code from SRV dji_osdk_ros/JoystickAction\n[ 81%] Generating C++ code from dji_osdk_ros/CameraStopShootPhoto.srv\n[ 81%] Generating C++ code from dji_osdk_ros/MissionHpResetYaw.srv\n[ 82%] Generating C++ code from dji_osdk_ros/UploadWaypointV2Action.srv\n[ 82%] Generating Python code from SRV dji_osdk_ros/GetM300StereoParams\n[ 82%] Generating Python code from SRV dji_osdk_ros/SetHardSync\n[ 82%] Generating C++ code from dji_osdk_ros/CameraRecordVideoAction.srv\n[ 82%] Generating Python code from SRV dji_osdk_ros/MFIOSetValue\n[ 82%] Generating C++ code from dji_osdk_ros/CameraISO.srv\n[ 82%] Generating Python code from SRV dji_osdk_ros/MissionWpAction\n[ 82%] Generating Python code from SRV dji_osdk_ros/CameraZoomCtrl\n[ 83%] Generating Python code from SRV dji_osdk_ros/Stereo240pSubscription\n[ 83%] Generating C++ code from dji_osdk_ros/StopWaypointV2Mission.srv\n[ 83%] Generating Python code from SRV dji_osdk_ros/GenerateWaypointV2Action\n[ 83%] Generating Python code from SRV dji_osdk_ros/CameraSetZoomPara\n[ 83%] Generating C++ code from dji_osdk_ros/StartWaypointV2Mission.srv\n[ 83%] Generating C++ code from dji_osdk_ros/MissionHpUpload.srv\n[ 84%] Generating C++ code from dji_osdk_ros/MissionStatus.srv\n[ 84%] Generating C++ code from dji_osdk_ros/UploadWaypointV2Mission.srv\n[ 84%] Generating Python code from SRV dji_osdk_ros/SubscribeWaypointV2Event\n[ 84%] Generating Python code from SRV dji_osdk_ros/MissionWpGetSpeed\n[ 84%] Generating Python code from SRV dji_osdk_ros/CameraStartShootIntervalPhoto\n[ 85%] Generating Python code from SRV dji_osdk_ros/SetGlobalCruisespeed\n[ 85%] Generating Python code from SRV dji_osdk_ros/MissionHpGetInfo\n[ 85%] Generating Python code from SRV dji_osdk_ros/DownloadWaypointV2Mission\n[ 85%] Generating C++ code from dji_osdk_ros/MissionHpUpdateRadius.srv\n[ 85%] Generating C++ code from dji_osdk_ros/Activation.srv\n[ 85%] Generating C++ code from dji_osdk_ros/CameraStartShootBurstPhoto.srv\n[ 86%] Generating C++ code from dji_osdk_ros/MissionWpSetSpeed.srv\n[ 86%] Generating C++ code from dji_osdk_ros/SetCurrentAircraftLocAsHomePoint.srv\n[ 86%] Generating Python msg init.py for dji_osdk_ros\n[ 86%] Generating Python srv init.py for dji_osdk_ros\n[ 86%] Generating C++ code from dji_osdk_ros/FlightTaskControl.srv\n[ 86%] Generating C++ code from dji_osdk_ros/GetSingleBatteryDynamicInfo.srv\n[ 86%] Generating C++ code from dji_osdk_ros/DroneArmControl.srv\n[ 86%] Generating C++ code from dji_osdk_ros/SetupCameraStream.srv\n[ 86%] Generating C++ code from dji_osdk_ros/GimbalAction.srv\n[ 86%] Built target dji_osdk_ros_generate_messages_py\n[ 87%] Generating C++ code from dji_osdk_ros/CameraStartShootAEBPhoto.srv\n[ 87%] Generating C++ code from dji_osdk_ros/CameraTapZoomPoint.srv\n[ 87%] Generating C++ code from dji_osdk_ros/MissionHpUpdateYawRate.srv\n[ 87%] Generating C++ code from dji_osdk_ros/SDKControlAuthority.srv\n[ 87%] Generating C++ code from dji_osdk_ros/SetAvoidEnable.srv\n[ 87%] Generating C++ code from dji_osdk_ros/ObtainControlAuthority.srv\n[ 87%] Generating C++ code from dji_osdk_ros/SetJoystickMode.srv\n[ 88%] Generating C++ code from dji_osdk_ros/JoystickAction.srv\n[ 88%] Generating C++ code from dji_osdk_ros/GetM300StereoParams.srv\n[ 88%] Generating C++ code from dji_osdk_ros/SetHardSync.srv\n[ 88%] Generating C++ code from dji_osdk_ros/MFIOSetValue.srv\n[ 88%] Generating C++ code from dji_osdk_ros/MissionWpAction.srv\n[ 88%] Generating C++ code from dji_osdk_ros/CameraZoomCtrl.srv\n[ 89%] Generating C++ code from dji_osdk_ros/Stereo240pSubscription.srv\n[ 89%] Generating C++ code from dji_osdk_ros/GenerateWaypointV2Action.srv\n[ 89%] Generating C++ code from dji_osdk_ros/CameraSetZoomPara.srv\n[ 89%] Generating C++ code from dji_osdk_ros/SubscribeWaypointV2Event.srv\n[ 89%] Generating C++ code from dji_osdk_ros/MissionWpGetSpeed.srv\n[ 89%] Generating C++ code from dji_osdk_ros/CameraStartShootIntervalPhoto.srv\n[ 90%] Generating C++ code from dji_osdk_ros/SetGlobalCruisespeed.srv\n[ 90%] Generating C++ code from dji_osdk_ros/MissionHpGetInfo.srv\n[ 90%] Generating C++ code from dji_osdk_ros/DownloadWaypointV2Mission.srv\n[ 90%] Built target dji_osdk_ros_generate_messages_cpp\nScanning dependencies of target dji_osdk_ros_generate_messages\nScanning dependencies of target dji_osdk_ros\nScanning dependencies of target dji_sdk_node\n[ 90%] Built target dji_osdk_ros_generate_messages\n[ 90%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_mobile_comm.cpp.o\n[ 90%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/main.cpp.o\n[ 90%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_payload_comm.cpp.o\n[ 91%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_mission_services.cpp.o\n[ 91%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_publisher.cpp.o\n[ 91%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/vehicle_wrapper.cpp.o\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/vehicle_wrapper.cpp: In member function \u2018bool dji_osdk_ros::VehicleWrapper::moveByPositionOffset(const dji_osdk_ros::JoystickCommand&, int, float, float)\u2019:\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/vehicle_wrapper.cpp:1707:34: error: \u2018class DJI::OSDK::FlightController\u2019 has no member named \u2018emergencyBrakeAction\u2019\nvehicle->flightController->emergencyBrakeAction();\n^\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/vehicle_wrapper.cpp: In member function \u2018bool dji_osdk_ros::VehicleWrapper::emergencyBrake()\u2019:\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/vehicle_wrapper.cpp:1848:32: error: \u2018class DJI::OSDK::FlightController\u2019 has no member named \u2018emergencyBrakeAction\u2019\nvehicle->flightController->emergencyBrakeAction();\n^\nOnboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/build.make:158: recipe for target 'Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/vehicle_wrapper.cpp.o' failed\nmake[2]: *** [Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/vehicle_wrapper.cpp.o] Error 1\nmake[2]: *** Waiting for unfinished jobs....\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_control.cpp.o\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_services.cpp.o\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/dji_vehicle_node_mission_services.cpp: In member function \u2018bool dji_osdk_ros::VehicleNode::waypointV2GenerateActionsCallback(dji_osdk_ros::GenerateWaypointV2Action::Request&, dji_osdk_ros::GenerateWaypointV2Action::Response&)\u2019:\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/dji_vehicle_node_mission_services.cpp:800:24: error: \u2018DJI::OSDK::DJIWaypointV2CameraFocusParam {aka struct DJI::OSDK::DJIWaypointV2CameraFocusParam}\u2019 has no member named \u2018regionType\u2019\nfocusParam.regionType = request.actions[i].waypointV2CameraActuator\n^\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/dji_vehicle_node_mission_services.cpp:801:24: error: \u2018DJI::OSDK::DJIWaypointV2CameraFocusParam {aka struct DJI::OSDK::DJIWaypointV2CameraFocusParam}\u2019 has no member named \u2018width\u2019\nfocusParam.width = request.actions[i].waypointV2CameraActuator.focu\n^\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/dji_vehicle_node_mission_services.cpp:802:24: error: \u2018DJI::OSDK::DJIWaypointV2CameraFocusParam {aka struct DJI::OSDK::DJIWaypointV2CameraFocusParam}\u2019 has no member named \u2018height\u2019\nfocusParam.height = request.actions[i].waypointV2CameraActuator.foc\n^\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node.cpp.o\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_mission_services.cpp.o\nOnboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/build.make:62: recipe for target 'Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_mission_services.cpp.o' failed\nmake[2]: *** [Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_mission_services.cpp.o] Error 1\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_subscriber.cpp.o\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_publisher.cpp.o\nCMakeFiles/Makefile2:6514: recipe for target 'Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/all' failed\nmake[1]: *** [Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/all] Error 2\nmake[1]: *** Waiting for unfinished jobs....\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_mobile_comm.cpp.o\n[ 93%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_payload_comm.cpp.o\n[ 93%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_time_sync.cpp.o\n[ 93%] Building C object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir//dji_osdk_ros/modules/osdkhal_linux.c.o\n[ 93%] Building C object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir//dji_osdk_ros/modules/osdkosal_linux.c.o\n[ 93%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/dji_linux_environment.cpp.o\n[ 93%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/dji_linux_helpers.cpp.o\n[ 94%] Linking CXX executable /home/dji/catkin_ws/devel/lib/dji_osdk_ros/dji_sdk_node\n[ 94%] Built target dji_sdk_node\nMakefile:138: recipe for target 'all' failed\nmake: *** [all] Error 2\nInvoking \"make -j6 -l6\" failed\n\n\n\nCould anyone please share the link for both packages, which are compatible with each other. Could someone please tell the versions and share their corresponding links?\nI tried various versions 3.8.1 and several others, but I am not able to find the compatible ones."], "question_code": ["[ 76%] Generating Python code from SRV dji_osdk_ros/UploadWaypointV2Mission\n[ 76%] Generating Python code from SRV dji_osdk_ros/MissionStatus\n[ 76%] Generating Python code from SRV dji_osdk_ros/MissionHpUpdateRadius\n[ 76%] Generating C++ code from dji_osdk_ros/SetupCameraH264.srv\n[ 77%] Generating C++ code from dji_osdk_ros/DroneTaskControl.srv\n[ 77%] Generating C++ code from dji_osdk_ros/CameraFocusPoint.srv\n[ 77%] Generating Python code from SRV dji_osdk_ros/CameraStartShootBurstPhoto\n[ 77%] Generating Python code from SRV dji_osdk_ros/Activation\n[ 77%] Generating Python code from SRV dji_osdk_ros/SetCurrentAircraftLocAsHomePoint\n[ 78%] Generating Python code from SRV dji_osdk_ros/MissionWpSetSpeed\n[ 78%] Generating C++ code from dji_osdk_ros/SetHomePoint.srv\n[ 78%] Generating Python code from SRV dji_osdk_ros/FlightTaskControl\n[ 78%] Generating C++ code from dji_osdk_ros/InitWaypointV2Setting.srv\n[ 78%] Generating Python code from SRV dji_osdk_ros/DroneArmControl\n[ 78%] Generating C++ code from dji_osdk_ros/GetGoHomeAltitude.srv\n[ 78%] Generating C++ code from dji_osdk_ros/GetHMSData.srv\n[ 78%] Generating Python code from SRV dji_osdk_ros/GetSingleBatteryDynamicInfo\n[ 78%] Generating Python code from SRV dji_osdk_ros/GimbalAction\n[ 78%] Built target dji_osdk_ros_generate_messages_eus\n[ 78%] Generating Python code from SRV dji_osdk_ros/SetupCameraStream\n[ 79%] Generating Python code from SRV dji_osdk_ros/CameraStartShootAEBPhoto\n[ 80%] Generating C++ code from dji_osdk_ros/ResumeWaypointV2Mission.srv\n[ 80%] Generating C++ code from dji_osdk_ros/CameraAperture.srv\n[ 80%] Generating Python code from SRV dji_osdk_ros/CameraTapZoomPoint\n[ 80%] Generating C++ code from dji_osdk_ros/KillSwitch.srv\n[ 80%] Generating Python code from SRV dji_osdk_ros/MissionHpUpdateYawRate\n[ 80%] Generating Python code from SRV dji_osdk_ros/SDKControlAuthority\n[ 80%] Generating C++ code from dji_osdk_ros/MFIO.srv\n[ 80%] Generating C++ code from dji_osdk_ros/SetLocalPosRef.srv\n[ 80%] Generating Python code from SRV dji_osdk_ros/SetAvoidEnable\n[ 80%] Generating Python code from SRV dji_osdk_ros/ObtainControlAuthority\n[ 80%] Generating Python code from SRV dji_osdk_ros/SetJoystickMode\n[ 81%] Generating Python code from SRV dji_osdk_ros/JoystickAction\n[ 81%] Generating C++ code from dji_osdk_ros/CameraStopShootPhoto.srv\n[ 81%] Generating C++ code from dji_osdk_ros/MissionHpResetYaw.srv\n[ 82%] Generating C++ code from dji_osdk_ros/UploadWaypointV2Action.srv\n[ 82%] Generating Python code from SRV dji_osdk_ros/GetM300StereoParams\n[ 82%] Generating Python code from SRV dji_osdk_ros/SetHardSync\n[ 82%] Generating C++ code from dji_osdk_ros/CameraRecordVideoAction.srv\n[ 82%] Generating Python code from SRV dji_osdk_ros/MFIOSetValue\n[ 82%] Generating C++ code from dji_osdk_ros/CameraISO.srv\n[ 82%] Generating Python code from SRV dji_osdk_ros/MissionWpAction\n[ 82%] Generating Python code from SRV dji_osdk_ros/CameraZoomCtrl\n[ 83%] Generating Python code from SRV dji_osdk_ros/Stereo240pSubscription\n[ 83%] Generating C++ code from dji_osdk_ros/StopWaypointV2Mission.srv\n[ 83%] Generating Python code from SRV dji_osdk_ros/GenerateWaypointV2Action\n[ 83%] Generating Python code from SRV dji_osdk_ros/CameraSetZoomPara\n[ 83%] Generating C++ code from dji_osdk_ros/StartWaypointV2Mission.srv\n[ 83%] Generating C++ code from dji_osdk_ros/MissionHpUpload.srv\n[ 84%] Generating C++ code from dji_osdk_ros/MissionStatus.srv\n[ 84%] Generating C++ code from dji_osdk_ros/UploadWaypointV2Mission.srv\n[ 84%] Generating Python code from SRV dji_osdk_ros/SubscribeWaypointV2Event\n[ 84%] Generating Python code from SRV dji_osdk_ros/MissionWpGetSpeed\n[ 84%] Generating Python code from SRV dji_osdk_ros/CameraStartShootIntervalPhoto\n[ 85%] Generating Python code from SRV dji_osdk_ros/SetGlobalCruisespeed\n[ 85%] Generating Python code from SRV dji_osdk_ros/MissionHpGetInfo\n[ 85%] Generating Python code from SRV dji_osdk_ros/DownloadWaypointV2Mission\n[ 85%] Generating C++ code from dji_osdk_ros/MissionHpUpdateRadius.srv\n[ 85%] Generating C++ code from dji_osdk_ros/Activation.srv\n[ 85%] Generating C++ code from dji_osdk_ros/CameraStartShootBurstPhoto.srv\n[ 86%] Generating C++ code from dji_osdk_ros/MissionWpSetSpeed.srv\n[ 86%] Generating C++ code from dji_osdk_ros/SetCurrentAircraftLocAsHomePoint.srv\n[ 86%] Generating Python msg init.py for dji_osdk_ros\n[ 86%] Generating Python srv init.py for dji_osdk_ros\n[ 86%] Generating C++ code from dji_osdk_ros/FlightTaskControl.srv\n[ 86%] Generating C++ code from dji_osdk_ros/GetSingleBatteryDynamicInfo.srv\n[ 86%] Generating C++ code from dji_osdk_ros/DroneArmControl.srv\n[ 86%] Generating C++ code from dji_osdk_ros/SetupCameraStream.srv\n[ 86%] Generating C++ code from dji_osdk_ros/GimbalAction.srv\n[ 86%] Built target dji_osdk_ros_generate_messages_py\n[ 87%] Generating C++ code from dji_osdk_ros/CameraStartShootAEBPhoto.srv\n[ 87%] Generating C++ code from dji_osdk_ros/CameraTapZoomPoint.srv\n[ 87%] Generating C++ code from dji_osdk_ros/MissionHpUpdateYawRate.srv\n[ 87%] Generating C++ code from dji_osdk_ros/SDKControlAuthority.srv\n[ 87%] Generating C++ code from dji_osdk_ros/SetAvoidEnable.srv\n[ 87%] Generating C++ code from dji_osdk_ros/ObtainControlAuthority.srv\n[ 87%] Generating C++ code from dji_osdk_ros/SetJoystickMode.srv\n[ 88%] Generating C++ code from dji_osdk_ros/JoystickAction.srv\n[ 88%] Generating C++ code from dji_osdk_ros/GetM300StereoParams.srv\n[ 88%] Generating C++ code from dji_osdk_ros/SetHardSync.srv\n[ 88%] Generating C++ code from dji_osdk_ros/MFIOSetValue.srv\n[ 88%] Generating C++ code from dji_osdk_ros/MissionWpAction.srv\n[ 88%] Generating C++ code from dji_osdk_ros/CameraZoomCtrl.srv\n[ 89%] Generating C++ code from dji_osdk_ros/Stereo240pSubscription.srv\n[ 89%] Generating C++ code from dji_osdk_ros/GenerateWaypointV2Action.srv\n[ 89%] Generating C++ code from dji_osdk_ros/CameraSetZoomPara.srv\n[ 89%] Generating C++ code from dji_osdk_ros/SubscribeWaypointV2Event.srv\n[ 89%] Generating C++ code from dji_osdk_ros/MissionWpGetSpeed.srv\n[ 89%] Generating C++ code from dji_osdk_ros/CameraStartShootIntervalPhoto.srv\n[ 90%] Generating C++ code from dji_osdk_ros/SetGlobalCruisespeed.srv\n[ 90%] Generating C++ code from dji_osdk_ros/MissionHpGetInfo.srv\n[ 90%] Generating C++ code from dji_osdk_ros/DownloadWaypointV2Mission.srv\n[ 90%] Built target dji_osdk_ros_generate_messages_cpp\nScanning dependencies of target dji_osdk_ros_generate_messages\nScanning dependencies of target dji_osdk_ros\nScanning dependencies of target dji_sdk_node\n[ 90%] Built target dji_osdk_ros_generate_messages\n[ 90%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_mobile_comm.cpp.o\n[ 90%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/main.cpp.o\n[ 90%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_payload_comm.cpp.o\n[ 91%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_mission_services.cpp.o\n[ 91%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_publisher.cpp.o\n[ 91%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/vehicle_wrapper.cpp.o\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/vehicle_wrapper.cpp: In member function \u2018bool dji_osdk_ros::VehicleWrapper::moveByPositionOffset(const dji_osdk_ros::JoystickCommand&amp;, int, float, float)\u2019:\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/vehicle_wrapper.cpp:1707:34: error: \u2018class DJI::OSDK::FlightController\u2019 has no member named \u2018emergencyBrakeAction\u2019\nvehicle-&gt;flightController-&gt;emergencyBrakeAction();\n^\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/vehicle_wrapper.cpp: In member function \u2018bool dji_osdk_ros::VehicleWrapper::emergencyBrake()\u2019:\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/vehicle_wrapper.cpp:1848:32: error: \u2018class DJI::OSDK::FlightController\u2019 has no member named \u2018emergencyBrakeAction\u2019\nvehicle-&gt;flightController-&gt;emergencyBrakeAction();\n^\nOnboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/build.make:158: recipe for target 'Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/vehicle_wrapper.cpp.o' failed\nmake[2]: *** [Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/vehicle_wrapper.cpp.o] Error 1\nmake[2]: *** Waiting for unfinished jobs....\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_control.cpp.o\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_services.cpp.o\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/dji_vehicle_node_mission_services.cpp: In member function \u2018bool dji_osdk_ros::VehicleNode::waypointV2GenerateActionsCallback(dji_osdk_ros::GenerateWaypointV2Action::Request&amp;, dji_osdk_ros::GenerateWaypointV2Action::Response&amp;)\u2019:\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/dji_vehicle_node_mission_services.cpp:800:24: error: \u2018DJI::OSDK::DJIWaypointV2CameraFocusParam {aka struct DJI::OSDK::DJIWaypointV2CameraFocusParam}\u2019 has no member named \u2018regionType\u2019\nfocusParam.regionType = request.actions[i].waypointV2CameraActuator\n^\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/dji_vehicle_node_mission_services.cpp:801:24: error: \u2018DJI::OSDK::DJIWaypointV2CameraFocusParam {aka struct DJI::OSDK::DJIWaypointV2CameraFocusParam}\u2019 has no member named \u2018width\u2019\nfocusParam.width = request.actions[i].waypointV2CameraActuator.focu\n^\n/home/dji/catkin_ws/src/Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/dji_vehicle_node_mission_services.cpp:802:24: error: \u2018DJI::OSDK::DJIWaypointV2CameraFocusParam {aka struct DJI::OSDK::DJIWaypointV2CameraFocusParam}\u2019 has no member named \u2018height\u2019\nfocusParam.height = request.actions[i].waypointV2CameraActuator.foc\n^\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node.cpp.o\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_mission_services.cpp.o\nOnboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/build.make:62: recipe for target 'Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_mission_services.cpp.o' failed\nmake[2]: *** [Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/dji_vehicle_node_mission_services.cpp.o] Error 1\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_subscriber.cpp.o\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_publisher.cpp.o\nCMakeFiles/Makefile2:6514: recipe for target 'Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/all' failed\nmake[1]: *** [Onboard-SDK-ROS-master/src/dji_osdk_ros/modules/CMakeFiles/dji_osdk_ros.dir/all] Error 2\nmake[1]: *** Waiting for unfinished jobs....\n[ 92%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_mobile_comm.cpp.o\n[ 93%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_payload_comm.cpp.o\n[ 93%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/modules/dji_sdk_node_time_sync.cpp.o\n[ 93%] Building C object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir//dji_osdk_ros/modules/osdkhal_linux.c.o\n[ 93%] Building C object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir//dji_osdk_ros/modules/osdkosal_linux.c.o\n[ 93%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/dji_linux_environment.cpp.o\n[ 93%] Building CXX object Onboard-SDK-ROS-master/src/dji_osdk_ros_obsoleted/CMakeFiles/dji_sdk_node.dir/dji_linux_helpers.cpp.o\n[ 94%] Linking CXX executable /home/dji/catkin_ws/devel/lib/dji_osdk_ros/dji_sdk_node\n[ 94%] Built target dji_sdk_node\nMakefile:138: recipe for target 'all' failed\nmake: *** [all] Error 2\nInvoking &quot;make -j6 -l6&quot; failed\n\n"], "quote": [], "url": "https://stackoverflow.com/questions/79421378/build-target-failed-dji-osdk-ros-compiling-error-catkin-make-not-working", "answer": [], "answer_code": []},
{"title": "ROS Kinetic: Custom Costmap Layer Not Registering in pluginlib", "time": 1738855728, "post_content": ["I am using ROS Kinetic (please do not suggest upgrading; Pepper robot only works with this version).\nI am trying to create a custom layer for the costmap and followed this tutorial:\nCreating a New Layer - ROS Wiki\nHowever, I am encountering the following error:\n[ INFO] [1738855251.292501336]: Received a 384 X 384 map at 0.050000 m/pix\n[ INFO] [1738855251.295259742]: Using plugin \"my_costmap_layer/MyLayer\"\nterminate called after throwing an instance of 'pluginlib::LibraryLoadException'\n  what():  According to the loaded plugin descriptions the class my_costmap_layer::MyLayer with base class type costmap_2d::Layer does not exist. Declared types are  costmap_2d::InflationLayer costmap_2d::ObstacleLayer costmap_2d::StaticLayer costmap_2d::VoxelLayer\n[move_base-1] process has died [pid 14850, exit code -6, cmd /opt/ros/kinetic/lib/move_base/move_base __name:=move_base __log:=/home/humanoidrobots/.ros/log/1c76ec54-e49c-11ef-8a78-8cc84b309b23/move_base-1.log].\nlog file: /home/humanoidrobots/.ros/log/1c76ec54-e49c-11ef-8a78-8cc84b309b23/move_base-1*.log\nall processes on machine have died, roslaunch will exit\nshutting down processing monitor...\n... shutting down processing monitor complete\ndone\n\n\nThis suggests that my layer is not being registered. What could be the issue?\nhere is my CmakeList.txt\ncmake_minimum_required(VERSION 3.0.2)\nproject(my_costmap_layer)\n\nset(CMAKE_CXX_STANDARD 11)\n\nfind_package(catkin REQUIRED COMPONENTS\n  roscpp\n  costmap_2d\n  pluginlib\n  tf\n  nav_msgs\n)\n\n# This ensures pluginlib's macros are available\nfind_package(pluginlib REQUIRED)\n\ncatkin_package(\n  INCLUDE_DIRS include\n  LIBRARIES my_costmap_layer\n  CATKIN_DEPENDS roscpp costmap_2d pluginlib tf\n)\n\ninclude_directories(\n  include\n  ${catkin_INCLUDE_DIRS}\n)\n\nadd_library(my_costmap_layer\n  src/my_layer.cpp\n)\n\n#target_link_libraries(my_costmap_layer\n#  ${catkin_LIBRARIES}\n#)\n\n# Export plugin description file for pluginlib\n#pluginlib_export_plugin_description_file(costmap_2d my_costmap_layer.xml)\n\n#install(TARGETS my_costmap_layer\n#  LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#)\n\n#install(FILES plugin.xml\n#  DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}\n#)\n\n\nHere is my plugin.xml:\n<?xml version=\"1.0\"?>\n<library path=\"lib/libmy_costmap_layer\">\n  <class name=\"my_costmap_layer::MyLayer\" type=\"my_costmap_layer::MyLayer\" base_class_type=\"costmap_2d::Layer\">\n    <description>My custom costmap layer</description>\n  </class>\n</library>\n\n\nI have included the following in my .cpp file:\nPLUGINLIB_EXPORT_CLASS(my_costmap_layer::MyLayer, costmap_2d::Layer)\n\nI did all the checks multiple times but despite everything nothing hels"], "question_code": ["[ INFO] [1738855251.292501336]: Received a 384 X 384 map at 0.050000 m/pix\n[ INFO] [1738855251.295259742]: Using plugin &quot;my_costmap_layer/MyLayer&quot;\nterminate called after throwing an instance of 'pluginlib::LibraryLoadException'\n  what():  According to the loaded plugin descriptions the class my_costmap_layer::MyLayer with base class type costmap_2d::Layer does not exist. Declared types are  costmap_2d::InflationLayer costmap_2d::ObstacleLayer costmap_2d::StaticLayer costmap_2d::VoxelLayer\n[move_base-1] process has died [pid 14850, exit code -6, cmd /opt/ros/kinetic/lib/move_base/move_base __name:=move_base __log:=/home/humanoidrobots/.ros/log/1c76ec54-e49c-11ef-8a78-8cc84b309b23/move_base-1.log].\nlog file: /home/humanoidrobots/.ros/log/1c76ec54-e49c-11ef-8a78-8cc84b309b23/move_base-1*.log\nall processes on machine have died, roslaunch will exit\nshutting down processing monitor...\n... shutting down processing monitor complete\ndone\n\n", "cmake_minimum_required(VERSION 3.0.2)\nproject(my_costmap_layer)\n\nset(CMAKE_CXX_STANDARD 11)\n\nfind_package(catkin REQUIRED COMPONENTS\n  roscpp\n  costmap_2d\n  pluginlib\n  tf\n  nav_msgs\n)\n\n# This ensures pluginlib's macros are available\nfind_package(pluginlib REQUIRED)\n\ncatkin_package(\n  INCLUDE_DIRS include\n  LIBRARIES my_costmap_layer\n  CATKIN_DEPENDS roscpp costmap_2d pluginlib tf\n)\n\ninclude_directories(\n  include\n  ${catkin_INCLUDE_DIRS}\n)\n\nadd_library(my_costmap_layer\n  src/my_layer.cpp\n)\n\n#target_link_libraries(my_costmap_layer\n#  ${catkin_LIBRARIES}\n#)\n\n# Export plugin description file for pluginlib\n#pluginlib_export_plugin_description_file(costmap_2d my_costmap_layer.xml)\n\n#install(TARGETS my_costmap_layer\n#  LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#)\n\n#install(FILES plugin.xml\n#  DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}\n#)\n\n", "&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;library path=&quot;lib/libmy_costmap_layer&quot;&gt;\n  &lt;class name=&quot;my_costmap_layer::MyLayer&quot; type=&quot;my_costmap_layer::MyLayer&quot; base_class_type=&quot;costmap_2d::Layer&quot;&gt;\n    &lt;description&gt;My custom costmap layer&lt;/description&gt;\n  &lt;/class&gt;\n&lt;/library&gt;\n\n", "PLUGINLIB_EXPORT_CLASS(my_costmap_layer::MyLayer, costmap_2d::Layer)\n"], "quote": [], "url": "https://stackoverflow.com/questions/79418484/ros-kinetic-custom-costmap-layer-not-registering-in-pluginlib", "answer": [], "answer_code": []},
{"title": "Transformation conventions and ROS Issue", "time": 1737288036, "post_content": ["I have given following transformation:\narguments=['-0.005', '0.1370', '0.00548', '0.0148379', '-0.1494206', '0.9886599', '-0.0021957', 'wrist_3_link', 'camera_color_optical_frame']\n\nThis is being published by static_transform_publihser.\nNext, from tf_tree I can get following transformation:\nrosrun tf tf_echo camera_bottom_screw camera_color_optical_frame which prints:\ntranslation: [0.008, 0.000, 0.045] \nrotation: in quaternion [-0.5, 0.5, -0.5, 0.5]\nin rpy (radians) [-1.571, -0.000, -1.571]\n\nI want to obtain transformation from wrist_3_link to camera_bottom_screw. I want this cuz I assume these two transformations above are ground truth (without error). Because first one is obtained from calibration (let's assume it's perfect) and second one is from URDF of realsense camera, provided by manufacturer. Previously transformation between wrist_3_link and camera_bottom_screw is defined by someone, and it is not correct. Now since I have these two transformations, I can obtain correct transformation between wrist_3_link and camera_bottom_screw.\nLet's call these frames like this:\nA - wrist_3_link\nB - camera_bottom_screw\nC - camera_color_optical_frame\n\nBut I have issue with (I guess) ROS conventions. I tried so many times but cannot get it right. When I first publish transfrom T_C_A frame C is placed with respect to frame A. Now I want to apply T_B_A and T_C_B to obtain same transformation i.e. same placement of frame C wrt to A.\nT_C_A = T_C_B * T_B_A\n\nThis is my code for calculation T_C_B:\nimport numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\ndef compute_transformation(T_C_A, T_C_B):\n    \"\"\"\n    Compute the transformation T_B_A (from A to B) given T_C_A and T_C_B.\n    \n    Args:\n        T_C_A: Transformation from A to C as (tx, ty, tz, qx, qy, qz, qw)\n        T_C_B: Transformation from B to C as (tx, ty, tz, qx, qy, qz, qw)\n        \n    Returns:\n        T_B_A: Transformation from A to B as (tx, ty, tz, qx, qy, qz, qw)\n    \"\"\"\n    # Unpack T_C_A and T_C_B\n    t_C_A, q_C_A = T_C_A[:3], T_C_A[3:]\n    t_C_B, q_C_B = T_C_B[:3], T_C_B[3:]\n    \n    # Create 4x4 transformation matrices\n    T_C_A_matrix = np.eye(4)\n    T_C_A_matrix[:3, :3] = R.from_quat(q_C_A).as_matrix()\n    T_C_A_matrix[:3, 3] = t_C_A\n\n    T_C_B_matrix = np.eye(4)\n    T_C_B_matrix[:3, :3] = R.from_quat(q_C_B).as_matrix()\n    T_C_B_matrix[:3, 3] = t_C_B\n\n    # Compute T_B_A = T_C_B^-1 * T_C_A\n    T_B_C_matrix = np.linalg.inv(T_C_B_matrix)\n    T_B_A_matrix = T_B_C_matrix @ T_C_A_matrix\n\n    # Extract translation and rotation from T_B_A_matrix\n    t_B_A = T_B_A_matrix[:3, 3]\n    q_B_A = R.from_matrix(T_B_A_matrix[:3, :3]).as_quat()\n    q_B_A /= np.linalg.norm(q_B_A)  # Ensure it's normalized\n    rpy_B_A = R.from_matrix(T_B_A_matrix[:3, :3]).as_euler('xyz', degrees=False) # better q (no ambiguity)\n\n    return T_B_A_matrix, t_B_A, q_B_A, rpy_B_A, T_C_A_matrix, T_C_B_matrix\n\n# Example input: T_C_A and T_C_B\nT_C_A = [-0.005, 0.1370, 0.00548, 0.0148379, -0.1494206, 0.9886599, -0.0021957]\nT_C_B = [0.008, 0.0, 0.045, -0.5, 0.5, -0.5, 0.5]  # Translation + quaternion\n\n# Compute T_B_A\nT_B_A_matrix, t_B_A, q_B_A, rpy_B_A, T_C_A_matrix, T_C_B_matrix = compute_transformation(T_C_A, T_C_B)\n\nT_test = T_C_B_matrix @ T_B_A_matrix\nprint(\"T_test\")\nprint(T_test) # Same as T_C_A (I guess everything fine now)\n\nBut when I publish T_C_B:\nrosrun tf static_transform_publisher 0.008 0.0 0.045 -0.5 0.5 -0.5 0.5 B C 10\nand T_B_A (obtained by my code):\nrosrun tf static_transform_publisher -0.137 0.03952 -0.013 0.41329857 0.56052348 -0.42594077 0.57755708 A B 10\nI am not getting same placement of frame C with respect to A. I tried so many times, but cannot solve it. I think there are some misunderstandings in axes orientations and similar, which I cannot solve.\nThese are results (first one aplying T_C_A) and second one these two consecutive transforms:\nfaris@faris-lenovo:~$ rosrun tf tf_echo wrist optical\nAt time 1737282624.483\n- Translation: [-0.005, 0.137, 0.005]\n- Rotation: in Quaternion [0.015, -0.149, 0.989, -0.002]\n            in RPY (radian) [-0.300, -0.029, -3.133]\n            in RPY (degree) [-17.196, -1.644, -179.497]\n^Cfaris@faris-lenovo:~$ rosrun rqt_tf_tree rqt_tf_tree \nfaris@faris-lenovo:~$ rosrun rqt_tf_tree rqt_tf_tree \nfaris@faris-lenovo:~$ rosrun rqt_tf_tree rqt_tf_tree \nfaris@faris-lenovo:~$ rosrun tf tf_echo wrist optical\nAt time 1737282746.657\n- Translation: [-0.124, -0.004, -0.020]\n- Rotation: in Quaternion [-0.149, 0.989, -0.015, 0.002]\n            in RPY (radian) [-3.112, -0.000, -2.842]\n            in RPY (degree) [-178.281, -0.005, -162.811]"], "question_code": ["arguments=['-0.005', '0.1370', '0.00548', '0.0148379', '-0.1494206', '0.9886599', '-0.0021957', 'wrist_3_link', 'camera_color_optical_frame']\n", "static_transform_publihser", "tf_tree", "rosrun tf tf_echo camera_bottom_screw camera_color_optical_frame", "translation: [0.008, 0.000, 0.045] \nrotation: in quaternion [-0.5, 0.5, -0.5, 0.5]\nin rpy (radians) [-1.571, -0.000, -1.571]\n", "wrist_3_link", "camera_bottom_screw", "URDF", "wrist_3_link", "camera_bottom_screw", "wrist_3_link", "camera_bottom_screw", "A - wrist_3_link\nB - camera_bottom_screw\nC - camera_color_optical_frame\n", "T_C_A", "C", "A", "T_B_A", "T_C_B", "C", "A", "T_C_A = T_C_B * T_B_A\n", "T_C_B", "import numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\ndef compute_transformation(T_C_A, T_C_B):\n    &quot;&quot;&quot;\n    Compute the transformation T_B_A (from A to B) given T_C_A and T_C_B.\n    \n    Args:\n        T_C_A: Transformation from A to C as (tx, ty, tz, qx, qy, qz, qw)\n        T_C_B: Transformation from B to C as (tx, ty, tz, qx, qy, qz, qw)\n        \n    Returns:\n        T_B_A: Transformation from A to B as (tx, ty, tz, qx, qy, qz, qw)\n    &quot;&quot;&quot;\n    # Unpack T_C_A and T_C_B\n    t_C_A, q_C_A = T_C_A[:3], T_C_A[3:]\n    t_C_B, q_C_B = T_C_B[:3], T_C_B[3:]\n    \n    # Create 4x4 transformation matrices\n    T_C_A_matrix = np.eye(4)\n    T_C_A_matrix[:3, :3] = R.from_quat(q_C_A).as_matrix()\n    T_C_A_matrix[:3, 3] = t_C_A\n\n    T_C_B_matrix = np.eye(4)\n    T_C_B_matrix[:3, :3] = R.from_quat(q_C_B).as_matrix()\n    T_C_B_matrix[:3, 3] = t_C_B\n\n    # Compute T_B_A = T_C_B^-1 * T_C_A\n    T_B_C_matrix = np.linalg.inv(T_C_B_matrix)\n    T_B_A_matrix = T_B_C_matrix @ T_C_A_matrix\n\n    # Extract translation and rotation from T_B_A_matrix\n    t_B_A = T_B_A_matrix[:3, 3]\n    q_B_A = R.from_matrix(T_B_A_matrix[:3, :3]).as_quat()\n    q_B_A /= np.linalg.norm(q_B_A)  # Ensure it's normalized\n    rpy_B_A = R.from_matrix(T_B_A_matrix[:3, :3]).as_euler('xyz', degrees=False) # better q (no ambiguity)\n\n    return T_B_A_matrix, t_B_A, q_B_A, rpy_B_A, T_C_A_matrix, T_C_B_matrix\n\n# Example input: T_C_A and T_C_B\nT_C_A = [-0.005, 0.1370, 0.00548, 0.0148379, -0.1494206, 0.9886599, -0.0021957]\nT_C_B = [0.008, 0.0, 0.045, -0.5, 0.5, -0.5, 0.5]  # Translation + quaternion\n\n# Compute T_B_A\nT_B_A_matrix, t_B_A, q_B_A, rpy_B_A, T_C_A_matrix, T_C_B_matrix = compute_transformation(T_C_A, T_C_B)\n\nT_test = T_C_B_matrix @ T_B_A_matrix\nprint(&quot;T_test&quot;)\nprint(T_test) # Same as T_C_A (I guess everything fine now)\n", "T_C_B", "rosrun tf static_transform_publisher 0.008 0.0 0.045 -0.5 0.5 -0.5 0.5 B C 10", "T_B_A", "rosrun tf static_transform_publisher -0.137 0.03952 -0.013 0.41329857 0.56052348 -0.42594077 0.57755708 A B 10", "C", "A", "T_C_A", "faris@faris-lenovo:~$ rosrun tf tf_echo wrist optical\nAt time 1737282624.483\n- Translation: [-0.005, 0.137, 0.005]\n- Rotation: in Quaternion [0.015, -0.149, 0.989, -0.002]\n            in RPY (radian) [-0.300, -0.029, -3.133]\n            in RPY (degree) [-17.196, -1.644, -179.497]\n^Cfaris@faris-lenovo:~$ rosrun rqt_tf_tree rqt_tf_tree \nfaris@faris-lenovo:~$ rosrun rqt_tf_tree rqt_tf_tree \nfaris@faris-lenovo:~$ rosrun rqt_tf_tree rqt_tf_tree \nfaris@faris-lenovo:~$ rosrun tf tf_echo wrist optical\nAt time 1737282746.657\n- Translation: [-0.124, -0.004, -0.020]\n- Rotation: in Quaternion [-0.149, 0.989, -0.015, 0.002]\n            in RPY (radian) [-3.112, -0.000, -2.842]\n            in RPY (degree) [-178.281, -0.005, -162.811]\n"], "quote": [], "url": "https://stackoverflow.com/questions/79368908/transformation-conventions-and-ros-issue", "answer": [], "answer_code": []},
{"title": "airsim_ros_pkgs:Exception raised by the API, didn't get image response. rpclib: function 'simGetImages' (called with 2 arg(s)) threw an exception", "time": 1736429860, "post_content": ["everyone. I'm a beginner just starting to learn AirSim.\nMy Question:\nI currently need to perform a joint simulation using AirSim and C++ ROS. When using the airsim_ros_pkgs, I encounter the following error:\nrpclib: function 'simGetImages' (called with 2 arg(s)) threw an exception. The exception is not derived from std::exception. No further information available.\nWhen this issue occurs:\n\nAll topics corresponding to AirSim have no data.\nEven the cout in my subscriber doesn't produce any output.\nHowever, the program does not crash but keeps printing the error in the terminal.\n\nMy Situation:\nI have two laptops:\n\nOld Laptop: NVIDIA GTX 1060.\nRunning the same code works fine (although I encountered the issue once, it disappeared after a restart and hasn\u2019t recurred).\nNew Laptop: NVIDIA RTX 4060.\nThe issue persists and occurs consistently on this machine.\n\nWhat I Have Tried:\n\nSetting.json Path:\nSome people reported solving this issue in Docker by placing the settings.json file under /root/Documents/AirSim. However, I confirmed that my file is in the default path ~/Documents/AirSim on both laptops.\n\nDowngrading AirSim:\nI tried rolling back AirSim to version 1.7 and running different scenes, but it didn\u2019t seem to help.\n\n\nCould anyone please help me? I've spent several days trying to solve this problem!"], "question_code": ["airsim_ros_pkgs", "rpclib: function 'simGetImages' (called with 2 arg(s)) threw an exception. The exception is not derived from std::exception. No further information available."], "quote": [], "url": "https://stackoverflow.com/questions/79342821/airsim-ros-pkgsexception-raised-by-the-api-didnt-get-image-response-rpclib", "answer": [], "answer_code": []},
{"title": "ROS2 and YDLiDAR", "time": 1736348652, "post_content": ["I have a YDLiDAR X4 PRO and need to use it with ROS2 Humble, in its offical website, I found a package for ROS2 but couldn't build it. After a lot of unsuccessful try, I decided to change the way. My plan was taking data by serial in python (c++ can be also used with ROS2 as well) and sending to /scan topic then visualizing In RViz2.\nHere is the rviz's visualizing results\nAs you can see it doesn't visualize as 360 degrees and is not able to use with other tools like SLAM or Navigation.\nHere is my expection without SLAM tools(I got it from web)\nSo, what to do for this lidar problem, why couldn't I use offical package"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79339668/ros2-and-ydlidar", "answer": [], "answer_code": []},
{"title": "compatibility issue with ydlidarx2 ubuntu24.4", "time": 1733507732, "post_content": ["i am trying to make ydlidar x2 work with ubuntu 24.4 (ros jazzy)\ni am getting cmake errors\n  The source directory\n\n    /home/pussycat/ydlidar_ws/src/YDLidar-SDK/src/core\n\n  does not contain a CMakeLists.txt file.\n\n\nCMake Error at src/CMakeLists.txt:12 (add_subdirectory):\n  The source directory\n\n    /home/pussycat/ydlidar_ws/src/YDLidar-SDK/src/examples\n\n  does not contain a CMakeLists.txt file.\n\n\nCMake Error at src/CMakeLists.txt:12 (add_subdirectory):\n  The source directory\n\n    /home/pussycat/ydlidar_ws/src/YDLidar-SDK/src/src\n\n  does not contain a CMakeLists.txt file.\n\nis it even compatible with 24.4 is there any way i can use lidar data without the ydlidar drivers ??"], "question_code": ["  The source directory\n\n    /home/pussycat/ydlidar_ws/src/YDLidar-SDK/src/core\n\n  does not contain a CMakeLists.txt file.\n\n\nCMake Error at src/CMakeLists.txt:12 (add_subdirectory):\n  The source directory\n\n    /home/pussycat/ydlidar_ws/src/YDLidar-SDK/src/examples\n\n  does not contain a CMakeLists.txt file.\n\n\nCMake Error at src/CMakeLists.txt:12 (add_subdirectory):\n  The source directory\n\n    /home/pussycat/ydlidar_ws/src/YDLidar-SDK/src/src\n\n  does not contain a CMakeLists.txt file.\n"], "quote": [], "url": "https://stackoverflow.com/questions/79258918/compatibility-issue-with-ydlidarx2-ubuntu24-4", "answer": [], "answer_code": []},
{"title": "LsLidar Poll Timeout", "time": 1733478520, "post_content": ["I use LsLidar C16, but when I roslaunch, it says lslidar poll timeout(): UDP port. Can you help me how to fix this problem?\nI did everything like turning on the firewall, changing the ip, eth0 going up, but still getting the lslidar poll time limit error. Please help me, Thank you.\nCan you guys give me the details?"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79257532/lslidar-poll-timeout", "answer": [], "answer_code": []},
{"title": "Package 'ros_gz_sim' not found: \"package 'ros_gz_sim' not found, searching:", "time": 1733150267, "post_content": ["Good afternoon, Is there anyone who know how to solve this issue, when I try to launch a file with ros2 it says that the package is not found.\nerror in terminal\nI've installed the package cloning the ros_gz_sim repository and it stills doesn't find the package.\npicture of the existing file\nI'm on MacOS btw."], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79244477/package-ros-gz-sim-not-found-package-ros-gz-sim-not-found-searching", "answer": [], "answer_code": []},
{"title": "Try to convert pointcloud2 from rosbag to google draco point cloud (encoded)", "time": 1732787102, "post_content": ["i'm trying to convert and encode a pointcloud from a rosbag to another pointcloud encoded with draco https://github.com/google/draco/\nThis is my code:\n#include <chrono> // Per misurare il tempo\n#include <rclcpp/rclcpp.hpp>\n#include <sensor_msgs/msg/point_cloud2.hpp>\n#include <sensor_msgs/point_cloud2_iterator.hpp>\n#include <draco/compression/encode.h>\n#include <draco/point_cloud/point_cloud.h>\n#include <draco/point_cloud/point_cloud_builder.h>\n#include <draco/core/encoder_buffer.h>\n#include <draco/core/decoder_buffer.h>\n#include <draco/compression/decode.h>\n\nclass PointCloudCompressorNode : public rclcpp::Node {\npublic:\n  PointCloudCompressorNode()\n    : Node(\"pointcloud_compressor_node\"),\n      compression_speed_(declare_parameter<int>(\"compression_speed\", 5)),\n      quantization_bits_(declare_parameter<int>(\"quantization_bits\", 10)) {\n\n    RCLCPP_INFO(this->get_logger(), \"Initializing PointCloudCompressorNode...\");\n    \n    sub_ = this->create_subscription<sensor_msgs::msg::PointCloud2>(\n      \"/zed/zed_node/point_cloud/cloud_registered\", rclcpp::SensorDataQoS(),\n      std::bind(&PointCloudCompressorNode::callback, this, std::placeholders::_1));\n\n    pub_ = this->create_publisher<sensor_msgs::msg::PointCloud2>(\n      \"/compressed_pointcloud\", rclcpp::QoS(10));\n  }\n\nprivate:\n  void callback(const sensor_msgs::msg::PointCloud2::SharedPtr msg) {\n    // Inizia il timer\n    auto start_time = std::chrono::steady_clock::now();\n\n    RCLCPP_INFO(this->get_logger(), \"Received PointCloud2 message.\");\n    RCLCPP_INFO(this->get_logger(), \"PointCloud2 message: width=%d, height=%d, fields=%ld, is_dense=%d\",\n                msg->width, msg->height, msg->fields.size(), msg->is_dense);\n\n    std::unique_ptr<draco::PointCloud> draco_cloud;\n    if (!convertToDracoPointCloud(msg, draco_cloud)) {\n      RCLCPP_ERROR(this->get_logger(), \"Failed to convert PointCloud2 to Draco.\");\n      return;\n    }\n\n    std::vector<uint8_t> compressed_data;\n    if (!compressPointCloud(*draco_cloud, compressed_data)) {\n      RCLCPP_ERROR(this->get_logger(), \"Failed to compress Draco PointCloud.\");\n      return;\n    }\n\n    auto compressed_msg = sensor_msgs::msg::PointCloud2();\n    compressed_msg.header = msg->header;\n    compressed_msg.data = compressed_data;\n    pub_->publish(compressed_msg);\n\n    // Ferma il timer e calcola il tempo totale\n    auto end_time = std::chrono::steady_clock::now();\n    auto elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time).count();\n\n    RCLCPP_INFO(this->get_logger(), \"Published compressed PointCloud2 message of size %zu bytes.\", compressed_data.size());\n    RCLCPP_INFO(this->get_logger(), \"Total processing time: %ld ms.\", elapsed_time);\n  }\n\nbool convertToDracoPointCloud(const sensor_msgs::msg::PointCloud2::SharedPtr &msg,\n                              std::unique_ptr<draco::PointCloud> &draco_cloud) {\n    draco::PointCloudBuilder builder;\n\n    // Calcola il numero di punti validi\n    size_t total_points = msg->width * msg->height;\n    draco::PointIndex::ValueType valid_points = 0;\n\n    sensor_msgs::PointCloud2ConstIterator<float> iter_x(*msg, \"x\");\n    sensor_msgs::PointCloud2ConstIterator<float> iter_y(*msg, \"y\");\n    sensor_msgs::PointCloud2ConstIterator<float> iter_z(*msg, \"z\");\n\n    // Conta i punti validi cio\u00e8 quelli che hanno almeno x y z:\n    for (size_t i = 0; i < total_points; ++i, ++iter_x, ++iter_y, ++iter_z) {\n        const float position[3] = {*iter_x, *iter_y, *iter_z};\n        if (std::isfinite(position[0]) && std::isfinite(position[1]) && std::isfinite(position[2])) {\n            valid_points++;\n        }\n    }\n\n    RCLCPP_INFO(this->get_logger(), \"Processed %zu valid points out of %zu total points.\", valid_points, total_points);\n\n    if (valid_points == 0) {\n        RCLCPP_ERROR(this->get_logger(), \"No valid points found in PointCloud2.\");\n        return false;\n    }\n\n    // Inizia il builder con il numero di punti validi\n    builder.Start(valid_points);\n\n    // Aggiungi attributi: POSITION\n    const int pos_att_id = builder.AddAttribute(draco::GeometryAttribute::POSITION, 3, draco::DataType::DT_FLOAT32);\n    if (pos_att_id == -1) {\n        RCLCPP_ERROR(this->get_logger(), \"Failed to add POSITION attribute to Draco PointCloud.\");\n        return false;\n    }\n\n    // Itera di nuovo e aggiungi i punti validi\n    iter_x = sensor_msgs::PointCloud2ConstIterator<float>(*msg, \"x\");\n    iter_y = sensor_msgs::PointCloud2ConstIterator<float>(*msg, \"y\");\n    iter_z = sensor_msgs::PointCloud2ConstIterator<float>(*msg, \"z\");\n\n    size_t point_index = 0;\n    for (size_t i = 0; i < valid_points; ++i, ++iter_x, ++iter_y, ++iter_z) {\n        const float position[3] = {*iter_x, *iter_y, *iter_z};\n        if (std::isfinite(position[0]) && std::isfinite(position[1]) && std::isfinite(position[2])) {\n            builder.SetAttributeValueForPoint(pos_att_id, draco::PointIndex(point_index), position);\n            point_index++;\n        }\n    }\n\n\n\n    // Finalizza il PointCloud Draco\n    draco_cloud = builder.Finalize(false);\n    if (!draco_cloud || draco_cloud->num_points() != valid_points) {\n        RCLCPP_ERROR(this->get_logger(), \"Mismatch in point count after Finalize: expected %zu, got %zu.\",\n                    valid_points, draco_cloud ? draco_cloud->num_points() : 0);\n        return false;\n    }\n\n    if (!draco_cloud) {\n        RCLCPP_ERROR(this->get_logger(), \"Failed to finalize Draco PointCloud.\");\n        return false;\n    }\n\n    RCLCPP_INFO(this->get_logger(), \"Draco PointCloud created with %zu points.\", draco_cloud->num_points());\n    return true;\n}\n\n  bool compressPointCloud(const draco::PointCloud &draco_cloud, std::vector<uint8_t> &compressed_data) {\n    draco::EncoderBuffer buffer;\n    draco::Encoder encoder;\n\n    // Impostazioni di compressione\n    // Questa \u00e8 la classe base:  Base::SetSpeedOptions(encoding_speed, decoding_speed); devo capire a cosa fa riferimento questa velocit\u00e0..\n    encoder.SetSpeedOptions(compression_speed_, compression_speed_);\n    encoder.SetAttributeQuantization(draco::GeometryAttribute::POSITION, quantization_bits_);\n    RCLCPP_INFO(this->get_logger(), \"Encoder settings: compression_speed=%d, quantization_bits=%d.\",\n                compression_speed_, quantization_bits_);\n\n    // Comprime il PointCloud\n    draco::Status status = encoder.EncodePointCloudToBuffer(draco_cloud, &buffer);\n    if (!status.ok()) {\n      RCLCPP_ERROR(this->get_logger(), \"Failed to encode Draco PointCloud: %s\", status.error_msg());\n      return false;\n    }\n\n    // Assegna i dati compressi\n    compressed_data.assign(buffer.data(), buffer.data() + buffer.size());\n    RCLCPP_INFO(this->get_logger(), \"PointCloud compressed to %zu bytes.\", compressed_data.size());\n    return true;\n  }\n\n  rclcpp::Subscription<sensor_msgs::msg::PointCloud2>::SharedPtr sub_;\n  rclcpp::Publisher<sensor_msgs::msg::PointCloud2>::SharedPtr pub_;\n\n  int compression_speed_;\n  int quantization_bits_;\n};\n\nint main(int argc, char **argv) {\n  rclcpp::init(argc, argv);\n  rclcpp::spin(std::make_shared<PointCloudCompressorNode>());\n  rclcpp::shutdown();\n  return 0;\n}\n\nWhen i run the package in ros2 humble i got message like that:\npc:~/teleoperation_ws$ ros2 run point_cloud_relay point_cloud_relay --ros-args -p compression_speed:=7 -p quantization_bits:=0\n[INFO] [1732786049.343657818] [pointcloud_compressor_node]: Initializing PointCloudCompressorNode...\n[INFO] [1732786071.338711408] [pointcloud_compressor_node]: Received PointCloud2 message.\n[INFO] [1732786071.338824018] [pointcloud_compressor_node]: PointCloud2 message: width=960, height=540, fields=4, is_dense=0\n[INFO] [1732786071.371806544] [pointcloud_compressor_node]: Processed 410328 valid points out of 518400 total points.\n[ERROR] [1732786071.418566633] [pointcloud_compressor_node]: Mismatch in point count after Finalize: expected 410328, got 1600938866.\n[ERROR] [1732786071.418736009] [pointcloud_compressor_node]: Failed to convert PointCloud2 to Draco.\n\nI see from error that i get 41000 valid points and when i try to finalize builder i get 1600938866 and i don't know why it behave in this way.\nCan anyone explain me how to fix it?"], "question_code": ["#include &lt;chrono&gt; // Per misurare il tempo\n#include &lt;rclcpp/rclcpp.hpp&gt;\n#include &lt;sensor_msgs/msg/point_cloud2.hpp&gt;\n#include &lt;sensor_msgs/point_cloud2_iterator.hpp&gt;\n#include &lt;draco/compression/encode.h&gt;\n#include &lt;draco/point_cloud/point_cloud.h&gt;\n#include &lt;draco/point_cloud/point_cloud_builder.h&gt;\n#include &lt;draco/core/encoder_buffer.h&gt;\n#include &lt;draco/core/decoder_buffer.h&gt;\n#include &lt;draco/compression/decode.h&gt;\n\nclass PointCloudCompressorNode : public rclcpp::Node {\npublic:\n  PointCloudCompressorNode()\n    : Node(&quot;pointcloud_compressor_node&quot;),\n      compression_speed_(declare_parameter&lt;int&gt;(&quot;compression_speed&quot;, 5)),\n      quantization_bits_(declare_parameter&lt;int&gt;(&quot;quantization_bits&quot;, 10)) {\n\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;Initializing PointCloudCompressorNode...&quot;);\n    \n    sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::PointCloud2&gt;(\n      &quot;/zed/zed_node/point_cloud/cloud_registered&quot;, rclcpp::SensorDataQoS(),\n      std::bind(&amp;PointCloudCompressorNode::callback, this, std::placeholders::_1));\n\n    pub_ = this-&gt;create_publisher&lt;sensor_msgs::msg::PointCloud2&gt;(\n      &quot;/compressed_pointcloud&quot;, rclcpp::QoS(10));\n  }\n\nprivate:\n  void callback(const sensor_msgs::msg::PointCloud2::SharedPtr msg) {\n    // Inizia il timer\n    auto start_time = std::chrono::steady_clock::now();\n\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;Received PointCloud2 message.&quot;);\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;PointCloud2 message: width=%d, height=%d, fields=%ld, is_dense=%d&quot;,\n                msg-&gt;width, msg-&gt;height, msg-&gt;fields.size(), msg-&gt;is_dense);\n\n    std::unique_ptr&lt;draco::PointCloud&gt; draco_cloud;\n    if (!convertToDracoPointCloud(msg, draco_cloud)) {\n      RCLCPP_ERROR(this-&gt;get_logger(), &quot;Failed to convert PointCloud2 to Draco.&quot;);\n      return;\n    }\n\n    std::vector&lt;uint8_t&gt; compressed_data;\n    if (!compressPointCloud(*draco_cloud, compressed_data)) {\n      RCLCPP_ERROR(this-&gt;get_logger(), &quot;Failed to compress Draco PointCloud.&quot;);\n      return;\n    }\n\n    auto compressed_msg = sensor_msgs::msg::PointCloud2();\n    compressed_msg.header = msg-&gt;header;\n    compressed_msg.data = compressed_data;\n    pub_-&gt;publish(compressed_msg);\n\n    // Ferma il timer e calcola il tempo totale\n    auto end_time = std::chrono::steady_clock::now();\n    auto elapsed_time = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(end_time - start_time).count();\n\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;Published compressed PointCloud2 message of size %zu bytes.&quot;, compressed_data.size());\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;Total processing time: %ld ms.&quot;, elapsed_time);\n  }\n\nbool convertToDracoPointCloud(const sensor_msgs::msg::PointCloud2::SharedPtr &amp;msg,\n                              std::unique_ptr&lt;draco::PointCloud&gt; &amp;draco_cloud) {\n    draco::PointCloudBuilder builder;\n\n    // Calcola il numero di punti validi\n    size_t total_points = msg-&gt;width * msg-&gt;height;\n    draco::PointIndex::ValueType valid_points = 0;\n\n    sensor_msgs::PointCloud2ConstIterator&lt;float&gt; iter_x(*msg, &quot;x&quot;);\n    sensor_msgs::PointCloud2ConstIterator&lt;float&gt; iter_y(*msg, &quot;y&quot;);\n    sensor_msgs::PointCloud2ConstIterator&lt;float&gt; iter_z(*msg, &quot;z&quot;);\n\n    // Conta i punti validi cio\u00e8 quelli che hanno almeno x y z:\n    for (size_t i = 0; i &lt; total_points; ++i, ++iter_x, ++iter_y, ++iter_z) {\n        const float position[3] = {*iter_x, *iter_y, *iter_z};\n        if (std::isfinite(position[0]) &amp;&amp; std::isfinite(position[1]) &amp;&amp; std::isfinite(position[2])) {\n            valid_points++;\n        }\n    }\n\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;Processed %zu valid points out of %zu total points.&quot;, valid_points, total_points);\n\n    if (valid_points == 0) {\n        RCLCPP_ERROR(this-&gt;get_logger(), &quot;No valid points found in PointCloud2.&quot;);\n        return false;\n    }\n\n    // Inizia il builder con il numero di punti validi\n    builder.Start(valid_points);\n\n    // Aggiungi attributi: POSITION\n    const int pos_att_id = builder.AddAttribute(draco::GeometryAttribute::POSITION, 3, draco::DataType::DT_FLOAT32);\n    if (pos_att_id == -1) {\n        RCLCPP_ERROR(this-&gt;get_logger(), &quot;Failed to add POSITION attribute to Draco PointCloud.&quot;);\n        return false;\n    }\n\n    // Itera di nuovo e aggiungi i punti validi\n    iter_x = sensor_msgs::PointCloud2ConstIterator&lt;float&gt;(*msg, &quot;x&quot;);\n    iter_y = sensor_msgs::PointCloud2ConstIterator&lt;float&gt;(*msg, &quot;y&quot;);\n    iter_z = sensor_msgs::PointCloud2ConstIterator&lt;float&gt;(*msg, &quot;z&quot;);\n\n    size_t point_index = 0;\n    for (size_t i = 0; i &lt; valid_points; ++i, ++iter_x, ++iter_y, ++iter_z) {\n        const float position[3] = {*iter_x, *iter_y, *iter_z};\n        if (std::isfinite(position[0]) &amp;&amp; std::isfinite(position[1]) &amp;&amp; std::isfinite(position[2])) {\n            builder.SetAttributeValueForPoint(pos_att_id, draco::PointIndex(point_index), position);\n            point_index++;\n        }\n    }\n\n\n\n    // Finalizza il PointCloud Draco\n    draco_cloud = builder.Finalize(false);\n    if (!draco_cloud || draco_cloud-&gt;num_points() != valid_points) {\n        RCLCPP_ERROR(this-&gt;get_logger(), &quot;Mismatch in point count after Finalize: expected %zu, got %zu.&quot;,\n                    valid_points, draco_cloud ? draco_cloud-&gt;num_points() : 0);\n        return false;\n    }\n\n    if (!draco_cloud) {\n        RCLCPP_ERROR(this-&gt;get_logger(), &quot;Failed to finalize Draco PointCloud.&quot;);\n        return false;\n    }\n\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;Draco PointCloud created with %zu points.&quot;, draco_cloud-&gt;num_points());\n    return true;\n}\n\n  bool compressPointCloud(const draco::PointCloud &amp;draco_cloud, std::vector&lt;uint8_t&gt; &amp;compressed_data) {\n    draco::EncoderBuffer buffer;\n    draco::Encoder encoder;\n\n    // Impostazioni di compressione\n    // Questa \u00e8 la classe base:  Base::SetSpeedOptions(encoding_speed, decoding_speed); devo capire a cosa fa riferimento questa velocit\u00e0..\n    encoder.SetSpeedOptions(compression_speed_, compression_speed_);\n    encoder.SetAttributeQuantization(draco::GeometryAttribute::POSITION, quantization_bits_);\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;Encoder settings: compression_speed=%d, quantization_bits=%d.&quot;,\n                compression_speed_, quantization_bits_);\n\n    // Comprime il PointCloud\n    draco::Status status = encoder.EncodePointCloudToBuffer(draco_cloud, &amp;buffer);\n    if (!status.ok()) {\n      RCLCPP_ERROR(this-&gt;get_logger(), &quot;Failed to encode Draco PointCloud: %s&quot;, status.error_msg());\n      return false;\n    }\n\n    // Assegna i dati compressi\n    compressed_data.assign(buffer.data(), buffer.data() + buffer.size());\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;PointCloud compressed to %zu bytes.&quot;, compressed_data.size());\n    return true;\n  }\n\n  rclcpp::Subscription&lt;sensor_msgs::msg::PointCloud2&gt;::SharedPtr sub_;\n  rclcpp::Publisher&lt;sensor_msgs::msg::PointCloud2&gt;::SharedPtr pub_;\n\n  int compression_speed_;\n  int quantization_bits_;\n};\n\nint main(int argc, char **argv) {\n  rclcpp::init(argc, argv);\n  rclcpp::spin(std::make_shared&lt;PointCloudCompressorNode&gt;());\n  rclcpp::shutdown();\n  return 0;\n}\n", "pc:~/teleoperation_ws$ ros2 run point_cloud_relay point_cloud_relay --ros-args -p compression_speed:=7 -p quantization_bits:=0\n[INFO] [1732786049.343657818] [pointcloud_compressor_node]: Initializing PointCloudCompressorNode...\n[INFO] [1732786071.338711408] [pointcloud_compressor_node]: Received PointCloud2 message.\n[INFO] [1732786071.338824018] [pointcloud_compressor_node]: PointCloud2 message: width=960, height=540, fields=4, is_dense=0\n[INFO] [1732786071.371806544] [pointcloud_compressor_node]: Processed 410328 valid points out of 518400 total points.\n[ERROR] [1732786071.418566633] [pointcloud_compressor_node]: Mismatch in point count after Finalize: expected 410328, got 1600938866.\n[ERROR] [1732786071.418736009] [pointcloud_compressor_node]: Failed to convert PointCloud2 to Draco.\n"], "quote": [], "url": "https://stackoverflow.com/questions/79233314/try-to-convert-pointcloud2-from-rosbag-to-google-draco-point-cloud-encoded", "answer": [], "answer_code": []},
{"title": "Visual Enabled does not work in rviz when running 'roslaunch husky_viz view_robot.launch'", "time": 1732767482, "post_content": ["Currently I am performing husky simulations on WSL - Ubuntu 20.04 - ROS Noetic environment.\nI am referring to the manual on the webpage you linked : https://www.clearpathrobotics.com/assets/guides/kinetic/husky/HuskyAMCL.html to practice the husky simulation.\nI have confirmed that the packages that need to be installed as described in the tutorial manual are installed as follows\nros-noetic-husky-control\nros-noetic-husky-description\nros-noetic-husky-desktop\nros-noetic-husky-gazebo\nros-noetic-husky-msgs\nros-noetic-husky-navigation\nros-noetic-husky-simulator\nros-noetic-husky-viz\nroslaunch husky_gazebo husky_playpen.launch\nroslaunch husky_viz view_robot.launch\nThe above two commands will launch the gazebo simulator and rviz, but the RobotModel - Visual Enabled feature will not work.\nIf you know how to solve this, please reply\nThank you.\nenter image description here\nFor reference, I thought it was a CUDA rendering issue with rviz in WSL - Ubuntu - ROS - Rviz settings, so I ran another example file and it worked fine.\nenter image description here\nTherefore, there does not appear to be a CUDA GPU rendering issue with WSL.\nIt's hard to understand why husky's Rviz Visual doesn't work."], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79232575/visual-enabled-does-not-work-in-rviz-when-running-roslaunch-husky-viz-view-robo", "answer": [], "answer_code": []},
{"title": "Testing global and local lplannes using created footprint and static map, is not working when given pose goal, why?", "time": 1732567691, "post_content": ["I created simplified footprints combining a robot and the some tow attachment with given dimensions. I dont need any sensors as I just want to test the planners with created footprint using move_base in ROS noetic in Navigation stack. Think, I dont need any node but correct me if wrong. So I created, firstly navigation launch file. Here its\n<?xml version=\"1.0\" ?>\n<launch>\n  <!-- Map Server -->\n  <node pkg=\"map_server\" type=\"map_server\" name=\"map_server\" args=\"$(find robot_navigation)/maps/map.yaml\"/>\n\n  <!-- Static Transforms -->\n  <node pkg=\"tf\" type=\"static_transform_publisher\" name=\"map_to_odom\" args=\"0 0 0 0 0 0 map odom 0.1\" />\n  <node pkg=\"tf\" type=\"static_transform_publisher\" name=\"odom_to_base_link\" args=\"0 0 0 0 0 0 odom base_link 0.1\" />\n  <node pkg=\"tf\" type=\"static_transform_publisher\" name=\"base_link_to_towing_attachment\" args=\"0 -0.35 0 0 0 0 base_link towing_attachment 0.1\" />\n\n\n  <!-- Robot State Publisher -->\n  <node pkg=\"robot_state_publisher\" type=\"robot_state_publisher\" name=\"robot_state_publisher\">\n    <param name=\"publish_frequency\" value=\"10.0\" />\n    <param name=\"robot_description\" command=\"$(find xacro)/xacro $(find robot_navigation)/urdf/robot.urdf.xacro\" />\n  </node>\n\n  <!-- Joint State Publisher (Optional for Visualization) -->\n  <node pkg=\"joint_state_publisher_gui\" type=\"joint_state_publisher_gui\" name=\"joint_state_publisher_gui\" />\n\n  <!-- Move Base Node -->\n  <node pkg=\"move_base\" type=\"move_base\" name=\"move_base\" output=\"screen\">\n    <!-- Load costmap and planner parameters -->\n    <rosparam file=\"$(find robot_navigation)/config/costmap_common_params.yaml\" />\n    <rosparam file=\"$(find robot_navigation)/config/global_planner_params.yaml\" />\n    <rosparam file=\"$(find robot_navigation)/config/local_planner_params.yaml\" />\n    <rosparam file=\"$(find robot_navigation)/config/recovery_behaviors.yaml\" />\n\n    <param name=\"base_global_planner\" value=\"navfn/NavfnROS\" />\n    <param name=\"base_local_planner\" value=\"dwa_local_planner/DWAPlannerROS\" />\n  </node>\n\n  <!-- RViz for Visualization -->\n  <node pkg=\"rviz\" type=\"rviz\" name=\"rviz\" args=\"-d $(find robot_navigation)/config/rviz_navigation_config.rviz\" required=\"true\" />\n</launch>\n\nThen the parameters file are the followings\nCommon_costmap_parametars.yaml\nplugins:\n  - {name: obstacle_layer, type: \"costmap_2d::ObstacleLayer\"}\n  - {name: inflation_layer, type: \"costmap_2d::InflationLayer\"}\n\nfootprint: [[-0.35, 0.35], [-0.35, -0.35], [0.35, -0.35], [0.35, 0.35], [0.6, 0.0]]\nfootprint_padding: 0.02\n\nrobot_radius: 0.2\nobstacle_range: 2.5\nraytrace_range: 3.0\ninflation_radius: 0.55\n\nglobal_costmap:\n  global_frame: map\n  robot_base_frame: base_link\n  update_frequency: 5.0\n  publish_frequency: 2.0\n  static_map: true\n  rolling_window: false  # Static map mode\n  width: 30.0  # Adjust based on your map size\n  height: 30.0\n  resolution: 0.05\n\nlocal_costmap:\n  global_frame: odom\n  robot_base_frame: base_link\n  update_frequency: 5.0\n  publish_frequency: 2.0\n  static_map: false\n  rolling_window: true  # Local window for dynamic updates\n  width: 6.0  # Focus on the robot's immediate surroundings\n  height: 6.0\n  resolution: 0.05\n\nglobal_planner_params.yaml\n NavfnROS:\n      allow_unknown: true\n      planner_patience: 5.0\n      default_tolerance: 0.0\n      use_dijkstra: true\n      use_quadratic: true\n      use_grid_path: false\n\nlocal_planner_params.yaml:\nDWAPlannerROS:\n  max_vel_x: 0.5\n  min_vel_x: 0.1\n  max_vel_theta: 1.0\n  min_vel_theta: -1.0\n  acc_lim_x: 2.5\n  acc_lim_theta: 2.5\n  xy_goal_tolerance: 0.2\n  yaw_goal_tolerance: 0.1 # Increased for smoother stops\n  sim_time: 1.5           # Increase simulation time for trajectory prediction\n  vx_samples: 20          # More velocity samples for smoother path\n  vtheta_samples: 40\n  path_distance_bias: 32.0\n  goal_distance_bias: 24.0\n  occdist_scale: 0.01\n  forward_point_distance: 0.2\n  stop_time_buffer: 0.2\n\nand recovery_behaviors.yaml:\nrecovery_behaviors:\n  - {name: \"clear_costmap_recovery\", type: \"clear_costmap_recovery/ClearCostmapRecovery\"}\n  - {name: \"rotate_recovery\", type: \"rotate_recovery/RotateRecovery\"}\n\nTrajectoryPlannerROS:\n  max_vel_x: 0.5\n  acc_lim_x: 2.5\n  recovery_behavior_enabled: true\n  clear_costmap_on_fail: true\n  rotate_recovery_enabled: true\n\nBut when launch the navigation file I got this warnings and errors\n[ WARN] [1732561758.050841599]: Control loop missed its desired rate of 20.0000Hz... the loop actually took 0.3805 seconds [ WARN] [1732561758.051388479]: Map update loop missed its desired rate of\n5.0000Hz... the loop actually took 0.2305 seconds [ WARN] [1732561758.426344393]: Control loop missed its desired rate of\n20.0000Hz... the loop actually took 0.3755 seconds [ WARN] [1732561758.426647247]: Map update loop missed its desired rate of\n5.0000Hz... the loop actually took 0.4060 seconds [ERROR] [1732561758.427151469]: Extrapolation Error: Lookup would require extrapolation 0.000719340s into the future.  Requested time\n1732561758.426456451 but the latest data is at time 1732561758.425737143, when looking up transform from frame [odom] to frame [map]\n\n[ERROR] [1732561758.427307796]: Global Frame: odom Plan Frame size 588: map\n\n[ WARN] [1732561758.427438369]: Could not transform the global plan to the frame of the controller [ERROR] [1732561758.427601409]: Could not get local plan [ INFO] [1732561758.476507989]: Got new plan [ERROR] [1732561758.477180604]: Extrapolation Error: Lookup would require extrapolation 0.000355752s into the future.  Requested time\n1732561758.476354599 but the latest data is at time 1732561758.475998878, when looking up transform from frame [odom] to frame [map]\n\n[ERROR] [1732561758.477320969]: Global Frame: odom Plan Frame size 588: map\n\nIn Rviz when send the Nav goal the robot is not moving. Any help?"], "question_code": ["&lt;?xml version=&quot;1.0&quot; ?&gt;\n&lt;launch&gt;\n  &lt;!-- Map Server --&gt;\n  &lt;node pkg=&quot;map_server&quot; type=&quot;map_server&quot; name=&quot;map_server&quot; args=&quot;$(find robot_navigation)/maps/map.yaml&quot;/&gt;\n\n  &lt;!-- Static Transforms --&gt;\n  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;map_to_odom&quot; args=&quot;0 0 0 0 0 0 map odom 0.1&quot; /&gt;\n  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;odom_to_base_link&quot; args=&quot;0 0 0 0 0 0 odom base_link 0.1&quot; /&gt;\n  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;base_link_to_towing_attachment&quot; args=&quot;0 -0.35 0 0 0 0 base_link towing_attachment 0.1&quot; /&gt;\n\n\n  &lt;!-- Robot State Publisher --&gt;\n  &lt;node pkg=&quot;robot_state_publisher&quot; type=&quot;robot_state_publisher&quot; name=&quot;robot_state_publisher&quot;&gt;\n    &lt;param name=&quot;publish_frequency&quot; value=&quot;10.0&quot; /&gt;\n    &lt;param name=&quot;robot_description&quot; command=&quot;$(find xacro)/xacro $(find robot_navigation)/urdf/robot.urdf.xacro&quot; /&gt;\n  &lt;/node&gt;\n\n  &lt;!-- Joint State Publisher (Optional for Visualization) --&gt;\n  &lt;node pkg=&quot;joint_state_publisher_gui&quot; type=&quot;joint_state_publisher_gui&quot; name=&quot;joint_state_publisher_gui&quot; /&gt;\n\n  &lt;!-- Move Base Node --&gt;\n  &lt;node pkg=&quot;move_base&quot; type=&quot;move_base&quot; name=&quot;move_base&quot; output=&quot;screen&quot;&gt;\n    &lt;!-- Load costmap and planner parameters --&gt;\n    &lt;rosparam file=&quot;$(find robot_navigation)/config/costmap_common_params.yaml&quot; /&gt;\n    &lt;rosparam file=&quot;$(find robot_navigation)/config/global_planner_params.yaml&quot; /&gt;\n    &lt;rosparam file=&quot;$(find robot_navigation)/config/local_planner_params.yaml&quot; /&gt;\n    &lt;rosparam file=&quot;$(find robot_navigation)/config/recovery_behaviors.yaml&quot; /&gt;\n\n    &lt;param name=&quot;base_global_planner&quot; value=&quot;navfn/NavfnROS&quot; /&gt;\n    &lt;param name=&quot;base_local_planner&quot; value=&quot;dwa_local_planner/DWAPlannerROS&quot; /&gt;\n  &lt;/node&gt;\n\n  &lt;!-- RViz for Visualization --&gt;\n  &lt;node pkg=&quot;rviz&quot; type=&quot;rviz&quot; name=&quot;rviz&quot; args=&quot;-d $(find robot_navigation)/config/rviz_navigation_config.rviz&quot; required=&quot;true&quot; /&gt;\n&lt;/launch&gt;\n", "plugins:\n  - {name: obstacle_layer, type: &quot;costmap_2d::ObstacleLayer&quot;}\n  - {name: inflation_layer, type: &quot;costmap_2d::InflationLayer&quot;}\n\nfootprint: [[-0.35, 0.35], [-0.35, -0.35], [0.35, -0.35], [0.35, 0.35], [0.6, 0.0]]\nfootprint_padding: 0.02\n\nrobot_radius: 0.2\nobstacle_range: 2.5\nraytrace_range: 3.0\ninflation_radius: 0.55\n\nglobal_costmap:\n  global_frame: map\n  robot_base_frame: base_link\n  update_frequency: 5.0\n  publish_frequency: 2.0\n  static_map: true\n  rolling_window: false  # Static map mode\n  width: 30.0  # Adjust based on your map size\n  height: 30.0\n  resolution: 0.05\n\nlocal_costmap:\n  global_frame: odom\n  robot_base_frame: base_link\n  update_frequency: 5.0\n  publish_frequency: 2.0\n  static_map: false\n  rolling_window: true  # Local window for dynamic updates\n  width: 6.0  # Focus on the robot's immediate surroundings\n  height: 6.0\n  resolution: 0.05\n", " NavfnROS:\n      allow_unknown: true\n      planner_patience: 5.0\n      default_tolerance: 0.0\n      use_dijkstra: true\n      use_quadratic: true\n      use_grid_path: false\n", "DWAPlannerROS:\n  max_vel_x: 0.5\n  min_vel_x: 0.1\n  max_vel_theta: 1.0\n  min_vel_theta: -1.0\n  acc_lim_x: 2.5\n  acc_lim_theta: 2.5\n  xy_goal_tolerance: 0.2\n  yaw_goal_tolerance: 0.1 # Increased for smoother stops\n  sim_time: 1.5           # Increase simulation time for trajectory prediction\n  vx_samples: 20          # More velocity samples for smoother path\n  vtheta_samples: 40\n  path_distance_bias: 32.0\n  goal_distance_bias: 24.0\n  occdist_scale: 0.01\n  forward_point_distance: 0.2\n  stop_time_buffer: 0.2\n", "recovery_behaviors:\n  - {name: &quot;clear_costmap_recovery&quot;, type: &quot;clear_costmap_recovery/ClearCostmapRecovery&quot;}\n  - {name: &quot;rotate_recovery&quot;, type: &quot;rotate_recovery/RotateRecovery&quot;}\n\nTrajectoryPlannerROS:\n  max_vel_x: 0.5\n  acc_lim_x: 2.5\n  recovery_behavior_enabled: true\n  clear_costmap_on_fail: true\n  rotate_recovery_enabled: true\n", "[ WARN] [1732561758.050841599]: Control loop missed its desired rate of 20.0000Hz... the loop actually took 0.3805 seconds [ WARN] [1732561758.051388479]: Map update loop missed its desired rate of\n5.0000Hz... the loop actually took 0.2305 seconds [ WARN] [1732561758.426344393]: Control loop missed its desired rate of\n20.0000Hz... the loop actually took 0.3755 seconds [ WARN] [1732561758.426647247]: Map update loop missed its desired rate of\n5.0000Hz... the loop actually took 0.4060 seconds [ERROR] [1732561758.427151469]: Extrapolation Error: Lookup would require extrapolation 0.000719340s into the future.  Requested time\n1732561758.426456451 but the latest data is at time 1732561758.425737143, when looking up transform from frame [odom] to frame [map]\n\n[ERROR] [1732561758.427307796]: Global Frame: odom Plan Frame size 588: map\n\n[ WARN] [1732561758.427438369]: Could not transform the global plan to the frame of the controller [ERROR] [1732561758.427601409]: Could not get local plan [ INFO] [1732561758.476507989]: Got new plan [ERROR] [1732561758.477180604]: Extrapolation Error: Lookup would require extrapolation 0.000355752s into the future.  Requested time\n1732561758.476354599 but the latest data is at time 1732561758.475998878, when looking up transform from frame [odom] to frame [map]\n\n[ERROR] [1732561758.477320969]: Global Frame: odom Plan Frame size 588: map\n"], "quote": [], "url": "https://stackoverflow.com/questions/79224562/testing-global-and-local-lplannes-using-created-footprint-and-static-map-is-not", "answer": [], "answer_code": []},
{"title": "URDF in ros2 no transform between lidar to base_link", "time": 1732083002, "post_content": ["<?xml version=\"1.0\"?>\n<robot name=\"my_robot\">\n    <material name=\"green\">\n        <color rgba=\"0.0 0.6 0.0 1\"/>\n    </material>\n    <material name=\"blue\">\n        <color rgba=\"0.0 0.0 1.0 1\"/>\n    </material>\n    <material name=\"white\">\n        <color rgba=\"1 1 1 1\"/>\n    </material>\n\n    <!-- Base Footprint -->\n    <link name=\"base_footprint\"/>\n\n    <!-- link name=\"base_footprint\"/ -->\n\n    <!-- Base Link -->\n    <link name=\"base_link\">\n        <inertial>\n            <mass value=\"1.0\"/>\n            <origin xyz=\"0.0 0.0 0.1\" rpy=\"0 0 0\"/>\n            <inertia ixx=\"0.02\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.02\" iyz=\"0.0\" izz=\"0.02\"/>\n        </inertial>\n        <visual>\n            <geometry>\n                <box size=\"0.6 0.4 0.2\"/>\n            </geometry>\n            <origin xyz=\"0.0 0.0 0.1\" rpy=\"0 0 0\"/>\n            <material name=\"blue\"/>\n        </visual>\n        <collision>\n            <geometry>\n                <box size=\"0.6 0.4 0.2\"/>\n            </geometry>\n            <origin xyz=\"0.0 0.0 0.1\" rpy=\"0 0 0\"/>\n        </collision>\n    </link>\n\n    <gazebo reference=\"base_link\">\n        <material>Gazebo/Blue</material>\n    </gazebo>\n    \n    <!-- Lidar -->\n    <link name=\"lidar\">\n        <inertial>\n            <mass value=\"0.1\"/>\n            <origin xyz=\"0.0 0.0 0.05\" rpy=\"0 0 0\"/>\n            <inertia ixx=\"0.001\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.001\" iyz=\"0.0\" izz=\"0.001\"/>\n        </inertial>\n        <visual>\n            <geometry>\n                <cylinder radius=\"0.1\" length=\"0.05\"/>\n            </geometry>\n            <origin xyz=\"0.0 0.0 0\" rpy=\"0 0 0\"/>\n            <material name=\"white\"/>\n        </visual>\n        <collision>\n            <geometry>\n                <cylinder radius=\"0.1\" length=\"0.05\"/>\n            </geometry>\n            <origin xyz=\"0.0 0.0 0.0\" rpy=\"0 0 0\"/>\n        </collision>\n    </link>\n\n    <!-- Caster Wheel -->\n    <link name=\"caster_wheel\">\n        <inertial>\n            <mass value=\"0.1\"/>\n            <origin xyz=\"0.0 0.0 0\" rpy=\"0 0 0\"/>\n            <inertia ixx=\"0.001\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.001\" iyz=\"0.0\" izz=\"0.001\"/>\n        </inertial>\n        <visual>\n            <geometry>\n                <sphere radius=\"0.05\"/>\n            </geometry> \n            <origin xyz=\"0.0 0.0 0\" rpy=\"0 0 0\"/>\n            <material name=\"white\"/>\n        </visual>\n        <collision>\n            <geometry>\n                <sphere radius=\"0.05\"/>\n            </geometry>\n            <origin xyz=\"0.0 0.0 0\" rpy=\"0 0 0\"/>\n        </collision>\n    </link>\n\n    <gazebo reference=\"caster_wheel\">\n        <mu1 value=\"0.001\"/>\n        <mu2 value=\"0.001\"/>\n    </gazebo>\n\n    <!-- Left Wheel -->\n    <link name=\"left_wheel\">\n        <inertial>\n            <mass value=\"0.2\"/>\n            <origin xyz=\"0.0 0.0 0\" rpy=\"0 0 0\"/>\n            <inertia ixx=\"0.002\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.002\" iyz=\"0.0\" izz=\"0.002\"/>\n        </inertial>\n        <visual>\n            <geometry>\n                <cylinder radius=\"0.1\" length=\"0.05\"/>\n            </geometry>\n            <origin xyz=\"0.0 0.0 0\" rpy=\"1.57 0 0\"/>\n            <material name=\"white\"/>\n        </visual>\n        <collision>\n            <geometry>\n                <cylinder radius=\"0.1\" length=\"0.05\"/>\n            </geometry>\n            <origin xyz=\"0.0 0.0 0\" rpy=\"1.57 0 0\"/>\n        </collision>\n    </link>\n\n    <!-- Right Wheel -->\n    <link name=\"right_wheel\">\n        <inertial>\n            <mass value=\"0.2\"/>\n            <origin xyz=\"0.0 0.0 0\" rpy=\"0 0 0\"/>\n            <inertia ixx=\"0.002\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.002\" iyz=\"0.0\" izz=\"0.002\"/>\n        </inertial>\n        <visual>\n            <geometry>\n                <cylinder radius=\"0.1\" length=\"0.05\"/>\n            </geometry>\n            <origin xyz=\"0.0 0.0 0\" rpy=\"1.57 0 0\"/>\n            <material name=\"white\"/>\n        </visual>\n        <collision>\n            <geometry>\n                <cylinder radius=\"0.1\" length=\"0.05\"/>\n            </geometry>\n            <origin xyz=\"0.0 0.0 0\" rpy=\"1.57 0 0\"/>\n        </collision>\n    </link>\n\n    <!-- Joints -->\n    <joint name=\"base_joint\" type=\"fixed\">\n        <parent link=\"base_link\"/>\n        <child link=\"base_footprint\"/>\n        <origin xyz=\"0.0 0.0 0.0\" rpy=\"0 0 0\"/>\n    </joint>\n\n    <joint name=\"base_lidar_joint\" type=\"fixed\">\n        <parent link=\"base_link\"/>\n        <child link=\"lidar\"/>\n        <origin xyz=\"0.2 0.0 0.225\" rpy=\"0 0 0\"/>\n    </joint>\n\n    <joint name=\"left_wheel_joint\" type=\"continuous\">\n        <parent link=\"base_link\"/>\n        <child link=\"left_wheel\"/>\n        <origin xyz=\"-0.15 -0.225 0.04\" rpy=\"0 0 0\"/>\n        <axis xyz=\"0.0 1.0 0.0\"/>\n    </joint>\n\n    <joint name=\"right_wheel_joint\" type=\"continuous\">\n        <parent link=\"base_link\"/>\n        <child link=\"right_wheel\"/>\n        <origin xyz=\"-0.15 0.225 0.04\" rpy=\"0 0 0\"/>\n        <axis xyz=\"0.0 1.0 0.0\"/>\n    </joint>\n\n    <joint name=\"caster_wheel_joint\" type=\"fixed\">\n        <parent link=\"base_link\"/>\n        <child link=\"caster_wheel\"/>\n        <origin xyz=\"0.2 0 -0.01\" rpy=\"0 0 0\"/>\n    </joint>\n\n    <!-- Gazebo Plugins -->\n     <!-- Gazebo plugin for Lidar Sensor -->\n    <gazebo reference=\"lidar\">\n        <sensor name=\"laser\" type=\"ray\">\n            <pose> 0 0 0 0 0 0 </pose>\n            <visualize>true</visualize>\n            <update_rate>30</update_rate>\n            <ray>\n                <scan>\n                    <horizontal>\n                        <samples>360</samples>\n                        <min_angle>-3.14</min_angle>\n                        <max_angle>3.14</max_angle>\n                    </horizontal>\n                </scan>\n                <range>\n                    <min>0.3</min>\n                    <max>12</max>\n                </range>\n            </ray>\n            <plugin name=\"laser_controller\" filename=\"libgazebo_ros_ray_sensor.so\">\n                <ros>\n                    <remapping>out:=/scan</remapping>\n                    <!-- <namespace>/bot</namespace> -->\n                </ros>\n                <output_type>sensor_msgs/LaserScan</output_type>\n                <frame_name>lidar</frame_name>\n            </plugin>\n        </sensor>\n    </gazebo>\n    \n    <gazebo>\n        <plugin name=\"bot_joint_state\" filename=\"libgazebo_ros_joint_state_publisher.so\">\n            <ros>\n                <remapping>~/out:=joint_states</remapping>\n            </ros>\n            <update_rate>30</update_rate>\n            <joint_name>right_wheel_joint</joint_name>\n            <joint_name>left_wheel_joint</joint_name>\n            <joint_name>caster_wheel_joint</joint_name>\n            <joint_name>base_lidar_joint</joint_name>\n        </plugin>\n    </gazebo>\n\n    <gazebo>\n        <plugin name=\"differential_drive_controller\" filename=\"libgazebo_ros_diff_drive.so\">\n            <!-- Wheel Information -->\n            <update_rate>30</update_rate>\n            <left_joint>left_wheel_joint</left_joint>\n            <right_joint>right_wheel_joint</right_joint>\n            <wheel_separation>0.45</wheel_separation>\n            <wheel_diameter>0.18</wheel_diameter>\n            <!-- Limits -->\n            <max_wheel_torque>10.0</max_wheel_torque>\n            <max_wheel_acceleration>1.0</max_wheel_acceleration>\n            <!-- Output -->\n            <command_topic>cmd_vel</command_topic>\n            <publish_odom>true</publish_odom>\n            <publish_odom_tf>true</publish_odom_tf>\n            <odometry_frame>odom</odometry_frame>\n            <robot_base_frame>base_link</robot_base_frame>\n            <publish_wheel_tf>true</publish_wheel_tf>\n        </plugin>\n    </gazebo>\n</robot>\n\nthis is my urdf\nWhile running this in gazebo laser of the lidar is visible\nbut in rviz not visible like it is sensing\nbut while checking the topic using\nros2 topic echo /laser_controller/out\n\n\nits publishing correcting\nbut not visible in rviz I also tried by increasing the laser visible size in rviz no use.\n#!/usr/bin/python3\n# -*- coding: utf-8 -*-\nimport os\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, SetEnvironmentVariable, IncludeLaunchDescription\nfrom launch_ros.actions import Node\nfrom ament_index_python.packages import get_package_share_directory\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\n\ndef generate_launch_description():\n    # Paths\n    pkg_bot = get_package_share_directory('bot')\n    pkg_gazebo_ros = get_package_share_directory('gazebo_ros')\n    world_path = os.path.join(pkg_bot, 'world', 'no_roof_small_warehouse.world')\n    urdf_file = os.path.join(pkg_bot, 'urdf', 'trial.urdf')\n\n    # Ensure files exist\n    if not os.path.exists(world_path):\n        raise FileNotFoundError(f\"World file not found: {world_path}\")\n    if not os.path.exists(urdf_file):\n        raise FileNotFoundError(f\"URDF file not found: {urdf_file}\")\n\n    # Read the URDF file to pass to robot_description\n    with open(urdf_file, 'r') as urdf_f:\n        robot_description = urdf_f.read()\n\n    return LaunchDescription([\n        # Set environment variables for Gazebo\n        SetEnvironmentVariable('GAZEBO_MODEL_PATH', os.path.join(pkg_bot, 'models')),\n        SetEnvironmentVariable('GAZEBO_PLUGIN_PATH', os.path.join(pkg_gazebo_ros, 'lib')),\n\n        # Launch Gazebo with the specified world\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource(\n                os.path.join(pkg_gazebo_ros, 'launch', 'gazebo.launch.py')\n            ),\n            launch_arguments={'world': world_path}.items()\n        ),\n\n        # Provide the robot_description to the robot_state_publisher\n        Node(\n            package='robot_state_publisher',\n            executable='robot_state_publisher',\n            parameters=[{'robot_description': robot_description}],\n            output='screen'\n        ),\n\n        # Spawn the robot in Gazebo\n        Node(\n            package='gazebo_ros',\n            executable='spawn_entity.py',\n            arguments=['-file', urdf_file, '-entity', 'your_robot_name'],\n            output='screen'\n        ),\n\n        # Static transform publisher for laser_frame relative to base_link\n        Node(\n            package='tf2_ros',\n            executable='static_transform_publisher',\n            arguments=[\n                '0.2', '0.0', '0.1',   # Translation (x, y, z)\n                '0', '0', '0',         # Rotation (roll, pitch, yaw in radians)\n                'base_link',           # Parent frame\n                'laser_frame'          # Child frame\n            ],\n            output='screen'\n        )\n    ])\n\nso I have added a new node for static transform as temporary solution but while running slam toolbox the map is not forming.\nIs there any solution for this?\nros2 run tf2_tools view_frames\n\nusing this I saw that there is no transform between lidar and base_link\nbut in gazebo its clearly visile , the lidar topic also correctly publishing"], "question_code": ["&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;robot name=&quot;my_robot&quot;&gt;\n    &lt;material name=&quot;green&quot;&gt;\n        &lt;color rgba=&quot;0.0 0.6 0.0 1&quot;/&gt;\n    &lt;/material&gt;\n    &lt;material name=&quot;blue&quot;&gt;\n        &lt;color rgba=&quot;0.0 0.0 1.0 1&quot;/&gt;\n    &lt;/material&gt;\n    &lt;material name=&quot;white&quot;&gt;\n        &lt;color rgba=&quot;1 1 1 1&quot;/&gt;\n    &lt;/material&gt;\n\n    &lt;!-- Base Footprint --&gt;\n    &lt;link name=&quot;base_footprint&quot;/&gt;\n\n    &lt;!-- link name=&quot;base_footprint&quot;/ --&gt;\n\n    &lt;!-- Base Link --&gt;\n    &lt;link name=&quot;base_link&quot;&gt;\n        &lt;inertial&gt;\n            &lt;mass value=&quot;1.0&quot;/&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0.1&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;inertia ixx=&quot;0.02&quot; ixy=&quot;0.0&quot; ixz=&quot;0.0&quot; iyy=&quot;0.02&quot; iyz=&quot;0.0&quot; izz=&quot;0.02&quot;/&gt;\n        &lt;/inertial&gt;\n        &lt;visual&gt;\n            &lt;geometry&gt;\n                &lt;box size=&quot;0.6 0.4 0.2&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0.1&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;material name=&quot;blue&quot;/&gt;\n        &lt;/visual&gt;\n        &lt;collision&gt;\n            &lt;geometry&gt;\n                &lt;box size=&quot;0.6 0.4 0.2&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0.1&quot; rpy=&quot;0 0 0&quot;/&gt;\n        &lt;/collision&gt;\n    &lt;/link&gt;\n\n    &lt;gazebo reference=&quot;base_link&quot;&gt;\n        &lt;material&gt;Gazebo/Blue&lt;/material&gt;\n    &lt;/gazebo&gt;\n    \n    &lt;!-- Lidar --&gt;\n    &lt;link name=&quot;lidar&quot;&gt;\n        &lt;inertial&gt;\n            &lt;mass value=&quot;0.1&quot;/&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0.05&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;inertia ixx=&quot;0.001&quot; ixy=&quot;0.0&quot; ixz=&quot;0.0&quot; iyy=&quot;0.001&quot; iyz=&quot;0.0&quot; izz=&quot;0.001&quot;/&gt;\n        &lt;/inertial&gt;\n        &lt;visual&gt;\n            &lt;geometry&gt;\n                &lt;cylinder radius=&quot;0.1&quot; length=&quot;0.05&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;material name=&quot;white&quot;/&gt;\n        &lt;/visual&gt;\n        &lt;collision&gt;\n            &lt;geometry&gt;\n                &lt;cylinder radius=&quot;0.1&quot; length=&quot;0.05&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0 0 0&quot;/&gt;\n        &lt;/collision&gt;\n    &lt;/link&gt;\n\n    &lt;!-- Caster Wheel --&gt;\n    &lt;link name=&quot;caster_wheel&quot;&gt;\n        &lt;inertial&gt;\n            &lt;mass value=&quot;0.1&quot;/&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;inertia ixx=&quot;0.001&quot; ixy=&quot;0.0&quot; ixz=&quot;0.0&quot; iyy=&quot;0.001&quot; iyz=&quot;0.0&quot; izz=&quot;0.001&quot;/&gt;\n        &lt;/inertial&gt;\n        &lt;visual&gt;\n            &lt;geometry&gt;\n                &lt;sphere radius=&quot;0.05&quot;/&gt;\n            &lt;/geometry&gt; \n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;material name=&quot;white&quot;/&gt;\n        &lt;/visual&gt;\n        &lt;collision&gt;\n            &lt;geometry&gt;\n                &lt;sphere radius=&quot;0.05&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n        &lt;/collision&gt;\n    &lt;/link&gt;\n\n    &lt;gazebo reference=&quot;caster_wheel&quot;&gt;\n        &lt;mu1 value=&quot;0.001&quot;/&gt;\n        &lt;mu2 value=&quot;0.001&quot;/&gt;\n    &lt;/gazebo&gt;\n\n    &lt;!-- Left Wheel --&gt;\n    &lt;link name=&quot;left_wheel&quot;&gt;\n        &lt;inertial&gt;\n            &lt;mass value=&quot;0.2&quot;/&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;inertia ixx=&quot;0.002&quot; ixy=&quot;0.0&quot; ixz=&quot;0.0&quot; iyy=&quot;0.002&quot; iyz=&quot;0.0&quot; izz=&quot;0.002&quot;/&gt;\n        &lt;/inertial&gt;\n        &lt;visual&gt;\n            &lt;geometry&gt;\n                &lt;cylinder radius=&quot;0.1&quot; length=&quot;0.05&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;1.57 0 0&quot;/&gt;\n            &lt;material name=&quot;white&quot;/&gt;\n        &lt;/visual&gt;\n        &lt;collision&gt;\n            &lt;geometry&gt;\n                &lt;cylinder radius=&quot;0.1&quot; length=&quot;0.05&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;1.57 0 0&quot;/&gt;\n        &lt;/collision&gt;\n    &lt;/link&gt;\n\n    &lt;!-- Right Wheel --&gt;\n    &lt;link name=&quot;right_wheel&quot;&gt;\n        &lt;inertial&gt;\n            &lt;mass value=&quot;0.2&quot;/&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n            &lt;inertia ixx=&quot;0.002&quot; ixy=&quot;0.0&quot; ixz=&quot;0.0&quot; iyy=&quot;0.002&quot; iyz=&quot;0.0&quot; izz=&quot;0.002&quot;/&gt;\n        &lt;/inertial&gt;\n        &lt;visual&gt;\n            &lt;geometry&gt;\n                &lt;cylinder radius=&quot;0.1&quot; length=&quot;0.05&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;1.57 0 0&quot;/&gt;\n            &lt;material name=&quot;white&quot;/&gt;\n        &lt;/visual&gt;\n        &lt;collision&gt;\n            &lt;geometry&gt;\n                &lt;cylinder radius=&quot;0.1&quot; length=&quot;0.05&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0&quot; rpy=&quot;1.57 0 0&quot;/&gt;\n        &lt;/collision&gt;\n    &lt;/link&gt;\n\n    &lt;!-- Joints --&gt;\n    &lt;joint name=&quot;base_joint&quot; type=&quot;fixed&quot;&gt;\n        &lt;parent link=&quot;base_link&quot;/&gt;\n        &lt;child link=&quot;base_footprint&quot;/&gt;\n        &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;/joint&gt;\n\n    &lt;joint name=&quot;base_lidar_joint&quot; type=&quot;fixed&quot;&gt;\n        &lt;parent link=&quot;base_link&quot;/&gt;\n        &lt;child link=&quot;lidar&quot;/&gt;\n        &lt;origin xyz=&quot;0.2 0.0 0.225&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;/joint&gt;\n\n    &lt;joint name=&quot;left_wheel_joint&quot; type=&quot;continuous&quot;&gt;\n        &lt;parent link=&quot;base_link&quot;/&gt;\n        &lt;child link=&quot;left_wheel&quot;/&gt;\n        &lt;origin xyz=&quot;-0.15 -0.225 0.04&quot; rpy=&quot;0 0 0&quot;/&gt;\n        &lt;axis xyz=&quot;0.0 1.0 0.0&quot;/&gt;\n    &lt;/joint&gt;\n\n    &lt;joint name=&quot;right_wheel_joint&quot; type=&quot;continuous&quot;&gt;\n        &lt;parent link=&quot;base_link&quot;/&gt;\n        &lt;child link=&quot;right_wheel&quot;/&gt;\n        &lt;origin xyz=&quot;-0.15 0.225 0.04&quot; rpy=&quot;0 0 0&quot;/&gt;\n        &lt;axis xyz=&quot;0.0 1.0 0.0&quot;/&gt;\n    &lt;/joint&gt;\n\n    &lt;joint name=&quot;caster_wheel_joint&quot; type=&quot;fixed&quot;&gt;\n        &lt;parent link=&quot;base_link&quot;/&gt;\n        &lt;child link=&quot;caster_wheel&quot;/&gt;\n        &lt;origin xyz=&quot;0.2 0 -0.01&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;/joint&gt;\n\n    &lt;!-- Gazebo Plugins --&gt;\n     &lt;!-- Gazebo plugin for Lidar Sensor --&gt;\n    &lt;gazebo reference=&quot;lidar&quot;&gt;\n        &lt;sensor name=&quot;laser&quot; type=&quot;ray&quot;&gt;\n            &lt;pose&gt; 0 0 0 0 0 0 &lt;/pose&gt;\n            &lt;visualize&gt;true&lt;/visualize&gt;\n            &lt;update_rate&gt;30&lt;/update_rate&gt;\n            &lt;ray&gt;\n                &lt;scan&gt;\n                    &lt;horizontal&gt;\n                        &lt;samples&gt;360&lt;/samples&gt;\n                        &lt;min_angle&gt;-3.14&lt;/min_angle&gt;\n                        &lt;max_angle&gt;3.14&lt;/max_angle&gt;\n                    &lt;/horizontal&gt;\n                &lt;/scan&gt;\n                &lt;range&gt;\n                    &lt;min&gt;0.3&lt;/min&gt;\n                    &lt;max&gt;12&lt;/max&gt;\n                &lt;/range&gt;\n            &lt;/ray&gt;\n            &lt;plugin name=&quot;laser_controller&quot; filename=&quot;libgazebo_ros_ray_sensor.so&quot;&gt;\n                &lt;ros&gt;\n                    &lt;remapping&gt;out:=/scan&lt;/remapping&gt;\n                    &lt;!-- &lt;namespace&gt;/bot&lt;/namespace&gt; --&gt;\n                &lt;/ros&gt;\n                &lt;output_type&gt;sensor_msgs/LaserScan&lt;/output_type&gt;\n                &lt;frame_name&gt;lidar&lt;/frame_name&gt;\n            &lt;/plugin&gt;\n        &lt;/sensor&gt;\n    &lt;/gazebo&gt;\n    \n    &lt;gazebo&gt;\n        &lt;plugin name=&quot;bot_joint_state&quot; filename=&quot;libgazebo_ros_joint_state_publisher.so&quot;&gt;\n            &lt;ros&gt;\n                &lt;remapping&gt;~/out:=joint_states&lt;/remapping&gt;\n            &lt;/ros&gt;\n            &lt;update_rate&gt;30&lt;/update_rate&gt;\n            &lt;joint_name&gt;right_wheel_joint&lt;/joint_name&gt;\n            &lt;joint_name&gt;left_wheel_joint&lt;/joint_name&gt;\n            &lt;joint_name&gt;caster_wheel_joint&lt;/joint_name&gt;\n            &lt;joint_name&gt;base_lidar_joint&lt;/joint_name&gt;\n        &lt;/plugin&gt;\n    &lt;/gazebo&gt;\n\n    &lt;gazebo&gt;\n        &lt;plugin name=&quot;differential_drive_controller&quot; filename=&quot;libgazebo_ros_diff_drive.so&quot;&gt;\n            &lt;!-- Wheel Information --&gt;\n            &lt;update_rate&gt;30&lt;/update_rate&gt;\n            &lt;left_joint&gt;left_wheel_joint&lt;/left_joint&gt;\n            &lt;right_joint&gt;right_wheel_joint&lt;/right_joint&gt;\n            &lt;wheel_separation&gt;0.45&lt;/wheel_separation&gt;\n            &lt;wheel_diameter&gt;0.18&lt;/wheel_diameter&gt;\n            &lt;!-- Limits --&gt;\n            &lt;max_wheel_torque&gt;10.0&lt;/max_wheel_torque&gt;\n            &lt;max_wheel_acceleration&gt;1.0&lt;/max_wheel_acceleration&gt;\n            &lt;!-- Output --&gt;\n            &lt;command_topic&gt;cmd_vel&lt;/command_topic&gt;\n            &lt;publish_odom&gt;true&lt;/publish_odom&gt;\n            &lt;publish_odom_tf&gt;true&lt;/publish_odom_tf&gt;\n            &lt;odometry_frame&gt;odom&lt;/odometry_frame&gt;\n            &lt;robot_base_frame&gt;base_link&lt;/robot_base_frame&gt;\n            &lt;publish_wheel_tf&gt;true&lt;/publish_wheel_tf&gt;\n        &lt;/plugin&gt;\n    &lt;/gazebo&gt;\n&lt;/robot&gt;\n", "ros2 topic echo /laser_controller/out\n\n", "#!/usr/bin/python3\n# -*- coding: utf-8 -*-\nimport os\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, SetEnvironmentVariable, IncludeLaunchDescription\nfrom launch_ros.actions import Node\nfrom ament_index_python.packages import get_package_share_directory\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\n\ndef generate_launch_description():\n    # Paths\n    pkg_bot = get_package_share_directory('bot')\n    pkg_gazebo_ros = get_package_share_directory('gazebo_ros')\n    world_path = os.path.join(pkg_bot, 'world', 'no_roof_small_warehouse.world')\n    urdf_file = os.path.join(pkg_bot, 'urdf', 'trial.urdf')\n\n    # Ensure files exist\n    if not os.path.exists(world_path):\n        raise FileNotFoundError(f&quot;World file not found: {world_path}&quot;)\n    if not os.path.exists(urdf_file):\n        raise FileNotFoundError(f&quot;URDF file not found: {urdf_file}&quot;)\n\n    # Read the URDF file to pass to robot_description\n    with open(urdf_file, 'r') as urdf_f:\n        robot_description = urdf_f.read()\n\n    return LaunchDescription([\n        # Set environment variables for Gazebo\n        SetEnvironmentVariable('GAZEBO_MODEL_PATH', os.path.join(pkg_bot, 'models')),\n        SetEnvironmentVariable('GAZEBO_PLUGIN_PATH', os.path.join(pkg_gazebo_ros, 'lib')),\n\n        # Launch Gazebo with the specified world\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource(\n                os.path.join(pkg_gazebo_ros, 'launch', 'gazebo.launch.py')\n            ),\n            launch_arguments={'world': world_path}.items()\n        ),\n\n        # Provide the robot_description to the robot_state_publisher\n        Node(\n            package='robot_state_publisher',\n            executable='robot_state_publisher',\n            parameters=[{'robot_description': robot_description}],\n            output='screen'\n        ),\n\n        # Spawn the robot in Gazebo\n        Node(\n            package='gazebo_ros',\n            executable='spawn_entity.py',\n            arguments=['-file', urdf_file, '-entity', 'your_robot_name'],\n            output='screen'\n        ),\n\n        # Static transform publisher for laser_frame relative to base_link\n        Node(\n            package='tf2_ros',\n            executable='static_transform_publisher',\n            arguments=[\n                '0.2', '0.0', '0.1',   # Translation (x, y, z)\n                '0', '0', '0',         # Rotation (roll, pitch, yaw in radians)\n                'base_link',           # Parent frame\n                'laser_frame'          # Child frame\n            ],\n            output='screen'\n        )\n    ])\n", "ros2 run tf2_tools view_frames\n"], "quote": [], "url": "https://stackoverflow.com/questions/79205989/urdf-in-ros2-no-transform-between-lidar-to-base-link", "answer": [], "answer_code": []},
{"title": "ROS1: RobotModel errors in RViz", "time": 1732078957, "post_content": ["Using ROS1, when I run the launch file below, the map is loaded successfully in Rviz, the robot is shown with white color. However, there are errors shown in RViz related to RobotModel: URDF is stated to be parsed OK; however, the other parameters like base_link, i get error messages: no transform from [base_link] to map. In the global status, there is the following error: Fixed Frame: Fixed Frame [map] does not exist...how can i solve this problem? I am using simulation and I did not launch gazebo before executing the below launch file. The below gives the list of topics opened when running the launch file\nrostopic list \n/amcl/parameter_descriptions\n/amcl/parameter_updates\n/amcl_pose\n/clicked_point\n/initialpose \n/joint_states\n/map\n/map_metadata\n/move_base_simple/goal\n/particlecloud\n/rosout\n/rosout_agg\n/scan\n/tf\n/tf_static\n\n\n\n<launch>\n  <!-- Arguments -->\n  <arg name=\"model\" default=\"$(env TURTLEBOT3_MODEL)\" doc=\"model type [burger, waffle, waffle_pi]\"/>\n  <arg name=\"map_file\" default=\"/home/maps/map.yaml\"/>\n  <arg name=\"open_rviz\" default=\"true\"/>\n  <arg name=\"move_forward_only\" default=\"false\"/>\n\n\n  <!-- Map server -->\n  <node pkg=\"map_server\" name=\"map_server\" type=\"map_server\" args=\"$(arg map_file)\"/>\n\n  <!-- AMCL -->\n  <include file=\"$(find turtlebot3_navigation)/launch/amcl.launch\"/>\n\n  <!-- move_base -->\n  <include file=\"$(find turtlebot3_navigation)/launch/move_base.launch\">\n    <arg name=\"model\" value=\"$(arg model)\" />\n    <arg name=\"move_forward_only\" value=\"$(arg move_forward_only)\"/>\n  </include>\n\n  <!-- rviz -->\n  <group if=\"$(arg open_rviz)\"> \n    <node pkg=\"rviz\" type=\"rviz\" name=\"rviz\" required=\"true\"\n          args=\"-d $(find turtlebot3_navigation)/rviz/turtlebot3_navigation.rviz\"/>\n  </group>\n</launch>"], "question_code": ["rostopic list \n/amcl/parameter_descriptions\n/amcl/parameter_updates\n/amcl_pose\n/clicked_point\n/initialpose \n/joint_states\n/map\n/map_metadata\n/move_base_simple/goal\n/particlecloud\n/rosout\n/rosout_agg\n/scan\n/tf\n/tf_static\n\n\n\n&lt;launch&gt;\n  &lt;!-- Arguments --&gt;\n  &lt;arg name=&quot;model&quot; default=&quot;$(env TURTLEBOT3_MODEL)&quot; doc=&quot;model type [burger, waffle, waffle_pi]&quot;/&gt;\n  &lt;arg name=&quot;map_file&quot; default=&quot;/home/maps/map.yaml&quot;/&gt;\n  &lt;arg name=&quot;open_rviz&quot; default=&quot;true&quot;/&gt;\n  &lt;arg name=&quot;move_forward_only&quot; default=&quot;false&quot;/&gt;\n\n\n  &lt;!-- Map server --&gt;\n  &lt;node pkg=&quot;map_server&quot; name=&quot;map_server&quot; type=&quot;map_server&quot; args=&quot;$(arg map_file)&quot;/&gt;\n\n  &lt;!-- AMCL --&gt;\n  &lt;include file=&quot;$(find turtlebot3_navigation)/launch/amcl.launch&quot;/&gt;\n\n  &lt;!-- move_base --&gt;\n  &lt;include file=&quot;$(find turtlebot3_navigation)/launch/move_base.launch&quot;&gt;\n    &lt;arg name=&quot;model&quot; value=&quot;$(arg model)&quot; /&gt;\n    &lt;arg name=&quot;move_forward_only&quot; value=&quot;$(arg move_forward_only)&quot;/&gt;\n  &lt;/include&gt;\n\n  &lt;!-- rviz --&gt;\n  &lt;group if=&quot;$(arg open_rviz)&quot;&gt; \n    &lt;node pkg=&quot;rviz&quot; type=&quot;rviz&quot; name=&quot;rviz&quot; required=&quot;true&quot;\n          args=&quot;-d $(find turtlebot3_navigation)/rviz/turtlebot3_navigation.rviz&quot;/&gt;\n  &lt;/group&gt;\n&lt;/launch&gt;\n"], "quote": [], "url": "https://stackoverflow.com/questions/79205868/ros1-robotmodel-errors-in-rviz", "answer": [], "answer_code": []},
{"title": "What is the best way to deal with protoc generated file with docker?", "time": 1731887238, "post_content": ["I am using Docker to manage my ROS environment, and I recreate the Docker container each time I run it. When I first run catkin_make on my ROS package, protoc generates some files that are stored in the system directory of the Docker container. However, these files are lost when I recreate the container, and subsequent attempts to run catkin_make fail because it doesn't regenerate those files, leading to errors.\nWhat is the best approach to manage these generated files? Should I store them in a local directory that persists across container runs, or should I modify the build process so catkin_make regenerates the files each time I start a new container?"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79198379/what-is-the-best-way-to-deal-with-protoc-generated-file-with-docker", "answer": [], "answer_code": []},
{"title": "implement nav2 navigation using d455 realsense camera", "time": 1731827480, "post_content": ["I am trying to develop slam with intelRealsense camera d455 for my robot.\nI converted the 3d point cloud data to 2d lidar data using depth_to_laser package.\nNow i want to develop nav2 but I am confused\nfor localization. I think amcl is not good choice because realsense has not 360 degree fov and amcl may not work correctly.\nAlso for odometry data I have wheel encoder and I want to fuse it with realsense imu data. Is it good to fuse realsense imu with odometry to get accurate odometry or use something like rgdb odometry from rtabmap package?\nAlso for localization in nav2 should I use robot localization package instead of amcl?\nAnd what if I use robot localization, what about map->odom tf?\nWill robot localization publish it correctly?\nThank you all\nI tried to localize with amcl but didnt work correctly."], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79196667/implement-nav2-navigation-using-d455-realsense-camera", "answer": [], "answer_code": []},
{"title": "WebRTC connection does not happen after ICE exchange", "time": 1731651914, "post_content": ["This is an issue that has been bugging me for a whole week.....\nI am trying to establish a webRTC connection with a python server using aiortc/ web client. Both client and server is connected within a local network with no firewall.\nI have exchanged SDP/ICE messages through ROS, and confirmed that the messages contain local addresses of both machines. (For those who are not familiar to ros, it is a sub/pub messaging protocol used in robotics)\nThe connection fails and the video feed is not shown, but I am not sure what I am doing wrong. Any help will be truly appreciated :)\nClient Code\nimport React, { useEffect, useRef } from 'react';\nimport { useROS } from './ROSContext';\nimport ROSLIB from 'roslib';\n\nconst WebRTCClient: React.FC = () => {\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const peerConnection = useRef<RTCPeerConnection | null>(null);\n  const { ros } = useROS();\n\n  useEffect(() => {\n    const configuration: RTCConfiguration = {\n      iceTransportPolicy: 'all', // TypeScript should accept 'all' here\n      iceServers: [] // No STUN or TURN servers needed for your local network\n    };\n    const pc = new RTCPeerConnection(configuration);\n    peerConnection.current = pc;\n\n    pc.addTransceiver('video');\n\n    // Display the incoming video stream\n    pc.ontrack = (event) => {\n      if (videoRef.current) {\n        videoRef.current.srcObject = event.streams[0];\n        console.log(event.streams[0]);\n        videoRef.current.play().then(() => {\n          console.log('Video playback started');\n        }).catch((error) => {\n          console.error('Error starting video playback:', error);\n        })\n      }\n    };\n\n    pc.onconnectionstatechange = () => {\n      console.log('Connection state changed:', pc.connectionState);\n    }\n\n    pc.onicecandidateerror = (event) => {\n      console.error('ICE candidate error:', event);\n    };\n\n    pc.onnegotiationneeded = () => {\n      console.log('Negotiation needed');\n    };\n\n    pc.onicegatheringstatechange = () => {\n      console.log('ICE gathering state changed:', pc.iceGatheringState);\n    }\n\n    pc.ondatachannel = (event) => {\n      console.log('Data channel created:', event.channel);\n    }\n\n    pc.onsignalingstatechange = () => {\n      console.log('Signaling state changed:', pc.signalingState);\n    }\n\n    pc.oniceconnectionstatechange = () => {\n      console.log('ICE connection state changed:', pc.iceConnectionState);\n    }\n\n    // Publish ICE candidates to the ROS node\n    const candidatePublishTopic = new ROSLIB.Topic({\n      ros: ros,\n      name: '/webrtc_ice_candidate_client',\n      messageType: 'webrtc_services/ICECandidate',\n    });\n\n    pc.onicecandidate = (event) => {\n      if (event.candidate) {\n        const candidateMsg = {\n          component: event.candidate.component,\n          foundation: event.candidate.foundation,\n          address: event.candidate.address,\n          port: event.candidate.port,\n          priority: event.candidate.priority,\n          protocol: event.candidate.protocol,\n          type: event.candidate.type,\n          sdpmid: event.candidate.sdpMid,\n          sdpmlineindex: event.candidate.sdpMLineIndex,\n        }\n        // print all parameters\n        console.log('ICE candidate:', candidateMsg);\n        candidatePublishTopic.publish(new ROSLIB.Message(candidateMsg));\n      }\n    };\n\n    // Subscribe to ICE candidates from ROS node\n    const candidateSubscribeTopic = new ROSLIB.Topic({\n      ros: ros,\n      name: '/webrtc_ice_candidate_server',\n      messageType: 'webrtc_services/ICECandidate',\n    });\n\n    candidateSubscribeTopic.subscribe((message) => {\n      const candidateData = JSON.parse(message.data);\n      const candidate = new RTCIceCandidate({\n        candidate: candidateData.candidate,\n        sdpMid: candidateData.sdpMid,\n        sdpMLineIndex: candidateData.sdpMLineIndex,\n      });\n      console.log('Received ICE candidate:', candidate);\n      pc.addIceCandidate(candidate).catch(console.error);\n    });\n\n    // Handle SDP offer/answer with ROS\n    pc.createOffer({ offerToReceiveVideo: true })\n      .then((offer) => pc.setLocalDescription(offer))\n      .then(() => {\n        const webrtcOfferService = new ROSLIB.Service({\n          ros: ros,\n          name: '/webrtc_sdp_offer',\n          serviceType: 'webrtc_services/SDPExchange',\n        });\n\n        webrtcOfferService.callService(\n          new ROSLIB.ServiceRequest({\n            sdp: pc.localDescription.sdp,\n            type: pc.localDescription.type,\n          }),\n          (response) => {\n            const answer = new RTCSessionDescription({\n              sdp: response.sdp,\n              type: response.type,\n            });\n\n            console.log('Received SDP answer:', answer);\n            pc.setRemoteDescription(answer)\n              .then(() => {\n                console.log('Remote description set');\n              });\n          }\n        );\n      })\n      .catch(console.error);\n\n    return () => {\n      if (peerConnection.current) {\n        peerConnection.current.close();\n        candidateSubscribeTopic.unsubscribe();\n      }\n    };\n  }, [ros]);\n\n  return (\n    <video ref={videoRef} autoPlay playsInline style={{ width: '100%', height: 'auto' }} />\n  );\n};\n\nexport default WebRTCClient;\n\n\nServer Code\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, QoSDurabilityPolicy, QoSReliabilityPolicy\nfrom sensor_msgs.msg import Image\nfrom webrtc_services.srv import SDPExchange\nfrom webrtc_services.msg import ICECandidate\nfrom aiortc import RTCPeerConnection, RTCIceCandidate, RTCSessionDescription, VideoStreamTrack\nfrom cv_bridge import CvBridge\nimport asyncio\nimport json\nimport cv2\n\nclass CameraStreamTrack(VideoStreamTrack):\n    def __init__(self, node):\n        super().__init__()\n        self.node = node\n        self.bridge = CvBridge()\n\n    async def recv(self):\n        pts, time_base = await self.next_timestamp()\n        frame = self.node.get_frame()\n        self.node.get_logging(\"recording frames\")\n        if frame is not None:\n            return frame\n\nclass WebRTCNode(Node):\n    def __init__(self):\n        super().__init__('webrtc_node')\n\n        # Publisher and subscriber for ICE candidates\n        self.ice_candidate_pub = self.create_publisher(ICECandidate, '/webrtc_ice_candidate_server', 10)\n        self.ice_candidate_sub = self.create_subscription(\n            ICECandidate,\n            '/webrtc_ice_candidate_client',\n            self.handle_remote_ice_candidate,\n            10\n        )\n\n        # ROS service for SDP exchange\n        self.create_service(SDPExchange, '/webrtc_sdp_offer', self.handle_offer)\n\n        # Subscription to the image topic\n        self.image_sub = self.create_subscription(Image, '/camera/image', self.image_callback, 10)\n        self.bridge = CvBridge()\n        self.frame = None\n        self.pc = None\n\n    def image_callback(self, msg):\n        # Convert the ROS image message to an OpenCV image and store it\n        self.frame = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\n\n    def get_frame(self):\n        # Convert OpenCV image to a WebRTC-compatible frame\n        if self.frame is None:\n            return None\n        frame_rgb = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)\n        return VideoFrame.from_ndarray(frame_rgb, format=\"rgb24\")\n\n    def handle_offer(self, request, response):\n        self.get_logger().info(f\"Received SDP offer: {request}\")\n\n        response = asyncio.run(self.sync_handle_offer(request, response))\n\n        self.get_logger().info(f\"Sending SDP answer: {response}\")\n\n        return response\n\n    async def sync_handle_offer(self, request, response):\n        self.pc = RTCPeerConnection()\n        # Debugging ICE state changes\n\n        @self.pc.on(\"icegatheringstatechange\")\n        def in_icegatheringstatechange():\n            print(f\"ICE Gathering State: {self.pc.iceGatheringState}\")\n\n        @self.pc.on(\"icecandidate\")\n        def on_icecandidate(event):\n            self.send_ice_candidate(event)\n\n        @self.pc.on(\"connectionstatechange\")\n        async def on_connectionstatechange():\n            self.get_logger().info(f\"Connection state is {pc.connectionState}\")\n            if self.pc.connectionState == \"failed\":\n                await self.pc.close()\n\n        self.pc.addTrack(CameraStreamTrack(self))\n        await self.pc.setRemoteDescription(RTCSessionDescription(sdp=request.sdp, type=request.type))\n        answer = await self.pc.createAnswer()\n        await self.pc.setLocalDescription(answer)\n        response.sdp = self.pc.localDescription.sdp\n        response.type = self.pc.localDescription.type\n        return response\n    def send_ice_candidate(self, event):\n        self.get_logger().info(f\"Sent ICE candidate: {event.candidate}\")\n        if event.candidate:\n            candidate_msg = {\n                'component': event.candidate.component,\n                'foundation': event.candidate.founndation,\n                'address': event.candidate.ip,\n                'sdpMid': event.candidate.sdpMid,\n                'sdpMLineIndex': event.candidate.sdpMLineIndex\n            }\n            self.ice_candidate_pub.publish(candidate_msg)\n\n    def handle_remote_ice_candidate(self, msg):\n        candidate = RTCIceCandidate(\n            ip=msg.address,\n            component=msg.component,\n            foundation=msg.foundation,\n            port=msg.port,\n            priority=msg.priority,\n            protocol=msg.protocol,\n            type=msg.type,\n            sdpMid=msg.sdpmid,\n            sdpMLineIndex=msg.sdpmlineindex\n\n        )\n\n        self.get_logger().info(f\"Adding remote ICE candidate: {candidate}\")\n        asyncio.run(self.pc.addIceCandidate(candidate))\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = WebRTCNode()\n    rclpy.spin(node)\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n\nHere are the detailed connection detail:\nWeb Connection Log:\n[Log] RTCPeerConnection::RTCPeerConnection(1E94BA3545EC2ECF) \n[Info] RTCPeerConnection::initializeConfiguration(1E94BA3545EC2ECF) \n[Info] RTCPeerConnection::addTransceiver(1E94BA3545EC2ECF) \n[Log] MediaStreamTrackPrivate::MediaStreamTrackPrivate(BA8E06A6504A3BD3) \n[Log] RealtimeIncomingVideoSource::setLogger(BA8E06A6504A3BD3) Video, remote video, , \n[Log] MediaStreamTrack::MediaStreamTrack(BA8E06A6504A3BD3) \n[Log] RTCPeerConnection::createOffer(1E94BA3545EC2ECF) \n[Log] RTCPeerConnection::setLocalDescription(1E94BA3545EC2ECF) Setting local description to:\nv=0\no=- 7782012141166886532 2 IN IP4 127.0.0.1\ns=-\nt=0 0\na=group:BUNDLE 0\na=extmap-allow-mixed\na=msid-semantic: WMS\nm=video 9 UDP/TLS/RTP/SAVPF 96 97 98 99 100 101 102 103 104 105 106 107 108 109 127 125 112 113 114\nc=IN IP4 0.0.0.0\na=rtcp:9 IN IP4 0.0.0.0\na=ice-ufrag:KQRm\na=ice-pwd:q8ENF12PK1LdBjpOjL4e2Skg\na=ice-options:trickle\na=fingerprint:sha-256 96:74:04:42:50:DF:8E:A0:6D:C4:86:B8:37:26:22:70:61:5F:63:E3:4A:B9:9C:16:D1:C4:2E:DF:97:76:91:88\na=setup:actpass\na=mid:0\na=extmap:1 urn:ietf:params:rtp-hdrext:toffset\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\na=extmap:3 urn:3gpp:video-orientation\na=extmap:4 http://www.ietf.org/id/draft-holmer-rmcat-transport-wide-cc-extensions-01\na=extmap:5 http://www.webrtc.org/experiments/rtp-hdrext/playout-delay\na=extmap:6 http://www.webrtc.org/experiments/rtp-hdrext/video-content-type\na=extmap:7 http://www.webrtc.org/experiments/rtp-hdrext/video-timing\na=extmap:8 http://www.webrtc.org/experiments/rtp-hdrext/color-space\na=extmap:9 urn:ietf:params:rtp-hdrext:sdes:mid\na=extmap:10 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id\na=extmap:11 urn:ietf:params:rtp-hdrext:sdes:repaired-rtp-stream-id\na=sendrecv\na=msid:- 9c5a3581-0b2f-4d66-834f-5139cfa5a44f\na=rtcp-mux\na=rtcp-rsize\na=rtpmap:96 H264/90000\na=rtcp-fb:96 goog-remb\na=rtcp-fb:96 transport-cc\na=rtcp-fb:96 ccm fir\na=rtcp-fb:96 nack\na=rtcp-fb:96 nack pli\na=fmtp:96 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=640c1f\na=rtpmap:97 rtx/90000\na=fmtp:97 apt=96\na=rtpmap:98 H264/90000\na=rtcp-fb:98 goog-remb\na=rtcp-fb:98 transport-cc\na=rtcp-fb:98 ccm fir\na=rtcp-fb:98 nack\na=rtcp-fb:98 nack pli\na=fmtp:98 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=42e01f\na=rtpmap:99 rtx/90000\na=fmtp:99 apt=98\na=rtpmap:100 H264/90000\na=rtcp-fb:100 goog-remb\na=rtcp-fb:100 transport-cc\na=rtcp-fb:100 ccm fir\na=rtcp-fb:100 nack\na=rtcp-fb:100 nack pli\na=fmtp:100 level-asymmetry-allowed=1;packetization-mode=0;profile-level-id=640c1f\na=rtpmap:101 rtx/90000\na=fmtp:101 apt=100\na=rtpmap:102 H264/90000\na=rtcp-fb:102 goog-remb\na=rtcp-fb:102 transport-cc\na=rtcp-fb:102 ccm fir\na=rtcp-fb:102 nack\na=rtcp-fb:102 nack pli\na=fmtp:102 level-asymmetry-allowed=1;packetization-mode=0;profile-level-id=42e01f\na=rtpmap:103 rtx/90000\na=fmtp:103 apt=102\na=rtpmap:104 H265/90000\na=rtcp-fb:104 goog-remb\na=rtcp-fb:104 transport-cc\na=rtcp-fb:104 ccm fir\na=rtcp-fb:104 nack\na=rtcp-fb:104 nack pli\na=rtpmap:105 rtx/90000\na=fmtp:105 apt=104\na=rtpmap:106 VP8/90000\na=rtcp-fb:106 goog-remb\na=rtcp-fb:106 transport-cc\na=rtcp-fb:106 ccm fir\na=rtcp-fb:106 nack\na=rtcp-fb:106 nack pli\na=rtpmap:107 rtx/90000\na=fmtp:107 apt=106\na=rtpmap:108 VP9/90000\na=rtcp-fb:108 goog-remb\na=rtcp-fb:108 transport-cc\na=rtcp-fb:108 ccm fir\na=rtcp-fb:108 nack\na=rtcp-fb:108 nack pli\na=fmtp:108 profile-id=0\na=rtpmap:109 rtx/90000\na=fmtp:109 apt=108\na=rtpmap:127 VP9/90000\na=rtcp-fb:127 goog-remb\na=rtcp-fb:127 transport-cc\na=rtcp-fb:127 ccm fir\na=rtcp-fb:127 nack\na=rtcp-fb:127 nack pli\na=fmtp:127 profile-id=2\na=rtpmap:125 rtx/90000\na=fmtp:125 apt=127\na=rtpmap:112 red/90000\na=rtpmap:113 rtx/90000\na=fmtp:113 apt=112\na=rtpmap:114 ulpfec/90000\na=ssrc-group:FID 1685303567 3271658131\na=ssrc:1685303567 cname:Z709ambahT0RDel0\na=ssrc:1685303567 msid:- 9c5a3581-0b2f-4d66-834f-5139cfa5a44f\na=ssrc:3271658131 cname:Z709ambahT0RDel0\na=ssrc:3271658131 msid:- 9c5a3581-0b2f-4d66-834f-5139cfa5a44f\n\n[Log] PeerConnectionBackend::setLocalDescriptionSucceeded(1E94BA3545EC2ECF) \n[Log] Signaling state changed: \u2013 \"have-local-offer\" (WebRTCClient.tsx, line 63)\n[Log] RTCPeerConnection::setSignalingState(1E94BA3545EC2ECF) have-local-offer\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'signalingstatechange'\n[Log] RTCPeerConnection::updateIceGatheringState(1E94BA3545EC2ECF) gathering\n[Log] ICE gathering state changed: \u2013 \"gathering\" (WebRTCClient.tsx, line 57)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icegatheringstatechange'\n[Log] ICE candidate: \u2013 {component: \"rtp\", foundation: \"3393445816\", address: \"4a67bbe8-d708-43f7-94e3-ea82ffb95089.local\", \u2026} (WebRTCClient.tsx, line 86)\n{component: \"rtp\", foundation: \"3393445816\", address: \"4a67bbe8-d708-43f7-94e3-ea82ffb95089.local\", port: 62974, priority: 2122260223, \u2026}Object\n[Log] PeerConnectionBackend::newICECandidate(1E94BA3545EC2ECF) Gathered ice candidate:candidate:3393445816 1 udp 2122260223 4a67bbe8-d708-43f7-94e3-ea82ffb95089.local 62974 typ host generation 0 ufrag KQRm network-id 1 network-cost 50\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icecandidate'\n[Log] Received SDP answer: \u2013 RTCSessionDescription {type: \"answer\", sdp: \"v=0\\r\u21b5o=- 3940639792 3940639792 IN IP4 0.0.0.0\\r\u21b5s=-\u20260:1A:7E:09:F8:50:19:8A:B0:2D:5C\\r\u21b5a=setup:active\\r\u21b5\", toJSON: function} (WebRTCClient.tsx, line 121)\nRTCSessionDescription {type: \"answer\", sdp: \"v=0\\r\u21b5o=- 3940639792 3940639792 IN IP4 0.0.0.0\\r\u21b5s=-\u20260:1A:7E:09:F8:50:19:8A:B0:2D:5C\\r\u21b5a=setup:active\\r\u21b5\", toJSON: function}RTCSessionDescription\n[Log] RTCPeerConnection::setRemoteDescription(1E94BA3545EC2ECF) Setting remote description to:\nv=0\no=- 3940639792 3940639792 IN IP4 0.0.0.0\ns=-\nt=0 0\na=group:BUNDLE 0\na=msid-semantic:WMS *\nm=video 58412 UDP/TLS/RTP/SAVPF 98 99 106 107\nc=IN IP4 192.168.0.20\na=sendrecv\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\na=extmap:9 urn:ietf:params:rtp-hdrext:sdes:mid\na=mid:0\na=msid:7dec0f4c-dccc-44f0-aa0a-4c2d1671cc1a acf20468-57dc-4ae7-b6ad-e4686c658e19\na=rtcp:9 IN IP4 0.0.0.0\na=rtcp-mux\na=ssrc-group:FID 3559455750 2867110572\na=ssrc:3559455750 cname:f11e3cba-8069-4a9a-a276-1f15fbfb4c5b\na=ssrc:2867110572 cname:f11e3cba-8069-4a9a-a276-1f15fbfb4c5b\na=rtpmap:98 H264/90000\na=rtcp-fb:98 nack\na=rtcp-fb:98 nack pli\na=rtcp-fb:98 goog-remb\na=fmtp:98 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42e01f\na=rtpmap:99 rtx/90000\na=fmtp:99 apt=98\na=rtpmap:106 VP8/90000\na=rtcp-fb:106 nack\na=rtcp-fb:106 nack pli\na=rtcp-fb:106 goog-remb\na=rtpmap:107 rtx/90000\na=fmtp:107 apt=106\na=candidate:4f322c660417b6096fd16770d34b336f 1 udp 2130706431 192.168.0.20 58412 typ host\na=candidate:bf734b071273f7d6ccf572c7ec2b884c 1 udp 2130706431 100.109.42.26 51514 typ host\na=candidate:cfde7b013ffc28500306e12b2dfcc5df 1 udp 2130706431 fd7a:115c:a1e0::4701:2a1a 34958 typ host\na=end-of-candidates\na=ice-ufrag:qpYE\na=ice-pwd:U5kNWMQLZBpmlO7X3Cl9aK\na=fingerprint:sha-256 F9:BD:7F:81:A7:4A:91:FC:F2:A3:52:6A:68:7E:45:AD:E5:1C:46:60:BE:80:1A:7E:09:F8:50:19:8A:B0:2D:5C\na=setup:active\n\n[Log] ICE connection state changed: \u2013 \"checking\" (WebRTCClient.tsx, line 66)\n[Log] Connection state changed: \u2013 \"connecting\" (WebRTCClient.tsx, line 48)\n[Log] MediaStream::MediaStream(4957DBA2058B65BF) \n[Log] PeerConnectionBackend::setRemoteDescriptionSucceeded(1E94BA3545EC2ECF) Set remote description succeeded\n[Log] Signaling state changed: \u2013 \"stable\" (WebRTCClient.tsx, line 63)\n[Log] MediaStream {id: \"7dec0f4c-dccc-44f0-aa0a-4c2d1671cc1a\", active: true, onaddtrack: null, onremovetrack: null, getAudioTracks: function, \u2026} (WebRTCClient.tsx, line 39)\n[Log] Remote description set (WebRTCClient.tsx, line 123)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'iceconnectionstatechange'\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'connectionstatechange'\n[Log] RTCPeerConnection::setSignalingState(1E94BA3545EC2ECF) stable\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'signalingstatechange'\n[Log] MediaStream::addTrackFromPlatform(4957DBA2058B65BF) (BA8E06A6504A3BD3)\n[Log] MediaStream::setIsActive(4957DBA2058B65BF) true\n[Log] MediaStreamPrivate::addTrack(4957DBA2058B65BF) (BA8E06A6504A3BD3)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'track'\n[Log] RealtimeIncomingVideoSource::setMuted(BA8E06A6504A3BD3) false\n[Log] RealtimeIncomingVideoSource::start(BA8E06A6504A3BD3) \n[Log] MediaStreamTrackPrivate::sourceStarted(BA8E06A6504A3BD3) \n[Log] MediaStreamTrack::trackStarted(BA8E06A6504A3BD3) \n[Log] MediaStreamPrivate::trackStarted(4957DBA2058B65BF) (BA8E06A6504A3BD3)\n[Log] MediaStreamTrackPrivate::sourceMutedChanged(BA8E06A6504A3BD3) \n[Log] MediaStreamPrivate::trackMutedChanged(4957DBA2058B65BF) (BA8E06A6504A3BD3) false\n[Log] ICE candidate: \u2013 {component: \"rtp\", foundation: \"887687980\", address: \"4a67bbe8-d708-43f7-94e3-ea82ffb95089.local\", \u2026} (WebRTCClient.tsx, line 86)\n{component: \"rtp\", foundation: \"887687980\", address: \"4a67bbe8-d708-43f7-94e3-ea82ffb95089.local\", port: 9, priority: 1518280447, \u2026}Object\n[Log] PeerConnectionBackend::newICECandidate(1E94BA3545EC2ECF) Gathered ice candidate:candidate:887687980 1 tcp 1518280447 4a67bbe8-d708-43f7-94e3-ea82ffb95089.local 9 typ host tcptype active generation 0 ufrag KQRm network-id 1 network-cost 50\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icecandidate'\n[Log] PeerConnectionBackend::doneGatheringCandidates(1E94BA3545EC2ECF) Finished ice candidate gathering\n[Log] RTCPeerConnection::updateIceGatheringState(1E94BA3545EC2ECF) complete\n[Log] ICE gathering state changed: \u2013 \"complete\" (WebRTCClient.tsx, line 57)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icecandidate'\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icegatheringstatechange'\n[Log] RTCPeerConnection::~RTCPeerConnection(338101729BB856C6) \n[Log] MediaStreamTrackPrivate::~MediaStreamTrackPrivate(4D28631C76C5CFBA) \n[Error] Error starting video playback: \u2013 AbortError: The operation was aborted.\nAbortError: The operation was aborted.\n    (anonymous function) (WebRTCClient.tsx:43)\n[Log] ICE connection state changed: \u2013 \"failed\" (WebRTCClient.tsx, line 66)\n[Log] Connection state changed: \u2013 \"failed\" (WebRTCClient.tsx, line 48)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'iceconnectionstatechange'\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'connectionstatechange'\n\nPython Log:\n[INFO] [1731651122.769201987] [webrtc_node]: Received SDP offer: webrtc_services.srv.SDPExchange_Request(sdp='v=0\\r\\no=- 3412801876427003791 2 IN IP4 127.0.0.1\\r\\ns=-\\r\\nt=0 0\\r\\na=group:BUNDLE 0\\r\\na=extmap-allow-mixed\\r\\na=msid-semantic: WMS\\r\\nm=video 9 UDP/TLS/RTP/SAVPF 96 97 98 99 100 101 102 103 104 105 106 107 108 109 127 125 112 113 114\\r\\nc=IN IP4 0.0.0.0\\r\\na=rtcp:9 IN IP4 0.0.0.0\\r\\na=ice-ufrag:riId\\r\\na=ice-pwd:jI71cRZ+Sxl0x36PmJbndf02\\r\\na=ice-options:trickle\\r\\na=fingerprint:sha-256 97:AD:D7:E4:A9:8A:CC:D2:79:E2:24:B0:F3:2E:DF:59:EA:B6:50:04:C3:53:94:CB:A9:57:B0:27:4E:13:8C:D3\\r\\na=setup:actpass\\r\\na=mid:0\\r\\na=extmap:1 urn:ietf:params:rtp-hdrext:toffset\\r\\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\\r\\na=extmap:3 urn:3gpp:video-orientation\\r\\na=extmap:4 http://www.ietf.org/id/draft-holmer-rmcat-transport-wide-cc-extensions-01\\r\\na=extmap:5 http://www.webrtc.org/experiments/rtp-hdrext/playout-delay\\r\\na=extmap:6 http://www.webrtc.org/experiments/rtp-hdrext/video-content-type\\r\\na=extmap:7 http://www.webrtc.org/experiments/rtp-hdrext/video-timing\\r\\na=extmap:8 http://www.webrtc.org/experiments/rtp-hdrext/color-space\\r\\na=extmap:9 urn:ietf:params:rtp-hdrext:sdes:mid\\r\\na=extmap:10 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id\\r\\na=extmap:11 urn:ietf:params:rtp-hdrext:sdes:repaired-rtp-stream-id\\r\\na=sendrecv\\r\\na=msid:- 1b95d910-2910-49e4-a9ac-50cbce42d3cd\\r\\na=rtcp-mux\\r\\na=rtcp-rsize\\r\\na=rtpmap:96 H264/90000\\r\\na=rtcp-fb:96 goog-remb\\r\\na=rtcp-fb:96 transport-cc\\r\\na=rtcp-fb:96 ccm fir\\r\\na=rtcp-fb:96 nack\\r\\na=rtcp-fb:96 nack pli\\r\\na=fmtp:96 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=640c1f\\r\\na=rtpmap:97 rtx/90000\\r\\na=fmtp:97 apt=96\\r\\na=rtpmap:98 H264/90000\\r\\na=rtcp-fb:98 goog-remb\\r\\na=rtcp-fb:98 transport-cc\\r\\na=rtcp-fb:98 ccm fir\\r\\na=rtcp-fb:98 nack\\r\\na=rtcp-fb:98 nack pli\\r\\na=fmtp:98 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=42e01f\\r\\na=rtpmap:99 rtx/90000\\r\\na=fmtp:99 apt=98\\r\\na=rtpmap:100 H264/90000\\r\\na=rtcp-fb:100 goog-remb\\r\\na=rtcp-fb:100 transport-cc\\r\\na=rtcp-fb:100 ccm fir\\r\\na=rtcp-fb:100 nack\\r\\na=rtcp-fb:100 nack pli\\r\\na=fmtp:100 level-asymmetry-allowed=1;packetization-mode=0;profile-level-id=640c1f\\r\\na=rtpmap:101 rtx/90000\\r\\na=fmtp:101 apt=100\\r\\na=rtpmap:102 H264/90000\\r\\na=rtcp-fb:102 goog-remb\\r\\na=rtcp-fb:102 transport-cc\\r\\na=rtcp-fb:102 ccm fir\\r\\na=rtcp-fb:102 nack\\r\\na=rtcp-fb:102 nack pli\\r\\na=fmtp:102 level-asymmetry-allowed=1;packetization-mode=0;profile-level-id=42e01f\\r\\na=rtpmap:103 rtx/90000\\r\\na=fmtp:103 apt=102\\r\\na=rtpmap:104 H265/90000\\r\\na=rtcp-fb:104 goog-remb\\r\\na=rtcp-fb:104 transport-cc\\r\\na=rtcp-fb:104 ccm fir\\r\\na=rtcp-fb:104 nack\\r\\na=rtcp-fb:104 nack pli\\r\\na=fmtp:104 level-id=93;tx-mode=SRST\\r\\na=rtpmap:105 rtx/90000\\r\\na=fmtp:105 apt=104\\r\\na=rtpmap:106 VP8/90000\\r\\na=rtcp-fb:106 goog-remb\\r\\na=rtcp-fb:106 transport-cc\\r\\na=rtcp-fb:106 ccm fir\\r\\na=rtcp-fb:106 nack\\r\\na=rtcp-fb:106 nack pli\\r\\na=rtpmap:107 rtx/90000\\r\\na=fmtp:107 apt=106\\r\\na=rtpmap:108 VP9/90000\\r\\na=rtcp-fb:108 goog-remb\\r\\na=rtcp-fb:108 transport-cc\\r\\na=rtcp-fb:108 ccm fir\\r\\na=rtcp-fb:108 nack\\r\\na=rtcp-fb:108 nack pli\\r\\na=fmtp:108 profile-id=0\\r\\na=rtpmap:109 rtx/90000\\r\\na=fmtp:109 apt=108\\r\\na=rtpmap:127 VP9/90000\\r\\na=rtcp-fb:127 goog-remb\\r\\na=rtcp-fb:127 transport-cc\\r\\na=rtcp-fb:127 ccm fir\\r\\na=rtcp-fb:127 nack\\r\\na=rtcp-fb:127 nack pli\\r\\na=fmtp:127 profile-id=2\\r\\na=rtpmap:125 rtx/90000\\r\\na=fmtp:125 apt=127\\r\\na=rtpmap:112 red/90000\\r\\na=rtpmap:113 rtx/90000\\r\\na=fmtp:113 apt=112\\r\\na=rtpmap:114 ulpfec/90000\\r\\na=ssrc-group:FID 3286714346 12295951\\r\\na=ssrc:3286714346 cname:dShL10ZK1y3XGZJD\\r\\na=ssrc:3286714346 msid:- 1b95d910-2910-49e4-a9ac-50cbce42d3cd\\r\\na=ssrc:12295951 cname:dShL10ZK1y3XGZJD\\r\\na=ssrc:12295951 msid:- 1b95d910-2910-49e4-a9ac-50cbce42d3cd\\r\\n', type='offer')\nICE Gathering State: gathering\nICE Gathering State: complete\n[INFO] [1731651122.789813194] [webrtc_node]: Sending SDP answer: webrtc_services.srv.SDPExchange_Response(sdp='v=0\\r\\no=- 3940639922 3940639922 IN IP4 0.0.0.0\\r\\ns=-\\r\\nt=0 0\\r\\na=group:BUNDLE 0\\r\\na=msid-semantic:WMS *\\r\\nm=video 44236 UDP/TLS/RTP/SAVPF 98 99 106 107\\r\\nc=IN IP4 192.168.0.20\\r\\na=sendrecv\\r\\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\\r\\na=extmap:9 urn:ietf:params:rtp-hdrext:sdes:mid\\r\\na=mid:0\\r\\na=msid:c98bd3b6-403c-4993-b56f-e4a9011b4ff9 60f6ea3e-5120-4d21-9130-9d50aadcc351\\r\\na=rtcp:9 IN IP4 0.0.0.0\\r\\na=rtcp-mux\\r\\na=ssrc-group:FID 1478075735 713819296\\r\\na=ssrc:1478075735 cname:9aa688cf-caad-4e7e-a604-7a23eb7c68d6\\r\\na=ssrc:713819296 cname:9aa688cf-caad-4e7e-a604-7a23eb7c68d6\\r\\na=rtpmap:98 H264/90000\\r\\na=rtcp-fb:98 nack\\r\\na=rtcp-fb:98 nack pli\\r\\na=rtcp-fb:98 goog-remb\\r\\na=fmtp:98 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42e01f\\r\\na=rtpmap:99 rtx/90000\\r\\na=fmtp:99 apt=98\\r\\na=rtpmap:106 VP8/90000\\r\\na=rtcp-fb:106 nack\\r\\na=rtcp-fb:106 nack pli\\r\\na=rtcp-fb:106 goog-remb\\r\\na=rtpmap:107 rtx/90000\\r\\na=fmtp:107 apt=106\\r\\na=candidate:4f322c660417b6096fd16770d34b336f 1 udp 2130706431 192.168.0.20 44236 typ host\\r\\na=candidate:bf734b071273f7d6ccf572c7ec2b884c 1 udp 2130706431 100.109.42.26 43464 typ host\\r\\na=candidate:cfde7b013ffc28500306e12b2dfcc5df 1 udp 2130706431 fd7a:115c:a1e0::4701:2a1a 38730 typ host\\r\\na=end-of-candidates\\r\\na=ice-ufrag:E7sT\\r\\na=ice-pwd:JCrFGjTr4LJmFM6VConLbC\\r\\na=fingerprint:sha-256 0D:44:B0:D7:40:CC:79:E2:4A:51:E4:68:45:05:7B:B7:4C:D8:F4:15:AA:47:A0:00:72:FC:60:51:58:0F:B5:5A\\r\\na=setup:active\\r\\n', type='answer')\n[INFO] [1731651122.794763206] [webrtc_node]: Adding remote ICE candidate: RTCIceCandidate(component='rtp', foundation='3240994852', ip='6f5ad9e3-e8c7-42a2-96e2-c416ccefca6d.local', port=64917, priority=2122260223, protocol='udp', type='host', relatedAddress=None, relatedPort=None, sdpMid='0', sdpMLineIndex=0, tcpType=None)\n[INFO] [1731651123.799837717] [webrtc_node]: Adding remote ICE candidate: RTCIceCandidate(component='rtp', foundation='1065843888', ip='6f5ad9e3-e8c7-42a2-96e2-c416ccefca6d.local', port=9, priority=1518280447, protocol='tcp', type='host', relatedAddress=None, relatedPort=None, sdpMid='0', sdpMLineIndex=0, tcpType=None)"], "question_code": ["import React, { useEffect, useRef } from 'react';\nimport { useROS } from './ROSContext';\nimport ROSLIB from 'roslib';\n\nconst WebRTCClient: React.FC = () =&gt; {\n  const videoRef = useRef&lt;HTMLVideoElement&gt;(null);\n  const peerConnection = useRef&lt;RTCPeerConnection | null&gt;(null);\n  const { ros } = useROS();\n\n  useEffect(() =&gt; {\n    const configuration: RTCConfiguration = {\n      iceTransportPolicy: 'all', // TypeScript should accept 'all' here\n      iceServers: [] // No STUN or TURN servers needed for your local network\n    };\n    const pc = new RTCPeerConnection(configuration);\n    peerConnection.current = pc;\n\n    pc.addTransceiver('video');\n\n    // Display the incoming video stream\n    pc.ontrack = (event) =&gt; {\n      if (videoRef.current) {\n        videoRef.current.srcObject = event.streams[0];\n        console.log(event.streams[0]);\n        videoRef.current.play().then(() =&gt; {\n          console.log('Video playback started');\n        }).catch((error) =&gt; {\n          console.error('Error starting video playback:', error);\n        })\n      }\n    };\n\n    pc.onconnectionstatechange = () =&gt; {\n      console.log('Connection state changed:', pc.connectionState);\n    }\n\n    pc.onicecandidateerror = (event) =&gt; {\n      console.error('ICE candidate error:', event);\n    };\n\n    pc.onnegotiationneeded = () =&gt; {\n      console.log('Negotiation needed');\n    };\n\n    pc.onicegatheringstatechange = () =&gt; {\n      console.log('ICE gathering state changed:', pc.iceGatheringState);\n    }\n\n    pc.ondatachannel = (event) =&gt; {\n      console.log('Data channel created:', event.channel);\n    }\n\n    pc.onsignalingstatechange = () =&gt; {\n      console.log('Signaling state changed:', pc.signalingState);\n    }\n\n    pc.oniceconnectionstatechange = () =&gt; {\n      console.log('ICE connection state changed:', pc.iceConnectionState);\n    }\n\n    // Publish ICE candidates to the ROS node\n    const candidatePublishTopic = new ROSLIB.Topic({\n      ros: ros,\n      name: '/webrtc_ice_candidate_client',\n      messageType: 'webrtc_services/ICECandidate',\n    });\n\n    pc.onicecandidate = (event) =&gt; {\n      if (event.candidate) {\n        const candidateMsg = {\n          component: event.candidate.component,\n          foundation: event.candidate.foundation,\n          address: event.candidate.address,\n          port: event.candidate.port,\n          priority: event.candidate.priority,\n          protocol: event.candidate.protocol,\n          type: event.candidate.type,\n          sdpmid: event.candidate.sdpMid,\n          sdpmlineindex: event.candidate.sdpMLineIndex,\n        }\n        // print all parameters\n        console.log('ICE candidate:', candidateMsg);\n        candidatePublishTopic.publish(new ROSLIB.Message(candidateMsg));\n      }\n    };\n\n    // Subscribe to ICE candidates from ROS node\n    const candidateSubscribeTopic = new ROSLIB.Topic({\n      ros: ros,\n      name: '/webrtc_ice_candidate_server',\n      messageType: 'webrtc_services/ICECandidate',\n    });\n\n    candidateSubscribeTopic.subscribe((message) =&gt; {\n      const candidateData = JSON.parse(message.data);\n      const candidate = new RTCIceCandidate({\n        candidate: candidateData.candidate,\n        sdpMid: candidateData.sdpMid,\n        sdpMLineIndex: candidateData.sdpMLineIndex,\n      });\n      console.log('Received ICE candidate:', candidate);\n      pc.addIceCandidate(candidate).catch(console.error);\n    });\n\n    // Handle SDP offer/answer with ROS\n    pc.createOffer({ offerToReceiveVideo: true })\n      .then((offer) =&gt; pc.setLocalDescription(offer))\n      .then(() =&gt; {\n        const webrtcOfferService = new ROSLIB.Service({\n          ros: ros,\n          name: '/webrtc_sdp_offer',\n          serviceType: 'webrtc_services/SDPExchange',\n        });\n\n        webrtcOfferService.callService(\n          new ROSLIB.ServiceRequest({\n            sdp: pc.localDescription.sdp,\n            type: pc.localDescription.type,\n          }),\n          (response) =&gt; {\n            const answer = new RTCSessionDescription({\n              sdp: response.sdp,\n              type: response.type,\n            });\n\n            console.log('Received SDP answer:', answer);\n            pc.setRemoteDescription(answer)\n              .then(() =&gt; {\n                console.log('Remote description set');\n              });\n          }\n        );\n      })\n      .catch(console.error);\n\n    return () =&gt; {\n      if (peerConnection.current) {\n        peerConnection.current.close();\n        candidateSubscribeTopic.unsubscribe();\n      }\n    };\n  }, [ros]);\n\n  return (\n    &lt;video ref={videoRef} autoPlay playsInline style={{ width: '100%', height: 'auto' }} /&gt;\n  );\n};\n\nexport default WebRTCClient;\n\n", "import rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, QoSDurabilityPolicy, QoSReliabilityPolicy\nfrom sensor_msgs.msg import Image\nfrom webrtc_services.srv import SDPExchange\nfrom webrtc_services.msg import ICECandidate\nfrom aiortc import RTCPeerConnection, RTCIceCandidate, RTCSessionDescription, VideoStreamTrack\nfrom cv_bridge import CvBridge\nimport asyncio\nimport json\nimport cv2\n\nclass CameraStreamTrack(VideoStreamTrack):\n    def __init__(self, node):\n        super().__init__()\n        self.node = node\n        self.bridge = CvBridge()\n\n    async def recv(self):\n        pts, time_base = await self.next_timestamp()\n        frame = self.node.get_frame()\n        self.node.get_logging(&quot;recording frames&quot;)\n        if frame is not None:\n            return frame\n\nclass WebRTCNode(Node):\n    def __init__(self):\n        super().__init__('webrtc_node')\n\n        # Publisher and subscriber for ICE candidates\n        self.ice_candidate_pub = self.create_publisher(ICECandidate, '/webrtc_ice_candidate_server', 10)\n        self.ice_candidate_sub = self.create_subscription(\n            ICECandidate,\n            '/webrtc_ice_candidate_client',\n            self.handle_remote_ice_candidate,\n            10\n        )\n\n        # ROS service for SDP exchange\n        self.create_service(SDPExchange, '/webrtc_sdp_offer', self.handle_offer)\n\n        # Subscription to the image topic\n        self.image_sub = self.create_subscription(Image, '/camera/image', self.image_callback, 10)\n        self.bridge = CvBridge()\n        self.frame = None\n        self.pc = None\n\n    def image_callback(self, msg):\n        # Convert the ROS image message to an OpenCV image and store it\n        self.frame = self.bridge.imgmsg_to_cv2(msg, &quot;bgr8&quot;)\n\n    def get_frame(self):\n        # Convert OpenCV image to a WebRTC-compatible frame\n        if self.frame is None:\n            return None\n        frame_rgb = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)\n        return VideoFrame.from_ndarray(frame_rgb, format=&quot;rgb24&quot;)\n\n    def handle_offer(self, request, response):\n        self.get_logger().info(f&quot;Received SDP offer: {request}&quot;)\n\n        response = asyncio.run(self.sync_handle_offer(request, response))\n\n        self.get_logger().info(f&quot;Sending SDP answer: {response}&quot;)\n\n        return response\n\n    async def sync_handle_offer(self, request, response):\n        self.pc = RTCPeerConnection()\n        # Debugging ICE state changes\n\n        @self.pc.on(&quot;icegatheringstatechange&quot;)\n        def in_icegatheringstatechange():\n            print(f&quot;ICE Gathering State: {self.pc.iceGatheringState}&quot;)\n\n        @self.pc.on(&quot;icecandidate&quot;)\n        def on_icecandidate(event):\n            self.send_ice_candidate(event)\n\n        @self.pc.on(&quot;connectionstatechange&quot;)\n        async def on_connectionstatechange():\n            self.get_logger().info(f&quot;Connection state is {pc.connectionState}&quot;)\n            if self.pc.connectionState == &quot;failed&quot;:\n                await self.pc.close()\n\n        self.pc.addTrack(CameraStreamTrack(self))\n        await self.pc.setRemoteDescription(RTCSessionDescription(sdp=request.sdp, type=request.type))\n        answer = await self.pc.createAnswer()\n        await self.pc.setLocalDescription(answer)\n        response.sdp = self.pc.localDescription.sdp\n        response.type = self.pc.localDescription.type\n        return response\n    def send_ice_candidate(self, event):\n        self.get_logger().info(f&quot;Sent ICE candidate: {event.candidate}&quot;)\n        if event.candidate:\n            candidate_msg = {\n                'component': event.candidate.component,\n                'foundation': event.candidate.founndation,\n                'address': event.candidate.ip,\n                'sdpMid': event.candidate.sdpMid,\n                'sdpMLineIndex': event.candidate.sdpMLineIndex\n            }\n            self.ice_candidate_pub.publish(candidate_msg)\n\n    def handle_remote_ice_candidate(self, msg):\n        candidate = RTCIceCandidate(\n            ip=msg.address,\n            component=msg.component,\n            foundation=msg.foundation,\n            port=msg.port,\n            priority=msg.priority,\n            protocol=msg.protocol,\n            type=msg.type,\n            sdpMid=msg.sdpmid,\n            sdpMLineIndex=msg.sdpmlineindex\n\n        )\n\n        self.get_logger().info(f&quot;Adding remote ICE candidate: {candidate}&quot;)\n        asyncio.run(self.pc.addIceCandidate(candidate))\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = WebRTCNode()\n    rclpy.spin(node)\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n", "[Log] RTCPeerConnection::RTCPeerConnection(1E94BA3545EC2ECF) \n[Info] RTCPeerConnection::initializeConfiguration(1E94BA3545EC2ECF) \n[Info] RTCPeerConnection::addTransceiver(1E94BA3545EC2ECF) \n[Log] MediaStreamTrackPrivate::MediaStreamTrackPrivate(BA8E06A6504A3BD3) \n[Log] RealtimeIncomingVideoSource::setLogger(BA8E06A6504A3BD3) Video, remote video, , \n[Log] MediaStreamTrack::MediaStreamTrack(BA8E06A6504A3BD3) \n[Log] RTCPeerConnection::createOffer(1E94BA3545EC2ECF) \n[Log] RTCPeerConnection::setLocalDescription(1E94BA3545EC2ECF) Setting local description to:\nv=0\no=- 7782012141166886532 2 IN IP4 127.0.0.1\ns=-\nt=0 0\na=group:BUNDLE 0\na=extmap-allow-mixed\na=msid-semantic: WMS\nm=video 9 UDP/TLS/RTP/SAVPF 96 97 98 99 100 101 102 103 104 105 106 107 108 109 127 125 112 113 114\nc=IN IP4 0.0.0.0\na=rtcp:9 IN IP4 0.0.0.0\na=ice-ufrag:KQRm\na=ice-pwd:q8ENF12PK1LdBjpOjL4e2Skg\na=ice-options:trickle\na=fingerprint:sha-256 96:74:04:42:50:DF:8E:A0:6D:C4:86:B8:37:26:22:70:61:5F:63:E3:4A:B9:9C:16:D1:C4:2E:DF:97:76:91:88\na=setup:actpass\na=mid:0\na=extmap:1 urn:ietf:params:rtp-hdrext:toffset\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\na=extmap:3 urn:3gpp:video-orientation\na=extmap:4 http://www.ietf.org/id/draft-holmer-rmcat-transport-wide-cc-extensions-01\na=extmap:5 http://www.webrtc.org/experiments/rtp-hdrext/playout-delay\na=extmap:6 http://www.webrtc.org/experiments/rtp-hdrext/video-content-type\na=extmap:7 http://www.webrtc.org/experiments/rtp-hdrext/video-timing\na=extmap:8 http://www.webrtc.org/experiments/rtp-hdrext/color-space\na=extmap:9 urn:ietf:params:rtp-hdrext:sdes:mid\na=extmap:10 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id\na=extmap:11 urn:ietf:params:rtp-hdrext:sdes:repaired-rtp-stream-id\na=sendrecv\na=msid:- 9c5a3581-0b2f-4d66-834f-5139cfa5a44f\na=rtcp-mux\na=rtcp-rsize\na=rtpmap:96 H264/90000\na=rtcp-fb:96 goog-remb\na=rtcp-fb:96 transport-cc\na=rtcp-fb:96 ccm fir\na=rtcp-fb:96 nack\na=rtcp-fb:96 nack pli\na=fmtp:96 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=640c1f\na=rtpmap:97 rtx/90000\na=fmtp:97 apt=96\na=rtpmap:98 H264/90000\na=rtcp-fb:98 goog-remb\na=rtcp-fb:98 transport-cc\na=rtcp-fb:98 ccm fir\na=rtcp-fb:98 nack\na=rtcp-fb:98 nack pli\na=fmtp:98 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=42e01f\na=rtpmap:99 rtx/90000\na=fmtp:99 apt=98\na=rtpmap:100 H264/90000\na=rtcp-fb:100 goog-remb\na=rtcp-fb:100 transport-cc\na=rtcp-fb:100 ccm fir\na=rtcp-fb:100 nack\na=rtcp-fb:100 nack pli\na=fmtp:100 level-asymmetry-allowed=1;packetization-mode=0;profile-level-id=640c1f\na=rtpmap:101 rtx/90000\na=fmtp:101 apt=100\na=rtpmap:102 H264/90000\na=rtcp-fb:102 goog-remb\na=rtcp-fb:102 transport-cc\na=rtcp-fb:102 ccm fir\na=rtcp-fb:102 nack\na=rtcp-fb:102 nack pli\na=fmtp:102 level-asymmetry-allowed=1;packetization-mode=0;profile-level-id=42e01f\na=rtpmap:103 rtx/90000\na=fmtp:103 apt=102\na=rtpmap:104 H265/90000\na=rtcp-fb:104 goog-remb\na=rtcp-fb:104 transport-cc\na=rtcp-fb:104 ccm fir\na=rtcp-fb:104 nack\na=rtcp-fb:104 nack pli\na=rtpmap:105 rtx/90000\na=fmtp:105 apt=104\na=rtpmap:106 VP8/90000\na=rtcp-fb:106 goog-remb\na=rtcp-fb:106 transport-cc\na=rtcp-fb:106 ccm fir\na=rtcp-fb:106 nack\na=rtcp-fb:106 nack pli\na=rtpmap:107 rtx/90000\na=fmtp:107 apt=106\na=rtpmap:108 VP9/90000\na=rtcp-fb:108 goog-remb\na=rtcp-fb:108 transport-cc\na=rtcp-fb:108 ccm fir\na=rtcp-fb:108 nack\na=rtcp-fb:108 nack pli\na=fmtp:108 profile-id=0\na=rtpmap:109 rtx/90000\na=fmtp:109 apt=108\na=rtpmap:127 VP9/90000\na=rtcp-fb:127 goog-remb\na=rtcp-fb:127 transport-cc\na=rtcp-fb:127 ccm fir\na=rtcp-fb:127 nack\na=rtcp-fb:127 nack pli\na=fmtp:127 profile-id=2\na=rtpmap:125 rtx/90000\na=fmtp:125 apt=127\na=rtpmap:112 red/90000\na=rtpmap:113 rtx/90000\na=fmtp:113 apt=112\na=rtpmap:114 ulpfec/90000\na=ssrc-group:FID 1685303567 3271658131\na=ssrc:1685303567 cname:Z709ambahT0RDel0\na=ssrc:1685303567 msid:- 9c5a3581-0b2f-4d66-834f-5139cfa5a44f\na=ssrc:3271658131 cname:Z709ambahT0RDel0\na=ssrc:3271658131 msid:- 9c5a3581-0b2f-4d66-834f-5139cfa5a44f\n\n[Log] PeerConnectionBackend::setLocalDescriptionSucceeded(1E94BA3545EC2ECF) \n[Log] Signaling state changed: \u2013 &quot;have-local-offer&quot; (WebRTCClient.tsx, line 63)\n[Log] RTCPeerConnection::setSignalingState(1E94BA3545EC2ECF) have-local-offer\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'signalingstatechange'\n[Log] RTCPeerConnection::updateIceGatheringState(1E94BA3545EC2ECF) gathering\n[Log] ICE gathering state changed: \u2013 &quot;gathering&quot; (WebRTCClient.tsx, line 57)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icegatheringstatechange'\n[Log] ICE candidate: \u2013 {component: &quot;rtp&quot;, foundation: &quot;3393445816&quot;, address: &quot;4a67bbe8-d708-43f7-94e3-ea82ffb95089.local&quot;, \u2026} (WebRTCClient.tsx, line 86)\n{component: &quot;rtp&quot;, foundation: &quot;3393445816&quot;, address: &quot;4a67bbe8-d708-43f7-94e3-ea82ffb95089.local&quot;, port: 62974, priority: 2122260223, \u2026}Object\n[Log] PeerConnectionBackend::newICECandidate(1E94BA3545EC2ECF) Gathered ice candidate:candidate:3393445816 1 udp 2122260223 4a67bbe8-d708-43f7-94e3-ea82ffb95089.local 62974 typ host generation 0 ufrag KQRm network-id 1 network-cost 50\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icecandidate'\n[Log] Received SDP answer: \u2013 RTCSessionDescription {type: &quot;answer&quot;, sdp: &quot;v=0\\r\u21b5o=- 3940639792 3940639792 IN IP4 0.0.0.0\\r\u21b5s=-\u20260:1A:7E:09:F8:50:19:8A:B0:2D:5C\\r\u21b5a=setup:active\\r\u21b5&quot;, toJSON: function} (WebRTCClient.tsx, line 121)\nRTCSessionDescription {type: &quot;answer&quot;, sdp: &quot;v=0\\r\u21b5o=- 3940639792 3940639792 IN IP4 0.0.0.0\\r\u21b5s=-\u20260:1A:7E:09:F8:50:19:8A:B0:2D:5C\\r\u21b5a=setup:active\\r\u21b5&quot;, toJSON: function}RTCSessionDescription\n[Log] RTCPeerConnection::setRemoteDescription(1E94BA3545EC2ECF) Setting remote description to:\nv=0\no=- 3940639792 3940639792 IN IP4 0.0.0.0\ns=-\nt=0 0\na=group:BUNDLE 0\na=msid-semantic:WMS *\nm=video 58412 UDP/TLS/RTP/SAVPF 98 99 106 107\nc=IN IP4 192.168.0.20\na=sendrecv\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\na=extmap:9 urn:ietf:params:rtp-hdrext:sdes:mid\na=mid:0\na=msid:7dec0f4c-dccc-44f0-aa0a-4c2d1671cc1a acf20468-57dc-4ae7-b6ad-e4686c658e19\na=rtcp:9 IN IP4 0.0.0.0\na=rtcp-mux\na=ssrc-group:FID 3559455750 2867110572\na=ssrc:3559455750 cname:f11e3cba-8069-4a9a-a276-1f15fbfb4c5b\na=ssrc:2867110572 cname:f11e3cba-8069-4a9a-a276-1f15fbfb4c5b\na=rtpmap:98 H264/90000\na=rtcp-fb:98 nack\na=rtcp-fb:98 nack pli\na=rtcp-fb:98 goog-remb\na=fmtp:98 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42e01f\na=rtpmap:99 rtx/90000\na=fmtp:99 apt=98\na=rtpmap:106 VP8/90000\na=rtcp-fb:106 nack\na=rtcp-fb:106 nack pli\na=rtcp-fb:106 goog-remb\na=rtpmap:107 rtx/90000\na=fmtp:107 apt=106\na=candidate:4f322c660417b6096fd16770d34b336f 1 udp 2130706431 192.168.0.20 58412 typ host\na=candidate:bf734b071273f7d6ccf572c7ec2b884c 1 udp 2130706431 100.109.42.26 51514 typ host\na=candidate:cfde7b013ffc28500306e12b2dfcc5df 1 udp 2130706431 fd7a:115c:a1e0::4701:2a1a 34958 typ host\na=end-of-candidates\na=ice-ufrag:qpYE\na=ice-pwd:U5kNWMQLZBpmlO7X3Cl9aK\na=fingerprint:sha-256 F9:BD:7F:81:A7:4A:91:FC:F2:A3:52:6A:68:7E:45:AD:E5:1C:46:60:BE:80:1A:7E:09:F8:50:19:8A:B0:2D:5C\na=setup:active\n\n[Log] ICE connection state changed: \u2013 &quot;checking&quot; (WebRTCClient.tsx, line 66)\n[Log] Connection state changed: \u2013 &quot;connecting&quot; (WebRTCClient.tsx, line 48)\n[Log] MediaStream::MediaStream(4957DBA2058B65BF) \n[Log] PeerConnectionBackend::setRemoteDescriptionSucceeded(1E94BA3545EC2ECF) Set remote description succeeded\n[Log] Signaling state changed: \u2013 &quot;stable&quot; (WebRTCClient.tsx, line 63)\n[Log] MediaStream {id: &quot;7dec0f4c-dccc-44f0-aa0a-4c2d1671cc1a&quot;, active: true, onaddtrack: null, onremovetrack: null, getAudioTracks: function, \u2026} (WebRTCClient.tsx, line 39)\n[Log] Remote description set (WebRTCClient.tsx, line 123)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'iceconnectionstatechange'\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'connectionstatechange'\n[Log] RTCPeerConnection::setSignalingState(1E94BA3545EC2ECF) stable\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'signalingstatechange'\n[Log] MediaStream::addTrackFromPlatform(4957DBA2058B65BF) (BA8E06A6504A3BD3)\n[Log] MediaStream::setIsActive(4957DBA2058B65BF) true\n[Log] MediaStreamPrivate::addTrack(4957DBA2058B65BF) (BA8E06A6504A3BD3)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'track'\n[Log] RealtimeIncomingVideoSource::setMuted(BA8E06A6504A3BD3) false\n[Log] RealtimeIncomingVideoSource::start(BA8E06A6504A3BD3) \n[Log] MediaStreamTrackPrivate::sourceStarted(BA8E06A6504A3BD3) \n[Log] MediaStreamTrack::trackStarted(BA8E06A6504A3BD3) \n[Log] MediaStreamPrivate::trackStarted(4957DBA2058B65BF) (BA8E06A6504A3BD3)\n[Log] MediaStreamTrackPrivate::sourceMutedChanged(BA8E06A6504A3BD3) \n[Log] MediaStreamPrivate::trackMutedChanged(4957DBA2058B65BF) (BA8E06A6504A3BD3) false\n[Log] ICE candidate: \u2013 {component: &quot;rtp&quot;, foundation: &quot;887687980&quot;, address: &quot;4a67bbe8-d708-43f7-94e3-ea82ffb95089.local&quot;, \u2026} (WebRTCClient.tsx, line 86)\n{component: &quot;rtp&quot;, foundation: &quot;887687980&quot;, address: &quot;4a67bbe8-d708-43f7-94e3-ea82ffb95089.local&quot;, port: 9, priority: 1518280447, \u2026}Object\n[Log] PeerConnectionBackend::newICECandidate(1E94BA3545EC2ECF) Gathered ice candidate:candidate:887687980 1 tcp 1518280447 4a67bbe8-d708-43f7-94e3-ea82ffb95089.local 9 typ host tcptype active generation 0 ufrag KQRm network-id 1 network-cost 50\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icecandidate'\n[Log] PeerConnectionBackend::doneGatheringCandidates(1E94BA3545EC2ECF) Finished ice candidate gathering\n[Log] RTCPeerConnection::updateIceGatheringState(1E94BA3545EC2ECF) complete\n[Log] ICE gathering state changed: \u2013 &quot;complete&quot; (WebRTCClient.tsx, line 57)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icecandidate'\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'icegatheringstatechange'\n[Log] RTCPeerConnection::~RTCPeerConnection(338101729BB856C6) \n[Log] MediaStreamTrackPrivate::~MediaStreamTrackPrivate(4D28631C76C5CFBA) \n[Error] Error starting video playback: \u2013 AbortError: The operation was aborted.\nAbortError: The operation was aborted.\n    (anonymous function) (WebRTCClient.tsx:43)\n[Log] ICE connection state changed: \u2013 &quot;failed&quot; (WebRTCClient.tsx, line 66)\n[Log] Connection state changed: \u2013 &quot;failed&quot; (WebRTCClient.tsx, line 48)\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'iceconnectionstatechange'\n[Info] RTCPeerConnection::dispatchEvent(1E94BA3545EC2ECF) dispatching 'connectionstatechange'\n", "[INFO] [1731651122.769201987] [webrtc_node]: Received SDP offer: webrtc_services.srv.SDPExchange_Request(sdp='v=0\\r\\no=- 3412801876427003791 2 IN IP4 127.0.0.1\\r\\ns=-\\r\\nt=0 0\\r\\na=group:BUNDLE 0\\r\\na=extmap-allow-mixed\\r\\na=msid-semantic: WMS\\r\\nm=video 9 UDP/TLS/RTP/SAVPF 96 97 98 99 100 101 102 103 104 105 106 107 108 109 127 125 112 113 114\\r\\nc=IN IP4 0.0.0.0\\r\\na=rtcp:9 IN IP4 0.0.0.0\\r\\na=ice-ufrag:riId\\r\\na=ice-pwd:jI71cRZ+Sxl0x36PmJbndf02\\r\\na=ice-options:trickle\\r\\na=fingerprint:sha-256 97:AD:D7:E4:A9:8A:CC:D2:79:E2:24:B0:F3:2E:DF:59:EA:B6:50:04:C3:53:94:CB:A9:57:B0:27:4E:13:8C:D3\\r\\na=setup:actpass\\r\\na=mid:0\\r\\na=extmap:1 urn:ietf:params:rtp-hdrext:toffset\\r\\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\\r\\na=extmap:3 urn:3gpp:video-orientation\\r\\na=extmap:4 http://www.ietf.org/id/draft-holmer-rmcat-transport-wide-cc-extensions-01\\r\\na=extmap:5 http://www.webrtc.org/experiments/rtp-hdrext/playout-delay\\r\\na=extmap:6 http://www.webrtc.org/experiments/rtp-hdrext/video-content-type\\r\\na=extmap:7 http://www.webrtc.org/experiments/rtp-hdrext/video-timing\\r\\na=extmap:8 http://www.webrtc.org/experiments/rtp-hdrext/color-space\\r\\na=extmap:9 urn:ietf:params:rtp-hdrext:sdes:mid\\r\\na=extmap:10 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id\\r\\na=extmap:11 urn:ietf:params:rtp-hdrext:sdes:repaired-rtp-stream-id\\r\\na=sendrecv\\r\\na=msid:- 1b95d910-2910-49e4-a9ac-50cbce42d3cd\\r\\na=rtcp-mux\\r\\na=rtcp-rsize\\r\\na=rtpmap:96 H264/90000\\r\\na=rtcp-fb:96 goog-remb\\r\\na=rtcp-fb:96 transport-cc\\r\\na=rtcp-fb:96 ccm fir\\r\\na=rtcp-fb:96 nack\\r\\na=rtcp-fb:96 nack pli\\r\\na=fmtp:96 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=640c1f\\r\\na=rtpmap:97 rtx/90000\\r\\na=fmtp:97 apt=96\\r\\na=rtpmap:98 H264/90000\\r\\na=rtcp-fb:98 goog-remb\\r\\na=rtcp-fb:98 transport-cc\\r\\na=rtcp-fb:98 ccm fir\\r\\na=rtcp-fb:98 nack\\r\\na=rtcp-fb:98 nack pli\\r\\na=fmtp:98 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=42e01f\\r\\na=rtpmap:99 rtx/90000\\r\\na=fmtp:99 apt=98\\r\\na=rtpmap:100 H264/90000\\r\\na=rtcp-fb:100 goog-remb\\r\\na=rtcp-fb:100 transport-cc\\r\\na=rtcp-fb:100 ccm fir\\r\\na=rtcp-fb:100 nack\\r\\na=rtcp-fb:100 nack pli\\r\\na=fmtp:100 level-asymmetry-allowed=1;packetization-mode=0;profile-level-id=640c1f\\r\\na=rtpmap:101 rtx/90000\\r\\na=fmtp:101 apt=100\\r\\na=rtpmap:102 H264/90000\\r\\na=rtcp-fb:102 goog-remb\\r\\na=rtcp-fb:102 transport-cc\\r\\na=rtcp-fb:102 ccm fir\\r\\na=rtcp-fb:102 nack\\r\\na=rtcp-fb:102 nack pli\\r\\na=fmtp:102 level-asymmetry-allowed=1;packetization-mode=0;profile-level-id=42e01f\\r\\na=rtpmap:103 rtx/90000\\r\\na=fmtp:103 apt=102\\r\\na=rtpmap:104 H265/90000\\r\\na=rtcp-fb:104 goog-remb\\r\\na=rtcp-fb:104 transport-cc\\r\\na=rtcp-fb:104 ccm fir\\r\\na=rtcp-fb:104 nack\\r\\na=rtcp-fb:104 nack pli\\r\\na=fmtp:104 level-id=93;tx-mode=SRST\\r\\na=rtpmap:105 rtx/90000\\r\\na=fmtp:105 apt=104\\r\\na=rtpmap:106 VP8/90000\\r\\na=rtcp-fb:106 goog-remb\\r\\na=rtcp-fb:106 transport-cc\\r\\na=rtcp-fb:106 ccm fir\\r\\na=rtcp-fb:106 nack\\r\\na=rtcp-fb:106 nack pli\\r\\na=rtpmap:107 rtx/90000\\r\\na=fmtp:107 apt=106\\r\\na=rtpmap:108 VP9/90000\\r\\na=rtcp-fb:108 goog-remb\\r\\na=rtcp-fb:108 transport-cc\\r\\na=rtcp-fb:108 ccm fir\\r\\na=rtcp-fb:108 nack\\r\\na=rtcp-fb:108 nack pli\\r\\na=fmtp:108 profile-id=0\\r\\na=rtpmap:109 rtx/90000\\r\\na=fmtp:109 apt=108\\r\\na=rtpmap:127 VP9/90000\\r\\na=rtcp-fb:127 goog-remb\\r\\na=rtcp-fb:127 transport-cc\\r\\na=rtcp-fb:127 ccm fir\\r\\na=rtcp-fb:127 nack\\r\\na=rtcp-fb:127 nack pli\\r\\na=fmtp:127 profile-id=2\\r\\na=rtpmap:125 rtx/90000\\r\\na=fmtp:125 apt=127\\r\\na=rtpmap:112 red/90000\\r\\na=rtpmap:113 rtx/90000\\r\\na=fmtp:113 apt=112\\r\\na=rtpmap:114 ulpfec/90000\\r\\na=ssrc-group:FID 3286714346 12295951\\r\\na=ssrc:3286714346 cname:dShL10ZK1y3XGZJD\\r\\na=ssrc:3286714346 msid:- 1b95d910-2910-49e4-a9ac-50cbce42d3cd\\r\\na=ssrc:12295951 cname:dShL10ZK1y3XGZJD\\r\\na=ssrc:12295951 msid:- 1b95d910-2910-49e4-a9ac-50cbce42d3cd\\r\\n', type='offer')\nICE Gathering State: gathering\nICE Gathering State: complete\n[INFO] [1731651122.789813194] [webrtc_node]: Sending SDP answer: webrtc_services.srv.SDPExchange_Response(sdp='v=0\\r\\no=- 3940639922 3940639922 IN IP4 0.0.0.0\\r\\ns=-\\r\\nt=0 0\\r\\na=group:BUNDLE 0\\r\\na=msid-semantic:WMS *\\r\\nm=video 44236 UDP/TLS/RTP/SAVPF 98 99 106 107\\r\\nc=IN IP4 192.168.0.20\\r\\na=sendrecv\\r\\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\\r\\na=extmap:9 urn:ietf:params:rtp-hdrext:sdes:mid\\r\\na=mid:0\\r\\na=msid:c98bd3b6-403c-4993-b56f-e4a9011b4ff9 60f6ea3e-5120-4d21-9130-9d50aadcc351\\r\\na=rtcp:9 IN IP4 0.0.0.0\\r\\na=rtcp-mux\\r\\na=ssrc-group:FID 1478075735 713819296\\r\\na=ssrc:1478075735 cname:9aa688cf-caad-4e7e-a604-7a23eb7c68d6\\r\\na=ssrc:713819296 cname:9aa688cf-caad-4e7e-a604-7a23eb7c68d6\\r\\na=rtpmap:98 H264/90000\\r\\na=rtcp-fb:98 nack\\r\\na=rtcp-fb:98 nack pli\\r\\na=rtcp-fb:98 goog-remb\\r\\na=fmtp:98 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42e01f\\r\\na=rtpmap:99 rtx/90000\\r\\na=fmtp:99 apt=98\\r\\na=rtpmap:106 VP8/90000\\r\\na=rtcp-fb:106 nack\\r\\na=rtcp-fb:106 nack pli\\r\\na=rtcp-fb:106 goog-remb\\r\\na=rtpmap:107 rtx/90000\\r\\na=fmtp:107 apt=106\\r\\na=candidate:4f322c660417b6096fd16770d34b336f 1 udp 2130706431 192.168.0.20 44236 typ host\\r\\na=candidate:bf734b071273f7d6ccf572c7ec2b884c 1 udp 2130706431 100.109.42.26 43464 typ host\\r\\na=candidate:cfde7b013ffc28500306e12b2dfcc5df 1 udp 2130706431 fd7a:115c:a1e0::4701:2a1a 38730 typ host\\r\\na=end-of-candidates\\r\\na=ice-ufrag:E7sT\\r\\na=ice-pwd:JCrFGjTr4LJmFM6VConLbC\\r\\na=fingerprint:sha-256 0D:44:B0:D7:40:CC:79:E2:4A:51:E4:68:45:05:7B:B7:4C:D8:F4:15:AA:47:A0:00:72:FC:60:51:58:0F:B5:5A\\r\\na=setup:active\\r\\n', type='answer')\n[INFO] [1731651122.794763206] [webrtc_node]: Adding remote ICE candidate: RTCIceCandidate(component='rtp', foundation='3240994852', ip='6f5ad9e3-e8c7-42a2-96e2-c416ccefca6d.local', port=64917, priority=2122260223, protocol='udp', type='host', relatedAddress=None, relatedPort=None, sdpMid='0', sdpMLineIndex=0, tcpType=None)\n[INFO] [1731651123.799837717] [webrtc_node]: Adding remote ICE candidate: RTCIceCandidate(component='rtp', foundation='1065843888', ip='6f5ad9e3-e8c7-42a2-96e2-c416ccefca6d.local', port=9, priority=1518280447, protocol='tcp', type='host', relatedAddress=None, relatedPort=None, sdpMid='0', sdpMLineIndex=0, tcpType=None)\n"], "quote": [], "url": "https://stackoverflow.com/questions/79191284/webrtc-connection-does-not-happen-after-ice-exchange", "answer": [], "answer_code": []},
{"title": "Unable to Connect ROS 2 Controller to Webots Instance from Docker Container", "time": 1730989937, "post_content": ["I'm trying to run a ROS 2 application inside a Docker container and simulate it using Webots on the host machine. (On Mac OS)\nI tried to run ROS 2 in a Docker container and then simulate it with Webots on the host.\nThis is the setup:\nDockerfile:  FROM cyberbotics/webots:latest ...\nThe Controller:\n    vehicle_driver = WebotsController(\n        robot_name=\"silicia2\",\n        parameters=[\n            {\"robot_description\": robot_description_path},\n        ],\n        protocol=\"tcp\",\n        ip_address=\"192.168.64.1\",\n        port=\"1234\",\n        respawn=True\n    )\n\nHowever, when I try to run it in the Docker container (after: docker run --rm --network=\"host\" --platform linux/amd64 -it core), and then execute ros2 launch core_simulation autonomous_driving_docker.py, i get the following error:\nros2 launch core_simulation autonomous_driving_docker.py ip_address:=192.168.64.1 port:=1234 [INFO] [launch]: All log files can be found below /root/.ros/log/2024-11-06-20-56-29-410256-docker-desktop-5937 \n[INFO] [launch]: Default logging verbosity is set to INFO \n[INFO] [webots_controller_silicia2-1]: process started with pid [5938] ... [INFO] [estimated_state_pub-5]: process started with pid \n[5946] [INFO] [visualizer-6]: process started with pid [5948] [webots_controller_silicia2-1] Cannot connect to Webots instance, retrying for another 50 seconds... ...\n\n- Webots is running in the Host\n- Adress and Port is correct\nThis is strange because the demo file from this documentation works: https://cyberbotics.com/doc/guide/running-extern-robot-controllers?tab-os=macos\nWhy might the ROS 2 controller in Docker be unable to connect to the Webots instance on the host, and how can I troubleshoot or resolve this?\nIt would be great if someone could provide some help. :)"], "question_code": ["Dockerfile:  FROM cyberbotics/webots:latest ...", "    vehicle_driver = WebotsController(\n        robot_name=&quot;silicia2&quot;,\n        parameters=[\n            {&quot;robot_description&quot;: robot_description_path},\n        ],\n        protocol=&quot;tcp&quot;,\n        ip_address=&quot;192.168.64.1&quot;,\n        port=&quot;1234&quot;,\n        respawn=True\n    )\n", "(after: docker run --rm --network=&quot;host&quot; --platform linux/amd64 -it core), and then execute ros2 launch core_simulation autonomous_driving_docker.py", "ros2 launch core_simulation autonomous_driving_docker.py ip_address:=192.168.64.1 port:=1234 [INFO] [launch]: All log files can be found below /root/.ros/log/2024-11-06-20-56-29-410256-docker-desktop-5937 \n[INFO] [launch]: Default logging verbosity is set to INFO \n[INFO] [webots_controller_silicia2-1]: process started with pid [5938] ... [INFO] [estimated_state_pub-5]: process started with pid \n[5946] [INFO] [visualizer-6]: process started with pid [5948] [webots_controller_silicia2-1] Cannot connect to Webots instance, retrying for another 50 seconds... ...\n"], "quote": [], "url": "https://stackoverflow.com/questions/79166911/unable-to-connect-ros-2-controller-to-webots-instance-from-docker-container", "answer": [], "answer_code": []},
{"title": "Unable to get CAN network to show up in Docker Container despite passing the --network host parameter", "time": 1730398533, "post_content": ["# Use the official ROS 2 Humble base image\nFROM ros:humble-ros-base\n\n# Set up workspace\nWORKDIR /walle_dt\n\n# Install necessary dependencies, including net-tools, can-utils, and ping\nRUN apt-get update && \\\n    apt-get install -y python3-rosdep python3-colcon-common-extensions nano \\\n    iproute2 net-tools can-utils iputils-ping && \\\n    rm -rf /var/lib/apt/lists/*\n\nRUN apt-get update && apt-get install -y python3 python3-pip\n\n# Initialize rosdep\nRUN rm -f /etc/ros/rosdep/sources.list.d/20-default.list\nRUN rosdep init\nRUN rosdep update\n\n# Create ROS 2 workspace directories\nRUN mkdir -p /walle_dt/walle_dt_ros2_ws/src\n\nWORKDIR /walle_dt\nWORKDIR /walle_dt/walle_dt_ros2_ws\n\n# Initialize workspace (this builds it in the correct directory)\nRUN /bin/bash -c \"source /opt/ros/humble/setup.bash && colcon build\"\n\n# Source ROS in the bashrc for new terminals\nRUN echo \"source /opt/ros/humble/setup.bash\" >> ~/.bashrc\n\nENV PYTHONPATH=/usr/bin/python3\n\n# Create entrypoint for workspace\nCOPY ./entrypoint.sh /\nENTRYPOINT [\"/entrypoint.sh\"]\n\n\n\nabove is my docker file and below is the script i run to start the container\n#!/bin/bash\n\n# Define the Docker image name\nIMAGE_NAME=\"walle_dt_ros2\"\n\n# Define the local directory to mount\nLOCAL_WS=\"/home/wall-e/WALL-E/ros2_ws\"\n\n# Build the Docker image\ndocker build -t $IMAGE_NAME .\n\n# Run the Docker container with the mounted workspace, privileged mode, and host network\ndocker run -it --rm --privileged --network host \\\n  --cap-add=ALL \\\n  -v \"/home/wall-e/WALL-E/ros2_ws:/walle_dt/walle_dt_ros2_ws\" walle_dt_ros2 /bin/bash\n\nwhen using ifconfig on the host I can see the CAN network is up and running but when I do this in the running container it is not present. Also not seeing wlan or eth0 but the container does have access to the internet so figure the container is using some bridge for those.\nalso worth noting this is running on a raspi 5"], "question_code": ["# Use the official ROS 2 Humble base image\nFROM ros:humble-ros-base\n\n# Set up workspace\nWORKDIR /walle_dt\n\n# Install necessary dependencies, including net-tools, can-utils, and ping\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y python3-rosdep python3-colcon-common-extensions nano \\\n    iproute2 net-tools can-utils iputils-ping &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\nRUN apt-get update &amp;&amp; apt-get install -y python3 python3-pip\n\n# Initialize rosdep\nRUN rm -f /etc/ros/rosdep/sources.list.d/20-default.list\nRUN rosdep init\nRUN rosdep update\n\n# Create ROS 2 workspace directories\nRUN mkdir -p /walle_dt/walle_dt_ros2_ws/src\n\nWORKDIR /walle_dt\nWORKDIR /walle_dt/walle_dt_ros2_ws\n\n# Initialize workspace (this builds it in the correct directory)\nRUN /bin/bash -c &quot;source /opt/ros/humble/setup.bash &amp;&amp; colcon build&quot;\n\n# Source ROS in the bashrc for new terminals\nRUN echo &quot;source /opt/ros/humble/setup.bash&quot; &gt;&gt; ~/.bashrc\n\nENV PYTHONPATH=/usr/bin/python3\n\n# Create entrypoint for workspace\nCOPY ./entrypoint.sh /\nENTRYPOINT [&quot;/entrypoint.sh&quot;]\n\n\n", "#!/bin/bash\n\n# Define the Docker image name\nIMAGE_NAME=&quot;walle_dt_ros2&quot;\n\n# Define the local directory to mount\nLOCAL_WS=&quot;/home/wall-e/WALL-E/ros2_ws&quot;\n\n# Build the Docker image\ndocker build -t $IMAGE_NAME .\n\n# Run the Docker container with the mounted workspace, privileged mode, and host network\ndocker run -it --rm --privileged --network host \\\n  --cap-add=ALL \\\n  -v &quot;/home/wall-e/WALL-E/ros2_ws:/walle_dt/walle_dt_ros2_ws&quot; walle_dt_ros2 /bin/bash\n"], "quote": [], "url": "https://stackoverflow.com/questions/79145888/unable-to-get-can-network-to-show-up-in-docker-container-despite-passing-the-n", "answer": [], "answer_code": []},
{"title": "TurtleBot3 Navigation Issue with Custom Local Costmap Using Intel RealSense D435i Data (ROS1)", "time": 1730318166, "post_content": ["I\u2019m working on navigation with a TurtleBot3 Burger, using a custom local costmap based on data from an Intel RealSense D435i. The RealSense D435i is installed at the front of the TurtleBot. This custom costmap is published to the topic /robot_hld_classifier/map as a nav_msgs/OccupancyGrid. The navigation stack is built upon the TurtleBot3 Navigation package.\nFor SLAM mapping and the global costmap, I am using the 360\u00b0 Laser Distance Sensor (LDS-01) that comes with the TurtleBot3 box set. While most configuration files from the original TurtleBot3 package remain unchanged, I modified the following:\n\nmove_base.launch\nmodified_costmap_common_params_burger.yaml\nmodified_local_costmap.yaml\n\nHere is my setup:\n\nmove_base.launch\n\n<launch>\n  <arg name=\"model\" default=\"$(env TURTLEBOT3_MODEL)\" doc=\"model type [burger, waffle, waffle_pi]\" />\n  <arg name=\"cmd_vel_topic\" default=\"/cmd_vel\" />\n  <arg name=\"odom_topic\" default=\"odom\" />\n  <arg name=\"move_forward_only\" default=\"false\" />\n\n  <node pkg=\"move_base\" type=\"move_base\" respawn=\"false\" name=\"move_base\" output=\"screen\">\n    <param name=\"base_local_planner\" value=\"dwa_local_planner/DWAPlannerROS\" />\n    <rosparam file=\"$(find turtlebot3_navigation)/param/costmap_common_params_$(arg model).yaml\" command=\"load\" ns=\"global_costmap\" />\n    <rosparam file=\"$(find turtlebot3_navigation)/param/modified_costmap_common_params_$(arg model).yaml\" command=\"load\" ns=\"local_costmap\" />\n    <rosparam file=\"$(find turtlebot3_navigation)/param/modified_local_costmap.yaml\" command=\"load\" />\n    <rosparam file=\"$(find turtlebot3_navigation)/param/global_costmap_params.yaml\" command=\"load\" />\n    <rosparam file=\"$(find turtlebot3_navigation)/param/move_base_params.yaml\" command=\"load\" />\n    <rosparam file=\"$(find turtlebot3_navigation)/param/dwa_local_planner_params_$(arg model).yaml\" command=\"load\" />\n    <remap from=\"cmd_vel\" to=\"$(arg cmd_vel_topic)\" />\n    <remap from=\"odom\" to=\"$(arg odom_topic)\" />\n    <param name=\"DWAPlannerROS/min_vel_x\" value=\"0.0\" if=\"$(arg move_forward_only)\" />\n  </node>\n</launch>\n\n\nmodified_costmap_common_params_burger.yaml\n\nobstacle_range: 3.0\nraytrace_range: 3.5\n\nfootprint: [[-0.105, -0.105], [-0.105, 0.105], [0.041, 0.105], [0.041, -0.105]]\n#robot_radius: 0.105\n\ninflation_radius: 1.0\ncost_scaling_factor: 3.0\n\nmap_type: costmap\nobservation_sources: pointcloud\npointcloud: {sensor_frame: camera_link, data_type: OccupancyGrid, topic: /robot_hld_classifier/map, marking: true, clearing: true}\n\n\nmodified_local_costmap.yaml\n\nlocal_costmap:\n  global_frame: odom\n  robot_base_frame: base_footprint\n  update_frequency: 10.0\n  publish_frequency: 10.0\n  transform_tolerance: 0.5\n  static_map: false\n  rolling_window: true\n\n  width: 4.0\n  height: 4.0\n  resolution: 0.02\n\n  plugins:\n    - {name: terrain_layer, type: \"costmap_2d::StaticLayer\"}\n    - {name: inflation_layer, type: \"costmap_2d::InflationLayer\"}\n\nterrain_layer:\n  map_topic: \"/robot_hld_classifier/map\"\n  subscribe_to_updates: true\n\ninflation_layer:\n  inflation_radius: 1\n  cost_scaling_factor: 3\n\nThe Issue\nUsing the default configuration (which relies only on the LDS-01 for both local and global costmaps), the robot performs well and avoids dynamic obstacles (like people walking in the environment) [Fig. 2]. However, when I switch to my custom local costmap (using data from the RealSense D435i), the robot cannot avoid dynamic obstacles\u2014it does not react to them at all [Fig. 3].\n\nFig. 1 Navigation using TurtleBot3 in an environment without dynamic obstacles\n\nFig. 2 Navigation using TurtleBot3 with the default configuration in an environment with dynamic obstacles\n\nFig. 3 Navigation using TurtleBot3 with a custom local costmap based on Intel RealSense D435i data in an environment with dynamic obstacles\nWhat I Have Tried\n\nChecked that the RealSense D435i data is being correctly processed by my pipeline.\nVerified that the /robot_hld_classifier/map topic publishes valid nav_msgs/OccupancyGrid data.\nConfirmed that the local and global costmaps are being correctly loaded from the launch files.\n\nWhat could be causing the TurtleBot3 to fail in avoiding dynamic obstacles with my custom costmap? Could it be related to the costmap plugins, update frequency, or the way I configured the terrain layer with the custom topic? Any insights or suggestions would be appreciated."], "question_code": ["&lt;launch&gt;\n  &lt;arg name=&quot;model&quot; default=&quot;$(env TURTLEBOT3_MODEL)&quot; doc=&quot;model type [burger, waffle, waffle_pi]&quot; /&gt;\n  &lt;arg name=&quot;cmd_vel_topic&quot; default=&quot;/cmd_vel&quot; /&gt;\n  &lt;arg name=&quot;odom_topic&quot; default=&quot;odom&quot; /&gt;\n  &lt;arg name=&quot;move_forward_only&quot; default=&quot;false&quot; /&gt;\n\n  &lt;node pkg=&quot;move_base&quot; type=&quot;move_base&quot; respawn=&quot;false&quot; name=&quot;move_base&quot; output=&quot;screen&quot;&gt;\n    &lt;param name=&quot;base_local_planner&quot; value=&quot;dwa_local_planner/DWAPlannerROS&quot; /&gt;\n    &lt;rosparam file=&quot;$(find turtlebot3_navigation)/param/costmap_common_params_$(arg model).yaml&quot; command=&quot;load&quot; ns=&quot;global_costmap&quot; /&gt;\n    &lt;rosparam file=&quot;$(find turtlebot3_navigation)/param/modified_costmap_common_params_$(arg model).yaml&quot; command=&quot;load&quot; ns=&quot;local_costmap&quot; /&gt;\n    &lt;rosparam file=&quot;$(find turtlebot3_navigation)/param/modified_local_costmap.yaml&quot; command=&quot;load&quot; /&gt;\n    &lt;rosparam file=&quot;$(find turtlebot3_navigation)/param/global_costmap_params.yaml&quot; command=&quot;load&quot; /&gt;\n    &lt;rosparam file=&quot;$(find turtlebot3_navigation)/param/move_base_params.yaml&quot; command=&quot;load&quot; /&gt;\n    &lt;rosparam file=&quot;$(find turtlebot3_navigation)/param/dwa_local_planner_params_$(arg model).yaml&quot; command=&quot;load&quot; /&gt;\n    &lt;remap from=&quot;cmd_vel&quot; to=&quot;$(arg cmd_vel_topic)&quot; /&gt;\n    &lt;remap from=&quot;odom&quot; to=&quot;$(arg odom_topic)&quot; /&gt;\n    &lt;param name=&quot;DWAPlannerROS/min_vel_x&quot; value=&quot;0.0&quot; if=&quot;$(arg move_forward_only)&quot; /&gt;\n  &lt;/node&gt;\n&lt;/launch&gt;\n", "obstacle_range: 3.0\nraytrace_range: 3.5\n\nfootprint: [[-0.105, -0.105], [-0.105, 0.105], [0.041, 0.105], [0.041, -0.105]]\n#robot_radius: 0.105\n\ninflation_radius: 1.0\ncost_scaling_factor: 3.0\n\nmap_type: costmap\nobservation_sources: pointcloud\npointcloud: {sensor_frame: camera_link, data_type: OccupancyGrid, topic: /robot_hld_classifier/map, marking: true, clearing: true}\n", "local_costmap:\n  global_frame: odom\n  robot_base_frame: base_footprint\n  update_frequency: 10.0\n  publish_frequency: 10.0\n  transform_tolerance: 0.5\n  static_map: false\n  rolling_window: true\n\n  width: 4.0\n  height: 4.0\n  resolution: 0.02\n\n  plugins:\n    - {name: terrain_layer, type: &quot;costmap_2d::StaticLayer&quot;}\n    - {name: inflation_layer, type: &quot;costmap_2d::InflationLayer&quot;}\n\nterrain_layer:\n  map_topic: &quot;/robot_hld_classifier/map&quot;\n  subscribe_to_updates: true\n\ninflation_layer:\n  inflation_radius: 1\n  cost_scaling_factor: 3\n"], "quote": [], "url": "https://stackoverflow.com/questions/79142618/turtlebot3-navigation-issue-with-custom-local-costmap-using-intel-realsense-d435", "answer": [], "answer_code": []},
{"title": "Unable to load controllers for URDF model in Gazebo and ROS Noetic", "time": 1729983136, "post_content": ["I'm trying to use some rather old ROS packages to control a simple simulation of a Robotis OP1 robot, using the darwin_description and darwin_control packages, but I'm facing a weird issue, whenever I use the bundled launch file in darwin_control I get the following messages/warning:\n[INFO] [1729969219.133353, 0.000000]: Controller Spawner: Waiting for service controller_manager/load_controller\n[WARN] [1729969249.437919, 97.394000]: Controller Spawner couldn't find the expected controller_manager ROS interface.\n\nwith the spawner node eventually terminating with no controller loaded.\nPrior to launching controllers, I'm successfully spawning the URDF model in Gazebo in a rather straightforward manner:\nrosparam load src/darwin_description/urdf/darwin.urdf /robot_description\n\nroslaunch gazebo_ros empty_world.launch\n\nrosrun gazebo_ros spawn_model -param /darwin/robot_description -urdf -model darwin\n\nIf relevant, I'm using a virtual machine w/ Ubuntu and ROS installation; I've read that controller_manager initialization is resource-dependent and may hang on virtual systems.\nI am also sure these packages somehow worked in ROS1 Melodic, so I wonder if the issue is somehow caused by some update to ros-noetic-controller-manager; in any case, I'm not sure what is missing here."], "question_code": ["darwin_description", "darwin_control", "darwin_control", "[INFO] [1729969219.133353, 0.000000]: Controller Spawner: Waiting for service controller_manager/load_controller\n[WARN] [1729969249.437919, 97.394000]: Controller Spawner couldn't find the expected controller_manager ROS interface.\n", "rosparam load src/darwin_description/urdf/darwin.urdf /robot_description\n\nroslaunch gazebo_ros empty_world.launch\n\nrosrun gazebo_ros spawn_model -param /darwin/robot_description -urdf -model darwin\n", "ros-noetic-controller-manager"], "quote": [], "url": "https://stackoverflow.com/questions/79129605/unable-to-load-controllers-for-urdf-model-in-gazebo-and-ros-noetic", "answer": [], "answer_code": []},
{"title": "Can't get data out of .bag files. Getting unsupported compression type error: lz4", "time": 1729777536, "post_content": ["I am trying to get data stored in .bag files on my linux machine using python. I have installed the required libraries however I every time I attempt to do something with the bag file I get an error like so, rosbag.bag.ROSBagException: unsupported compression type: lz4. I have tried this solution as well as installing lz4 but I can't seem to get past this issue. Here is a sample of my code:\nimport bagpy\nimport rosbag\nfrom bagpy import bagreader\n\nb = bagreader('my_bag_file.bag')\nlsr = b.message_by_topic('/my/topic')\nprint(lsr)\n\nI have also tried printing the messages this way but also get the same error:\nfor topic, msg, t in bag.read_messages(topics=['chatter', 'numbers']):\n    print(msg)\nbag.close()\n\nis there something that needs to be installed or am I running my python file incorrectly or is it something else?\nHere is the full error message:\nerror message"], "question_code": ["rosbag.bag.ROSBagException: unsupported compression type: lz4", "import bagpy\nimport rosbag\nfrom bagpy import bagreader\n\nb = bagreader('my_bag_file.bag')\nlsr = b.message_by_topic('/my/topic')\nprint(lsr)\n", "for topic, msg, t in bag.read_messages(topics=['chatter', 'numbers']):\n    print(msg)\nbag.close()\n"], "quote": [], "url": "https://stackoverflow.com/questions/79122227/cant-get-data-out-of-bag-files-getting-unsupported-compression-type-error-lz", "answer": [], "answer_code": []},
{"title": "PID Controller for Linear and Angular Velocity of A Vehicle Using Torque as Input For Wheels", "time": 1729589985, "post_content": ["When implementing a PID controller for a skid-steer vehicle, I am able to reach a constant linear velocity using PID, but when angular velocity is added to the equation with its own PID, my results are not good. What is the formula for combining linear and angular velocity of the vehicle?\nThe formula I use for the calculations is :\nV_left_wheel = V_forward - yaw_rate * d/2\n\nV_right_wheel = V_forward + yaw_rate * d/2\n\nWhere d is distance between wheels, yaw_rate is the target angular velocity, and V forward is forward velocity of the vehicle. This formula does not work. I tried multiple PID combinations where I have a PID for yaw rate, velocities of the wheels- forward velocity of the vehicle etc.\nIs there any other formula that I can use, as I feel like the formula is what is limiting me. I am in a simulation environment where I have access to current velocities of the vehicle, and to control velocity I apply torque to each wheel independently."], "question_code": ["V_left_wheel = V_forward - yaw_rate * d/2\n\nV_right_wheel = V_forward + yaw_rate * d/2\n"], "quote": [], "url": "https://stackoverflow.com/questions/79113408/pid-controller-for-linear-and-angular-velocity-of-a-vehicle-using-torque-as-inpu", "answer": [], "answer_code": []},
{"title": "python3 dowgrade in ubuntu 22.04.1", "time": 1733594473, "post_content": ["to be able to install ros2, need python3=3.10.6-1~22.04 but system wide python is 3.10.12\nsudo apt install python3=3.10.6-1~22.04\n\nThe following packages have unmet dependencies:\npython3 : PreDepends: python3-minimal (= 3.10.6-1~22.04) but 3.10.6-1~22.04.1 is to be installed\nDepends: libpython3-stdlib (= 3.10.6-1~22.04) but 3.10.6-1~22.04.1 is to be installed\nE: Unable to correct problems, you have held broken packages."], "question_code": [], "quote": ["The following packages have unmet dependencies:\npython3 : PreDepends: python3-minimal (= 3.10.6-1~22.04) but 3.10.6-1~22.04.1 is to be installed\nDepends: libpython3-stdlib (= 3.10.6-1~22.04) but 3.10.6-1~22.04.1 is to be installed\nE: Unable to correct problems, you have held broken packages."], "url": "https://stackoverflow.com/questions/79261100/python3-dowgrade-in-ubuntu-22-04-1", "answer": ["You can install python3.10 alongside system Python using a PPA: (see https://linuxcapable.com/how-to-install-python-3-10-on-ubuntu-linux/)\nsudo apt update && sudo apt upgrade\nsudo add-apt-repository ppa:deadsnakes/ppa -y\nsudo apt update\nsudo apt install python3.10\n\nAlso install the modules that you need, e.g. venv:\nsudo apt install python3.10-venv\n\nA more powerful, but also more involved, alternative is to use PyEnv, as pointed out in @tink's comment. This requires building Python from source, which means you need to install a bunch of dependencies and need to bring some time as well, depending on how powerful your machine is.", "It can be installed https://www.python.org/ftp/python/3.10.6/ from python.org"], "answer_code": ["sudo apt update &amp;&amp; sudo apt upgrade\nsudo add-apt-repository ppa:deadsnakes/ppa -y\nsudo apt update\nsudo apt install python3.10\n", "venv", "sudo apt install python3.10-venv\n"]},
{"title": "Learning results from rostopic list", "time": 1747190557, "post_content": ["I'm running  rostopic list\n/clock\n/cmd_vel\n/gazebo/link_states\n/gazebo/model_states\n/gazebo/parameter_descriptions\n/gazebo/parameter_updates\n/gazebo/performance_metrics\n/gazebo/set_link_state\n/gazebo/set_model_state\n/imu\n/imu_data\n/joint_states\n/odom\n/pr2_base_odometry/odom\n...\n\n\nCan I ask for some clarification, does it make sense to ask\nDo all these topics come from all running ros nodes?\nIf so, how do I view what node they're coming from?\nThanks,"], "question_code": ["/clock\n/cmd_vel\n/gazebo/link_states\n/gazebo/model_states\n/gazebo/parameter_descriptions\n/gazebo/parameter_updates\n/gazebo/performance_metrics\n/gazebo/set_link_state\n/gazebo/set_model_state\n/imu\n/imu_data\n/joint_states\n/odom\n/pr2_base_odometry/odom\n...\n\n"], "quote": [], "url": "https://stackoverflow.com/questions/79620651/learning-results-from-rostopic-list", "answer": ["Run rostopic list -v to see how many publishers and subscribers there are per topic, e.g.:\n\ud83d\udf82 rostopic list -v\n\nPublished topics:\n * /rosout_agg [rosgraph_msgs/Log] 1 publisher\n * /rosout [rosgraph_msgs/Log] 1 publisher\n * /transitive/remote_teleop/lag [std_msgs/Float32] 49 publishers\n * /transitive/remote_teleop/bps [std_msgs/Float32] 49 publishers\n * /transitive/webrtc_video/lag [std_msgs/Float32] 30 publishers\n * /transitive/webrtc_video/bps [std_msgs/Float32] 30 publishers\n * /transitive/terminal/lag [std_msgs/Float32] 7 publishers\n * /transitive/terminal/bps [std_msgs/Float32] 7 publishers\n * /mapping/map [nav_msgs/OccupancyGrid] 1 publisher\n * /mapping/access_map [nav_msgs/OccupancyGrid] 1 publisher\n * /mapping/speed_map [nav_msgs/OccupancyGrid] 1 publisher\n * /currentLocation [std_msgs/String] 1 publisher\n * /localization/pose [geometry_msgs/Pose] 1 publisher\n * /slam/stampedpose [geometry_msgs/PoseStamped] 1 publisher\n * /tf [tf2_msgs/TFMessage] 1 publisher\n * /laser_scan [sensor_msgs/LaserScan] 1 publisher\n * /joy [sensor_msgs/Joy] 1 publisher\n\nSubscribed topics:\n * /rosout [rosgraph_msgs/Log] 1 subscriber\n * /tf_static [tf2_msgs/TFMessage] 2 subscribers\n * /tf [tf2_msgs/TFMessage] 2 subscribers\n * /camera_forward/rgb/throttle/image_raw/compressed [sensor_msgs/CompressedImage] 1 subscriber\n * /camera_forward/depth/throttle/image_nav/compressedDepth [sensor_msgs/CompressedImage] 1 subscriber\n * /camera_down/rgb/throttle/image_raw/compressed [sensor_msgs/CompressedImage] 1 subscriber\n * /currentLocation [std_msgs/String] 1 subscriber\n\nAnd use rostopic info TOPICNAME to get the respective nodes, e.g.:\n\ud83d\udf82 rostopic info /tf\nType: tf2_msgs/TFMessage\n\nPublishers: \n * /transitive/_local/mock_bot (http://localhost:40899)\n\nSubscribers: \n * /ros_blessed (http://localhost:43637)\n * /transitive/_transitive_robotics/maps (http://localhost:37595)\n\nBonus\nUse lsof -i :PORTNUMBER to find the respective processes for these ports, e.g.:\n\ud83d\udf82 lsof -i :40899\nCOMMAND     PID   USER   FD   TYPE    DEVICE SIZE/OFF NODE NAME\nnode    4126810 cfritz   24u  IPv6 461968110      0t0  TCP *:40899 (LISTEN)\n\nAnd now you can even \"go to\" that process using the proc filesystem:\ncd /proc/4126810/cwd"], "answer_code": ["rostopic list -v", "\ud83d\udf82 rostopic list -v\n\nPublished topics:\n * /rosout_agg [rosgraph_msgs/Log] 1 publisher\n * /rosout [rosgraph_msgs/Log] 1 publisher\n * /transitive/remote_teleop/lag [std_msgs/Float32] 49 publishers\n * /transitive/remote_teleop/bps [std_msgs/Float32] 49 publishers\n * /transitive/webrtc_video/lag [std_msgs/Float32] 30 publishers\n * /transitive/webrtc_video/bps [std_msgs/Float32] 30 publishers\n * /transitive/terminal/lag [std_msgs/Float32] 7 publishers\n * /transitive/terminal/bps [std_msgs/Float32] 7 publishers\n * /mapping/map [nav_msgs/OccupancyGrid] 1 publisher\n * /mapping/access_map [nav_msgs/OccupancyGrid] 1 publisher\n * /mapping/speed_map [nav_msgs/OccupancyGrid] 1 publisher\n * /currentLocation [std_msgs/String] 1 publisher\n * /localization/pose [geometry_msgs/Pose] 1 publisher\n * /slam/stampedpose [geometry_msgs/PoseStamped] 1 publisher\n * /tf [tf2_msgs/TFMessage] 1 publisher\n * /laser_scan [sensor_msgs/LaserScan] 1 publisher\n * /joy [sensor_msgs/Joy] 1 publisher\n\nSubscribed topics:\n * /rosout [rosgraph_msgs/Log] 1 subscriber\n * /tf_static [tf2_msgs/TFMessage] 2 subscribers\n * /tf [tf2_msgs/TFMessage] 2 subscribers\n * /camera_forward/rgb/throttle/image_raw/compressed [sensor_msgs/CompressedImage] 1 subscriber\n * /camera_forward/depth/throttle/image_nav/compressedDepth [sensor_msgs/CompressedImage] 1 subscriber\n * /camera_down/rgb/throttle/image_raw/compressed [sensor_msgs/CompressedImage] 1 subscriber\n * /currentLocation [std_msgs/String] 1 subscriber\n", "rostopic info TOPICNAME", "\ud83d\udf82 rostopic info /tf\nType: tf2_msgs/TFMessage\n\nPublishers: \n * /transitive/_local/mock_bot (http://localhost:40899)\n\nSubscribers: \n * /ros_blessed (http://localhost:43637)\n * /transitive/_transitive_robotics/maps (http://localhost:37595)\n", "lsof -i :PORTNUMBER", "\ud83d\udf82 lsof -i :40899\nCOMMAND     PID   USER   FD   TYPE    DEVICE SIZE/OFF NODE NAME\nnode    4126810 cfritz   24u  IPv6 461968110      0t0  TCP *:40899 (LISTEN)\n", "cd /proc/4126810/cwd\n"]},
{"title": "Subscriber issues on ESP32 running Micro-ros", "time": 1745588527, "post_content": ["I'm working on a micro-ROS project using ESP32 connected to a PC via serial (USB) at 921600 baud. While the publisher functionality works fine, when I add a subscriber , the ESP32 goes into an error loop consistently in the moment in which i launch the micro ros agent.\nThis is the current launch file and command, where another testing node is run to verify publishing and subscribing\nros2 launch robot_launcher robot_launcher.launch.py\nfrom launch import LaunchDescription\nfrom launch.actions import ExecuteProcess, SetEnvironmentVariable\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        SetEnvironmentVariable('ROS_DOMAIN_ID', '0'),\n        Node(\n            package='micro_ros_agent',\n            executable='micro_ros_agent',\n            name='micro_ros_agent',\n            output='screen',\n            arguments=[\n                'serial',\n                '--dev', '/dev/ttyACM0',\n                '--baudrate', '921600',\n            ],\n        ),        \n        Node(\n            package='robot_launcher',\n            executable='angle_listener',\n            name='angle_listener',\n            output='screen',\n        ),\n    ])\n\n\n\nSetup\n\nESP32 microcontroller (esp32 environment downgraded to 2.0.2 to address microros compatibility issues)\nmicro-ROS agent running on PC (Ubuntu 22.04)\nPython ROS2 node (angle_listener.py) that subscribes to encoder data and publishes velocity commands\nSerial connection via USB (UART0) at 921600 baud\nThe setup is just a test so some of the solutions (like the 1 dimensional arrays of size 1 because of N_MOTORS) are to scale the code up to 6 motors later\n\nHardware Limitation\nI have limited debugging capabilities because the hardware serial port I'm using for  USB communication (UART0) is the only one available on the board I'm using. This means I can't add Serial.print statements for debugging.\nCode\nESP32 Code Snippet (C++):\n#include <Wire.h>\n#include <AS5600.h>\n#include <TMCStepper.h>\n\n\n#include <micro_ros_arduino.h>\n#include <AccelStepper.h>\n\n#include <std_msgs/msg/float64.h>\n\n#include <stdio.h>\n#include <rcl/rcl.h>\n#include <rcl/error_handling.h>\n#include <rclc/rclc.h>\n#include <rclc/executor.h>\n\n#include <std_msgs/msg/int32.h>\n\nfloat a2s(float angular_velocity_rad_s);\n\n#define RCCHECK(fn)                                                    \\\n  {                                                                    \\\n    rcl_ret_t rc = fn;                                                 \\\n    if (rc != RCL_RET_OK) {                                            \\\n      Serial.print(F(\"ERROR at \"));                                    \\\n      Serial.print(F(#fn));                                            \\\n      Serial.print(F(\": \"));                                           \\\n      Serial.println(rcl_get_error_string().str);                      \\\n      error_loop();                                                    \\\n    }                                                                  \\\n  }\n#define RCSOFTCHECK(fn) \\\n  { \\\n    rcl_ret_t temp_rc = fn; \\\n    if ((temp_rc != RCL_RET_OK)) {} \\\n  }\n\n#define MICROSTEP 64\n#define STEPS_PER_REV 200.0\n#define LED_PIN 14\n// Pin definitions\n#define CLK_PIN 18\n#define PDN_UART_PIN 16\n#define SPREAD_PIN 17\n\n#define DIR1_PIN 4\n#define STEP1_PIN 13\n\n#define DIR2_PIN 32\n#define STEP2_PIN 25\n\n\n#define N_MOTOR 1\n\n#define SERIAL_PORT Serial2\n#define UART_RX_PIN 16        // PDN_UART used as UART RX\n#define UART_TX_PIN 17        // SPREAD used as UART TX (optional)\n#define DRIVER_ADDRESS1 0b00  // Driver address (if multiple drivers on UART)\n#define DRIVER_ADDRESS2 0b01\n\n#define R_SENSE 0.11f\n#define DRIVER_CURRENT 1000  // mA, adjust based on your motor\n\n\n\nrcl_subscription_t subscriber;\nstd_msgs__msg__Float64 sub_msg;\nfloat motor_velocities[N_MOTOR] = {0.0f};\n\nAccelStepper motors[N_MOTOR] = {\n  AccelStepper(AccelStepper::DRIVER, STEP1_PIN, DIR1_PIN),\n  // \u2026 fino a 6\n};\n\n\nTMC2209Stepper drivers[N_MOTOR]={\n  TMC2209Stepper(&SERIAL_PORT, R_SENSE, DRIVER_ADDRESS1)\n};\n\n\nvoid error_loop() {\n  while (1) {\n    digitalWrite(LED_PIN, !digitalRead(LED_PIN));\n    delay(100);\n  }\n}\n\n\nrcl_publisher_t publisher;\nstd_msgs__msg__Int32 msg;\nrclc_executor_t executor;\nrclc_support_t support;\nrcl_allocator_t allocator;\nrcl_node_t node;\nrcl_timer_t timer;\n\n#define MULTIPLEXER_ADDR 0x70\n\n#define ENCODER_PUBLISH_TIME 20  //ms\nTwoWire &i2cBus = Wire;\n\n// Classe per multiplexer PCA9548A\nclass PCA9548A {\npublic:\n  PCA9548A(uint8_t address, TwoWire &wire = Wire)\n    : _addr(address), _wire(wire) {}\n\n  void begin() {\n    _wire.begin();\n  }\n\n  void selectChannel(uint8_t channel) {\n    if (channel > 7) return;\n    _wire.beginTransmission(_addr);\n    _wire.write(1 << channel);\n    _wire.endTransmission();\n  }\n\nprivate:\n  uint8_t _addr;\n  TwoWire &_wire;\n};\n\nPCA9548A mux(MULTIPLEXER_ADDR, Wire);\nAS5600 encoder(&i2cBus);\n\n\n\nvoid timer_callback(rcl_timer_t *timer, int64_t last_call_time) {\n  RCLC_UNUSED(last_call_time);\n  if (timer != NULL) {\n    int32_t angle = encoder.readAngle();\n    msg.data = angle;\n    RCSOFTCHECK(rcl_publish(&publisher, &msg, NULL));\n  }\n}\nvoid velocity_callback(const void * msgin) {\n  // Cast the incoming pointer to a Float64 message\n  const auto *incoming = (const std_msgs__msg__Float64 *)msgin;\n  float vel = incoming->data;                     // get the single float\n\n  motor_velocities[0] = vel;                      // assuming N_MOTOR == 1\n  motors[0].setSpeed(a2s(motor_velocities[0]));   // update stepper speed\n}\nvoid setup() {\n  Serial.begin(921600);\n  SERIAL_PORT.begin(115200, SERIAL_8N1, UART_RX_PIN, UART_TX_PIN);\n  delay(500);\n\n  for(int i=0; i<N_MOTOR;i++){\n    drivers[i].begin();\n    drivers[i].toff(5);\n    drivers[i].rms_current(DRIVER_CURRENT);\n    drivers[i].microsteps(MICROSTEP);\n    drivers[i].en_spreadCycle(false);  // StealthChop\n\n    motors[i].setMaxSpeed(a2s(100));\n  }\n\n\n  set_microros_transports();\n\n  pinMode(LED_PIN, OUTPUT);\n  digitalWrite(LED_PIN, HIGH);\n\n  delay(100);\n\n  allocator = rcl_get_default_allocator();\n\n  //create init_options\n  RCCHECK(rclc_support_init(&support, 0, NULL, &allocator));\n\n  // create node\n  RCCHECK(rclc_node_init_default(&node, \"ESP32_node\", \"\", &support));\n\n  // create publisher\n  RCCHECK(rclc_publisher_init_default(\n    &publisher,\n    &node,\n    ROSIDL_GET_MSG_TYPE_SUPPORT(std_msgs, msg, Int32),\n    \"axis_1_encoder\"));\n\n  // create timer,\n  RCCHECK(rclc_timer_init_default(\n    &timer,\n    &support,\n    RCL_MS_TO_NS(ENCODER_PUBLISH_TIME),\n    timer_callback));\n\n   // ### 2. initialize subscriber message\n  RCCHECK(std_msgs__msg__Float64__init(&sub_msg));\n\n  // 3. create subscriber\n  RCCHECK(rclc_subscription_init_default(\n    &subscriber,\n    &node,\n    ROSIDL_GET_MSG_TYPE_SUPPORT(std_msgs, msg, Float64),\n    \"motor_velocity_1\"      // rename topic as you wish\n  ));\n\n  // create executor\n  RCCHECK(rclc_executor_init(&executor, &support.context, 2, &allocator));\n\n  RCCHECK(rclc_executor_add_timer(&executor, &timer));\n\n    // 4. add subscription to executor\n  RCCHECK(rclc_executor_add_subscription(\n    &executor,\n    &subscriber,\n    &sub_msg,\n    &velocity_callback,\n    ON_NEW_DATA\n  ));\n\n  mux.begin();\n  mux.selectChannel(0);\n\n  encoder.begin();\n}\n\n\nvoid loop() {\n  // Gestione micro-ROS\n  rclc_executor_spin_some(&executor, RCL_MS_TO_NS(20));\n  for (int i = 0; i < N_MOTOR; i++) {\n    motors[i].runSpeed();\n  }\n}\n\n\nfloat a2s(float angular_velocity_rad_s) {\n  // steps_per_rev is typically 200 for 1.8\u00b0/step motors\n  float rev_per_sec = angular_velocity_rad_s / (2.0f * M_PI);\n  float steps_per_sec = rev_per_sec * STEPS_PER_REV * MICROSTEP;\n  return steps_per_sec;\n}\n\n\n\nPython Node:\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Int32, Float64  # use Float64 instead of Float64MultiArray\n\nclass Listener(Node):\n\n    def __init__(self):\n        super().__init__(\"angle_listener\")\n\n        # publisher for a single float64\n        self.velocity_publisher = self.create_publisher(\n            Float64, \n            \"motor_velocity_1\", \n            10\n        )\n\n        # subscriber as before\n        self.subscriber = self.create_subscription(\n            Int32, \n            \"axis_1_encoder\", \n            self.angle_callback, \n            10\n        )\n        self.get_logger().info(\"Subscribed to encoder topic\")\n\n    def angle_callback(self, message):\n        # log incoming value\n        self.get_logger().info(f\"Received encoder: {message.data}\")\n\n        # build and publish single Float64 with value 2.0\n        vel_msg = Float64()\n        vel_msg.data = 2.0\n        self.velocity_publisher.publish(vel_msg)\n        self.get_logger().info(\"Published velocity: 2.0\")\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = Listener()\n    rclpy.spin(node)\n    rclpy.shutdown()\n\nif __name__ == \"__main__\":\n    main()\n\n\nBehavior\n\nESP32 works correctly with just the publisher (encoder data)\nWhen I add the subscriber code, the ESP32 immediately enters the error loop function\nThe error loop is triggered by one of the RCCHECK macros failing\n\nWhat I've Tried\n\nVerified topic names match between ESP32 and Python node\nVerified that the topics are correctly initialized\nIncreased spin timing on esp32 to ensure the problem wasn't related to cpu\n\nWhat could be causing the ESP32 to enter the error loop when adding a subscriber\nAny help would be greatly appreciated!"], "question_code": ["ros2 launch robot_launcher robot_launcher.launch.py", "from launch import LaunchDescription\nfrom launch.actions import ExecuteProcess, SetEnvironmentVariable\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        SetEnvironmentVariable('ROS_DOMAIN_ID', '0'),\n        Node(\n            package='micro_ros_agent',\n            executable='micro_ros_agent',\n            name='micro_ros_agent',\n            output='screen',\n            arguments=[\n                'serial',\n                '--dev', '/dev/ttyACM0',\n                '--baudrate', '921600',\n            ],\n        ),        \n        Node(\n            package='robot_launcher',\n            executable='angle_listener',\n            name='angle_listener',\n            output='screen',\n        ),\n    ])\n\n\n", "angle_listener.py", "#include &lt;Wire.h&gt;\n#include &lt;AS5600.h&gt;\n#include &lt;TMCStepper.h&gt;\n\n\n#include &lt;micro_ros_arduino.h&gt;\n#include &lt;AccelStepper.h&gt;\n\n#include &lt;std_msgs/msg/float64.h&gt;\n\n#include &lt;stdio.h&gt;\n#include &lt;rcl/rcl.h&gt;\n#include &lt;rcl/error_handling.h&gt;\n#include &lt;rclc/rclc.h&gt;\n#include &lt;rclc/executor.h&gt;\n\n#include &lt;std_msgs/msg/int32.h&gt;\n\nfloat a2s(float angular_velocity_rad_s);\n\n#define RCCHECK(fn)                                                    \\\n  {                                                                    \\\n    rcl_ret_t rc = fn;                                                 \\\n    if (rc != RCL_RET_OK) {                                            \\\n      Serial.print(F(&quot;ERROR at &quot;));                                    \\\n      Serial.print(F(#fn));                                            \\\n      Serial.print(F(&quot;: &quot;));                                           \\\n      Serial.println(rcl_get_error_string().str);                      \\\n      error_loop();                                                    \\\n    }                                                                  \\\n  }\n#define RCSOFTCHECK(fn) \\\n  { \\\n    rcl_ret_t temp_rc = fn; \\\n    if ((temp_rc != RCL_RET_OK)) {} \\\n  }\n\n#define MICROSTEP 64\n#define STEPS_PER_REV 200.0\n#define LED_PIN 14\n// Pin definitions\n#define CLK_PIN 18\n#define PDN_UART_PIN 16\n#define SPREAD_PIN 17\n\n#define DIR1_PIN 4\n#define STEP1_PIN 13\n\n#define DIR2_PIN 32\n#define STEP2_PIN 25\n\n\n#define N_MOTOR 1\n\n#define SERIAL_PORT Serial2\n#define UART_RX_PIN 16        // PDN_UART used as UART RX\n#define UART_TX_PIN 17        // SPREAD used as UART TX (optional)\n#define DRIVER_ADDRESS1 0b00  // Driver address (if multiple drivers on UART)\n#define DRIVER_ADDRESS2 0b01\n\n#define R_SENSE 0.11f\n#define DRIVER_CURRENT 1000  // mA, adjust based on your motor\n\n\n\nrcl_subscription_t subscriber;\nstd_msgs__msg__Float64 sub_msg;\nfloat motor_velocities[N_MOTOR] = {0.0f};\n\nAccelStepper motors[N_MOTOR] = {\n  AccelStepper(AccelStepper::DRIVER, STEP1_PIN, DIR1_PIN),\n  // \u2026 fino a 6\n};\n\n\nTMC2209Stepper drivers[N_MOTOR]={\n  TMC2209Stepper(&amp;SERIAL_PORT, R_SENSE, DRIVER_ADDRESS1)\n};\n\n\nvoid error_loop() {\n  while (1) {\n    digitalWrite(LED_PIN, !digitalRead(LED_PIN));\n    delay(100);\n  }\n}\n\n\nrcl_publisher_t publisher;\nstd_msgs__msg__Int32 msg;\nrclc_executor_t executor;\nrclc_support_t support;\nrcl_allocator_t allocator;\nrcl_node_t node;\nrcl_timer_t timer;\n\n#define MULTIPLEXER_ADDR 0x70\n\n#define ENCODER_PUBLISH_TIME 20  //ms\nTwoWire &amp;i2cBus = Wire;\n\n// Classe per multiplexer PCA9548A\nclass PCA9548A {\npublic:\n  PCA9548A(uint8_t address, TwoWire &amp;wire = Wire)\n    : _addr(address), _wire(wire) {}\n\n  void begin() {\n    _wire.begin();\n  }\n\n  void selectChannel(uint8_t channel) {\n    if (channel &gt; 7) return;\n    _wire.beginTransmission(_addr);\n    _wire.write(1 &lt;&lt; channel);\n    _wire.endTransmission();\n  }\n\nprivate:\n  uint8_t _addr;\n  TwoWire &amp;_wire;\n};\n\nPCA9548A mux(MULTIPLEXER_ADDR, Wire);\nAS5600 encoder(&amp;i2cBus);\n\n\n\nvoid timer_callback(rcl_timer_t *timer, int64_t last_call_time) {\n  RCLC_UNUSED(last_call_time);\n  if (timer != NULL) {\n    int32_t angle = encoder.readAngle();\n    msg.data = angle;\n    RCSOFTCHECK(rcl_publish(&amp;publisher, &amp;msg, NULL));\n  }\n}\nvoid velocity_callback(const void * msgin) {\n  // Cast the incoming pointer to a Float64 message\n  const auto *incoming = (const std_msgs__msg__Float64 *)msgin;\n  float vel = incoming-&gt;data;                     // get the single float\n\n  motor_velocities[0] = vel;                      // assuming N_MOTOR == 1\n  motors[0].setSpeed(a2s(motor_velocities[0]));   // update stepper speed\n}\nvoid setup() {\n  Serial.begin(921600);\n  SERIAL_PORT.begin(115200, SERIAL_8N1, UART_RX_PIN, UART_TX_PIN);\n  delay(500);\n\n  for(int i=0; i&lt;N_MOTOR;i++){\n    drivers[i].begin();\n    drivers[i].toff(5);\n    drivers[i].rms_current(DRIVER_CURRENT);\n    drivers[i].microsteps(MICROSTEP);\n    drivers[i].en_spreadCycle(false);  // StealthChop\n\n    motors[i].setMaxSpeed(a2s(100));\n  }\n\n\n  set_microros_transports();\n\n  pinMode(LED_PIN, OUTPUT);\n  digitalWrite(LED_PIN, HIGH);\n\n  delay(100);\n\n  allocator = rcl_get_default_allocator();\n\n  //create init_options\n  RCCHECK(rclc_support_init(&amp;support, 0, NULL, &amp;allocator));\n\n  // create node\n  RCCHECK(rclc_node_init_default(&amp;node, &quot;ESP32_node&quot;, &quot;&quot;, &amp;support));\n\n  // create publisher\n  RCCHECK(rclc_publisher_init_default(\n    &amp;publisher,\n    &amp;node,\n    ROSIDL_GET_MSG_TYPE_SUPPORT(std_msgs, msg, Int32),\n    &quot;axis_1_encoder&quot;));\n\n  // create timer,\n  RCCHECK(rclc_timer_init_default(\n    &amp;timer,\n    &amp;support,\n    RCL_MS_TO_NS(ENCODER_PUBLISH_TIME),\n    timer_callback));\n\n   // ### 2. initialize subscriber message\n  RCCHECK(std_msgs__msg__Float64__init(&amp;sub_msg));\n\n  // 3. create subscriber\n  RCCHECK(rclc_subscription_init_default(\n    &amp;subscriber,\n    &amp;node,\n    ROSIDL_GET_MSG_TYPE_SUPPORT(std_msgs, msg, Float64),\n    &quot;motor_velocity_1&quot;      // rename topic as you wish\n  ));\n\n  // create executor\n  RCCHECK(rclc_executor_init(&amp;executor, &amp;support.context, 2, &amp;allocator));\n\n  RCCHECK(rclc_executor_add_timer(&amp;executor, &amp;timer));\n\n    // 4. add subscription to executor\n  RCCHECK(rclc_executor_add_subscription(\n    &amp;executor,\n    &amp;subscriber,\n    &amp;sub_msg,\n    &amp;velocity_callback,\n    ON_NEW_DATA\n  ));\n\n  mux.begin();\n  mux.selectChannel(0);\n\n  encoder.begin();\n}\n\n\nvoid loop() {\n  // Gestione micro-ROS\n  rclc_executor_spin_some(&amp;executor, RCL_MS_TO_NS(20));\n  for (int i = 0; i &lt; N_MOTOR; i++) {\n    motors[i].runSpeed();\n  }\n}\n\n\nfloat a2s(float angular_velocity_rad_s) {\n  // steps_per_rev is typically 200 for 1.8\u00b0/step motors\n  float rev_per_sec = angular_velocity_rad_s / (2.0f * M_PI);\n  float steps_per_sec = rev_per_sec * STEPS_PER_REV * MICROSTEP;\n  return steps_per_sec;\n}\n\n\n", "import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Int32, Float64  # use Float64 instead of Float64MultiArray\n\nclass Listener(Node):\n\n    def __init__(self):\n        super().__init__(&quot;angle_listener&quot;)\n\n        # publisher for a single float64\n        self.velocity_publisher = self.create_publisher(\n            Float64, \n            &quot;motor_velocity_1&quot;, \n            10\n        )\n\n        # subscriber as before\n        self.subscriber = self.create_subscription(\n            Int32, \n            &quot;axis_1_encoder&quot;, \n            self.angle_callback, \n            10\n        )\n        self.get_logger().info(&quot;Subscribed to encoder topic&quot;)\n\n    def angle_callback(self, message):\n        # log incoming value\n        self.get_logger().info(f&quot;Received encoder: {message.data}&quot;)\n\n        # build and publish single Float64 with value 2.0\n        vel_msg = Float64()\n        vel_msg.data = 2.0\n        self.velocity_publisher.publish(vel_msg)\n        self.get_logger().info(&quot;Published velocity: 2.0&quot;)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = Listener()\n    rclpy.spin(node)\n    rclpy.shutdown()\n\nif __name__ == &quot;__main__&quot;:\n    main()\n\n"], "quote": [], "url": "https://stackoverflow.com/questions/79592649/subscriber-issues-on-esp32-running-micro-ros", "answer": ["Apparently the problem was related to an error in the documentation I was using. In particular RCCHECK(std_msgs__msg__Float64__init(&sub_msg)) was the line triggering the error.\nMy code was calling the RCCHECK macro on a function that returns a bool, not an rcl_ret_t. Since true != RCL_RET_OK (which is 0), it instantly trip the error handler.\nThis error also apply to all the other type publisher initializers."], "answer_code": ["RCCHECK(std_msgs__msg__Float64__init(&amp;sub_msg))", "true != RCL_RET_OK (which is 0)"]},
{"title": "rviz2 doesnt detect one of the joint/link combos in the urdf while other urdf viewers do", "time": 1734668569, "post_content": ["I'm using ROS Jazzy on Ubuntu 24. I have a URDF file written with the help of xacro:\n<?xml version=\"1.0\"?>\n<robot name=\"my_robot\" xmlns:xacro=\"http://www.ros.org/wiki/xacro\">\n\n  <xacro:include filename=\"macros.xacro\"/>\n\n  <link name=\"world\"></link>\n\n  <joint name=\"base_joint\" type=\"fixed\">\n    <origin xyz=\"1.5 1 0\" rpy=\"0 0 0\"/>\n    <parent link=\"world\"/>\n    <child link=\"base_link\"/>\n  </joint>\n\n  <link name=\"base_link\">\n    <visual>\n      <origin xyz=\"0 0 0.05\" rpy=\"0 0 0\"/>\n      <geometry>\n        <box size=\"2.5 1.5 0.1\"/>\n      </geometry>\n      <material name=\"green\"/>\n    </visual>\n    <collision>\n      <origin xyz=\"0 0 0.05\" rpy=\"0 0 0\"/>\n      <geometry>\n        <box size=\"2.5 1.5 0.1\"/>\n      </geometry>\n    </collision>\n    <xacro:inertial_box mass=\"12\" x=\"2.5\" y=\"1.5\" z=\"0.1\">\n      <origin xyz=\"0 0 0.05\" rpy=\"0 0 0\"/>\n    </xacro:inertial_box>\n  </link>\n  \n  <joint name=\"slider_joint\" type=\"prismatic\">\n    <origin xyz=\"-1.25 0 0.1\" rpy=\"0 0 0\"/>\n    <parent link=\"base_link\"/>\n    <child link=\"slider_link\"/>\n    <axis xyz=\"1 0 0\"/>\n    <limit lower=\"0\" upper=\"2\" velocity=\"100\" effort=\"100\"/>\n  </joint>\n\n  <link name=\"slider_link\">\n    <visual>\n      <origin xyz=\"0 0 0.075\" rpy=\"0 0 0\"/>\n      <geometry>\n          <box size=\"0.5 0.25 0.15\"/>\n      </geometry>\n      <material name=\"blue\"/>\n    </visual>\n    <collision>\n      <origin xyz=\"0 0 0.075\" rpy=\"0 0 0\"/>\n      <geometry>\n          <box size=\"0.5 0.25 0.15\"/>\n      </geometry>\n    </collision>\n    <xacro:inertial_box mass=\"0.5\" x=\"0.5\" y=\"0.25\" z=\"0.15\">\n      <origin xyz=\"0 0 0.075\" rpy=\"0 0 0\"/>\n    </xacro:inertial_box>\n  </link>\n\n  <joint name=\"arm_joint\" type=\"revolute\">\n    <origin xyz=\"0.25 0 0.15\" rpy=\"0 0 0\"/>\n    <parent link=\"slider_link\"/>\n    <child link=\"arm_link\"/>\n    <axis xyz=\"0 -1 0\"/>\n    <limit lower=\"0\" upper=\"${pi/2}\" velocity=\"100\" effort=\"100\"/>\n  </joint>\n\n  <xacro:property name=\"arm_length\" value=\"1\"/>\n  <xacro:property name=\"arm_radius\" value=\"0.1\"/>\n  <link name=\"arm_link\">\n    <visual>\n      <origin xyz=\"${arm_length/2} 0 0\" rpy=\"0 ${pi/2} 0\"/>\n      <geometry>                \n          <cylinder length=\"${arm_length}\" radius=\"${arm_radius}\"/>\n      </geometry>\n      <material name=\"orange\"/>\n    </visual>\n    <collision>\n      <origin xyz=\"${arm_length/2} 0 0\" rpy=\"0 ${pi/2} 0\"/>\n      <geometry>                \n          <cylinder length=\"${arm_length}\" radius=\"${arm_radius}\"/>\n      </geometry>      \n    </collision>\n    <xacro:inertial_cylinder mass=\"1.0\" length=\"${arm_length}\" radius=\"${arm_radius}\">\n      <origin xyz=\"${arm_length/2} 0 0 \" rpy=\"0 ${pi/2} 0\"/>\n    </xacro:inertial_cylinder>\n  </link>\n\n  <joint name=\"camera_joint\" type=\"fixed\">\n        <origin xyz=\"${arm_length} 0 ${arm_radius + 0.075}\"/>\n        <parent link=\"arm_link\"/>\n        <child link=\"camera_link\"/>        \n  </joint>\n\n  <link name=\"camera_link\">\n    <visual>\n      <origin xyz=\"-0.03 0 0\" rpy=\"0 0 0\"/>\n      <geometry>\n        <box size=\"0.06 0.15 0.15\" />\n      </geometry>\n      <material name=\"white\"/>\n    </visual>\n    <visual>\n      <origin xyz=\"0.03 0 0\" rpy=\"0 ${pi/2} 0\"/>\n      <geometry>\n        <cylinder length=\"0.06\" radius=\"0.04\"/>\n      </geometry>\n      <material name=\"blue\"/>\n    </visual>\n    <collision>\n      <origin xyz=\"0.0 0 0\" rpy=\"0 0 0\"/>\n      <geometry>\n        <box size=\"0.12 0.15 0.15\"/>\n      </geometry>\n    </collision>\n    <xacro:inertial_box mass=\"0.1\" x=\"0.12\" y=\"0.15\" z=\"0.15\">\n      <origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n    </xacro:inertial_box>\n  </link>\n\n</robot>\n\nThis is the macros.xacro file:\n<?xml version=\"1.0\"?>\n<robot xmlns:xacro=\"http://www.ros.org/wiki/xacro\">\n  \n  <!-- inertial calculations from wikipedia https://en.wikipedia.org/wiki/List_of_moments_of_inertia-->\n\n  <xacro:macro name=\"inertial_sphere\" params=\"mass radius *origin\">\n    <inertial>\n      <xacro:insert_block name=\"origin\"/>\n      <mass value=\"${mass}\"/>\n      <inertia ixx=\"${(2/5) * mass * radius*radius}\" ixy=\"0\" ixz=\"0\"\n               iyy=\"${(2/5) * mass * radius*radius}\" iyz=\"0\"\n               izz=\"${(2/5) * mass * radius*radius}\"\n      />\n    </inertial>\n  </xacro:macro>\n\n  <xacro:macro name=\"inertial_box\" params=\"mass x y z *origin\">\n    <inertial>\n      <xacro:insert_block name=\"origin\"/>\n      <mass value=\"${mass}\"/>\n      <inertia ixx=\"${(1/12) * mass * (y*y + z*z)}\" ixy=\"0\" ixz=\"0\"\n               iyy=\"${(1/12) * mass * (x*x + z*z)}\" iyz=\"0\"\n               izz=\"${(1/12) * mass * (x*x + y*y)}\"\n      />\n    </inertial>\n  </xacro:macro>\n\n  <xacro:macro name=\"inertial_cylinder\" params=\"mass length radius *origin\">\n    <inertial>\n      <xacro:insert_block name=\"origin\"/>\n      <mass value=\"${mass}\"/>\n      <inertia ixx=\"${(1/12) * mass * (3*radius*radius + length*length)}\" ixy=\"0\" ixz=\"0\"\n               iyy=\"${(1/12) * mass * (3*radius*radius + length*length)}\" iyz=\"0\"\n               izz=\"${(1/12) * mass * (3*radius*radius + length*length)}\"\n      />\n    </inertial>\n  </xacro:macro>\n\n\n  <!-- colours -->\n\n  <material name=\"green\">\n    <color rgba=\"0.2 1 0.2 1\"/>\n  </material>\n\n  <material name=\"white\">\n    <color rgba=\"1 1 1 1\"/>\n  </material>\n\n  <material name=\"orange\">\n    <color rgba=\"1 0.3 0.1 1\"/>\n  </material>\n\n  <material name=\"blue\">\n    <color rgba=\"0.2 0.2 1 1\"/>\n  </material>\n\n\n</robot>\n\nViewing this urdf using a VSCode extension works perfectly as expected:\nviewing the urdf in VSCode\nBut, in rviz i get the following error:\nviewing the urdf in rviz\nI suspect it may have something to do with rviz not recognizing the prismatic joint? But that is just a baseless suspicion i have no idea.\nI tried exporting the output of xacro to a file to see if it was an xacro issue, but it wasnt."], "question_code": ["&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;robot name=&quot;my_robot&quot; xmlns:xacro=&quot;http://www.ros.org/wiki/xacro&quot;&gt;\n\n  &lt;xacro:include filename=&quot;macros.xacro&quot;/&gt;\n\n  &lt;link name=&quot;world&quot;&gt;&lt;/link&gt;\n\n  &lt;joint name=&quot;base_joint&quot; type=&quot;fixed&quot;&gt;\n    &lt;origin xyz=&quot;1.5 1 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;parent link=&quot;world&quot;/&gt;\n    &lt;child link=&quot;base_link&quot;/&gt;\n  &lt;/joint&gt;\n\n  &lt;link name=&quot;base_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;origin xyz=&quot;0 0 0.05&quot; rpy=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;box size=&quot;2.5 1.5 0.1&quot;/&gt;\n      &lt;/geometry&gt;\n      &lt;material name=&quot;green&quot;/&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;origin xyz=&quot;0 0 0.05&quot; rpy=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;box size=&quot;2.5 1.5 0.1&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;xacro:inertial_box mass=&quot;12&quot; x=&quot;2.5&quot; y=&quot;1.5&quot; z=&quot;0.1&quot;&gt;\n      &lt;origin xyz=&quot;0 0 0.05&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;/xacro:inertial_box&gt;\n  &lt;/link&gt;\n  \n  &lt;joint name=&quot;slider_joint&quot; type=&quot;prismatic&quot;&gt;\n    &lt;origin xyz=&quot;-1.25 0 0.1&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;parent link=&quot;base_link&quot;/&gt;\n    &lt;child link=&quot;slider_link&quot;/&gt;\n    &lt;axis xyz=&quot;1 0 0&quot;/&gt;\n    &lt;limit lower=&quot;0&quot; upper=&quot;2&quot; velocity=&quot;100&quot; effort=&quot;100&quot;/&gt;\n  &lt;/joint&gt;\n\n  &lt;link name=&quot;slider_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;origin xyz=&quot;0 0 0.075&quot; rpy=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n          &lt;box size=&quot;0.5 0.25 0.15&quot;/&gt;\n      &lt;/geometry&gt;\n      &lt;material name=&quot;blue&quot;/&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;origin xyz=&quot;0 0 0.075&quot; rpy=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n          &lt;box size=&quot;0.5 0.25 0.15&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;xacro:inertial_box mass=&quot;0.5&quot; x=&quot;0.5&quot; y=&quot;0.25&quot; z=&quot;0.15&quot;&gt;\n      &lt;origin xyz=&quot;0 0 0.075&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;/xacro:inertial_box&gt;\n  &lt;/link&gt;\n\n  &lt;joint name=&quot;arm_joint&quot; type=&quot;revolute&quot;&gt;\n    &lt;origin xyz=&quot;0.25 0 0.15&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;parent link=&quot;slider_link&quot;/&gt;\n    &lt;child link=&quot;arm_link&quot;/&gt;\n    &lt;axis xyz=&quot;0 -1 0&quot;/&gt;\n    &lt;limit lower=&quot;0&quot; upper=&quot;${pi/2}&quot; velocity=&quot;100&quot; effort=&quot;100&quot;/&gt;\n  &lt;/joint&gt;\n\n  &lt;xacro:property name=&quot;arm_length&quot; value=&quot;1&quot;/&gt;\n  &lt;xacro:property name=&quot;arm_radius&quot; value=&quot;0.1&quot;/&gt;\n  &lt;link name=&quot;arm_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;origin xyz=&quot;${arm_length/2} 0 0&quot; rpy=&quot;0 ${pi/2} 0&quot;/&gt;\n      &lt;geometry&gt;                \n          &lt;cylinder length=&quot;${arm_length}&quot; radius=&quot;${arm_radius}&quot;/&gt;\n      &lt;/geometry&gt;\n      &lt;material name=&quot;orange&quot;/&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;origin xyz=&quot;${arm_length/2} 0 0&quot; rpy=&quot;0 ${pi/2} 0&quot;/&gt;\n      &lt;geometry&gt;                \n          &lt;cylinder length=&quot;${arm_length}&quot; radius=&quot;${arm_radius}&quot;/&gt;\n      &lt;/geometry&gt;      \n    &lt;/collision&gt;\n    &lt;xacro:inertial_cylinder mass=&quot;1.0&quot; length=&quot;${arm_length}&quot; radius=&quot;${arm_radius}&quot;&gt;\n      &lt;origin xyz=&quot;${arm_length/2} 0 0 &quot; rpy=&quot;0 ${pi/2} 0&quot;/&gt;\n    &lt;/xacro:inertial_cylinder&gt;\n  &lt;/link&gt;\n\n  &lt;joint name=&quot;camera_joint&quot; type=&quot;fixed&quot;&gt;\n        &lt;origin xyz=&quot;${arm_length} 0 ${arm_radius + 0.075}&quot;/&gt;\n        &lt;parent link=&quot;arm_link&quot;/&gt;\n        &lt;child link=&quot;camera_link&quot;/&gt;        \n  &lt;/joint&gt;\n\n  &lt;link name=&quot;camera_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;origin xyz=&quot;-0.03 0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;box size=&quot;0.06 0.15 0.15&quot; /&gt;\n      &lt;/geometry&gt;\n      &lt;material name=&quot;white&quot;/&gt;\n    &lt;/visual&gt;\n    &lt;visual&gt;\n      &lt;origin xyz=&quot;0.03 0 0&quot; rpy=&quot;0 ${pi/2} 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=&quot;0.06&quot; radius=&quot;0.04&quot;/&gt;\n      &lt;/geometry&gt;\n      &lt;material name=&quot;blue&quot;/&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;origin xyz=&quot;0.0 0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;box size=&quot;0.12 0.15 0.15&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;xacro:inertial_box mass=&quot;0.1&quot; x=&quot;0.12&quot; y=&quot;0.15&quot; z=&quot;0.15&quot;&gt;\n      &lt;origin xyz=&quot;0 0 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;/xacro:inertial_box&gt;\n  &lt;/link&gt;\n\n&lt;/robot&gt;\n", "&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;robot xmlns:xacro=&quot;http://www.ros.org/wiki/xacro&quot;&gt;\n  \n  &lt;!-- inertial calculations from wikipedia https://en.wikipedia.org/wiki/List_of_moments_of_inertia--&gt;\n\n  &lt;xacro:macro name=&quot;inertial_sphere&quot; params=&quot;mass radius *origin&quot;&gt;\n    &lt;inertial&gt;\n      &lt;xacro:insert_block name=&quot;origin&quot;/&gt;\n      &lt;mass value=&quot;${mass}&quot;/&gt;\n      &lt;inertia ixx=&quot;${(2/5) * mass * radius*radius}&quot; ixy=&quot;0&quot; ixz=&quot;0&quot;\n               iyy=&quot;${(2/5) * mass * radius*radius}&quot; iyz=&quot;0&quot;\n               izz=&quot;${(2/5) * mass * radius*radius}&quot;\n      /&gt;\n    &lt;/inertial&gt;\n  &lt;/xacro:macro&gt;\n\n  &lt;xacro:macro name=&quot;inertial_box&quot; params=&quot;mass x y z *origin&quot;&gt;\n    &lt;inertial&gt;\n      &lt;xacro:insert_block name=&quot;origin&quot;/&gt;\n      &lt;mass value=&quot;${mass}&quot;/&gt;\n      &lt;inertia ixx=&quot;${(1/12) * mass * (y*y + z*z)}&quot; ixy=&quot;0&quot; ixz=&quot;0&quot;\n               iyy=&quot;${(1/12) * mass * (x*x + z*z)}&quot; iyz=&quot;0&quot;\n               izz=&quot;${(1/12) * mass * (x*x + y*y)}&quot;\n      /&gt;\n    &lt;/inertial&gt;\n  &lt;/xacro:macro&gt;\n\n  &lt;xacro:macro name=&quot;inertial_cylinder&quot; params=&quot;mass length radius *origin&quot;&gt;\n    &lt;inertial&gt;\n      &lt;xacro:insert_block name=&quot;origin&quot;/&gt;\n      &lt;mass value=&quot;${mass}&quot;/&gt;\n      &lt;inertia ixx=&quot;${(1/12) * mass * (3*radius*radius + length*length)}&quot; ixy=&quot;0&quot; ixz=&quot;0&quot;\n               iyy=&quot;${(1/12) * mass * (3*radius*radius + length*length)}&quot; iyz=&quot;0&quot;\n               izz=&quot;${(1/12) * mass * (3*radius*radius + length*length)}&quot;\n      /&gt;\n    &lt;/inertial&gt;\n  &lt;/xacro:macro&gt;\n\n\n  &lt;!-- colours --&gt;\n\n  &lt;material name=&quot;green&quot;&gt;\n    &lt;color rgba=&quot;0.2 1 0.2 1&quot;/&gt;\n  &lt;/material&gt;\n\n  &lt;material name=&quot;white&quot;&gt;\n    &lt;color rgba=&quot;1 1 1 1&quot;/&gt;\n  &lt;/material&gt;\n\n  &lt;material name=&quot;orange&quot;&gt;\n    &lt;color rgba=&quot;1 0.3 0.1 1&quot;/&gt;\n  &lt;/material&gt;\n\n  &lt;material name=&quot;blue&quot;&gt;\n    &lt;color rgba=&quot;0.2 0.2 1 1&quot;/&gt;\n  &lt;/material&gt;\n\n\n&lt;/robot&gt;\n"], "quote": [], "url": "https://stackoverflow.com/questions/79296182/rviz2-doesnt-detect-one-of-the-joint-link-combos-in-the-urdf-while-other-urdf-vi", "answer": ["You have to broadcast your tf transformations for all the joints defined in the urdf file. You can publish these using a ROS node:\n#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import TransformStamped\nfrom tf2_ros import TransformBroadcaster\nimport math\n\nclass TFBroadcaster(Node):\n    def __init__(self):\n        super().__init__('tf_broadcaster')\n        \n        # Create a transform broadcaster\n        self.broadcaster = TransformBroadcaster(self)\n        \n        # Create a timer to publish transforms periodically\n        self.timer = self.create_timer(0.1, self.broadcast_transforms)  # 10Hz\n        \n        # Initialize joint states (you might want to subscribe to actual joint states)\n        self.slider_position = 0.0\n        self.arm_angle = 0.0\n\n    def broadcast_transforms(self):\n        current_time = self.get_clock().now().to_msg()\n        \n        # Base link transform\n        t = TransformStamped()\n        t.header.stamp = current_time\n        t.header.frame_id = 'world'\n        t.child_frame_id = 'base_link'\n        t.transform.translation.x = 1.5\n        t.transform.translation.y = 1.0\n        t.transform.translation.z = 0.0\n        t.transform.rotation.w = 1.0\n        self.broadcaster.sendTransform(t)\n        \n        # Slider link transform\n        t = TransformStamped()\n        t.header.stamp = current_time\n        t.header.frame_id = 'base_link'\n        t.child_frame_id = 'slider_link'\n        t.transform.translation.x = -1.25 + self.slider_position  # Add slider position\n        t.transform.translation.y = 0.0\n        t.transform.translation.z = 0.1\n        t.transform.rotation.w = 1.0\n        self.broadcaster.sendTransform(t)\n        \n        # Arm link transform\n        t = TransformStamped()\n        t.header.stamp = current_time\n        t.header.frame_id = 'slider_link'\n        t.child_frame_id = 'arm_link'\n        t.transform.translation.x = 0.25\n        t.transform.translation.y = 0.0\n        t.transform.translation.z = 0.15\n        # Convert arm angle to quaternion (rotation around Y axis)\n        t.transform.rotation.w = math.cos(self.arm_angle/2)\n        t.transform.rotation.x = 0.0\n        t.transform.rotation.y = -math.sin(self.arm_angle/2)  # Negative because of axis direction\n        t.transform.rotation.z = 0.0\n        self.broadcaster.sendTransform(t)\n        \n        # Camera link transform\n        t = TransformStamped()\n        t.header.stamp = current_time\n        t.header.frame_id = 'arm_link'\n        t.child_frame_id = 'camera_link'\n        t.transform.translation.x = 2.0  # arm_length\n        t.transform.translation.y = 0.0\n        t.transform.translation.z = 0.175  # arm_radius + 0.075\n        t.transform.rotation.w = 1.0\n        self.broadcaster.sendTransform(t)\n\ndef main():\n    rclpy.init()\n    node = TFBroadcaster()\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    \n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n\nLaunch the package\nros2 run <your-package> <your-node>"], "answer_code": ["#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import TransformStamped\nfrom tf2_ros import TransformBroadcaster\nimport math\n\nclass TFBroadcaster(Node):\n    def __init__(self):\n        super().__init__('tf_broadcaster')\n        \n        # Create a transform broadcaster\n        self.broadcaster = TransformBroadcaster(self)\n        \n        # Create a timer to publish transforms periodically\n        self.timer = self.create_timer(0.1, self.broadcast_transforms)  # 10Hz\n        \n        # Initialize joint states (you might want to subscribe to actual joint states)\n        self.slider_position = 0.0\n        self.arm_angle = 0.0\n\n    def broadcast_transforms(self):\n        current_time = self.get_clock().now().to_msg()\n        \n        # Base link transform\n        t = TransformStamped()\n        t.header.stamp = current_time\n        t.header.frame_id = 'world'\n        t.child_frame_id = 'base_link'\n        t.transform.translation.x = 1.5\n        t.transform.translation.y = 1.0\n        t.transform.translation.z = 0.0\n        t.transform.rotation.w = 1.0\n        self.broadcaster.sendTransform(t)\n        \n        # Slider link transform\n        t = TransformStamped()\n        t.header.stamp = current_time\n        t.header.frame_id = 'base_link'\n        t.child_frame_id = 'slider_link'\n        t.transform.translation.x = -1.25 + self.slider_position  # Add slider position\n        t.transform.translation.y = 0.0\n        t.transform.translation.z = 0.1\n        t.transform.rotation.w = 1.0\n        self.broadcaster.sendTransform(t)\n        \n        # Arm link transform\n        t = TransformStamped()\n        t.header.stamp = current_time\n        t.header.frame_id = 'slider_link'\n        t.child_frame_id = 'arm_link'\n        t.transform.translation.x = 0.25\n        t.transform.translation.y = 0.0\n        t.transform.translation.z = 0.15\n        # Convert arm angle to quaternion (rotation around Y axis)\n        t.transform.rotation.w = math.cos(self.arm_angle/2)\n        t.transform.rotation.x = 0.0\n        t.transform.rotation.y = -math.sin(self.arm_angle/2)  # Negative because of axis direction\n        t.transform.rotation.z = 0.0\n        self.broadcaster.sendTransform(t)\n        \n        # Camera link transform\n        t = TransformStamped()\n        t.header.stamp = current_time\n        t.header.frame_id = 'arm_link'\n        t.child_frame_id = 'camera_link'\n        t.transform.translation.x = 2.0  # arm_length\n        t.transform.translation.y = 0.0\n        t.transform.translation.z = 0.175  # arm_radius + 0.075\n        t.transform.rotation.w = 1.0\n        self.broadcaster.sendTransform(t)\n\ndef main():\n    rclpy.init()\n    node = TFBroadcaster()\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    \n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n", "ros2 run &lt;your-package&gt; &lt;your-node&gt;\n"]},
{"title": "ImportError: cannot import name 'FileContent' from 'launch.substitutions' - Ros2", "time": 1758203592, "post_content": ["I'm following the tutorial from Ros2 Humble and I'm at the \"Using a URDF with robot_state_publisher (C++)\" step (https://docs.ros.org/en/humble/Tutorials/Intermediate/URDF/Using-URDF-with-Robot-State-Publisher-cpp.html), that learns how to put a robot model in Rviz.\nBut when I launch the \"ros2 launch urdf_tutorial_cpp launch.py\" I keep getting the error:\n\n1758202900.8759410 [INFO] [launch]: All log files can be found below /home/usr/.ros/log/2025-09-18-15-41-40-875088-ubuntu-118960\n1758202900.8760602 [INFO] [launch]: Default logging verbosity is set to INFO\n1758202900.8782122 [ERROR] [launch]: Caught exception in launch (see debug for traceback): Caught multiple exceptions when trying to load file of format [py]:\n\nImportError: cannot import name 'FileContent' from 'launch.substitutions' (/opt/ros/humble/lib/python3.10/site-packages/launch/substitutions/init.py)\nInvalidFrontendLaunchFileError: The launch file may have a syntax error, or its format is unknown\n\n\nAll the files are identical to the tutorial, I just copied and pasted them, so I don't know where the problem is coming from and I don't know how to fix it.\nI appreciate your help, thanks in advance!"], "question_code": [], "quote": ["1758202900.8759410 [INFO] [launch]: All log files can be found below /home/usr/.ros/log/2025-09-18-15-41-40-875088-ubuntu-118960\n1758202900.8760602 [INFO] [launch]: Default logging verbosity is set to INFO\n1758202900.8782122 [ERROR] [launch]: Caught exception in launch (see debug for traceback): Caught multiple exceptions when trying to load file of format [py]:\n\nImportError: cannot import name 'FileContent' from 'launch.substitutions' (/opt/ros/humble/lib/python3.10/site-packages/launch/substitutions/init.py)\nInvalidFrontendLaunchFileError: The launch file may have a syntax error, or its format is unknown"], "url": "https://stackoverflow.com/questions/79768540/importerror-cannot-import-name-filecontent-from-launch-substitutions-ros2", "answer": ["from launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\n\nimport os\n\ndef generate_launch_description():\n    # Use /clock if running in simulation\n    use_sim_time = LaunchConfiguration('use_sim_time', default='false')\n\n    # Get full path to the URDF file\n    urdf_file_path = os.path.join(\n        FindPackageShare('urdf_tutorial_cpp').find('urdf_tutorial_cpp'),\n        'urdf',\n        'r2d2.urdf.xml'\n    )\n\n    # Read the URDF file contents\n    with open(urdf_file_path, 'r') as infp:\n        robot_description_content = infp.read()\n\n    return LaunchDescription([\n        DeclareLaunchArgument(\n            'use_sim_time',\n            default_value='false',\n            description='Use simulation (Gazebo) clock if true'),\n        \n        Node(\n            package='robot_state_publisher',\n            executable='robot_state_publisher',\n            name='robot_state_publisher',\n            output='screen',\n            parameters=[\n                {'use_sim_time': use_sim_time,\n                 'robot_description': robot_description_content}\n            ]\n        ),\n\n        Node(\n            package='urdf_tutorial_cpp',\n            executable='urdf_tutorial_cpp',\n            name='urdf_tutorial_cpp',\n            output='screen'),\n    ])"], "answer_code": ["from launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\n\nimport os\n\ndef generate_launch_description():\n    # Use /clock if running in simulation\n    use_sim_time = LaunchConfiguration('use_sim_time', default='false')\n\n    # Get full path to the URDF file\n    urdf_file_path = os.path.join(\n        FindPackageShare('urdf_tutorial_cpp').find('urdf_tutorial_cpp'),\n        'urdf',\n        'r2d2.urdf.xml'\n    )\n\n    # Read the URDF file contents\n    with open(urdf_file_path, 'r') as infp:\n        robot_description_content = infp.read()\n\n    return LaunchDescription([\n        DeclareLaunchArgument(\n            'use_sim_time',\n            default_value='false',\n            description='Use simulation (Gazebo) clock if true'),\n        \n        Node(\n            package='robot_state_publisher',\n            executable='robot_state_publisher',\n            name='robot_state_publisher',\n            output='screen',\n            parameters=[\n                {'use_sim_time': use_sim_time,\n                 'robot_description': robot_description_content}\n            ]\n        ),\n\n        Node(\n            package='urdf_tutorial_cpp',\n            executable='urdf_tutorial_cpp',\n            name='urdf_tutorial_cpp',\n            output='screen'),\n    ])\n"]},
{"title": "why does ros launch param uses max exposure", "time": 1751624555, "post_content": ["i am trying to use ros for image acquisition on a blackfly flir camera , i have followed the install instructions, and it seems to work when i launch my nodes, but it looks like ros is using the max value for exposure time when i set the mode to \"continuous\" (auto).\nHere is an example when i set the exposure upper limit to 10000 (in micro seconds):\n\nAnd here is what it looks like when i set it to 50000 :\n\nHere are the parameters in the camera.launch i am using, modified from the git:\n<?xml version=\"1.0\"?>\n<!--\nSoftware License Agreement (BSD)\n\n\\file      camera.launch\n\\authors   Michael Hosmar <mhosmar@clearpathrobotics.com>\n\\copyright Copyright (c) 2018, Clearpath Robotics, Inc., All rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that\nthe following conditions are met:\n * Redistributions of source code must retain the above copyright notice, this list of conditions and the\n   following disclaimer.\n * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the \n   following disclaimer in the documentation and/or other materials provided with the distribution.\n * Neither the name of Clearpath Robotics nor the names of its contributors may be used to endorse or promote\n   products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WAR-\nRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, IN-\nDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT\nOF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n-->\n<launch>\n   <!-- Determine this using rosrun spinnaker_camera_driver list_cameras.\n       If not specified, defaults to first camera found. -->\n  <arg name=\"camera_name\"               default=\"camera\" />\n  <arg name=\"camera_serial\"             default=\"0\" />\n  <arg name=\"calibrated\"                default=\"0\" />\n  <arg name=\"device_type\"               default=\"USB3\" /> <!-- USB3 or GigE -->\n\n  <!-- When unspecified, the driver will use the default framerate as given by the\n      camera itself. Use the parameter 'control_frame_rate' to enable manual frame \n      rate control, and 'frame_rate' to set the frame rate value. -->\n  <arg name=\"control_frame_rate\"        default=\"True\" />\n  <arg name=\"frame_rate\"                default=\"24\" />\n\n  <!-- Exposure params -->\n  <arg name=\"auto_exposure_time_upper_limit\"                default=\"50000\" />\n\n  <!-- Disabling ISP will dramatically increase frame-rate. However, it can only be \n      disabled when using Bayer encoding (e.g. BayerRG8)-->\n  <arg name=\"isp_enable\"                default=\"False\" /> \n  <arg name=\"encoding\"                  default=\"BayerRG8\" />\n  <arg name=\"color_balance\"             default=\"Continuous\" /> <!-- Off, Once, or Continuous -->\n  <!-- Available Encodings:\n        Mono:              YUV:              YCbCr:          Other:\n        - Mono8            - YUV411Packed    - YCbCr8        - BGR8\n        - Mono16           - YUV422Packed    - YCbCr422_8    - BGRa8\n        - Mono12p          - YUV444Packed    - YCbCr411_8    - RGB8Packed\n        - Mono12Packed\n\n        Bayer:\n        - BayerGR8         - BayerGR12p\n        - BayerRG8         - BayerRG12p\n        - BayerGB8         - BayerGB12p\n        - BayerBG8         - BayerBG12p\n        - BayerGR16        - BayerGR12Packed\n        - BayerRG16        - BayerRG12Packed\n        - BayerGB16        - BayerGB12Packed\n        - BayerBG16        - BayerBG12Packed\n  -->\n\n  <group ns=\"$(arg camera_name)\">\n    <!-- Nodelet manager -->\n    <node pkg=\"nodelet\" type=\"nodelet\" name=\"camera_nodelet_manager\" args=\"manager\" cwd=\"node\" output=\"screen\"/>\n->\n    <!-- Camera nodelet -->\n    <node pkg=\"nodelet\" type=\"nodelet\" name=\"spinnaker_camera_nodelet\"\n          args=\"load spinnaker_camera_driver/SpinnakerCameraNodelet camera_nodelet_manager\" >\n\n      <param name=\"frame_id\"                        value=\"$(arg camera_name)\" />\n      <param name=\"serial\"                          value=\"$(arg camera_serial)\" />\n      <param name=\"device_type\"                     value=\"$(arg device_type)\" />\n\n      <!-- Frame rate -->\n      <param name=\"acquisition_frame_rate_enable\"   value=\"$(arg control_frame_rate)\" />\n      <param name=\"acquisition_frame_rate\"          value=\"$(arg frame_rate)\" />\n\n      <!-- Image Processing -->\n      <param name=\"isp_enable\"                      value=\"$(arg isp_enable)\" />\n      <param name=\"auto_white_balance\"              value=\"$(arg color_balance)\" />\n      <param name=\"image_format_color_coding\"       value=\"$(arg encoding)\" />\n\n      <param name=\"auto_exposure_roi_offset_x\" value=\"1080\"/>\n      <param name=\"auto_exposure_roi_offset_y\" value=\"1200\"/>\n      <param name=\"auto_exposure_roi_height\" value=\"1000\"/>\n      <param name=\"auto_exposure_roi_width\" value=\"1000\"/>\n\n\n      <param name=\"exposure_time\" value=\"0\"/>\n      <param name=\"exposure_auto\" value=\"Continuous\"/>\n      <!-- <param name=\"auto_white_balance\" value=\"Continuous\"/> -->\n      <param name=\"auto_gain\" value=\"Continuous\"/>\n\n      <!-- <param name=\"brightness\" value=\"0.1\"/> -->\n      <param name=\"auto_exposure_time_upper_limit\" type=\"int\" value=\"$(arg auto_exposure_time_upper_limit)\"/>\n      \n\n      <param name=\"gain\" value=\"1.0\"/>\n\n      \n      <param name=\"image_format_y_binning\" value=\"2\"/>\n      <param name=\"image_format_x_binning\" value=\"2\"/>\n      \n\n      \n\n      <!--<param name=\"exposure_time\" value=\"{ width: 1240, height: 1240, x_offset: 1200, y_offset: 1080 } \"/>-->\n\n      <!-- Image Resolution -->\n      <!-- Height and width pixel size cannot be set directly. Instead use the \n          binning, offset, and region of interest options. \n          - RoI: range of pixels to select from original image\n                (Note: RoI is defined from image pixel origin (i.e. top left))\n          - Binning: reduces resolution by a factor of 1, 2, 4, or 8\n          - Offset: moves the pixel origin\n                x-offset = max_width/x_binning - roi_width/2\n                y-offset = max_height/y_binning - roi_height/2\n      -->\n      <!--\n      <param name=\"image_format_x_binning\" value=\"2\" />\n      <param name=\"image_format_y_binning\" value=\"2\" />\n      <param name=\"image_format_x_offset\" value=\"128\" />\n      <param name=\"image_format_y_offset\" value=\"122\" />\n      <param name=\"image_format_roi_width\" value=\"1280\" />\n      <param name=\"image_format_roi_height\" value=\"720\" />\n      -->\n\n      <!-- Use the camera_calibration package to create this file -->\n      <!--<param name=\"camera_info_url\" if=\"$(arg calibrated)\"\n             value=\"file://$(env HOME)/.ros/camera_info/$(arg camera_serial).yaml\" />-->\n    </node>\n\n    <!-- Debayering nodelet -->\n    <node pkg=\"nodelet\" type=\"nodelet\" name=\"image_proc_debayer\"\n          args=\"load image_proc/debayer camera_nodelet_manager\">\n    </node>\n  </group>\n</launch>\n\n\nIf anyone is familiar with why and how ros chooses parameters value to give me some hints that'd be great, or if there is a way to track the parameters value at runtime, i know that i can use rosparam get but i think it just gives the intial value."], "question_code": ["&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!--\nSoftware License Agreement (BSD)\n\n\\file      camera.launch\n\\authors   Michael Hosmar &lt;mhosmar@clearpathrobotics.com&gt;\n\\copyright Copyright (c) 2018, Clearpath Robotics, Inc., All rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that\nthe following conditions are met:\n * Redistributions of source code must retain the above copyright notice, this list of conditions and the\n   following disclaimer.\n * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the \n   following disclaimer in the documentation and/or other materials provided with the distribution.\n * Neither the name of Clearpath Robotics nor the names of its contributors may be used to endorse or promote\n   products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WAR-\nRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, IN-\nDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT\nOF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n--&gt;\n&lt;launch&gt;\n   &lt;!-- Determine this using rosrun spinnaker_camera_driver list_cameras.\n       If not specified, defaults to first camera found. --&gt;\n  &lt;arg name=&quot;camera_name&quot;               default=&quot;camera&quot; /&gt;\n  &lt;arg name=&quot;camera_serial&quot;             default=&quot;0&quot; /&gt;\n  &lt;arg name=&quot;calibrated&quot;                default=&quot;0&quot; /&gt;\n  &lt;arg name=&quot;device_type&quot;               default=&quot;USB3&quot; /&gt; &lt;!-- USB3 or GigE --&gt;\n\n  &lt;!-- When unspecified, the driver will use the default framerate as given by the\n      camera itself. Use the parameter 'control_frame_rate' to enable manual frame \n      rate control, and 'frame_rate' to set the frame rate value. --&gt;\n  &lt;arg name=&quot;control_frame_rate&quot;        default=&quot;True&quot; /&gt;\n  &lt;arg name=&quot;frame_rate&quot;                default=&quot;24&quot; /&gt;\n\n  &lt;!-- Exposure params --&gt;\n  &lt;arg name=&quot;auto_exposure_time_upper_limit&quot;                default=&quot;50000&quot; /&gt;\n\n  &lt;!-- Disabling ISP will dramatically increase frame-rate. However, it can only be \n      disabled when using Bayer encoding (e.g. BayerRG8)--&gt;\n  &lt;arg name=&quot;isp_enable&quot;                default=&quot;False&quot; /&gt; \n  &lt;arg name=&quot;encoding&quot;                  default=&quot;BayerRG8&quot; /&gt;\n  &lt;arg name=&quot;color_balance&quot;             default=&quot;Continuous&quot; /&gt; &lt;!-- Off, Once, or Continuous --&gt;\n  &lt;!-- Available Encodings:\n        Mono:              YUV:              YCbCr:          Other:\n        - Mono8            - YUV411Packed    - YCbCr8        - BGR8\n        - Mono16           - YUV422Packed    - YCbCr422_8    - BGRa8\n        - Mono12p          - YUV444Packed    - YCbCr411_8    - RGB8Packed\n        - Mono12Packed\n\n        Bayer:\n        - BayerGR8         - BayerGR12p\n        - BayerRG8         - BayerRG12p\n        - BayerGB8         - BayerGB12p\n        - BayerBG8         - BayerBG12p\n        - BayerGR16        - BayerGR12Packed\n        - BayerRG16        - BayerRG12Packed\n        - BayerGB16        - BayerGB12Packed\n        - BayerBG16        - BayerBG12Packed\n  --&gt;\n\n  &lt;group ns=&quot;$(arg camera_name)&quot;&gt;\n    &lt;!-- Nodelet manager --&gt;\n    &lt;node pkg=&quot;nodelet&quot; type=&quot;nodelet&quot; name=&quot;camera_nodelet_manager&quot; args=&quot;manager&quot; cwd=&quot;node&quot; output=&quot;screen&quot;/&gt;\n-&gt;\n    &lt;!-- Camera nodelet --&gt;\n    &lt;node pkg=&quot;nodelet&quot; type=&quot;nodelet&quot; name=&quot;spinnaker_camera_nodelet&quot;\n          args=&quot;load spinnaker_camera_driver/SpinnakerCameraNodelet camera_nodelet_manager&quot; &gt;\n\n      &lt;param name=&quot;frame_id&quot;                        value=&quot;$(arg camera_name)&quot; /&gt;\n      &lt;param name=&quot;serial&quot;                          value=&quot;$(arg camera_serial)&quot; /&gt;\n      &lt;param name=&quot;device_type&quot;                     value=&quot;$(arg device_type)&quot; /&gt;\n\n      &lt;!-- Frame rate --&gt;\n      &lt;param name=&quot;acquisition_frame_rate_enable&quot;   value=&quot;$(arg control_frame_rate)&quot; /&gt;\n      &lt;param name=&quot;acquisition_frame_rate&quot;          value=&quot;$(arg frame_rate)&quot; /&gt;\n\n      &lt;!-- Image Processing --&gt;\n      &lt;param name=&quot;isp_enable&quot;                      value=&quot;$(arg isp_enable)&quot; /&gt;\n      &lt;param name=&quot;auto_white_balance&quot;              value=&quot;$(arg color_balance)&quot; /&gt;\n      &lt;param name=&quot;image_format_color_coding&quot;       value=&quot;$(arg encoding)&quot; /&gt;\n\n      &lt;param name=&quot;auto_exposure_roi_offset_x&quot; value=&quot;1080&quot;/&gt;\n      &lt;param name=&quot;auto_exposure_roi_offset_y&quot; value=&quot;1200&quot;/&gt;\n      &lt;param name=&quot;auto_exposure_roi_height&quot; value=&quot;1000&quot;/&gt;\n      &lt;param name=&quot;auto_exposure_roi_width&quot; value=&quot;1000&quot;/&gt;\n\n\n      &lt;param name=&quot;exposure_time&quot; value=&quot;0&quot;/&gt;\n      &lt;param name=&quot;exposure_auto&quot; value=&quot;Continuous&quot;/&gt;\n      &lt;!-- &lt;param name=&quot;auto_white_balance&quot; value=&quot;Continuous&quot;/&gt; --&gt;\n      &lt;param name=&quot;auto_gain&quot; value=&quot;Continuous&quot;/&gt;\n\n      &lt;!-- &lt;param name=&quot;brightness&quot; value=&quot;0.1&quot;/&gt; --&gt;\n      &lt;param name=&quot;auto_exposure_time_upper_limit&quot; type=&quot;int&quot; value=&quot;$(arg auto_exposure_time_upper_limit)&quot;/&gt;\n      \n\n      &lt;param name=&quot;gain&quot; value=&quot;1.0&quot;/&gt;\n\n      \n      &lt;param name=&quot;image_format_y_binning&quot; value=&quot;2&quot;/&gt;\n      &lt;param name=&quot;image_format_x_binning&quot; value=&quot;2&quot;/&gt;\n      \n\n      \n\n      &lt;!--&lt;param name=&quot;exposure_time&quot; value=&quot;{ width: 1240, height: 1240, x_offset: 1200, y_offset: 1080 } &quot;/&gt;--&gt;\n\n      &lt;!-- Image Resolution --&gt;\n      &lt;!-- Height and width pixel size cannot be set directly. Instead use the \n          binning, offset, and region of interest options. \n          - RoI: range of pixels to select from original image\n                (Note: RoI is defined from image pixel origin (i.e. top left))\n          - Binning: reduces resolution by a factor of 1, 2, 4, or 8\n          - Offset: moves the pixel origin\n                x-offset = max_width/x_binning - roi_width/2\n                y-offset = max_height/y_binning - roi_height/2\n      --&gt;\n      &lt;!--\n      &lt;param name=&quot;image_format_x_binning&quot; value=&quot;2&quot; /&gt;\n      &lt;param name=&quot;image_format_y_binning&quot; value=&quot;2&quot; /&gt;\n      &lt;param name=&quot;image_format_x_offset&quot; value=&quot;128&quot; /&gt;\n      &lt;param name=&quot;image_format_y_offset&quot; value=&quot;122&quot; /&gt;\n      &lt;param name=&quot;image_format_roi_width&quot; value=&quot;1280&quot; /&gt;\n      &lt;param name=&quot;image_format_roi_height&quot; value=&quot;720&quot; /&gt;\n      --&gt;\n\n      &lt;!-- Use the camera_calibration package to create this file --&gt;\n      &lt;!--&lt;param name=&quot;camera_info_url&quot; if=&quot;$(arg calibrated)&quot;\n             value=&quot;file://$(env HOME)/.ros/camera_info/$(arg camera_serial).yaml&quot; /&gt;--&gt;\n    &lt;/node&gt;\n\n    &lt;!-- Debayering nodelet --&gt;\n    &lt;node pkg=&quot;nodelet&quot; type=&quot;nodelet&quot; name=&quot;image_proc_debayer&quot;\n          args=&quot;load image_proc/debayer camera_nodelet_manager&quot;&gt;\n    &lt;/node&gt;\n  &lt;/group&gt;\n&lt;/launch&gt;\n\n", "rosparam get"], "quote": [], "url": "https://stackoverflow.com/questions/79690032/why-does-ros-launch-param-uses-max-exposure", "answer": ["In ROS, roslaunch uses the max_exposure parameter to set the maximum exposure time for a camera sensor. This controls how long the sensor collects light, helping to optimize image brightness and prevent overexposure in bright environments."], "answer_code": ["roslaunch", "max_exposure"]},
{"title": "How can I create a live video stream in a SvelteKit app using a websocket as a source", "time": 1736925879, "post_content": ["I am working on a web based robotics control panel with one of the desired features being the ability to stream video data from an onboard camera. The problem that I have found is that the data I receive from the rosbridge node for the camera are JPEG's in string form over a websocket and I'm having trouble finding a good way of converting this data into a video.\nThe current solution that I have tested to make sure that the camera is working it to update the src property of a <img /> tag with the string.\nAn example of what im trying to achive is the foxglove studio image panel however I can't find any open source code for it."], "question_code": ["&lt;img /&gt;"], "quote": [], "url": "https://stackoverflow.com/questions/79357349/how-can-i-create-a-live-video-stream-in-a-sveltekit-app-using-a-websocket-as-a-s", "answer": ["You will want to use webrtc for that. We wrote a long blog post explaining why this is the right choice for robotics. The key point is that it gives you UDP (so when network is bad, old frames can be dropped), h264 compression, congestion control (reduce image quality when network is bad), packet loss mitigation, it avoids the need for a VPN, and of course most of all: low-latency (~200ms). On the robot you will most likely want to use hardware acceleration, assuming your computer or SoC support that (they better).\nHere the post: 5 Ways to Stream Video from Robots and Why You Should Use WebRTC"], "answer_code": []},
{"title": "How do we infer the way create_publisher should be defined in ROS from the documentation?", "time": 1730206656, "post_content": ["I would like to correlate the ROS documentation with its reference examples. This is a nit-picking, but I would like to know if it's ROS specific or generic C++ implementation.\nConsider the create_publisher() function defined in ROS here\ntemplate<typename MessageT , typename Alloc , typename PublisherT >\nstd::shared_ptr< PublisherT > rclcpp::Node::create_publisher    (   const std::string &     topic_name,\nsize_t  qos_history_depth,\nstd::shared_ptr< Alloc >    allocator = nullptr \n)       \n\nCreate and return a Publisher.\nParameters\n[in]    topic_name  The topic for this publisher to publish on.\n[in]    qos_history_depth   The depth of the publisher message queue.\n[in]    allocator   Optional custom allocator.\n\nReturns\nShared pointer to the created publisher.\nNow, consider the code sample in its example for Creating a Publisher - here\nclass MinimalPublisher : public rclcpp::Node {   public:\n    MinimalPublisher()\n    : Node(\"minimal_publisher\"), count_(0)\n    {\n      publisher_ = this->create_publisher<std_msgs::msg::String>(\"topic\", 10);\n      timer_ = this->create_wall_timer(\n      500ms, std::bind(&MinimalPublisher::timer_callback, this));\n    } \n}\n\nHere, if we look at the definition of publisher_ shared pointer, it takes template parameter std_msgs::msg::String as input, and parameters- topic name and size_t as non-type parameters. Based on some of my findings, this is a template function. So, is the right way to define such functions something like-\ncreate_publisher<typename MessageT , typename Alloc , typename PublisherT > (   const std::string &     topic_name,\n    size_t  qos_history_depth,\n    std::shared_ptr< Alloc >    allocator = nullptr \n    )   \n\nAlso, that would mean Node is the template class. Then how do we access the member function without initializing the class? Does it take place in the background?\nI think I am bit confused with the whole template implementation, as it doesn't follow the syntax from the template tutorials that I have seen till now."], "question_code": ["create_publisher()", "template&lt;typename MessageT , typename Alloc , typename PublisherT &gt;\nstd::shared_ptr&lt; PublisherT &gt; rclcpp::Node::create_publisher    (   const std::string &amp;     topic_name,\nsize_t  qos_history_depth,\nstd::shared_ptr&lt; Alloc &gt;    allocator = nullptr \n)       \n", "[in]    topic_name  The topic for this publisher to publish on.\n[in]    qos_history_depth   The depth of the publisher message queue.\n[in]    allocator   Optional custom allocator.\n", "class MinimalPublisher : public rclcpp::Node {   public:\n    MinimalPublisher()\n    : Node(&quot;minimal_publisher&quot;), count_(0)\n    {\n      publisher_ = this-&gt;create_publisher&lt;std_msgs::msg::String&gt;(&quot;topic&quot;, 10);\n      timer_ = this-&gt;create_wall_timer(\n      500ms, std::bind(&amp;MinimalPublisher::timer_callback, this));\n    } \n}\n", "std_msgs::msg::String", "topic name", "size_t", "create_publisher&lt;typename MessageT , typename Alloc , typename PublisherT &gt; (   const std::string &amp;     topic_name,\n    size_t  qos_history_depth,\n    std::shared_ptr&lt; Alloc &gt;    allocator = nullptr \n    )   \n"], "quote": [], "url": "https://stackoverflow.com/questions/79137319/how-do-we-infer-the-way-create-publisher-should-be-defined-in-ros-from-the-docum", "answer": ["The doxygen autogenerated docs are missing some details. If you look at the implementation:\n  template<\n    typename MessageT,\n    typename AllocatorT = std::allocator<void>,\n    typename PublisherT = rclcpp::Publisher<MessageT, AllocatorT>>\n  std::shared_ptr<PublisherT>\n  create_publisher(\n    const std::string & topic_name,\n    const rclcpp::QoS & qos,\n    const PublisherOptionsWithAllocator<AllocatorT> & options =\n    PublisherOptionsWithAllocator<AllocatorT>()\n  );\n\nyou see that second and third template parameters have default values, so you only need to specify the MessageT, that will imply the publisher returned type. So, if you call\nauto pub = _myNode->create_publisher<String>(\"chatter\", 10);\n\nthe pub will have a type std::shared_ptr<rclcpp::Publisher<String, std::allocator<void>>>.\nclass Node itself is not a template, it just has templated create_publisher method.\nIn MinimalPublisher example authors suggest to subclass rclcpp::Node, probably for convenience - to be able to pass it directly to rclcpp::spin function, and to make sure that publishers/timers lifetime do not exceed the lifetime of provided callback. But in principle you could achieve similar behavior by working directly with std::make_shared<rclcpp::Node>(...)."], "answer_code": ["  template&lt;\n    typename MessageT,\n    typename AllocatorT = std::allocator&lt;void&gt;,\n    typename PublisherT = rclcpp::Publisher&lt;MessageT, AllocatorT&gt;&gt;\n  std::shared_ptr&lt;PublisherT&gt;\n  create_publisher(\n    const std::string &amp; topic_name,\n    const rclcpp::QoS &amp; qos,\n    const PublisherOptionsWithAllocator&lt;AllocatorT&gt; &amp; options =\n    PublisherOptionsWithAllocator&lt;AllocatorT&gt;()\n  );\n", "MessageT", "auto pub = _myNode-&gt;create_publisher&lt;String&gt;(&quot;chatter&quot;, 10);\n", "pub", "std::shared_ptr&lt;rclcpp::Publisher&lt;String, std::allocator&lt;void&gt;&gt;&gt;", "class Node", "create_publisher", "MinimalPublisher", "rclcpp::Node", "rclcpp::spin", "std::make_shared&lt;rclcpp::Node&gt;(...)"]},
{"title": "Can't publish to /cmd_vel in ROS Gazebo", "time": 1737218600, "post_content": ["I am currently working on a RRT* path planning homework and I can't able to publish speeds to /cmd_vel for turtlesim3 gazebo. I can see the nodes are connected in rqt_graph but when I echo the topic nothing pops up. I can control the robot using teleop and terminal.I can see the nodes are connected in rqt_graph but when I echo the topic nothing pops up. I can control the robot using teleop and terminal.\n#!/usr/bin/env python3\nimport matplotlib.pyplot as plt\nimport random\nimport math\nimport copy\nimport rospy\nimport time\nimport numpy as np\nfrom numpy import genfromtxt\nfrom numpy import array\nfrom sensor_msgs.msg import NavSatFix\nfrom sensor_msgs.msg import Imu\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Vector3Stamped\nfrom geometry_msgs.msg import Twist\nfrom geometry_msgs.msg import Pose2D\nfrom nav_msgs.msg import Path\nfrom geometry_msgs.msg import PoseStamped\nfrom std_msgs.msg import Float32MultiArray\n\nshow_animation = True\n\nclass RRT():\n    \"\"\"\n    Class for RRT Planning\n    \"\"\"\n    \n    def __init__(self, start, goal, obstacles,\n                 randArea, expandDis=1.0, goalSampleRate=5, maxIter = 500):\n        \"\"\"\n        Setting Parameter\n\n        start: Start Position [x, y]\n        goal: Goal Position [x, y]\n        obstacles: Obstacle Positions [[x, y, size], ...]\n        randArea: Random Sampling Area [min, max]\n        \"\"\"\n        self.start = Node(start[0], start[1])\n        self.end = Node(goal[0], goal[1])\n        self.minrand = randArea[0]\n        self.maxrand = randArea[1]\n        self.expandDis = expandDis\n        self.goalSampleRate = goalSampleRate\n        self.maxIter = maxIter\n        self.obstacles = obstacles\n\n    def Planning(self, animation=True):\n        \"\"\"\n        Path planning\n\n        animation: flag for animation on or off\n        \"\"\"\n        self.nodeList = [self.start]\n        while True:\n            # Random Sampling\n            if random.randint(0, 100) > self.goalSampleRate:\n                rnd = [random.uniform(self.minrand, self.maxrand), random.uniform(self.minrand, self.maxrand)]\n            else:\n                rnd = [self.end.x, self.end.y]\n\n            # Find nearest node\n            nind = self.GetNearestListIndex(self.nodeList, rnd)\n\n            # Expand tree\n            nearestNode = self.nodeList[nind]\n            theta = math.atan2(rnd[1] - nearestNode.y, rnd[0] - nearestNode.x)\n\n            newNode = copy.deepcopy(nearestNode)\n            newNode.x += self.expandDis * math.cos(theta)\n            newNode.y += self.expandDis * math.sin(theta)\n            newNode.parent = nind\n\n            if not self.__CollisionCheck(newNode, self.obstacles):\n                continue\n\n            self.nodeList.append(newNode)\n            print(\"Node list length:\", len(self.nodeList))\n\n            # Check goal\n            dx = newNode.x - self.end.x\n            dy = newNode.y - self.end.y\n            d = math.sqrt(dx * dx + dy * dy)\n            if d <= self.expandDis:\n                print(\"Goal reached!\")\n                break\n\n            if animation:\n                self.DrawGraph(rnd)\n\n        path = [[self.end.x, self.end.y]]\n        lastIndex = len(self.nodeList) - 1\n        while self.nodeList[lastIndex].parent is not None:\n            node = self.nodeList[lastIndex]\n            path.append([node.x, node.y])\n            lastIndex = node.parent\n        path.append([self.start.x, self.start.y])\n\n        return path\n\n    def DrawGraph(self, rnd=None):\n        \"\"\"\n        Draw Graph\n        \"\"\"\n        plt.clf()\n        if rnd is not None:\n            plt.plot(rnd[0], rnd[1], \"^k\")\n        for node in self.nodeList:\n            if node.parent is not None:\n                plt.plot([node.x, self.nodeList[node.parent].x], [\n                         node.y, self.nodeList[node.parent].y], \"-g\")\n\n        for (ox, oy, size) in self.obstacles:\n            plt.plot(ox, oy, \"ok\", ms=30 * size)\n\n        plt.plot(self.start.x, self.start.y, \"xr\")\n        plt.plot(self.end.x, self.end.y, \"xr\")\n        plt.axis([-10, 10, -10, 10])\n        plt.grid(True)\n        plt.pause(0.01)\n\n    def GetNearestListIndex(self, nodeList, rnd):\n        dlist = [(node.x - rnd[0]) ** 2 + (node.y - rnd[1]) ** 2 for node in nodeList]\n        minind = dlist.index(min(dlist))\n        return minind\n\n    def __CollisionCheck(self, node, obstacles):\n        for (ox, oy, size) in obstacles:\n            dx = ox - node.x\n            dy = oy - node.y\n            d = math.sqrt(dx * dx + dy * dy)\n            if d <= size:\n                return False  # Collision\n\n        return True  # Safe\n\n\nclass Node():\n    \"\"\"\n    RRT Node\n    \"\"\"\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        self.parent = None\n\n\n# Variable to store robot's current position\ncurrent_position = [0, 0]  # Initial position of the robot\n\ndef topic2_callback(msg):\n    \"\"\"\n    Callback function for receiving robot's position from /topic2\n    This function updates the robot's position with data from Float32MultiArray.\n    \"\"\"\n    global current_position\n\n    # Assuming msg.data contains the position as [x, y]\n    current_position = msg.data\n    print(f\"Received robot position: {current_position}\")\n\n\ndef goal_pose_callback(msg):\n    \"\"\"\n    Callback function for receiving goal pose via /goal_pose topic.\n    \"\"\"\n    print(f\"Received new goal position: ({msg.x}, {msg.y})\")\n    start_position = current_position[:2]  # Start position from current robot position\n    rand_area = [-15, 15]  # Define the random sampling area for the planner\n    \n    # Load obstacles from file\n    f = open(\"/home/ercan/catkin_ws/src/localization_ekf/obstacles.txt\", \"r\")\n    obstacles = []\n    for i in range(8):    \n        x = int(f.readline())\n        y = int(f.readline())\n        cap = int(f.readline())\n        obstacles.append((int(x), int(y), int(cap)))\n    f.close()\n\n    # Plan the path using RRT\n    rrt = RRT(start=start_position, goal=[msg.x, msg.y], randArea=rand_area, obstacles=obstacles)\n    path = rrt.Planning(animation=show_animation)\n\n    # Draw the final path\n    if show_animation:\n        rrt.DrawGraph()\n        plt.plot([x for (x, y) in path], [y for (x, y) in path], '-r')\n        plt.grid(True)\n        plt.show()\n\n    # Return the path\n    follow_path(path, pub, rate)\n\n\ndef follow_path(path, pub, rate):\n    \"\"\"\n    Function to follow the generated path using a simple control approach\n    \"\"\"\n    # Robot speed and control parameters\n    linear_speed = 0.5\n    angular_speed = 1.0\n\n    for i in range(1, len(path)):\n        x1, y1 = path[i - 1]\n        x2, y2 = path[i]\n\n        # Calculate the distance and angle to the next waypoint\n        distance = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n        angle = math.atan2(y2 - y1, x2 - x1)\n\n        # Initialize the Twist message\n        twist = Twist()\n\n        while distance > 0.1:  # Continue moving until the robot reaches the waypoint\n            # Calculate the angle difference\n            angle_to_goal = math.atan2(y2 - current_position[1], x2 - current_position[0])\n            angle_diff = angle_to_goal - current_position[2]\n\n            # Normalize the angle difference to the range [-pi, pi]\n            angle_diff = (angle_diff + math.pi) % (2 * math.pi) - math.pi\n\n            # Adjust velocities based on distance and angle difference\n            if abs(angle_diff) > 0.1:\n                twist.linear.x = 0.0  # Stop moving forward if we need to rotate\n                twist.angular.z = angular_speed * angle_diff  # Rotate towards the goal\n            else:\n                twist.linear.x = linear_speed  # Move forward\n                twist.angular.z = 0.0  # Stop rotating\n\n            pub.publish(twist)\n            rate.sleep()\n\n            # Update current position (for simulation purposes, assuming we update it here)\n            current_position[0] += twist.linear.x * 0.1  # Update x based on linear speed\n            current_position[1] += twist.linear.x * 0.1  # Update y based on linear speed\n            distance = math.sqrt((x2 - current_position[0]) ** 2 + (y2 - current_position[1]) ** 2)\n\n    twist.linear.x = 0\n    twist.angular.z = 0\n    pub.publish(twist)  # Stop the robot when finished\n\n\ndef main():\n    # Initialize the ROS node\n    rospy.init_node('motion_planning_node')\n\n    # Create a publisher to send /cmd_vel messages\n    pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)\n    rate = rospy.Rate(10) # 10hz\n    # Print waiting message before goal input\n    print(\"Waiting for goal position input...\")\n\n    # Subscribe to the /goal_pose topic to get the goal position\n    rospy.Subscriber('/goal_pose', Pose2D, goal_pose_callback)\n\n    # Subscribe to the /topic2 topic to get the robot's current position\n    rospy.Subscriber('/topic2', Float32MultiArray, topic2_callback)\n\n    rospy.spin()\n\n\nif __name__ == '__main__':\n    main()\n\n\nI think the problem is caused by placement or order of the codes but I won't able to find a solution.\nThanks"], "question_code": ["#!/usr/bin/env python3\nimport matplotlib.pyplot as plt\nimport random\nimport math\nimport copy\nimport rospy\nimport time\nimport numpy as np\nfrom numpy import genfromtxt\nfrom numpy import array\nfrom sensor_msgs.msg import NavSatFix\nfrom sensor_msgs.msg import Imu\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Vector3Stamped\nfrom geometry_msgs.msg import Twist\nfrom geometry_msgs.msg import Pose2D\nfrom nav_msgs.msg import Path\nfrom geometry_msgs.msg import PoseStamped\nfrom std_msgs.msg import Float32MultiArray\n\nshow_animation = True\n\nclass RRT():\n    &quot;&quot;&quot;\n    Class for RRT Planning\n    &quot;&quot;&quot;\n    \n    def __init__(self, start, goal, obstacles,\n                 randArea, expandDis=1.0, goalSampleRate=5, maxIter = 500):\n        &quot;&quot;&quot;\n        Setting Parameter\n\n        start: Start Position [x, y]\n        goal: Goal Position [x, y]\n        obstacles: Obstacle Positions [[x, y, size], ...]\n        randArea: Random Sampling Area [min, max]\n        &quot;&quot;&quot;\n        self.start = Node(start[0], start[1])\n        self.end = Node(goal[0], goal[1])\n        self.minrand = randArea[0]\n        self.maxrand = randArea[1]\n        self.expandDis = expandDis\n        self.goalSampleRate = goalSampleRate\n        self.maxIter = maxIter\n        self.obstacles = obstacles\n\n    def Planning(self, animation=True):\n        &quot;&quot;&quot;\n        Path planning\n\n        animation: flag for animation on or off\n        &quot;&quot;&quot;\n        self.nodeList = [self.start]\n        while True:\n            # Random Sampling\n            if random.randint(0, 100) &gt; self.goalSampleRate:\n                rnd = [random.uniform(self.minrand, self.maxrand), random.uniform(self.minrand, self.maxrand)]\n            else:\n                rnd = [self.end.x, self.end.y]\n\n            # Find nearest node\n            nind = self.GetNearestListIndex(self.nodeList, rnd)\n\n            # Expand tree\n            nearestNode = self.nodeList[nind]\n            theta = math.atan2(rnd[1] - nearestNode.y, rnd[0] - nearestNode.x)\n\n            newNode = copy.deepcopy(nearestNode)\n            newNode.x += self.expandDis * math.cos(theta)\n            newNode.y += self.expandDis * math.sin(theta)\n            newNode.parent = nind\n\n            if not self.__CollisionCheck(newNode, self.obstacles):\n                continue\n\n            self.nodeList.append(newNode)\n            print(&quot;Node list length:&quot;, len(self.nodeList))\n\n            # Check goal\n            dx = newNode.x - self.end.x\n            dy = newNode.y - self.end.y\n            d = math.sqrt(dx * dx + dy * dy)\n            if d &lt;= self.expandDis:\n                print(&quot;Goal reached!&quot;)\n                break\n\n            if animation:\n                self.DrawGraph(rnd)\n\n        path = [[self.end.x, self.end.y]]\n        lastIndex = len(self.nodeList) - 1\n        while self.nodeList[lastIndex].parent is not None:\n            node = self.nodeList[lastIndex]\n            path.append([node.x, node.y])\n            lastIndex = node.parent\n        path.append([self.start.x, self.start.y])\n\n        return path\n\n    def DrawGraph(self, rnd=None):\n        &quot;&quot;&quot;\n        Draw Graph\n        &quot;&quot;&quot;\n        plt.clf()\n        if rnd is not None:\n            plt.plot(rnd[0], rnd[1], &quot;^k&quot;)\n        for node in self.nodeList:\n            if node.parent is not None:\n                plt.plot([node.x, self.nodeList[node.parent].x], [\n                         node.y, self.nodeList[node.parent].y], &quot;-g&quot;)\n\n        for (ox, oy, size) in self.obstacles:\n            plt.plot(ox, oy, &quot;ok&quot;, ms=30 * size)\n\n        plt.plot(self.start.x, self.start.y, &quot;xr&quot;)\n        plt.plot(self.end.x, self.end.y, &quot;xr&quot;)\n        plt.axis([-10, 10, -10, 10])\n        plt.grid(True)\n        plt.pause(0.01)\n\n    def GetNearestListIndex(self, nodeList, rnd):\n        dlist = [(node.x - rnd[0]) ** 2 + (node.y - rnd[1]) ** 2 for node in nodeList]\n        minind = dlist.index(min(dlist))\n        return minind\n\n    def __CollisionCheck(self, node, obstacles):\n        for (ox, oy, size) in obstacles:\n            dx = ox - node.x\n            dy = oy - node.y\n            d = math.sqrt(dx * dx + dy * dy)\n            if d &lt;= size:\n                return False  # Collision\n\n        return True  # Safe\n\n\nclass Node():\n    &quot;&quot;&quot;\n    RRT Node\n    &quot;&quot;&quot;\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        self.parent = None\n\n\n# Variable to store robot's current position\ncurrent_position = [0, 0]  # Initial position of the robot\n\ndef topic2_callback(msg):\n    &quot;&quot;&quot;\n    Callback function for receiving robot's position from /topic2\n    This function updates the robot's position with data from Float32MultiArray.\n    &quot;&quot;&quot;\n    global current_position\n\n    # Assuming msg.data contains the position as [x, y]\n    current_position = msg.data\n    print(f&quot;Received robot position: {current_position}&quot;)\n\n\ndef goal_pose_callback(msg):\n    &quot;&quot;&quot;\n    Callback function for receiving goal pose via /goal_pose topic.\n    &quot;&quot;&quot;\n    print(f&quot;Received new goal position: ({msg.x}, {msg.y})&quot;)\n    start_position = current_position[:2]  # Start position from current robot position\n    rand_area = [-15, 15]  # Define the random sampling area for the planner\n    \n    # Load obstacles from file\n    f = open(&quot;/home/ercan/catkin_ws/src/localization_ekf/obstacles.txt&quot;, &quot;r&quot;)\n    obstacles = []\n    for i in range(8):    \n        x = int(f.readline())\n        y = int(f.readline())\n        cap = int(f.readline())\n        obstacles.append((int(x), int(y), int(cap)))\n    f.close()\n\n    # Plan the path using RRT\n    rrt = RRT(start=start_position, goal=[msg.x, msg.y], randArea=rand_area, obstacles=obstacles)\n    path = rrt.Planning(animation=show_animation)\n\n    # Draw the final path\n    if show_animation:\n        rrt.DrawGraph()\n        plt.plot([x for (x, y) in path], [y for (x, y) in path], '-r')\n        plt.grid(True)\n        plt.show()\n\n    # Return the path\n    follow_path(path, pub, rate)\n\n\ndef follow_path(path, pub, rate):\n    &quot;&quot;&quot;\n    Function to follow the generated path using a simple control approach\n    &quot;&quot;&quot;\n    # Robot speed and control parameters\n    linear_speed = 0.5\n    angular_speed = 1.0\n\n    for i in range(1, len(path)):\n        x1, y1 = path[i - 1]\n        x2, y2 = path[i]\n\n        # Calculate the distance and angle to the next waypoint\n        distance = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n        angle = math.atan2(y2 - y1, x2 - x1)\n\n        # Initialize the Twist message\n        twist = Twist()\n\n        while distance &gt; 0.1:  # Continue moving until the robot reaches the waypoint\n            # Calculate the angle difference\n            angle_to_goal = math.atan2(y2 - current_position[1], x2 - current_position[0])\n            angle_diff = angle_to_goal - current_position[2]\n\n            # Normalize the angle difference to the range [-pi, pi]\n            angle_diff = (angle_diff + math.pi) % (2 * math.pi) - math.pi\n\n            # Adjust velocities based on distance and angle difference\n            if abs(angle_diff) &gt; 0.1:\n                twist.linear.x = 0.0  # Stop moving forward if we need to rotate\n                twist.angular.z = angular_speed * angle_diff  # Rotate towards the goal\n            else:\n                twist.linear.x = linear_speed  # Move forward\n                twist.angular.z = 0.0  # Stop rotating\n\n            pub.publish(twist)\n            rate.sleep()\n\n            # Update current position (for simulation purposes, assuming we update it here)\n            current_position[0] += twist.linear.x * 0.1  # Update x based on linear speed\n            current_position[1] += twist.linear.x * 0.1  # Update y based on linear speed\n            distance = math.sqrt((x2 - current_position[0]) ** 2 + (y2 - current_position[1]) ** 2)\n\n    twist.linear.x = 0\n    twist.angular.z = 0\n    pub.publish(twist)  # Stop the robot when finished\n\n\ndef main():\n    # Initialize the ROS node\n    rospy.init_node('motion_planning_node')\n\n    # Create a publisher to send /cmd_vel messages\n    pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)\n    rate = rospy.Rate(10) # 10hz\n    # Print waiting message before goal input\n    print(&quot;Waiting for goal position input...&quot;)\n\n    # Subscribe to the /goal_pose topic to get the goal position\n    rospy.Subscriber('/goal_pose', Pose2D, goal_pose_callback)\n\n    # Subscribe to the /topic2 topic to get the robot's current position\n    rospy.Subscriber('/topic2', Float32MultiArray, topic2_callback)\n\n    rospy.spin()\n\n\nif __name__ == '__main__':\n    main()\n\n"], "quote": [], "url": "https://stackoverflow.com/questions/79367558/cant-publish-to-cmd-vel-in-ros-gazebo", "answer": ["This method of using variables does not work, and in fact will cause errors. If you're doing it this way your pub should be a global variable at the top of your file. Then it should not be passed as a function arg and just used directly in your following function:\n#!/usr/bin/env python3\nimport matplotlib.pyplot as plt\nimport random\nimport math\nimport copy\nimport rospy\nimport time\nimport numpy as np\nfrom numpy import genfromtxt\nfrom numpy import array\nfrom sensor_msgs.msg import NavSatFix\nfrom sensor_msgs.msg import Imu\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Vector3Stamped\nfrom geometry_msgs.msg import Twist\nfrom geometry_msgs.msg import Pose2D\nfrom nav_msgs.msg import Path\nfrom geometry_msgs.msg import PoseStamped\nfrom std_msgs.msg import Float32MultiArray\n\nshow_animation = True\npub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)\n\nclass RRT():\n    ....\n\nThe other issue is that this will cause a runtime error. So if the above node does not die it means you have another issue. Being either your /goal_pose topic is not being published to or the messages being published to it are the same as your current position."], "answer_code": ["pub", "#!/usr/bin/env python3\nimport matplotlib.pyplot as plt\nimport random\nimport math\nimport copy\nimport rospy\nimport time\nimport numpy as np\nfrom numpy import genfromtxt\nfrom numpy import array\nfrom sensor_msgs.msg import NavSatFix\nfrom sensor_msgs.msg import Imu\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Vector3Stamped\nfrom geometry_msgs.msg import Twist\nfrom geometry_msgs.msg import Pose2D\nfrom nav_msgs.msg import Path\nfrom geometry_msgs.msg import PoseStamped\nfrom std_msgs.msg import Float32MultiArray\n\nshow_animation = True\npub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)\n\nclass RRT():\n    ....\n", "/goal_pose"]},
{"title": "In the TurtleBot3 Gazebo simulation, the angular velocity exhibits significant fluctuations at certain points, leading to instability", "time": 1728559810, "post_content": ["I am using Ubuntu 20.04 and Gazebo 11.14 to simulate the TurtleBot 3 Waffle Pi robot. I run the code below, and record the command data and odmetry data form topic \"/odom\".\n#include \"ros/ros.h\"\n#include <Eigen/Core>\n#include <Eigen/Dense>\n#include <iostream>\n#include \"nav_msgs/Path.h\"\n#include \"nav_msgs/Odometry.h\"\n#include <tf2_ros/buffer.h>\n#include <tf2/LinearMath/Matrix3x3.h>\n#include \"tf2_ros/transform_listener.h\"\n#include \"tf2_geometry_msgs/tf2_geometry_msgs.h\"\n#include \"narrow_space_navigation/point_style.h\"\n#include \"narrow_space_navigation/utils.h\"\n#include <random>\n\nController::car_state cur_pose;\n\nvoid odom_callback(const nav_msgs::Odometry::ConstPtr &msg)\n{\n    try\n    {\n        geometry_msgs::Quaternion odom_quat = msg->pose.pose.orientation;\n        tf2::Quaternion quat;\n        tf2::fromMsg(odom_quat, quat);\n\n        double roll, pitch, yaw;\n        tf2::Matrix3x3(quat).getRPY(roll, pitch, yaw);\n\n        cur_pose.x = msg->pose.pose.position.x;\n        cur_pose.y = msg->pose.pose.position.y;\n        cur_pose.yaw = yaw;\n        cur_pose.v = msg->twist.twist.linear.x;\n        cur_pose.w = msg->twist.twist.angular.z;\n\n    }\n    catch(const std::exception& e)\n    {\n        ROS_INFO(\"Some errors in the odom_callback.\");\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    ros::init(argc,argv,\"ramdom_test\");\n    FILE* new_log;\n    new_log = fopen(\"new_test.txt\", \"w\");\n    ROS_INFO(\"ros init\");\n    ros::NodeHandle nh;\n    ros::Publisher twist_pub = nh.advertise<geometry_msgs::Twist>(\"/cmd_vel\", 10);\n    ros::Subscriber odom_sub = nh.subscribe(\"/odom\", 10, odom_callback);\n\n    int multiplier = atoi(argv[1]);\n    geometry_msgs::Twist control_output;\n    double dt = 0.02;\n    double a = 0.0;\n    ros::Rate r(50);\n    while (ros::ok())\n    {\n        a = a + dt;\n        control_output.linear.x = 0.25 * (1 - cos(a)) * multiplier;\n        double w_acc = 0.25 * sin(a) * multiplier;\n        control_output.angular.z = control_output.angular.z + w_acc * dt;\n        r.sleep();\n        ros::spinOnce();\n        twist_pub.publish(control_output);\n        fprintf(new_log, \"%.6f \"\n                             \"%.6f %.6f %.6f %.6f %.6f %.6f %.6f\\n\",\n                cur_pose.x, cur_pose.y, cur_pose.yaw, control_output.linear.x, control_output.angular.z,\n                cur_pose.v, cur_pose.w, w_acc);\n        fflush(new_log);\n    }\n    return 0;\n}\n\nWith the default gazebo urdf of the waffle pi robot, and multiplier = 4 ( which means the linear control speed cmd_v = 0.25 * multiplier  * (1 - cos(a)), angular speed cmd_w = cmd_w  + 0.25 * multiplier * sin(a), a += dt, please see the code above).\nWe have: (w_is is the angular speed from \"/odom\" and the w_cmd is the command, please neglect the w_should)\n\nIt is clear this urdf settings can not handle that much angular speed and angular acceleration. So I change the urdf into this:\n<?xml version=\"1.0\"?>\n<robot name=\"turtlebot3_waffle_pi_sim\" xmlns:xacro=\"http://ros.org/wiki/xacro\">\n  <xacro:arg name=\"laser_visual\"  default=\"false\"/>\n  <xacro:arg name=\"camera_visual\" default=\"false\"/>\n  <xacro:arg name=\"imu_visual\"    default=\"false\"/>\n\n  <gazebo reference=\"base_link\">\n    <material>Gazebo/DarkGrey</material>\n  </gazebo>\n\n  <gazebo reference=\"wheel_left_link\">\n    <mu1>1.0</mu1>\n    <mu2>1.0</mu2>\n    <soft_cfm>0.0</soft_cfm>\n    <soft_erp>0.2</soft_erp>\n    <kp>1e15</kp>\n    <kd>4e12</kd>\n    <minDepth>0.001</minDepth>\n    <maxVel>10</maxVel>\n    <fdir1>1 0 0</fdir1>\n    <material>Gazebo/FlatBlack</material>\n  </gazebo>\n\n  <gazebo reference=\"wheel_right_link\">\n    <mu1>1.0</mu1>\n    <mu2>1.0</mu2>\n    <soft_cfm>0.0</soft_cfm>\n    <soft_erp>0.2</soft_erp>\n    <kp>1e15</kp>\n    <kd>4e12</kd>\n    <minDepth>0.001</minDepth>\n    <maxVel>10</maxVel>\n    <fdir1>1 0 0</fdir1>\n    <material>Gazebo/FlatBlack</material>\n  </gazebo>\n\n  <gazebo reference=\"caster_back_right_link\">\n    <mu1>0.01</mu1>\n    <mu2>0.01</mu2>\n    <soft_cfm>0.0</soft_cfm>\n    <soft_erp>0.2</soft_erp>\n    <kp>1e15</kp>\n    <kd>4e12</kd>\n    <minDepth>0.001</minDepth>\n    <maxVel>10</maxVel>\n    <material>Gazebo/FlatBlack</material>\n  </gazebo>\n\n  <gazebo reference=\"caster_back_left_link\">\n    <mu1>0.01</mu1>\n    <mu2>0.01</mu2>\n    <soft_cfm>0.0</soft_cfm>\n    <soft_erp>0.2</soft_erp>\n    <kp>1e15</kp>\n    <kd>4e12</kd>\n    <minDepth>0.001</minDepth>\n    <maxVel>10</maxVel>\n    <material>Gazebo/FlatBlack</material>\n  </gazebo>\n\n  <gazebo reference=\"imu_link\">\n    <sensor type=\"imu\" name=\"imu\">\n      <always_on>true</always_on>\n      <visualize>$(arg imu_visual)</visualize>\n    </sensor>\n    <material>Gazebo/Grey</material>\n  </gazebo>\n\n  <gazebo>\n    <plugin name=\"turtlebot3_waffle_pi_controller\" filename=\"libgazebo_ros_diff_drive.so\">\n      <commandTopic>cmd_vel</commandTopic>\n      <odometryTopic>odom</odometryTopic>\n      <odometryFrame>odom</odometryFrame>\n      <odometrySource>world</odometrySource>\n      <publishOdomTF>true</publishOdomTF>\n      <robotBaseFrame>base_footprint</robotBaseFrame>\n      <publishWheelTF>false</publishWheelTF>\n      <publishTf>true</publishTf>\n      <publishWheelJointState>true</publishWheelJointState>\n      <legacyMode>false</legacyMode>\n      <updateRate>100</updateRate>\n      <leftJoint>wheel_left_joint</leftJoint>\n      <rightJoint>wheel_right_joint</rightJoint>\n      <wheelSeparation>0.287</wheelSeparation>\n      <wheelDiameter>0.066</wheelDiameter>\n      <wheelAcceleration>4</wheelAcceleration>\n      <wheelTorque>10</wheelTorque>\n      <rosDebugLevel>na</rosDebugLevel>\n    </plugin>\n  </gazebo>\n\n  <gazebo>\n    <plugin name=\"imu_plugin\" filename=\"libgazebo_ros_imu.so\">\n      <alwaysOn>true</alwaysOn>\n      <bodyName>imu_link</bodyName>\n      <frameName>imu_link</frameName>\n      <topicName>imu</topicName>\n      <serviceName>imu_service</serviceName>\n      <gaussianNoise>0.0</gaussianNoise>\n      <updateRate>0</updateRate>\n      <imu>\n        <noise>\n          <type>gaussian</type>\n          <rate>\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </rate>\n          <accel>\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </accel>\n        </noise>\n      </imu>\n    </plugin>\n  </gazebo>\n\n  <gazebo reference=\"base_scan\">\n    <material>Gazebo/FlatBlack</material>\n    <sensor type=\"ray\" name=\"lds_lfcd_sensor\">\n      <pose>0 0 0 0 0 0</pose>\n      <visualize>$(arg laser_visual)</visualize>\n      <update_rate>5</update_rate>\n      <ray>\n        <scan>\n          <horizontal>\n            <samples>360</samples>\n            <resolution>1</resolution>\n            <min_angle>0.0</min_angle>\n            <max_angle>6.28319</max_angle>\n          </horizontal>\n        </scan>\n        <range>\n          <min>0.120</min>\n          <max>3.5</max>\n          <resolution>0.015</resolution>\n        </range>\n        <noise>\n          <type>gaussian</type>\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n        </noise>\n      </ray>\n      <plugin name=\"gazebo_ros_lds_lfcd_controller\" filename=\"libgazebo_ros_laser.so\">\n        <topicName>scan</topicName>\n        <frameName>base_scan</frameName>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n<!--link : https://www.raspberrypi.org/documentation/hardware/camera/-->\n  <gazebo reference=\"camera_rgb_frame\">\n    <sensor type=\"camera\" name=\"Pi Camera\">\n      <always_on>true</always_on>\n      <visualize>$(arg camera_visual)</visualize>\n      <camera>\n          <horizontal_fov>1.085595</horizontal_fov>\n          <image>\n              <width>640</width>\n              <height>480</height>\n              <format>R8G8B8</format>\n          </image>\n          <clip>\n              <near>0.03</near>\n              <far>100</far>\n          </clip>\n      </camera>\n      <plugin name=\"camera_controller\" filename=\"libgazebo_ros_camera.so\">\n        <alwaysOn>true</alwaysOn>\n        <updateRate>30.0</updateRate>\n        <cameraName>camera</cameraName>\n        <frameName>camera_rgb_optical_frame</frameName>\n        <imageTopicName>rgb/image_raw</imageTopicName>\n        <cameraInfoTopicName>rgb/camera_info</cameraInfoTopicName>\n        <hackBaseline>0.07</hackBaseline>\n        <distortionK1>0.0</distortionK1>\n        <distortionK2>0.0</distortionK2>\n        <distortionK3>0.0</distortionK3>\n        <distortionT1>0.0</distortionT1>\n        <distortionT2>0.0</distortionT2>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n</robot>\n\nNow the control graph is:\n\nIt looks good but there is a significant fluctuation at the begining, and if I run another code, which is a model predict controller to follow a path. The graph is:\n\nwe still get some significant fluctuations, in this picture, at the end of the control, which will make the final precision not that good.\nI wonder where this fluctuation comes from?\nI observe that the robot does perform this fluctuating angular velocity, so maybe it's not just the odom, right? And these fluctuations seem to be in the direction to the X-axis, are they interspersed with some unknown 0 angular velocity control signals outside my control?\nIs this potentially related to my control algorithm? (The command is smooth enough, so I doubt it's the cause.)\nCould it be due to the modifications made in the Gazebo URDF file or specific settings in Gazebo?\nI'm uncertain, so I would appreciate any insights you might have if you're familiar with the Gazebo simulation platform. Thank you for your help!"], "question_code": ["#include &quot;ros/ros.h&quot;\n#include &lt;Eigen/Core&gt;\n#include &lt;Eigen/Dense&gt;\n#include &lt;iostream&gt;\n#include &quot;nav_msgs/Path.h&quot;\n#include &quot;nav_msgs/Odometry.h&quot;\n#include &lt;tf2_ros/buffer.h&gt;\n#include &lt;tf2/LinearMath/Matrix3x3.h&gt;\n#include &quot;tf2_ros/transform_listener.h&quot;\n#include &quot;tf2_geometry_msgs/tf2_geometry_msgs.h&quot;\n#include &quot;narrow_space_navigation/point_style.h&quot;\n#include &quot;narrow_space_navigation/utils.h&quot;\n#include &lt;random&gt;\n\nController::car_state cur_pose;\n\nvoid odom_callback(const nav_msgs::Odometry::ConstPtr &amp;msg)\n{\n    try\n    {\n        geometry_msgs::Quaternion odom_quat = msg-&gt;pose.pose.orientation;\n        tf2::Quaternion quat;\n        tf2::fromMsg(odom_quat, quat);\n\n        double roll, pitch, yaw;\n        tf2::Matrix3x3(quat).getRPY(roll, pitch, yaw);\n\n        cur_pose.x = msg-&gt;pose.pose.position.x;\n        cur_pose.y = msg-&gt;pose.pose.position.y;\n        cur_pose.yaw = yaw;\n        cur_pose.v = msg-&gt;twist.twist.linear.x;\n        cur_pose.w = msg-&gt;twist.twist.angular.z;\n\n    }\n    catch(const std::exception&amp; e)\n    {\n        ROS_INFO(&quot;Some errors in the odom_callback.&quot;);\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    ros::init(argc,argv,&quot;ramdom_test&quot;);\n    FILE* new_log;\n    new_log = fopen(&quot;new_test.txt&quot;, &quot;w&quot;);\n    ROS_INFO(&quot;ros init&quot;);\n    ros::NodeHandle nh;\n    ros::Publisher twist_pub = nh.advertise&lt;geometry_msgs::Twist&gt;(&quot;/cmd_vel&quot;, 10);\n    ros::Subscriber odom_sub = nh.subscribe(&quot;/odom&quot;, 10, odom_callback);\n\n    int multiplier = atoi(argv[1]);\n    geometry_msgs::Twist control_output;\n    double dt = 0.02;\n    double a = 0.0;\n    ros::Rate r(50);\n    while (ros::ok())\n    {\n        a = a + dt;\n        control_output.linear.x = 0.25 * (1 - cos(a)) * multiplier;\n        double w_acc = 0.25 * sin(a) * multiplier;\n        control_output.angular.z = control_output.angular.z + w_acc * dt;\n        r.sleep();\n        ros::spinOnce();\n        twist_pub.publish(control_output);\n        fprintf(new_log, &quot;%.6f &quot;\n                             &quot;%.6f %.6f %.6f %.6f %.6f %.6f %.6f\\n&quot;,\n                cur_pose.x, cur_pose.y, cur_pose.yaw, control_output.linear.x, control_output.angular.z,\n                cur_pose.v, cur_pose.w, w_acc);\n        fflush(new_log);\n    }\n    return 0;\n}\n", "&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;robot name=&quot;turtlebot3_waffle_pi_sim&quot; xmlns:xacro=&quot;http://ros.org/wiki/xacro&quot;&gt;\n  &lt;xacro:arg name=&quot;laser_visual&quot;  default=&quot;false&quot;/&gt;\n  &lt;xacro:arg name=&quot;camera_visual&quot; default=&quot;false&quot;/&gt;\n  &lt;xacro:arg name=&quot;imu_visual&quot;    default=&quot;false&quot;/&gt;\n\n  &lt;gazebo reference=&quot;base_link&quot;&gt;\n    &lt;material&gt;Gazebo/DarkGrey&lt;/material&gt;\n  &lt;/gazebo&gt;\n\n  &lt;gazebo reference=&quot;wheel_left_link&quot;&gt;\n    &lt;mu1&gt;1.0&lt;/mu1&gt;\n    &lt;mu2&gt;1.0&lt;/mu2&gt;\n    &lt;soft_cfm&gt;0.0&lt;/soft_cfm&gt;\n    &lt;soft_erp&gt;0.2&lt;/soft_erp&gt;\n    &lt;kp&gt;1e15&lt;/kp&gt;\n    &lt;kd&gt;4e12&lt;/kd&gt;\n    &lt;minDepth&gt;0.001&lt;/minDepth&gt;\n    &lt;maxVel&gt;10&lt;/maxVel&gt;\n    &lt;fdir1&gt;1 0 0&lt;/fdir1&gt;\n    &lt;material&gt;Gazebo/FlatBlack&lt;/material&gt;\n  &lt;/gazebo&gt;\n\n  &lt;gazebo reference=&quot;wheel_right_link&quot;&gt;\n    &lt;mu1&gt;1.0&lt;/mu1&gt;\n    &lt;mu2&gt;1.0&lt;/mu2&gt;\n    &lt;soft_cfm&gt;0.0&lt;/soft_cfm&gt;\n    &lt;soft_erp&gt;0.2&lt;/soft_erp&gt;\n    &lt;kp&gt;1e15&lt;/kp&gt;\n    &lt;kd&gt;4e12&lt;/kd&gt;\n    &lt;minDepth&gt;0.001&lt;/minDepth&gt;\n    &lt;maxVel&gt;10&lt;/maxVel&gt;\n    &lt;fdir1&gt;1 0 0&lt;/fdir1&gt;\n    &lt;material&gt;Gazebo/FlatBlack&lt;/material&gt;\n  &lt;/gazebo&gt;\n\n  &lt;gazebo reference=&quot;caster_back_right_link&quot;&gt;\n    &lt;mu1&gt;0.01&lt;/mu1&gt;\n    &lt;mu2&gt;0.01&lt;/mu2&gt;\n    &lt;soft_cfm&gt;0.0&lt;/soft_cfm&gt;\n    &lt;soft_erp&gt;0.2&lt;/soft_erp&gt;\n    &lt;kp&gt;1e15&lt;/kp&gt;\n    &lt;kd&gt;4e12&lt;/kd&gt;\n    &lt;minDepth&gt;0.001&lt;/minDepth&gt;\n    &lt;maxVel&gt;10&lt;/maxVel&gt;\n    &lt;material&gt;Gazebo/FlatBlack&lt;/material&gt;\n  &lt;/gazebo&gt;\n\n  &lt;gazebo reference=&quot;caster_back_left_link&quot;&gt;\n    &lt;mu1&gt;0.01&lt;/mu1&gt;\n    &lt;mu2&gt;0.01&lt;/mu2&gt;\n    &lt;soft_cfm&gt;0.0&lt;/soft_cfm&gt;\n    &lt;soft_erp&gt;0.2&lt;/soft_erp&gt;\n    &lt;kp&gt;1e15&lt;/kp&gt;\n    &lt;kd&gt;4e12&lt;/kd&gt;\n    &lt;minDepth&gt;0.001&lt;/minDepth&gt;\n    &lt;maxVel&gt;10&lt;/maxVel&gt;\n    &lt;material&gt;Gazebo/FlatBlack&lt;/material&gt;\n  &lt;/gazebo&gt;\n\n  &lt;gazebo reference=&quot;imu_link&quot;&gt;\n    &lt;sensor type=&quot;imu&quot; name=&quot;imu&quot;&gt;\n      &lt;always_on&gt;true&lt;/always_on&gt;\n      &lt;visualize&gt;$(arg imu_visual)&lt;/visualize&gt;\n    &lt;/sensor&gt;\n    &lt;material&gt;Gazebo/Grey&lt;/material&gt;\n  &lt;/gazebo&gt;\n\n  &lt;gazebo&gt;\n    &lt;plugin name=&quot;turtlebot3_waffle_pi_controller&quot; filename=&quot;libgazebo_ros_diff_drive.so&quot;&gt;\n      &lt;commandTopic&gt;cmd_vel&lt;/commandTopic&gt;\n      &lt;odometryTopic&gt;odom&lt;/odometryTopic&gt;\n      &lt;odometryFrame&gt;odom&lt;/odometryFrame&gt;\n      &lt;odometrySource&gt;world&lt;/odometrySource&gt;\n      &lt;publishOdomTF&gt;true&lt;/publishOdomTF&gt;\n      &lt;robotBaseFrame&gt;base_footprint&lt;/robotBaseFrame&gt;\n      &lt;publishWheelTF&gt;false&lt;/publishWheelTF&gt;\n      &lt;publishTf&gt;true&lt;/publishTf&gt;\n      &lt;publishWheelJointState&gt;true&lt;/publishWheelJointState&gt;\n      &lt;legacyMode&gt;false&lt;/legacyMode&gt;\n      &lt;updateRate&gt;100&lt;/updateRate&gt;\n      &lt;leftJoint&gt;wheel_left_joint&lt;/leftJoint&gt;\n      &lt;rightJoint&gt;wheel_right_joint&lt;/rightJoint&gt;\n      &lt;wheelSeparation&gt;0.287&lt;/wheelSeparation&gt;\n      &lt;wheelDiameter&gt;0.066&lt;/wheelDiameter&gt;\n      &lt;wheelAcceleration&gt;4&lt;/wheelAcceleration&gt;\n      &lt;wheelTorque&gt;10&lt;/wheelTorque&gt;\n      &lt;rosDebugLevel&gt;na&lt;/rosDebugLevel&gt;\n    &lt;/plugin&gt;\n  &lt;/gazebo&gt;\n\n  &lt;gazebo&gt;\n    &lt;plugin name=&quot;imu_plugin&quot; filename=&quot;libgazebo_ros_imu.so&quot;&gt;\n      &lt;alwaysOn&gt;true&lt;/alwaysOn&gt;\n      &lt;bodyName&gt;imu_link&lt;/bodyName&gt;\n      &lt;frameName&gt;imu_link&lt;/frameName&gt;\n      &lt;topicName&gt;imu&lt;/topicName&gt;\n      &lt;serviceName&gt;imu_service&lt;/serviceName&gt;\n      &lt;gaussianNoise&gt;0.0&lt;/gaussianNoise&gt;\n      &lt;updateRate&gt;0&lt;/updateRate&gt;\n      &lt;imu&gt;\n        &lt;noise&gt;\n          &lt;type&gt;gaussian&lt;/type&gt;\n          &lt;rate&gt;\n            &lt;mean&gt;0.0&lt;/mean&gt;\n            &lt;stddev&gt;2e-4&lt;/stddev&gt;\n            &lt;bias_mean&gt;0.0000075&lt;/bias_mean&gt;\n            &lt;bias_stddev&gt;0.0000008&lt;/bias_stddev&gt;\n          &lt;/rate&gt;\n          &lt;accel&gt;\n            &lt;mean&gt;0.0&lt;/mean&gt;\n            &lt;stddev&gt;1.7e-2&lt;/stddev&gt;\n            &lt;bias_mean&gt;0.1&lt;/bias_mean&gt;\n            &lt;bias_stddev&gt;0.001&lt;/bias_stddev&gt;\n          &lt;/accel&gt;\n        &lt;/noise&gt;\n      &lt;/imu&gt;\n    &lt;/plugin&gt;\n  &lt;/gazebo&gt;\n\n  &lt;gazebo reference=&quot;base_scan&quot;&gt;\n    &lt;material&gt;Gazebo/FlatBlack&lt;/material&gt;\n    &lt;sensor type=&quot;ray&quot; name=&quot;lds_lfcd_sensor&quot;&gt;\n      &lt;pose&gt;0 0 0 0 0 0&lt;/pose&gt;\n      &lt;visualize&gt;$(arg laser_visual)&lt;/visualize&gt;\n      &lt;update_rate&gt;5&lt;/update_rate&gt;\n      &lt;ray&gt;\n        &lt;scan&gt;\n          &lt;horizontal&gt;\n            &lt;samples&gt;360&lt;/samples&gt;\n            &lt;resolution&gt;1&lt;/resolution&gt;\n            &lt;min_angle&gt;0.0&lt;/min_angle&gt;\n            &lt;max_angle&gt;6.28319&lt;/max_angle&gt;\n          &lt;/horizontal&gt;\n        &lt;/scan&gt;\n        &lt;range&gt;\n          &lt;min&gt;0.120&lt;/min&gt;\n          &lt;max&gt;3.5&lt;/max&gt;\n          &lt;resolution&gt;0.015&lt;/resolution&gt;\n        &lt;/range&gt;\n        &lt;noise&gt;\n          &lt;type&gt;gaussian&lt;/type&gt;\n          &lt;mean&gt;0.0&lt;/mean&gt;\n          &lt;stddev&gt;0.01&lt;/stddev&gt;\n        &lt;/noise&gt;\n      &lt;/ray&gt;\n      &lt;plugin name=&quot;gazebo_ros_lds_lfcd_controller&quot; filename=&quot;libgazebo_ros_laser.so&quot;&gt;\n        &lt;topicName&gt;scan&lt;/topicName&gt;\n        &lt;frameName&gt;base_scan&lt;/frameName&gt;\n      &lt;/plugin&gt;\n    &lt;/sensor&gt;\n  &lt;/gazebo&gt;\n\n&lt;!--link : https://www.raspberrypi.org/documentation/hardware/camera/--&gt;\n  &lt;gazebo reference=&quot;camera_rgb_frame&quot;&gt;\n    &lt;sensor type=&quot;camera&quot; name=&quot;Pi Camera&quot;&gt;\n      &lt;always_on&gt;true&lt;/always_on&gt;\n      &lt;visualize&gt;$(arg camera_visual)&lt;/visualize&gt;\n      &lt;camera&gt;\n          &lt;horizontal_fov&gt;1.085595&lt;/horizontal_fov&gt;\n          &lt;image&gt;\n              &lt;width&gt;640&lt;/width&gt;\n              &lt;height&gt;480&lt;/height&gt;\n              &lt;format&gt;R8G8B8&lt;/format&gt;\n          &lt;/image&gt;\n          &lt;clip&gt;\n              &lt;near&gt;0.03&lt;/near&gt;\n              &lt;far&gt;100&lt;/far&gt;\n          &lt;/clip&gt;\n      &lt;/camera&gt;\n      &lt;plugin name=&quot;camera_controller&quot; filename=&quot;libgazebo_ros_camera.so&quot;&gt;\n        &lt;alwaysOn&gt;true&lt;/alwaysOn&gt;\n        &lt;updateRate&gt;30.0&lt;/updateRate&gt;\n        &lt;cameraName&gt;camera&lt;/cameraName&gt;\n        &lt;frameName&gt;camera_rgb_optical_frame&lt;/frameName&gt;\n        &lt;imageTopicName&gt;rgb/image_raw&lt;/imageTopicName&gt;\n        &lt;cameraInfoTopicName&gt;rgb/camera_info&lt;/cameraInfoTopicName&gt;\n        &lt;hackBaseline&gt;0.07&lt;/hackBaseline&gt;\n        &lt;distortionK1&gt;0.0&lt;/distortionK1&gt;\n        &lt;distortionK2&gt;0.0&lt;/distortionK2&gt;\n        &lt;distortionK3&gt;0.0&lt;/distortionK3&gt;\n        &lt;distortionT1&gt;0.0&lt;/distortionT1&gt;\n        &lt;distortionT2&gt;0.0&lt;/distortionT2&gt;\n      &lt;/plugin&gt;\n    &lt;/sensor&gt;\n  &lt;/gazebo&gt;\n\n&lt;/robot&gt;\n"], "quote": [], "url": "https://stackoverflow.com/questions/79074188/in-the-turtlebot3-gazebo-simulation-the-angular-velocity-exhibits-significant-f", "answer": [], "answer_code": []},
{"title": "Delegate of my function has a null target", "time": 1728367103, "post_content": ["I am using ROS or ZMQ in Unity to communicate with my device, and I want my code to be adaptable to both methods without having to refactor all my code. Then I created an interface class that make the link between my main code, and the communication library. However, when subscribing to a ROS topic, I need to use a callback function to get the data. But my callback is never called, and when I check the target of the Delegate, it is null, even if I specified this at the creation.\nHere is the main class, that defines the subscriber and asks for the creation to the interface. I put with comments the results of each debug command. Since the type for the messages is different between ROS and ZMQ, I am using an alias, defined like this for ROS: public override Type TypeFloatArrayAlias { get; } = typeof(Float32MultiArrayMsg);.\n// ... (class RobotCommand)\n\n    try\n    {\n        var defineSubscriberMethod = m_interface.GetType().GetMethod(\"DefineSubscriber\");\n        var genericMethod = defineSubscriberMethod.MakeGenericMethod(m_interface.TypeFloatArrayAlias);\n        var delegateType = typeof(Action<>).MakeGenericType(m_interface.TypeFloatArrayAlias);\n        \n        var methodInfo = this.GetType().GetMethod(nameof(UpdateVirtualRobotJointsCallback),\n            BindingFlags.Instance | BindingFlags.NonPublic | BindingFlags.Public);\n        if (methodInfo == null)\n            throw new Exception(\"Method 'UpdateVirtualRobotJointsCallback' not found.\");\n\n        Debug.Log($\"Method Info: {methodInfo.Name} Target: {this.GetType().Name}\");\n        // Method Info: UpdateVirtualRobotJointsCallback Target: RobotCommand\n        Delegate callbackDelegate = Delegate.CreateDelegate(delegateType, this, methodInfo);\n        Debug.Log($\"Delegate Target: {callbackDelegate.Target}, Method: {callbackDelegate.Method}\");\n        // Delegate Target: null, Method: Void UpdateVirtualRobotJointsCallback(RosMessageTypes.Std.Float32MultiArrayMsg)\n\n        genericMethod.Invoke(m_interface, new object[]\n        {\n            Const.ROS_NAMESPACE + \"robot_joint_values\",\n            callbackDelegate\n        });\n    }\n    catch (Exception e)\n    {\n        Debug.LogError($\"Error invoking DefineSubscriber: {e.Message}\");\n    }\n}\n\npublic void UpdateVirtualRobotJointsCallback(Float32MultiArrayMsg msg)\n{\n    Debug.Log(\"called\");\n    StartCoroutine(m_controller.MoveRobot_Coroutine(m_interface.ToFloatArray(msg)));\n}\n\nHere is the DefineSubscriber<T> method of the interface:\npublic override void DefineSubscriber<T>(string topic, Action<T> callback)\n{\n    try\n    {\n        Debug.Log($\"Delegate Callback: Target={callback.Target}, Method={callback.Method}\");\n        // Delegate Callback: Target=null, Method=Void UpdateVirtualRobotJointsCallback(RosMessageTypes.Std.Float32MultiArrayMsg)\n\n        Type msgType = typeof(T);\n        // _node is the ROS object (ROSConnection.GetOrCreateInstance())\n        var subscribeMethod = _node.GetType().GetMethod(\"Subscribe\").MakeGenericMethod(msgType);\n        subscribeMethod.Invoke(_node, new object[] { topic, callback });\n        \n        _subscriberList[topic] = (x => callback((T)x), msgType);\n        Debug.Log($\"Subscriber created for topic: {topic} with message type: {msgType.Name}\");\n    }\n    catch (Exception e)\n    {\n        Debug.LogError($\"Error while defining subscriber for topic {topic}: {e.Message}\");\n    }\n}\n\nI don't understand why the target of my callback is null, then I guess that's why it is never called because it is not linked to the object.\nFYI, here is a working creation of a subscriber:\nvoid Start()\n{\n    ROSConnection.GetOrCreateInstance().Subscribe<Float32MultiArrayMsg>(m_topicName, UpdateVirtualRobotJointsCallback);\n}\n\n// Update is called once per frame\nvoid Update()\n{\n    \n}\n\nvoid UpdateVirtualRobotJointsCallback(Float32MultiArrayMsg msg)\n{\n    Debug.Log(\"called\");\n    StartCoroutine(xarmController.MoveRobot_Coroutine(new List<float>(msg.data)));\n}"], "question_code": ["this", "public override Type TypeFloatArrayAlias { get; } = typeof(Float32MultiArrayMsg);", "// ... (class RobotCommand)\n\n    try\n    {\n        var defineSubscriberMethod = m_interface.GetType().GetMethod(&quot;DefineSubscriber&quot;);\n        var genericMethod = defineSubscriberMethod.MakeGenericMethod(m_interface.TypeFloatArrayAlias);\n        var delegateType = typeof(Action&lt;&gt;).MakeGenericType(m_interface.TypeFloatArrayAlias);\n        \n        var methodInfo = this.GetType().GetMethod(nameof(UpdateVirtualRobotJointsCallback),\n            BindingFlags.Instance | BindingFlags.NonPublic | BindingFlags.Public);\n        if (methodInfo == null)\n            throw new Exception(&quot;Method 'UpdateVirtualRobotJointsCallback' not found.&quot;);\n\n        Debug.Log($&quot;Method Info: {methodInfo.Name} Target: {this.GetType().Name}&quot;);\n        // Method Info: UpdateVirtualRobotJointsCallback Target: RobotCommand\n        Delegate callbackDelegate = Delegate.CreateDelegate(delegateType, this, methodInfo);\n        Debug.Log($&quot;Delegate Target: {callbackDelegate.Target}, Method: {callbackDelegate.Method}&quot;);\n        // Delegate Target: null, Method: Void UpdateVirtualRobotJointsCallback(RosMessageTypes.Std.Float32MultiArrayMsg)\n\n        genericMethod.Invoke(m_interface, new object[]\n        {\n            Const.ROS_NAMESPACE + &quot;robot_joint_values&quot;,\n            callbackDelegate\n        });\n    }\n    catch (Exception e)\n    {\n        Debug.LogError($&quot;Error invoking DefineSubscriber: {e.Message}&quot;);\n    }\n}\n\npublic void UpdateVirtualRobotJointsCallback(Float32MultiArrayMsg msg)\n{\n    Debug.Log(&quot;called&quot;);\n    StartCoroutine(m_controller.MoveRobot_Coroutine(m_interface.ToFloatArray(msg)));\n}\n", "DefineSubscriber&lt;T&gt;", "public override void DefineSubscriber&lt;T&gt;(string topic, Action&lt;T&gt; callback)\n{\n    try\n    {\n        Debug.Log($&quot;Delegate Callback: Target={callback.Target}, Method={callback.Method}&quot;);\n        // Delegate Callback: Target=null, Method=Void UpdateVirtualRobotJointsCallback(RosMessageTypes.Std.Float32MultiArrayMsg)\n\n        Type msgType = typeof(T);\n        // _node is the ROS object (ROSConnection.GetOrCreateInstance())\n        var subscribeMethod = _node.GetType().GetMethod(&quot;Subscribe&quot;).MakeGenericMethod(msgType);\n        subscribeMethod.Invoke(_node, new object[] { topic, callback });\n        \n        _subscriberList[topic] = (x =&gt; callback((T)x), msgType);\n        Debug.Log($&quot;Subscriber created for topic: {topic} with message type: {msgType.Name}&quot;);\n    }\n    catch (Exception e)\n    {\n        Debug.LogError($&quot;Error while defining subscriber for topic {topic}: {e.Message}&quot;);\n    }\n}\n", "void Start()\n{\n    ROSConnection.GetOrCreateInstance().Subscribe&lt;Float32MultiArrayMsg&gt;(m_topicName, UpdateVirtualRobotJointsCallback);\n}\n\n// Update is called once per frame\nvoid Update()\n{\n    \n}\n\nvoid UpdateVirtualRobotJointsCallback(Float32MultiArrayMsg msg)\n{\n    Debug.Log(&quot;called&quot;);\n    StartCoroutine(xarmController.MoveRobot_Coroutine(new List&lt;float&gt;(msg.data)));\n}\n"], "quote": [], "url": "https://stackoverflow.com/questions/79064501/delegate-of-my-function-has-a-null-target", "answer": [], "answer_code": []},
{"title": "PointCloud2 is not display correct", "time": 1727318839, "post_content": ["enter code hereI have a relatively large point cloud data with max_pts set to a maximum of 150000000. PointCloud2 loads the latest data and cleans up old data every time. How to accumulate and display data each time\nThis is the code for me to load point cloud according to the official example\n\r\n\r\n<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"utf-8\" />\n\n<!--<script src=\"https://cdn.jsdelivr.net/npm/three@0.89.0/build/three.min.js\"></script>-->\n<!--<script src=\"https://cdn.jsdelivr.net/npm/eventemitter2@6.4/lib/eventemitter2.js\"></script>-->\n<!--<script src=\"https://cdn.jsdelivr.net/npm/roslib@1/build/roslib.js\"></script>-->\n  <script src=\"./libs/three.min.js\"></script>\n  <script src=\"./libs/eventemitter2.js\"></script>\n  <script src=\"./libs/roslib.js\"></script>\n<script src=\"../build/ros3d.js\"></script>\n\n<script>\n\n  function init() {\n\n    var ros = new ROSLIB.Ros({\n      url : 'ws://192.168.0.123:9090'\n    });\n\n    var viewer = new ROS3D.Viewer({\n      divID : 'viewer',\n      width : 800,\n      height : 600,\n      antialias : true\n    });\n\n    var tfClient = new ROSLIB.TFClient({\n      ros : ros,\n      angularThres : 0.01,\n      transThres : 0.01,\n      rate : 10.0,\n      fixedFrame : '/camera_init'\n    });\n\n    var cloudClient = new ROS3D.PointCloud2({\n      ros: ros,\n      tfClient: tfClient,\n      rootObject: viewer.scene,\n      topic: '/cloud_registered',\n      max_pts: 1000000,  // \u8bbe\u7f6e\u53ef\u89c6\u5316\u7684\u6700\u5927\u70b9\u6570\n      material: { size: 0.05, color: 0xff00ff }\n    });\n\n  }\n</script>\n</head>\n\n<body onload=\"init()\">\n  <h1>Simple PointCloud2 Example</h1>\n  <p>Run the following commands in the terminal then refresh the page.</p>\n  <ol>\n    <li><tt>roscore</tt></li>\n    <li><tt>roslaunch rosbridge_server rosbridge_websocket.launch</tt></li>\n    <li><tt>rosrun tf2_web_republisher tf2_web_republisher</tt></li>\n    <li><tt>roslaunch openni_launch openni.launch depth_registration:=true</tt></li>\n  </ol>\n  <div id=\"viewer\"></div>\n</body>\n</html>\r\n\r\n\r\n\nThis is the source code of PointCloud2 that I reviewed. This code updates the latest received data every time, and old data is replaced\n\r\n\r\nROS3D.PointCloud2.prototype.subscribe = function(){\n  this.unsubscribe();\n\n  // subscribe to the topic\n  this.rosTopic = new ROSLIB.Topic({\n    ros : this.ros,\n    name : this.topicName,\n    messageType : 'sensor_msgs/PointCloud2',\n    throttle_rate : this.throttle_rate,\n    queue_length : 1,\n    compression: this.compression\n  });\n  this.rosTopic.subscribe(this.processMessageBound);\n};\n\nROS3D.PointCloud2.prototype.processMessage = function(msg){\n  if(!this.points.setup(msg.header.frame_id, msg.point_step, msg.fields)) {\n      return;\n  }\n\n  var n, pointRatio = this.points.pointRatio;\n  var bufSz = this.max_pts * msg.point_step;\n\n  if (msg.data.buffer) {\n    this.buffer = msg.data.slice(0, Math.min(msg.data.byteLength, bufSz));\n     n = Math.min(msg.height*msg.width / pointRatio, this.points.positions.array.length / 3);\n  } else {\n    if (!this.buffer || this.buffer.byteLength < bufSz) {\n      this.buffer = new Uint8Array(bufSz);\n    }\n    n = decode64(msg.data, this.buffer, msg.point_step, pointRatio);\n    pointRatio = 1;\n  }\n\n  var dv = new DataView(this.buffer.buffer);\n  var littleEndian = !msg.is_bigendian;\n  var x = this.points.fields.x.offset;\n  var y = this.points.fields.y.offset;\n  var z = this.points.fields.z.offset;\n  var base, color;\n  for(var i = 0; i < n; i++){\n    base = i * pointRatio * msg.point_step;\n    this.points.positions.array[3*i    ] = dv.getFloat32(base+x, littleEndian);\n    this.points.positions.array[3*i + 1] = dv.getFloat32(base+y, littleEndian);\n    this.points.positions.array[3*i + 2] = dv.getFloat32(base+z, littleEndian);\n\n    if(this.points.colors){\n        color = this.points.colormap(this.points.getColor(dv,base,littleEndian));\n        this.points.colors.array[3*i    ] = color.r;\n        this.points.colors.array[3*i + 1] = color.g;\n        this.points.colors.array[3*i + 2] = color.b;\n    }\n  }\n  this.points.update(n);\n};\r\n\r\n\r\n\nIf I want new data to accumulate and display data without replacing old data, I should need to change the source code of PointCloud2.\nMy data is pushed repeatedly, and the new data pushed each time does not include the data that has already been pushed. However, I am not sure how to push new data that includes the data that has already been pushed"], "question_code": ["&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;meta charset=\"utf-8\" /&gt;\n\n&lt;!--&lt;script src=\"https://cdn.jsdelivr.net/npm/three@0.89.0/build/three.min.js\"&gt;&lt;/script&gt;--&gt;\n&lt;!--&lt;script src=\"https://cdn.jsdelivr.net/npm/eventemitter2@6.4/lib/eventemitter2.js\"&gt;&lt;/script&gt;--&gt;\n&lt;!--&lt;script src=\"https://cdn.jsdelivr.net/npm/roslib@1/build/roslib.js\"&gt;&lt;/script&gt;--&gt;\n  &lt;script src=\"./libs/three.min.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"./libs/eventemitter2.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"./libs/roslib.js\"&gt;&lt;/script&gt;\n&lt;script src=\"../build/ros3d.js\"&gt;&lt;/script&gt;\n\n&lt;script&gt;\n\n  function init() {\n\n    var ros = new ROSLIB.Ros({\n      url : 'ws://192.168.0.123:9090'\n    });\n\n    var viewer = new ROS3D.Viewer({\n      divID : 'viewer',\n      width : 800,\n      height : 600,\n      antialias : true\n    });\n\n    var tfClient = new ROSLIB.TFClient({\n      ros : ros,\n      angularThres : 0.01,\n      transThres : 0.01,\n      rate : 10.0,\n      fixedFrame : '/camera_init'\n    });\n\n    var cloudClient = new ROS3D.PointCloud2({\n      ros: ros,\n      tfClient: tfClient,\n      rootObject: viewer.scene,\n      topic: '/cloud_registered',\n      max_pts: 1000000,  // \u8bbe\u7f6e\u53ef\u89c6\u5316\u7684\u6700\u5927\u70b9\u6570\n      material: { size: 0.05, color: 0xff00ff }\n    });\n\n  }\n&lt;/script&gt;\n&lt;/head&gt;\n\n&lt;body onload=\"init()\"&gt;\n  &lt;h1&gt;Simple PointCloud2 Example&lt;/h1&gt;\n  &lt;p&gt;Run the following commands in the terminal then refresh the page.&lt;/p&gt;\n  &lt;ol&gt;\n    &lt;li&gt;&lt;tt&gt;roscore&lt;/tt&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;tt&gt;roslaunch rosbridge_server rosbridge_websocket.launch&lt;/tt&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;tt&gt;rosrun tf2_web_republisher tf2_web_republisher&lt;/tt&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;tt&gt;roslaunch openni_launch openni.launch depth_registration:=true&lt;/tt&gt;&lt;/li&gt;\n  &lt;/ol&gt;\n  &lt;div id=\"viewer\"&gt;&lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;", "ROS3D.PointCloud2.prototype.subscribe = function(){\n  this.unsubscribe();\n\n  // subscribe to the topic\n  this.rosTopic = new ROSLIB.Topic({\n    ros : this.ros,\n    name : this.topicName,\n    messageType : 'sensor_msgs/PointCloud2',\n    throttle_rate : this.throttle_rate,\n    queue_length : 1,\n    compression: this.compression\n  });\n  this.rosTopic.subscribe(this.processMessageBound);\n};\n\nROS3D.PointCloud2.prototype.processMessage = function(msg){\n  if(!this.points.setup(msg.header.frame_id, msg.point_step, msg.fields)) {\n      return;\n  }\n\n  var n, pointRatio = this.points.pointRatio;\n  var bufSz = this.max_pts * msg.point_step;\n\n  if (msg.data.buffer) {\n    this.buffer = msg.data.slice(0, Math.min(msg.data.byteLength, bufSz));\n     n = Math.min(msg.height*msg.width / pointRatio, this.points.positions.array.length / 3);\n  } else {\n    if (!this.buffer || this.buffer.byteLength &lt; bufSz) {\n      this.buffer = new Uint8Array(bufSz);\n    }\n    n = decode64(msg.data, this.buffer, msg.point_step, pointRatio);\n    pointRatio = 1;\n  }\n\n  var dv = new DataView(this.buffer.buffer);\n  var littleEndian = !msg.is_bigendian;\n  var x = this.points.fields.x.offset;\n  var y = this.points.fields.y.offset;\n  var z = this.points.fields.z.offset;\n  var base, color;\n  for(var i = 0; i &lt; n; i++){\n    base = i * pointRatio * msg.point_step;\n    this.points.positions.array[3*i    ] = dv.getFloat32(base+x, littleEndian);\n    this.points.positions.array[3*i + 1] = dv.getFloat32(base+y, littleEndian);\n    this.points.positions.array[3*i + 2] = dv.getFloat32(base+z, littleEndian);\n\n    if(this.points.colors){\n        color = this.points.colormap(this.points.getColor(dv,base,littleEndian));\n        this.points.colors.array[3*i    ] = color.r;\n        this.points.colors.array[3*i + 1] = color.g;\n        this.points.colors.array[3*i + 2] = color.b;\n    }\n  }\n  this.points.update(n);\n};"], "quote": [], "url": "https://stackoverflow.com/questions/79025340/pointcloud2-is-not-display-correct", "answer": [], "answer_code": []},
{"title": "Getting the error munmap_chunk(): invalid pointer: 0x00007ffe53bfa2c0 *** but not using free or malloc", "time": 1725628154, "post_content": ["When i do rosrun i get the error of the title but I'm using smart pointers so I don't know why it appears and I'm not using free or malloc. It's about hole avoidance using a robot. IT receives a point cloud and a costmap and tries to change the costmap values when there's a hole so it should avoid it by move_base.\n\nstd::shared_ptr<nav_msgs::OccupancyGrid> costmap_p = std::make_shared<nav_msgs::OccupancyGrid>();\nstd::shared_ptr<pcl::PointCloud<pcl::PointXYZ>> nubeDePuntos_p = std::make_shared<pcl::PointCloud<pcl::PointXYZ>>();\nstd::shared_ptr<pcl::PointCloud<pcl::PointXYZ>> nube_filt = std::make_shared<pcl::PointCloud<pcl::PointXYZ>>();\npcl::PointCloud<pcl::PointXYZ> output_cloud;\n// output_cloud.width = 0;  // Inicializa el ancho como 0\n// output_cloud.height = 0; // Inicializa la altura como 0\n// output_cloud.points.resize(0); // Inicializa el vector de puntos con tamano 0\nnav_msgs::OccupancyGrid dev;\n//costmap_2d::Costmap2D tf_costmap;\n//tf::TransformListener* tf_listener = nullptr; \n\ncostmap_2d::Costmap2D tf_costmap(1, 1, 1.0, 0.0, 0.0); // Valores predeterminados arbitrarios \nstd::mutex mtx;\n\n//tf::TransformListener tf_listener;\n//nav_msgs::OccupancyGrid* occupancy_grid = malloc(100*sizeof(nav_msgs::OccupancyGrid));\n\n// Funcion para convertir un nav_msgs::OccupancyGrid a un costmap_2d::Costmap2D\ncostmap_2d::Costmap2D convertirACostmap2D( nav_msgs::OccupancyGrid occupancy_grid, tf::TransformListener& tf) {\n    //auto costmap = std::make_shared<costmap_2d::Costmap2DROS>(\"mi_costmap\", tf);\n    //ROS_INFO(\"no\");\n    costmap_2d::Costmap2D costmap_data(occupancy_grid.info.width, occupancy_grid.info.height, \n                                        occupancy_grid.info.resolution, \n                                        occupancy_grid.info.origin.position.x, \n                                        occupancy_grid.info.origin.position.y);\n\n    // Copiar los datos de ocupacion del mensaje OccupancyGrid al Costmap2D\n    for(unsigned int x = 0; x < occupancy_grid.info.width; ++x) {\n        for(unsigned int y = 0; y < occupancy_grid.info.height; ++y) {\n            int8_t occupancy_value = occupancy_grid.data[x + y * occupancy_grid.info.width];\n            unsigned char cost = costmap_2d::FREE_SPACE; // Por defecto, se considera celda libre\n\n            if (occupancy_value == 100) {\n                cost = costmap_2d::LETHAL_OBSTACLE; // Si es 100, se considera un obstaculo letal\n            } else if (occupancy_value > 0) {\n                cost = costmap_2d::INSCRIBED_INFLATED_OBSTACLE; // Si es mayor que 0, se considera un obstaculo inscrito\n            }\n\n            costmap_data.setCost(x, y, cost);\n        }\n    }\n\n    //costmap->updateMap();\n    return costmap_data;\n}\n\n\nnav_msgs::OccupancyGrid cambia(pcl::PointCloud<pcl::PointXYZ> input_cloud,\n                               nav_msgs::OccupancyGrid costmap_data,\n                               pcl::PointCloud<pcl::PointXYZ> nube_filter) {\n    std::size_t i = 1;\n    tf::TransformListener tf_listener;\n       \n\n    if (input_cloud.points.empty() || costmap_data.data.empty()) { \n        ROS_WARN(\"La nube de puntos esta vacia.\"); \n    return costmap_data; }  \n\n    //Extraccion de coordenadas\n    for(auto& point : input_cloud.points){\n        //Conversion a costmap 2d\n        \n        double costmap_x = point.x;\n        double costmap_y = point.y;\n        int width = costmap_data.info.width;\n        int height = costmap_data.info.height;\n\n        // Calcula el indice correspondiente a la posicion (costmap_x, costmap_y)\n        int index = static_cast<int>(costmap_x) + static_cast<int>(costmap_y) * width; // Verificar que el \u00edndice est\u00e9 dentro de los l\u00edmites del costmap \n        if(index >= 0 && index < static_cast<int>(costmap_data.data.size())) { // Operar solo si el \u00edndice es v\u00e1lido // Modifica el valor en el \u00edndice correspondiente del costmap \n   \n\n        // Asegurate de que el indice este dentro de los limites del array de datos\n\n        if(pcl_isfinite(point.x) && pcl_isfinite(point.y) && pcl_isfinite(point.z)){\n            std::lock_guard<std::mutex> lock(mtx);\n            //ROS_INFO(\"paso\");\n            tf_costmap = convertirACostmap2D(costmap_data, tf_listener);\n            // Accede y modifica el valor del mapa en la posicion (costmap_x, costmap_y)\n            // if(index>=0 && index<costmap_data.data.size())\n            //     tf_costmap.setCost(costmap_x, costmap_y, 255);\n            // i = i+1;\n            //std::cout<<tf_costmap<<std::endl;\n            //costmap_2d::Costmap2DROS costmap_final(\"costmapfinal\", tf_listener);\n        }\n        }\n    // Copiar los datos del costmap a los datos de la grid de ocupacion\n    //ROS_INFO(\"no\");\n    if(i >= input_cloud.size()){\n        std::lock_guard<std::mutex> lock(mtx);\n        //ROS_INFO(\"%lu\", input_cloud.size());\n        costmap_data.data.resize(tf_costmap.getSizeInCellsX() * tf_costmap.getSizeInCellsY());\n        for (unsigned int y = 0; y < tf_costmap.getSizeInCellsY(); ++y) {\n            for (unsigned int x = 0; x < tf_costmap.getSizeInCellsX(); ++x) {\n                ROS_INFO(\"paso\");\n                unsigned int costmap_index = tf_costmap.getIndex(x, y);\n                unsigned char cost = tf_costmap.getCost(x, y);\n                if (cost == costmap_2d::LETHAL_OBSTACLE) {\n                    costmap_data.data[y * tf_costmap.getSizeInCellsX() + x] = 100; // Celda ocupada\n                } else if (cost == costmap_2d::INSCRIBED_INFLATED_OBSTACLE ||\n                        cost == costmap_2d::NO_INFORMATION) {\n                    costmap_data.data[y * tf_costmap.getSizeInCellsX() + x] = 100; // Celda desconocida\n                } else {\n                    costmap_data.data[y * tf_costmap.getSizeInCellsX() + x] = 100; // Celda libre\n                }\n            }\n        }\n    }\n    \n    }\n    //ROS_INFO(\"no\");\n    //pub.publish(dev);\n    return costmap_data;\n\n}\n\nnav_msgs::OccupancyGrid Hole_fn(  pcl::PointCloud<pcl::PointXYZ>& input_cloud_p,\n                                  nav_msgs::OccupancyGrid& costmap_data_p,\n                                  pcl::PointCloud<pcl::PointXYZ>& nube_filt_p)\n{\n    //ros::Rate;\n    //input_cloud_p.clear();\n    ros::spinOnce();\n    pcl::PointCloud<pcl::PointXYZ>::Ptr cloud_out_ptr(new pcl::PointCloud<pcl::PointXYZ>);\n    // Filtro de muestreo para reducir la densidad\n    pcl::VoxelGrid<pcl::PointXYZ> sor;\n    sor.setInputCloud(input_cloud_p.makeShared());\n    sor.setLeafSize(0.1, 0.1, 0.1);  // Ajusta el tamano del voxel segun tus necesidades\n    sor.filter(*cloud_out_ptr);\n    //ROS_INFO(\"%lu\", input_cloud_p.size());\n    if(input_cloud_p.size()>0)\n        return cambia(*cloud_out_ptr, costmap_data_p, nube_filt_p);\n}\n\n\nvoid nubeCallback(const pcl::PointCloud<pcl::PointXYZ>::ConstPtr& dato1)\n{     \n    std::lock_guard<std::mutex> lock(mtx);\n    if (!dato1 || dato1->points.empty()) { \n        ROS_WARN(\"Nube de puntos vacia o no inicializada.\"); \n    return; \n    } \n    // Filtrar pendientes\n    *nubeDePuntos_p = *dato1;\n    //ROS_INFO(\"%lu\", nubeDePuntos_p.size());\n    // Publicar la nube de puntos filtrada si es necesario\n    Hole_fn(*nubeDePuntos_p, *costmap_p, *nube_filt); \n}\n\nvoid nubeCallback2(const pcl::PointCloud<pcl::PointXYZ>::ConstPtr& dato1)\n{   \n    std::lock_guard<std::mutex> lock(mtx);  \n    // Filtrar pendientes\n    if (!dato1 || dato1->points.empty()) { \n        ROS_WARN(\"Nube de puntos vacia o no inicializada.\"); \n    return; \n    } \n    *nube_filt = *dato1;\n    // Publicar la nube de puntos filtrada si es necesario\n    Hole_fn(*nubeDePuntos_p, *costmap_p, *nube_filt);\n}\n\nvoid costmapCallback(const nav_msgs::OccupancyGrid::ConstPtr& dato2)\n{     \n    std::lock_guard<std::mutex> lock(mtx);\n\n    if (!dato2) { \n        ROS_WARN(\"El mensaje OccupancyGrid es nulo.\"); \n        return; \n    }  \n\n    // Filtrar pendientes\n    *costmap_p = *dato2;\n    // Publicar la nube de puntos filtrada si es necesario\n    Hole_fn(*nubeDePuntos_p, *costmap_p, *nube_filt);}\n\nint main(int argc, char** argv) {\n    ros::init(argc, argv, \"hole_node\");\n    //HoleDetectionNode node;\n    ros::NodeHandle nh2;\n    ros::Publisher pub;\n    ros::Subscriber sub = nh2.subscribe<pcl::PointCloud<pcl::PointXYZ>>(\"/robot/front_rgbd_camera/depth/points\", 1000, nubeCallback);\n    ros::Subscriber sub2 = nh2.subscribe<nav_msgs::OccupancyGrid>(\"/robot/move_base/local_costmap/costmap\", 1000, costmapCallback);\n    ros::Subscriber sub3 = nh2.subscribe<pcl::PointCloud<pcl::PointXYZ>>(\"/nube_hole_topic\", 1000, nubeCallback2);\n    //pub = nh2.advertise<nav_msgs::OccupancyGrid>(\"/robot/nube_filtrada1\", 1000);\n    //pub.publish(dev);\n    ros::spin();\n    return 0;\n}\n\nI've tried to use mutex and that stuff but nothing works"], "question_code": ["\nstd::shared_ptr&lt;nav_msgs::OccupancyGrid&gt; costmap_p = std::make_shared&lt;nav_msgs::OccupancyGrid&gt;();\nstd::shared_ptr&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;&gt; nubeDePuntos_p = std::make_shared&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;&gt;();\nstd::shared_ptr&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;&gt; nube_filt = std::make_shared&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;&gt;();\npcl::PointCloud&lt;pcl::PointXYZ&gt; output_cloud;\n// output_cloud.width = 0;  // Inicializa el ancho como 0\n// output_cloud.height = 0; // Inicializa la altura como 0\n// output_cloud.points.resize(0); // Inicializa el vector de puntos con tamano 0\nnav_msgs::OccupancyGrid dev;\n//costmap_2d::Costmap2D tf_costmap;\n//tf::TransformListener* tf_listener = nullptr; \n\ncostmap_2d::Costmap2D tf_costmap(1, 1, 1.0, 0.0, 0.0); // Valores predeterminados arbitrarios \nstd::mutex mtx;\n\n//tf::TransformListener tf_listener;\n//nav_msgs::OccupancyGrid* occupancy_grid = malloc(100*sizeof(nav_msgs::OccupancyGrid));\n\n// Funcion para convertir un nav_msgs::OccupancyGrid a un costmap_2d::Costmap2D\ncostmap_2d::Costmap2D convertirACostmap2D( nav_msgs::OccupancyGrid occupancy_grid, tf::TransformListener&amp; tf) {\n    //auto costmap = std::make_shared&lt;costmap_2d::Costmap2DROS&gt;(&quot;mi_costmap&quot;, tf);\n    //ROS_INFO(&quot;no&quot;);\n    costmap_2d::Costmap2D costmap_data(occupancy_grid.info.width, occupancy_grid.info.height, \n                                        occupancy_grid.info.resolution, \n                                        occupancy_grid.info.origin.position.x, \n                                        occupancy_grid.info.origin.position.y);\n\n    // Copiar los datos de ocupacion del mensaje OccupancyGrid al Costmap2D\n    for(unsigned int x = 0; x &lt; occupancy_grid.info.width; ++x) {\n        for(unsigned int y = 0; y &lt; occupancy_grid.info.height; ++y) {\n            int8_t occupancy_value = occupancy_grid.data[x + y * occupancy_grid.info.width];\n            unsigned char cost = costmap_2d::FREE_SPACE; // Por defecto, se considera celda libre\n\n            if (occupancy_value == 100) {\n                cost = costmap_2d::LETHAL_OBSTACLE; // Si es 100, se considera un obstaculo letal\n            } else if (occupancy_value &gt; 0) {\n                cost = costmap_2d::INSCRIBED_INFLATED_OBSTACLE; // Si es mayor que 0, se considera un obstaculo inscrito\n            }\n\n            costmap_data.setCost(x, y, cost);\n        }\n    }\n\n    //costmap-&gt;updateMap();\n    return costmap_data;\n}\n\n\nnav_msgs::OccupancyGrid cambia(pcl::PointCloud&lt;pcl::PointXYZ&gt; input_cloud,\n                               nav_msgs::OccupancyGrid costmap_data,\n                               pcl::PointCloud&lt;pcl::PointXYZ&gt; nube_filter) {\n    std::size_t i = 1;\n    tf::TransformListener tf_listener;\n       \n\n    if (input_cloud.points.empty() || costmap_data.data.empty()) { \n        ROS_WARN(&quot;La nube de puntos esta vacia.&quot;); \n    return costmap_data; }  \n\n    //Extraccion de coordenadas\n    for(auto&amp; point : input_cloud.points){\n        //Conversion a costmap 2d\n        \n        double costmap_x = point.x;\n        double costmap_y = point.y;\n        int width = costmap_data.info.width;\n        int height = costmap_data.info.height;\n\n        // Calcula el indice correspondiente a la posicion (costmap_x, costmap_y)\n        int index = static_cast&lt;int&gt;(costmap_x) + static_cast&lt;int&gt;(costmap_y) * width; // Verificar que el \u00edndice est\u00e9 dentro de los l\u00edmites del costmap \n        if(index &gt;= 0 &amp;&amp; index &lt; static_cast&lt;int&gt;(costmap_data.data.size())) { // Operar solo si el \u00edndice es v\u00e1lido // Modifica el valor en el \u00edndice correspondiente del costmap \n   \n\n        // Asegurate de que el indice este dentro de los limites del array de datos\n\n        if(pcl_isfinite(point.x) &amp;&amp; pcl_isfinite(point.y) &amp;&amp; pcl_isfinite(point.z)){\n            std::lock_guard&lt;std::mutex&gt; lock(mtx);\n            //ROS_INFO(&quot;paso&quot;);\n            tf_costmap = convertirACostmap2D(costmap_data, tf_listener);\n            // Accede y modifica el valor del mapa en la posicion (costmap_x, costmap_y)\n            // if(index&gt;=0 &amp;&amp; index&lt;costmap_data.data.size())\n            //     tf_costmap.setCost(costmap_x, costmap_y, 255);\n            // i = i+1;\n            //std::cout&lt;&lt;tf_costmap&lt;&lt;std::endl;\n            //costmap_2d::Costmap2DROS costmap_final(&quot;costmapfinal&quot;, tf_listener);\n        }\n        }\n    // Copiar los datos del costmap a los datos de la grid de ocupacion\n    //ROS_INFO(&quot;no&quot;);\n    if(i &gt;= input_cloud.size()){\n        std::lock_guard&lt;std::mutex&gt; lock(mtx);\n        //ROS_INFO(&quot;%lu&quot;, input_cloud.size());\n        costmap_data.data.resize(tf_costmap.getSizeInCellsX() * tf_costmap.getSizeInCellsY());\n        for (unsigned int y = 0; y &lt; tf_costmap.getSizeInCellsY(); ++y) {\n            for (unsigned int x = 0; x &lt; tf_costmap.getSizeInCellsX(); ++x) {\n                ROS_INFO(&quot;paso&quot;);\n                unsigned int costmap_index = tf_costmap.getIndex(x, y);\n                unsigned char cost = tf_costmap.getCost(x, y);\n                if (cost == costmap_2d::LETHAL_OBSTACLE) {\n                    costmap_data.data[y * tf_costmap.getSizeInCellsX() + x] = 100; // Celda ocupada\n                } else if (cost == costmap_2d::INSCRIBED_INFLATED_OBSTACLE ||\n                        cost == costmap_2d::NO_INFORMATION) {\n                    costmap_data.data[y * tf_costmap.getSizeInCellsX() + x] = 100; // Celda desconocida\n                } else {\n                    costmap_data.data[y * tf_costmap.getSizeInCellsX() + x] = 100; // Celda libre\n                }\n            }\n        }\n    }\n    \n    }\n    //ROS_INFO(&quot;no&quot;);\n    //pub.publish(dev);\n    return costmap_data;\n\n}\n\nnav_msgs::OccupancyGrid Hole_fn(  pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; input_cloud_p,\n                                  nav_msgs::OccupancyGrid&amp; costmap_data_p,\n                                  pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; nube_filt_p)\n{\n    //ros::Rate;\n    //input_cloud_p.clear();\n    ros::spinOnce();\n    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud_out_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);\n    // Filtro de muestreo para reducir la densidad\n    pcl::VoxelGrid&lt;pcl::PointXYZ&gt; sor;\n    sor.setInputCloud(input_cloud_p.makeShared());\n    sor.setLeafSize(0.1, 0.1, 0.1);  // Ajusta el tamano del voxel segun tus necesidades\n    sor.filter(*cloud_out_ptr);\n    //ROS_INFO(&quot;%lu&quot;, input_cloud_p.size());\n    if(input_cloud_p.size()&gt;0)\n        return cambia(*cloud_out_ptr, costmap_data_p, nube_filt_p);\n}\n\n\nvoid nubeCallback(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::ConstPtr&amp; dato1)\n{     \n    std::lock_guard&lt;std::mutex&gt; lock(mtx);\n    if (!dato1 || dato1-&gt;points.empty()) { \n        ROS_WARN(&quot;Nube de puntos vacia o no inicializada.&quot;); \n    return; \n    } \n    // Filtrar pendientes\n    *nubeDePuntos_p = *dato1;\n    //ROS_INFO(&quot;%lu&quot;, nubeDePuntos_p.size());\n    // Publicar la nube de puntos filtrada si es necesario\n    Hole_fn(*nubeDePuntos_p, *costmap_p, *nube_filt); \n}\n\nvoid nubeCallback2(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::ConstPtr&amp; dato1)\n{   \n    std::lock_guard&lt;std::mutex&gt; lock(mtx);  \n    // Filtrar pendientes\n    if (!dato1 || dato1-&gt;points.empty()) { \n        ROS_WARN(&quot;Nube de puntos vacia o no inicializada.&quot;); \n    return; \n    } \n    *nube_filt = *dato1;\n    // Publicar la nube de puntos filtrada si es necesario\n    Hole_fn(*nubeDePuntos_p, *costmap_p, *nube_filt);\n}\n\nvoid costmapCallback(const nav_msgs::OccupancyGrid::ConstPtr&amp; dato2)\n{     \n    std::lock_guard&lt;std::mutex&gt; lock(mtx);\n\n    if (!dato2) { \n        ROS_WARN(&quot;El mensaje OccupancyGrid es nulo.&quot;); \n        return; \n    }  \n\n    // Filtrar pendientes\n    *costmap_p = *dato2;\n    // Publicar la nube de puntos filtrada si es necesario\n    Hole_fn(*nubeDePuntos_p, *costmap_p, *nube_filt);}\n\nint main(int argc, char** argv) {\n    ros::init(argc, argv, &quot;hole_node&quot;);\n    //HoleDetectionNode node;\n    ros::NodeHandle nh2;\n    ros::Publisher pub;\n    ros::Subscriber sub = nh2.subscribe&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;&gt;(&quot;/robot/front_rgbd_camera/depth/points&quot;, 1000, nubeCallback);\n    ros::Subscriber sub2 = nh2.subscribe&lt;nav_msgs::OccupancyGrid&gt;(&quot;/robot/move_base/local_costmap/costmap&quot;, 1000, costmapCallback);\n    ros::Subscriber sub3 = nh2.subscribe&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;&gt;(&quot;/nube_hole_topic&quot;, 1000, nubeCallback2);\n    //pub = nh2.advertise&lt;nav_msgs::OccupancyGrid&gt;(&quot;/robot/nube_filtrada1&quot;, 1000);\n    //pub.publish(dev);\n    ros::spin();\n    return 0;\n}\n"], "quote": [], "url": "https://stackoverflow.com/questions/78957298/getting-the-error-munmap-chunk-invalid-pointer-0x00007ffe53bfa2c0-but-no", "answer": [], "answer_code": []},
{"title": "rosrun rosserial_python serial_node.py /dev/ttyUSB0 error while running this file", "time": 1724859167, "post_content": ["File \"/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py\", line 15, in <module>\n    exec(compile(fh.read(), python_script, 'exec'), context)\n  File \"/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py\", line 15, in <module>\n    exec(compile(fh.read(), python_script, 'exec'), context)\n  File \"/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py\", line 15, in <module>\n    exec(compile(fh.read(), python_script, 'exec'), context)\n  File \"/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py\", line 15, in <module>\n    exec(compile(fh.read(), python_script, 'exec'), context)\n  File \"/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py\", line 7, in <module>\n    with open(python_script, 'r') as fh:\nRecursionError: maximum recursion depth exceeded while calling a Python object\ntilak@tilak-Lenovo-ideapad-330S-14IKB:~$ rosrun rosserial_python serial_node.py /dev/ttyUSB0 \n\ni was just trying to use rosserial and this error is constantly coming while trying to use esp32 with rosserial"], "question_code": ["File &quot;/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py&quot;, line 15, in &lt;module&gt;\n    exec(compile(fh.read(), python_script, 'exec'), context)\n  File &quot;/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py&quot;, line 15, in &lt;module&gt;\n    exec(compile(fh.read(), python_script, 'exec'), context)\n  File &quot;/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py&quot;, line 15, in &lt;module&gt;\n    exec(compile(fh.read(), python_script, 'exec'), context)\n  File &quot;/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py&quot;, line 15, in &lt;module&gt;\n    exec(compile(fh.read(), python_script, 'exec'), context)\n  File &quot;/home/tilak/catkin_ws/devel/lib/rosserial_python/serial_node.py&quot;, line 7, in &lt;module&gt;\n    with open(python_script, 'r') as fh:\nRecursionError: maximum recursion depth exceeded while calling a Python object\ntilak@tilak-Lenovo-ideapad-330S-14IKB:~$ rosrun rosserial_python serial_node.py /dev/ttyUSB0 \n"], "quote": [], "url": "https://stackoverflow.com/questions/78924165/rosrun-rosserial-python-serial-node-py-dev-ttyusb0-error-while-running-this-fil", "answer": [], "answer_code": []},
{"title": "teleop_twist_keyboard moving the bot in reverse", "time": 1724735360, "post_content": ["Tried to control my gazebo bot through teleop_twist_keyboard.\nrosrun teleop_twist_keyboard teleop_twist_keyboard.py cmd_vel:=forklift/cmd_vel\n\nHowever the bot ends up going in reverse (for example pressing \".\" should go backward by default, but my bot go forward). Checked my wheel joints axis and it looks fine to me, have no idea what's wrong. Here's my bot urdf code down below, and the project's git just in case more information is needed for this issue.\nforklift.urdf.xacro\n<?xml version=\"1.0\"?>\n<robot xmlns:xacro=\"http://www.ros.org/wiki/xacro\" name=\"forklift\">\n    \n    <link name=\"base_footprint\"/>\n\n    <link name=\"base_link\">\n        <inertial>\n            <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n            <mass value=\"50.0\"/>\n            <!--\n            <inertia ixx=\"0.05\" ixy=\"0.05\" ixz=\"0.05\" iyy=\"1.3419385416666667\" iyz=\"1.3419385416666667\" izz=\"2.296875\"/>\n            -->\n            <inertia ixx=\"1.3419385416666667\"\n                iyy=\"1.3419385416666667\"\n                izz=\"2.296875\"\n                ixy=\"0.0\"\n                ixz=\"0.0\"\n                iyz=\"0.0\"/>\n        </inertial>\n        <visual name=\"\">\n            <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n            <geometry>\n                <box size=\"0.525 0.525 0.2155\"/>\n            </geometry>\n            <material name=\"blue\">\n                <color rgba=\"0.0 0.0 1.0 1.0\"/>\n                <texture filename=\"\"/>\n            </material>\n        </visual>\n        <collision>\n            <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n            <geometry>\n                <box size=\"0.525 0.525 0.2155\"/>\n            </geometry>\n            <!--\n            <surface>\n                <friction>\n                    <ode>\n                        <mu>100</mu>\n                        <mu2>100</mu2>\n                    </ode>\n                </friction>\n            </surface>\n            -->\n        </collision>\n    </link>\n    <gazebo reference=\"base_link\">\n        <material>Gazebo/Blue</material>\n    </gazebo>\n    <joint name=\"base_joint\" type=\"fixed\">\n        <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n        <parent link=\"base_footprint\"/>\n        <child link=\"base_link\"/>\n    </joint>\n\n<!--    ***   wheels   ***   -->    \n\n    <xacro:macro name=\"wheel\" params=\"name x y\">\n        <link name=\"wheel_link_${name}\">\n            <inertial>\n                <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n                <mass value=\"1.0\"/>\n                <!--\n                <inertia ixx=\"0.05\" ixy=\"0.05\" ixz=\"0.05\" \n                    iyy=\"0.0009333333333333333\" iyz=\"0.0009333333333333333\" izz=\"0.0018\"/>\n                -->        \n                <inertia ixx=\"0.0009333333333333333\"  \n                    iyy=\"0.0009333333333333333\"  \n                    izz=\"0.0018\"\n                    ixy=\"0.0\"\n                    ixz=\"0.0\"\n                    iyz=\"0.0\"/>\n                </inertial>\n            <visual name=\"\">\n                <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n                <geometry>\n                    <cylinder radius=\"0.06\" length=\"0.02\"/>\n                </geometry>\n                <material name=\"black\">\n                    <color rgba=\"0.0 0.0 0.0 1.0\"/>\n                    <texture filename=\"\"/>\n                </material>\n            </visual>\n            <collision>\n                <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n                <geometry>\n                    <cylinder radius=\"0.06\" length=\"0.02\"/>\n                </geometry>\n                <!--\n                <surface>\n                    <friction>\n                        <ode>\n                            <mu>100</mu>\n                            <mu2>100</mu2>\n                        </ode>\n                    </friction>\n                </surface>\n                -->\n            </collision>\n        </link>\n        <gazebo reference=\"wheel_link_${name}\">\n            <material>Gazebo/Black</material>\n        </gazebo>\n\n        <joint name=\"wheel_joint_${name}\" type=\"continuous\">\n            <origin xyz=\"${x} ${y} -0.100250\" rpy=\"1.57 0.0 0.0\"/>\n            <parent link=\"base_link\"/>\n            <child link=\"wheel_link_${name}\"/>\n            <axis xyz=\"0.0 0.0 1.0\"/>\n            <limit effort=\"10000\" velocity=\"1000\" />\n        <dynamics damping=\"1.0\" friction=\"1.0\" />\n        </joint>\n    </xacro:macro>\n\n<!--   ***   fork base   ***   -->\n    <xacro:macro name=\"fork_base\" params=\"name y\">\n        <link name=\"forkbase_link_${name}\">\n            <inertial>\n                <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n                <mass value=\"0.5\"/>\n                <inertia ixx=\"0.0005208333333333334\"  \n                    iyy=\"0.0004208333333333334\"  \n                    izz=\"0.00010833333333333334\"\n                    ixy=\"0.0\"\n                    ixz=\"0.0\"\n                    iyz=\"0.0\"/>\n            </inertial>\n            <visual name=\"\">\n                <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n                <geometry>\n                    <box size=\"0.01 0.05 0.1\"/>\n                </geometry>\n                <material name=\"green\">\n                    <color rgba=\"0.0 1.0 0.0 1.0\"/>\n                    <texture filename=\"\"/>\n                </material>\n            </visual>\n            <collision>\n                <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n                <geometry>\n                    <box size=\"0.01 0.05 0.1\"/>\n                </geometry>\n            </collision>\n        </link>\n        <gazebo reference=\"forkbase_link_${name}\">\n            <material>Gazebo/Green</material>\n        </gazebo>\n\n        <joint name=\"forkbase_link_${name}\" type=\"fixed\">\n            <origin xyz=\"0.2675 ${y} -0.10025\" rpy=\"0.0 0.0 0.0\"/>\n            <parent link=\"base_link\"/>\n            <child link=\"forkbase_link_${name}\"/>\n        </joint>\n    </xacro:macro>\n\n<!--   ***   fork   ***   -->\n    <xacro:macro name=\"fork_link\" params=\"name\">\n        <link name=\"fork_link_${name}\">\n            <inertial>\n                <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n                <mass value=\"0.5\"/>\n                <inertia ixx=\"0.00010833333333333334\"  \n                    iyy=\"0.0026083333333333336\"  \n                    izz=\"0.0027083333333333334\"\n                    ixy=\"0.0\"\n                    ixz=\"0.0\"\n                    iyz=\"0.0\"/>\n            </inertial>\n            <visual name=\"\">\n                <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n                <geometry>\n                    <box size=\"0.25 0.05 0.01\"/>\n                </geometry>\n                <material name=\"green\">\n                    <color rgba=\"0.0 1.0 0.0 1.0\"/>\n                    <texture filename=\"\"/>\n                </material>\n            </visual>\n            <collision>\n                <origin xyz=\"0.0 0.0 0.0\" rpy=\"0.0 0.0 0.0\"/>\n                <geometry>\n                    <box size=\"0.25 0.05 0.01\"/>\n                </geometry>\n            </collision>\n        </link>\n        <gazebo reference=\"fork_link_${name}\">\n            <material>Gazebo/Green</material>\n        </gazebo>\n\n        <joint name=\"fork_link_${name}\" type=\"fixed\">\n            <origin xyz=\"0.13 0 -0.045\" rpy=\"0.0 0.0 0.0\"/>\n            <parent link=\"forkbase_link_${name}\"/>\n            <child link=\"fork_link_${name}\"/>\n        </joint>\n    </xacro:macro>\n\n    <xacro:include filename=\"$(find realsense2_description)/urdf/_d435.urdf.xacro\" />\n    <xacro:sensor_d435 name=\"camera\" topics_ns=\"camera\" parent=\"base_link\" publish_pointcloud=\"true\">\n        <origin xyz=\"0.2625 0 -0.10775\" rpy=\"0 0 0\" />\n    </xacro:sensor_d435>  \n\n<!--   ***   combine component   ***   -->\n\n    <xacro:wheel name=\"back_right\" x=\"-0.150000\" y =\"-0.272513\"/>\n    <xacro:wheel name=\"back_left\" x=\"-0.150000\" y =\"0.272513\"/>\n    <xacro:wheel name=\"front_right\" x=\"0.150000\" y =\"-0.272513\"/>\n    <xacro:wheel name=\"front_left\" x=\"0.150000\" y =\"0.272513\"/>\n\n    <xacro:fork_base name=\"right\" y =\"-0.055\"/>\n    <xacro:fork_base name=\"left\" y =\"0.055\"/>\n\n    <xacro:fork_link name=\"right\"/>\n    <xacro:fork_link name=\"left\"/>\n    \n    <gazebo>\n    \n    <plugin name=\"skid_steer_drive_controller\" filename=\"libgazebo_ros_skid_steer_drive.so\">\n        <updateRate>10.0</updateRate>\n        <robotNamespace>/forklift</robotNamespace>\n        <leftFrontJoint>wheel_joint_front_left</leftFrontJoint>\n        <rightFrontJoint>wheel_joint_front_right</rightFrontJoint>\n        <leftRearJoint>wheel_joint_back_left</leftRearJoint>\n        <rightRearJoint>wheel_joint_back_right</rightRearJoint>\n        <wheelSeparation>0.4</wheelSeparation>\n        <wheelDiameter>0.12</wheelDiameter>\n        <robotBaseFrame>base_footprint</robotBaseFrame>\n        <torque>10</torque>\n\n        <topicName>cmd_vel</topicName>\n        <odometryTopic>odom</odometryTopic>\n        <odometryFrame>odom</odometryFrame>\n\n        <commandTopic>cmd_vel</commandTopic>\n        <topic_name_twist>cmd_vel</topic_name_twist>\n        <topic_name_odometry>odom</topic_name_odometry>\n        <topic_name_joint>joint</topic_name_joint>\n\n        <broadcastTF>true</broadcastTF>\n\n        <covariance_x>0.0001</covariance_x>\n        <covariance_y>0.0001</covariance_y>\n        <covariance_yaw>0.01</covariance_yaw>\n\n    </plugin>\n\n    </gazebo>\n\n</robot>"], "question_code": ["rosrun teleop_twist_keyboard teleop_twist_keyboard.py cmd_vel:=forklift/cmd_vel\n", "&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;robot xmlns:xacro=&quot;http://www.ros.org/wiki/xacro&quot; name=&quot;forklift&quot;&gt;\n    \n    &lt;link name=&quot;base_footprint&quot;/&gt;\n\n    &lt;link name=&quot;base_link&quot;&gt;\n        &lt;inertial&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n            &lt;mass value=&quot;50.0&quot;/&gt;\n            &lt;!--\n            &lt;inertia ixx=&quot;0.05&quot; ixy=&quot;0.05&quot; ixz=&quot;0.05&quot; iyy=&quot;1.3419385416666667&quot; iyz=&quot;1.3419385416666667&quot; izz=&quot;2.296875&quot;/&gt;\n            --&gt;\n            &lt;inertia ixx=&quot;1.3419385416666667&quot;\n                iyy=&quot;1.3419385416666667&quot;\n                izz=&quot;2.296875&quot;\n                ixy=&quot;0.0&quot;\n                ixz=&quot;0.0&quot;\n                iyz=&quot;0.0&quot;/&gt;\n        &lt;/inertial&gt;\n        &lt;visual name=&quot;&quot;&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n            &lt;geometry&gt;\n                &lt;box size=&quot;0.525 0.525 0.2155&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;material name=&quot;blue&quot;&gt;\n                &lt;color rgba=&quot;0.0 0.0 1.0 1.0&quot;/&gt;\n                &lt;texture filename=&quot;&quot;/&gt;\n            &lt;/material&gt;\n        &lt;/visual&gt;\n        &lt;collision&gt;\n            &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n            &lt;geometry&gt;\n                &lt;box size=&quot;0.525 0.525 0.2155&quot;/&gt;\n            &lt;/geometry&gt;\n            &lt;!--\n            &lt;surface&gt;\n                &lt;friction&gt;\n                    &lt;ode&gt;\n                        &lt;mu&gt;100&lt;/mu&gt;\n                        &lt;mu2&gt;100&lt;/mu2&gt;\n                    &lt;/ode&gt;\n                &lt;/friction&gt;\n            &lt;/surface&gt;\n            --&gt;\n        &lt;/collision&gt;\n    &lt;/link&gt;\n    &lt;gazebo reference=&quot;base_link&quot;&gt;\n        &lt;material&gt;Gazebo/Blue&lt;/material&gt;\n    &lt;/gazebo&gt;\n    &lt;joint name=&quot;base_joint&quot; type=&quot;fixed&quot;&gt;\n        &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n        &lt;parent link=&quot;base_footprint&quot;/&gt;\n        &lt;child link=&quot;base_link&quot;/&gt;\n    &lt;/joint&gt;\n\n&lt;!--    ***   wheels   ***   --&gt;    \n\n    &lt;xacro:macro name=&quot;wheel&quot; params=&quot;name x y&quot;&gt;\n        &lt;link name=&quot;wheel_link_${name}&quot;&gt;\n            &lt;inertial&gt;\n                &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n                &lt;mass value=&quot;1.0&quot;/&gt;\n                &lt;!--\n                &lt;inertia ixx=&quot;0.05&quot; ixy=&quot;0.05&quot; ixz=&quot;0.05&quot; \n                    iyy=&quot;0.0009333333333333333&quot; iyz=&quot;0.0009333333333333333&quot; izz=&quot;0.0018&quot;/&gt;\n                --&gt;        \n                &lt;inertia ixx=&quot;0.0009333333333333333&quot;  \n                    iyy=&quot;0.0009333333333333333&quot;  \n                    izz=&quot;0.0018&quot;\n                    ixy=&quot;0.0&quot;\n                    ixz=&quot;0.0&quot;\n                    iyz=&quot;0.0&quot;/&gt;\n                &lt;/inertial&gt;\n            &lt;visual name=&quot;&quot;&gt;\n                &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n                &lt;geometry&gt;\n                    &lt;cylinder radius=&quot;0.06&quot; length=&quot;0.02&quot;/&gt;\n                &lt;/geometry&gt;\n                &lt;material name=&quot;black&quot;&gt;\n                    &lt;color rgba=&quot;0.0 0.0 0.0 1.0&quot;/&gt;\n                    &lt;texture filename=&quot;&quot;/&gt;\n                &lt;/material&gt;\n            &lt;/visual&gt;\n            &lt;collision&gt;\n                &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n                &lt;geometry&gt;\n                    &lt;cylinder radius=&quot;0.06&quot; length=&quot;0.02&quot;/&gt;\n                &lt;/geometry&gt;\n                &lt;!--\n                &lt;surface&gt;\n                    &lt;friction&gt;\n                        &lt;ode&gt;\n                            &lt;mu&gt;100&lt;/mu&gt;\n                            &lt;mu2&gt;100&lt;/mu2&gt;\n                        &lt;/ode&gt;\n                    &lt;/friction&gt;\n                &lt;/surface&gt;\n                --&gt;\n            &lt;/collision&gt;\n        &lt;/link&gt;\n        &lt;gazebo reference=&quot;wheel_link_${name}&quot;&gt;\n            &lt;material&gt;Gazebo/Black&lt;/material&gt;\n        &lt;/gazebo&gt;\n\n        &lt;joint name=&quot;wheel_joint_${name}&quot; type=&quot;continuous&quot;&gt;\n            &lt;origin xyz=&quot;${x} ${y} -0.100250&quot; rpy=&quot;1.57 0.0 0.0&quot;/&gt;\n            &lt;parent link=&quot;base_link&quot;/&gt;\n            &lt;child link=&quot;wheel_link_${name}&quot;/&gt;\n            &lt;axis xyz=&quot;0.0 0.0 1.0&quot;/&gt;\n            &lt;limit effort=&quot;10000&quot; velocity=&quot;1000&quot; /&gt;\n        &lt;dynamics damping=&quot;1.0&quot; friction=&quot;1.0&quot; /&gt;\n        &lt;/joint&gt;\n    &lt;/xacro:macro&gt;\n\n&lt;!--   ***   fork base   ***   --&gt;\n    &lt;xacro:macro name=&quot;fork_base&quot; params=&quot;name y&quot;&gt;\n        &lt;link name=&quot;forkbase_link_${name}&quot;&gt;\n            &lt;inertial&gt;\n                &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n                &lt;mass value=&quot;0.5&quot;/&gt;\n                &lt;inertia ixx=&quot;0.0005208333333333334&quot;  \n                    iyy=&quot;0.0004208333333333334&quot;  \n                    izz=&quot;0.00010833333333333334&quot;\n                    ixy=&quot;0.0&quot;\n                    ixz=&quot;0.0&quot;\n                    iyz=&quot;0.0&quot;/&gt;\n            &lt;/inertial&gt;\n            &lt;visual name=&quot;&quot;&gt;\n                &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n                &lt;geometry&gt;\n                    &lt;box size=&quot;0.01 0.05 0.1&quot;/&gt;\n                &lt;/geometry&gt;\n                &lt;material name=&quot;green&quot;&gt;\n                    &lt;color rgba=&quot;0.0 1.0 0.0 1.0&quot;/&gt;\n                    &lt;texture filename=&quot;&quot;/&gt;\n                &lt;/material&gt;\n            &lt;/visual&gt;\n            &lt;collision&gt;\n                &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n                &lt;geometry&gt;\n                    &lt;box size=&quot;0.01 0.05 0.1&quot;/&gt;\n                &lt;/geometry&gt;\n            &lt;/collision&gt;\n        &lt;/link&gt;\n        &lt;gazebo reference=&quot;forkbase_link_${name}&quot;&gt;\n            &lt;material&gt;Gazebo/Green&lt;/material&gt;\n        &lt;/gazebo&gt;\n\n        &lt;joint name=&quot;forkbase_link_${name}&quot; type=&quot;fixed&quot;&gt;\n            &lt;origin xyz=&quot;0.2675 ${y} -0.10025&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n            &lt;parent link=&quot;base_link&quot;/&gt;\n            &lt;child link=&quot;forkbase_link_${name}&quot;/&gt;\n        &lt;/joint&gt;\n    &lt;/xacro:macro&gt;\n\n&lt;!--   ***   fork   ***   --&gt;\n    &lt;xacro:macro name=&quot;fork_link&quot; params=&quot;name&quot;&gt;\n        &lt;link name=&quot;fork_link_${name}&quot;&gt;\n            &lt;inertial&gt;\n                &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n                &lt;mass value=&quot;0.5&quot;/&gt;\n                &lt;inertia ixx=&quot;0.00010833333333333334&quot;  \n                    iyy=&quot;0.0026083333333333336&quot;  \n                    izz=&quot;0.0027083333333333334&quot;\n                    ixy=&quot;0.0&quot;\n                    ixz=&quot;0.0&quot;\n                    iyz=&quot;0.0&quot;/&gt;\n            &lt;/inertial&gt;\n            &lt;visual name=&quot;&quot;&gt;\n                &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n                &lt;geometry&gt;\n                    &lt;box size=&quot;0.25 0.05 0.01&quot;/&gt;\n                &lt;/geometry&gt;\n                &lt;material name=&quot;green&quot;&gt;\n                    &lt;color rgba=&quot;0.0 1.0 0.0 1.0&quot;/&gt;\n                    &lt;texture filename=&quot;&quot;/&gt;\n                &lt;/material&gt;\n            &lt;/visual&gt;\n            &lt;collision&gt;\n                &lt;origin xyz=&quot;0.0 0.0 0.0&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n                &lt;geometry&gt;\n                    &lt;box size=&quot;0.25 0.05 0.01&quot;/&gt;\n                &lt;/geometry&gt;\n            &lt;/collision&gt;\n        &lt;/link&gt;\n        &lt;gazebo reference=&quot;fork_link_${name}&quot;&gt;\n            &lt;material&gt;Gazebo/Green&lt;/material&gt;\n        &lt;/gazebo&gt;\n\n        &lt;joint name=&quot;fork_link_${name}&quot; type=&quot;fixed&quot;&gt;\n            &lt;origin xyz=&quot;0.13 0 -0.045&quot; rpy=&quot;0.0 0.0 0.0&quot;/&gt;\n            &lt;parent link=&quot;forkbase_link_${name}&quot;/&gt;\n            &lt;child link=&quot;fork_link_${name}&quot;/&gt;\n        &lt;/joint&gt;\n    &lt;/xacro:macro&gt;\n\n    &lt;xacro:include filename=&quot;$(find realsense2_description)/urdf/_d435.urdf.xacro&quot; /&gt;\n    &lt;xacro:sensor_d435 name=&quot;camera&quot; topics_ns=&quot;camera&quot; parent=&quot;base_link&quot; publish_pointcloud=&quot;true&quot;&gt;\n        &lt;origin xyz=&quot;0.2625 0 -0.10775&quot; rpy=&quot;0 0 0&quot; /&gt;\n    &lt;/xacro:sensor_d435&gt;  \n\n&lt;!--   ***   combine component   ***   --&gt;\n\n    &lt;xacro:wheel name=&quot;back_right&quot; x=&quot;-0.150000&quot; y =&quot;-0.272513&quot;/&gt;\n    &lt;xacro:wheel name=&quot;back_left&quot; x=&quot;-0.150000&quot; y =&quot;0.272513&quot;/&gt;\n    &lt;xacro:wheel name=&quot;front_right&quot; x=&quot;0.150000&quot; y =&quot;-0.272513&quot;/&gt;\n    &lt;xacro:wheel name=&quot;front_left&quot; x=&quot;0.150000&quot; y =&quot;0.272513&quot;/&gt;\n\n    &lt;xacro:fork_base name=&quot;right&quot; y =&quot;-0.055&quot;/&gt;\n    &lt;xacro:fork_base name=&quot;left&quot; y =&quot;0.055&quot;/&gt;\n\n    &lt;xacro:fork_link name=&quot;right&quot;/&gt;\n    &lt;xacro:fork_link name=&quot;left&quot;/&gt;\n    \n    &lt;gazebo&gt;\n    \n    &lt;plugin name=&quot;skid_steer_drive_controller&quot; filename=&quot;libgazebo_ros_skid_steer_drive.so&quot;&gt;\n        &lt;updateRate&gt;10.0&lt;/updateRate&gt;\n        &lt;robotNamespace&gt;/forklift&lt;/robotNamespace&gt;\n        &lt;leftFrontJoint&gt;wheel_joint_front_left&lt;/leftFrontJoint&gt;\n        &lt;rightFrontJoint&gt;wheel_joint_front_right&lt;/rightFrontJoint&gt;\n        &lt;leftRearJoint&gt;wheel_joint_back_left&lt;/leftRearJoint&gt;\n        &lt;rightRearJoint&gt;wheel_joint_back_right&lt;/rightRearJoint&gt;\n        &lt;wheelSeparation&gt;0.4&lt;/wheelSeparation&gt;\n        &lt;wheelDiameter&gt;0.12&lt;/wheelDiameter&gt;\n        &lt;robotBaseFrame&gt;base_footprint&lt;/robotBaseFrame&gt;\n        &lt;torque&gt;10&lt;/torque&gt;\n\n        &lt;topicName&gt;cmd_vel&lt;/topicName&gt;\n        &lt;odometryTopic&gt;odom&lt;/odometryTopic&gt;\n        &lt;odometryFrame&gt;odom&lt;/odometryFrame&gt;\n\n        &lt;commandTopic&gt;cmd_vel&lt;/commandTopic&gt;\n        &lt;topic_name_twist&gt;cmd_vel&lt;/topic_name_twist&gt;\n        &lt;topic_name_odometry&gt;odom&lt;/topic_name_odometry&gt;\n        &lt;topic_name_joint&gt;joint&lt;/topic_name_joint&gt;\n\n        &lt;broadcastTF&gt;true&lt;/broadcastTF&gt;\n\n        &lt;covariance_x&gt;0.0001&lt;/covariance_x&gt;\n        &lt;covariance_y&gt;0.0001&lt;/covariance_y&gt;\n        &lt;covariance_yaw&gt;0.01&lt;/covariance_yaw&gt;\n\n    &lt;/plugin&gt;\n\n    &lt;/gazebo&gt;\n\n&lt;/robot&gt;\n"], "quote": [], "url": "https://stackoverflow.com/questions/78917193/teleop-twist-keyboard-moving-the-bot-in-reverse", "answer": [], "answer_code": []},
{"title": "How to test a function on a ROS 2 node that requires a static transform to be published?", "time": 1723572335, "post_content": ["I want to do some unit testing on a ROS 2 node. On a particular function, the node looks up for a specific transform. If not available, it should throw an exception.\nWhile in other instances I have managed by populating some attributes of the node, I cannot do that for this instance without altering the node's source code.\nThe ideal would be to programmatically publish the static transform, inside a test_*.py, and then check the function output to assert it is the expected result, but I have been trying and cannot do it.\nAny ideas?\nI tried to create some ROS 2 nodes on my tests, but I cannot get them to communicate.\nThe node has a lot of code, but the relevant part is here:\n\ndef get_new_transform_coordinates(\n    self, mission_x, image_msg, camera_name, image_type\n):\n    try:\n        timestamp = Time.from_msg(image_msg[\"timestamp\"])\n        base_link = (\n            self.__base_link_frame_id.get_parameter_value().string_value\n        )\n\n        if self.check_time_stamp_fresh(timestamp):\n            transform = self.tf_buffer.lookup_transform(\n                base_link, image_msg[\"frame_id\"], timestamp\n            )\n            pos_x = int(\n                transform.transform.translations.x * 1000\n                + mission_x * 1000\n            )\n            pos_y = int(transform.transform.translations.y * -1000)\n        else:\n            self.get_logger().error(\n                f\"The image of type {image_type} for camera {camera_name} is too old!\"\n            )\n            pos_x = pos_y = -1\n    except TransformException as ex:\n        self.get_logger().error(\n            f\"Could not transform {camera_name} to base_link: {ex}\"\n        )\n        pos_x = pos_y = -1\n    return pos_x, pos_y"], "question_code": ["def get_new_transform_coordinates(\n    self, mission_x, image_msg, camera_name, image_type\n):\n    try:\n        timestamp = Time.from_msg(image_msg[&quot;timestamp&quot;])\n        base_link = (\n            self.__base_link_frame_id.get_parameter_value().string_value\n        )\n\n        if self.check_time_stamp_fresh(timestamp):\n            transform = self.tf_buffer.lookup_transform(\n                base_link, image_msg[&quot;frame_id&quot;], timestamp\n            )\n            pos_x = int(\n                transform.transform.translations.x * 1000\n                + mission_x * 1000\n            )\n            pos_y = int(transform.transform.translations.y * -1000)\n        else:\n            self.get_logger().error(\n                f&quot;The image of type {image_type} for camera {camera_name} is too old!&quot;\n            )\n            pos_x = pos_y = -1\n    except TransformException as ex:\n        self.get_logger().error(\n            f&quot;Could not transform {camera_name} to base_link: {ex}&quot;\n        )\n        pos_x = pos_y = -1\n    return pos_x, pos_y\n"], "quote": [], "url": "https://stackoverflow.com/questions/78867765/how-to-test-a-function-on-a-ros-2-node-that-requires-a-static-transform-to-be-pu", "answer": [], "answer_code": []},
{"title": "How to Load and Display a .sdf File as a 3D Model Using Swift, UIKit, and SceneKit?", "time": 1722315419, "post_content": ["I am trying to load a .sdf (Simulation Description Format) file and display it as a 3D model using Swift, UIKit, and SceneKit on iPad and macOS only. However, SceneKit does not directly support loading .sdf files.\nI attempted to parse the .sdf file using an XML parser, but I wasn't successful. I would prefer to load the .sdf file without converting it to another format, if possible. As I am new to Swift, I need guidance on how to achieve this\nWhat I've tried:\nUsed an XML parser to try and parse the .sdf file. Searched for any SceneKit extensions or libraries that might support .sdf files directly. Environment:\nSwift UIKit SceneKit\nbelow is my codes\nimport UIKit\nimport SceneKit\nimport PhyKit\n\nclass ViewController: UIViewController {\n    \n    override func viewDidLoad() {\n        super.viewDidLoad()\n        \n        self.view.backgroundColor = .white\n        \n        // Load and display the SDF model\n            if let sdfURL = Bundle.main.url(forResource: \"model\", withExtension: \"sdf\") {\n                    loadAndDisplaySDFModel(from: sdfURL)\n                }\n        \n            }\n        \n        \n        func loadAndDisplaySDFModel(from url: URL) {\n                // Create a new SceneKit scene\n                let scene = SCNScene()\n                \n                // Parse the SDF file and add nodes to the scene\n                if let sdfNodes = parseSDFFile(at: url) {\n                    for node in sdfNodes {\n                        scene.rootNode.addChildNode(node)\n                    }\n                }\n                \n                // Create a SceneKit view and set its scene\n                let scnView = SCNView(frame: self.view.frame)\n                scnView.scene = scene\n                \n                // Add the SceneKit view to the view controller's view\n                self.view.addSubview(scnView)\n                \n                // Allow the user to manipulate the camera\n                scnView.allowsCameraControl = true\n            scnView.autoenablesDefaultLighting = true\n            scnView.backgroundColor = .white\n            }\n        \n        func parseSDFFile(at url: URL) -> [SCNNode]? {\n                \n                guard let data = try? Data(contentsOf: url) else {\n                    print(\"Failed to read SDF file\")\n                    return nil\n                }\n                \n               \n                let parser = XMLParser(data: data)\n                let sdfParserDelegate = SDFParserDelegate()\n                parser.delegate = sdfParserDelegate\n                \n                if parser.parse() {\n                    \n                    return sdfParserDelegate.nodes\n                } else {\n                    print(\"Failed to parse SDF file\")\n                    return nil\n                }\n            }\n}\n\nclass SDFParserDelegate: NSObject, XMLParserDelegate {\n    var nodes: [SCNNode] = []\n    var currentElement: String = \"\"\n    \n    func parser(_ parser: XMLParser, didStartElement elementName: String, namespaceURI: String?, qualifiedName qName: String?, attributes attributeDict: [String : String] = [:]) {\n        currentElement = elementName\n        \n        if elementName == \"box\" {\n            let size = attributeDict[\"size\"]?.split(separator: \" \").map { CGFloat(Double($0) ?? 1.0) } ?? [1.0, 1.0, 1.0]\n            let box = SCNBox(width: size[0], height: size[1], length: size[2], chamferRadius: 0.0)\n            let material = SCNMaterial()\n            material.diffuse.contents = UIColor.red\n            box.materials = [material]\n            let boxNode = SCNNode(geometry: box)\n            nodes.append(boxNode)\n        }\n    }\n}\n\n\nThank you for your help!"], "question_code": ["import UIKit\nimport SceneKit\nimport PhyKit\n\nclass ViewController: UIViewController {\n    \n    override func viewDidLoad() {\n        super.viewDidLoad()\n        \n        self.view.backgroundColor = .white\n        \n        // Load and display the SDF model\n            if let sdfURL = Bundle.main.url(forResource: &quot;model&quot;, withExtension: &quot;sdf&quot;) {\n                    loadAndDisplaySDFModel(from: sdfURL)\n                }\n        \n            }\n        \n        \n        func loadAndDisplaySDFModel(from url: URL) {\n                // Create a new SceneKit scene\n                let scene = SCNScene()\n                \n                // Parse the SDF file and add nodes to the scene\n                if let sdfNodes = parseSDFFile(at: url) {\n                    for node in sdfNodes {\n                        scene.rootNode.addChildNode(node)\n                    }\n                }\n                \n                // Create a SceneKit view and set its scene\n                let scnView = SCNView(frame: self.view.frame)\n                scnView.scene = scene\n                \n                // Add the SceneKit view to the view controller's view\n                self.view.addSubview(scnView)\n                \n                // Allow the user to manipulate the camera\n                scnView.allowsCameraControl = true\n            scnView.autoenablesDefaultLighting = true\n            scnView.backgroundColor = .white\n            }\n        \n        func parseSDFFile(at url: URL) -&gt; [SCNNode]? {\n                \n                guard let data = try? Data(contentsOf: url) else {\n                    print(&quot;Failed to read SDF file&quot;)\n                    return nil\n                }\n                \n               \n                let parser = XMLParser(data: data)\n                let sdfParserDelegate = SDFParserDelegate()\n                parser.delegate = sdfParserDelegate\n                \n                if parser.parse() {\n                    \n                    return sdfParserDelegate.nodes\n                } else {\n                    print(&quot;Failed to parse SDF file&quot;)\n                    return nil\n                }\n            }\n}\n\nclass SDFParserDelegate: NSObject, XMLParserDelegate {\n    var nodes: [SCNNode] = []\n    var currentElement: String = &quot;&quot;\n    \n    func parser(_ parser: XMLParser, didStartElement elementName: String, namespaceURI: String?, qualifiedName qName: String?, attributes attributeDict: [String : String] = [:]) {\n        currentElement = elementName\n        \n        if elementName == &quot;box&quot; {\n            let size = attributeDict[&quot;size&quot;]?.split(separator: &quot; &quot;).map { CGFloat(Double($0) ?? 1.0) } ?? [1.0, 1.0, 1.0]\n            let box = SCNBox(width: size[0], height: size[1], length: size[2], chamferRadius: 0.0)\n            let material = SCNMaterial()\n            material.diffuse.contents = UIColor.red\n            box.materials = [material]\n            let boxNode = SCNNode(geometry: box)\n            nodes.append(boxNode)\n        }\n    }\n}\n\n"], "quote": [], "url": "https://stackoverflow.com/questions/78809865/how-to-load-and-display-a-sdf-file-as-a-3d-model-using-swift-uikit-and-scenek", "answer": [], "answer_code": []},
{"title": "Convert a ros2 topic to a v4l2 virtual camera", "time": 1720540275, "post_content": ["I am trying to convert a ros2 topic which named \"/serit\" to a v4l2 virtual camera which named \"/dev/video4\"\ni have writen this code\n#include <opencv2/opencv.hpp>\n#include <fcntl.h>\n#include <unistd.h>\n#include <sys/ioctl.h>\n#include <linux/videodev2.h>\n#include <rclcpp/rclcpp.hpp>\n#include <sensor_msgs/msg/image.hpp>\n#include <cv_bridge/cv_bridge.h>\n#include <opencv2/highgui/highgui.hpp>\n#include <iostream>\n#include <errno.h>\n#include <cstring>\n\nusing namespace std;\nusing namespace cv;\n\nbool writeToV4L2VirtualCamera(cv::Mat& image, const char* device = \"/dev/video4\") {\n    // Open the V4L2 device\n    int fd = open(device, O_RDWR);\n    if (fd == -1) {\n        std::cerr << \"Error: Could not open V4L2 device. Error code: \" << errno << std::endl;\n        return false;\n    }\n\n    // Get the current format of the device\n    struct v4l2_format fmt;\n    memset(&fmt, 0, sizeof(fmt));\n    fmt.type = V4L2_BUF_TYPE_VIDEO_OUTPUT;\n    if (ioctl(fd, VIDIOC_G_FMT, &fmt) == -1) {\n        std::cerr << \"Error: Could not get format. Error code: \" << errno << std::endl;\n        close(fd);\n        return false;\n    }\n\n    // Print the current format\n    std::cout << \"Current format - Width: \" << fmt.fmt.pix.width\n              << \", Height: \" << fmt.fmt.pix.height\n              << \", Pixelformat: \" << (char*)&fmt.fmt.pix.pixelformat\n              << \", Field: \" << fmt.fmt.pix.field << std::endl;\n\n    // Convert the image to the format required by V4L2\n    cv::Mat yuv_image;\n    cv::cvtColor(image, yuv_image, cv::COLOR_BGR2YUV_I420);\n\n    // Write the image data to the device\n    size_t bufferSize = yuv_image.total() * yuv_image.elemSize();\n    if (write(fd, yuv_image.data, bufferSize) == -1) {\n        std::cerr << \"Error: Could not write to V4L2 device. Error code: \" << errno << \" - \" << strerror(errno) << std::endl;\n        close(fd);\n        return false;\n    }  \n\n    // Close the device\n    close(fd);\n    return true;\n}\n\nclass ImageSubscriber : public rclcpp::Node {\npublic:\n    ImageSubscriber() : Node(\"image_subscriber\") {\n        subscription_ = this->create_subscription<sensor_msgs::msg::Image>(\n            \"/serit\", 10, std::bind(&ImageSubscriber::listener_callback, this, std::placeholders::_1));\n    }\n\nprivate:\n    void listener_callback(const sensor_msgs::msg::Image::SharedPtr msg) {\n        cv::Mat cv_image = cv_bridge::toCvCopy(msg, \"bgr8\")->image;\n\n        // Specify new size directly\n        cv::Size newSize(640, 480); // Example: resize to 640x480\n\n        cv::Mat resizedImage;\n        cv::resize(cv_image, resizedImage, newSize);\n\n        if (!writeToV4L2VirtualCamera(resizedImage)) {\n            std::cerr << \"Error: Failed to write image to V4L2 device\" << std::endl;\n        }\n\n        imshow(\"Image\", resizedImage);\n        waitKey(1);\n\n        namedWindow(\"Image\", WINDOW_KEEPRATIO);\n    }\n\n    rclcpp::Subscription<sensor_msgs::msg::Image>::SharedPtr subscription_;\n};\n\nint main(int argc, char* argv[]) {\n    rclcpp::init(argc, argv);\n    auto node = std::make_shared<ImageSubscriber>();\n    rclcpp::spin(node);\n    rclcpp::shutdown();\n    return 0;\n}\n\n\nBut it didn't work out.\nI got this error:\n\nCurrent format - Width: 640, Height: 480, Pixelformat: YU12, Field: 1\nError: Could not write to V4L2 device. Error code: 22 - Invalid argument\nError: Failed to write image to V4L2 device\n\nAt every image that I am trying to convert.\nCan you help me out, please?\nonvert a ros2 topic named \"/serit\" to a v4l2 virtual camera named \"/dev/video4\"."], "question_code": ["#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/ioctl.h&gt;\n#include &lt;linux/videodev2.h&gt;\n#include &lt;rclcpp/rclcpp.hpp&gt;\n#include &lt;sensor_msgs/msg/image.hpp&gt;\n#include &lt;cv_bridge/cv_bridge.h&gt;\n#include &lt;opencv2/highgui/highgui.hpp&gt;\n#include &lt;iostream&gt;\n#include &lt;errno.h&gt;\n#include &lt;cstring&gt;\n\nusing namespace std;\nusing namespace cv;\n\nbool writeToV4L2VirtualCamera(cv::Mat&amp; image, const char* device = &quot;/dev/video4&quot;) {\n    // Open the V4L2 device\n    int fd = open(device, O_RDWR);\n    if (fd == -1) {\n        std::cerr &lt;&lt; &quot;Error: Could not open V4L2 device. Error code: &quot; &lt;&lt; errno &lt;&lt; std::endl;\n        return false;\n    }\n\n    // Get the current format of the device\n    struct v4l2_format fmt;\n    memset(&amp;fmt, 0, sizeof(fmt));\n    fmt.type = V4L2_BUF_TYPE_VIDEO_OUTPUT;\n    if (ioctl(fd, VIDIOC_G_FMT, &amp;fmt) == -1) {\n        std::cerr &lt;&lt; &quot;Error: Could not get format. Error code: &quot; &lt;&lt; errno &lt;&lt; std::endl;\n        close(fd);\n        return false;\n    }\n\n    // Print the current format\n    std::cout &lt;&lt; &quot;Current format - Width: &quot; &lt;&lt; fmt.fmt.pix.width\n              &lt;&lt; &quot;, Height: &quot; &lt;&lt; fmt.fmt.pix.height\n              &lt;&lt; &quot;, Pixelformat: &quot; &lt;&lt; (char*)&amp;fmt.fmt.pix.pixelformat\n              &lt;&lt; &quot;, Field: &quot; &lt;&lt; fmt.fmt.pix.field &lt;&lt; std::endl;\n\n    // Convert the image to the format required by V4L2\n    cv::Mat yuv_image;\n    cv::cvtColor(image, yuv_image, cv::COLOR_BGR2YUV_I420);\n\n    // Write the image data to the device\n    size_t bufferSize = yuv_image.total() * yuv_image.elemSize();\n    if (write(fd, yuv_image.data, bufferSize) == -1) {\n        std::cerr &lt;&lt; &quot;Error: Could not write to V4L2 device. Error code: &quot; &lt;&lt; errno &lt;&lt; &quot; - &quot; &lt;&lt; strerror(errno) &lt;&lt; std::endl;\n        close(fd);\n        return false;\n    }  \n\n    // Close the device\n    close(fd);\n    return true;\n}\n\nclass ImageSubscriber : public rclcpp::Node {\npublic:\n    ImageSubscriber() : Node(&quot;image_subscriber&quot;) {\n        subscription_ = this-&gt;create_subscription&lt;sensor_msgs::msg::Image&gt;(\n            &quot;/serit&quot;, 10, std::bind(&amp;ImageSubscriber::listener_callback, this, std::placeholders::_1));\n    }\n\nprivate:\n    void listener_callback(const sensor_msgs::msg::Image::SharedPtr msg) {\n        cv::Mat cv_image = cv_bridge::toCvCopy(msg, &quot;bgr8&quot;)-&gt;image;\n\n        // Specify new size directly\n        cv::Size newSize(640, 480); // Example: resize to 640x480\n\n        cv::Mat resizedImage;\n        cv::resize(cv_image, resizedImage, newSize);\n\n        if (!writeToV4L2VirtualCamera(resizedImage)) {\n            std::cerr &lt;&lt; &quot;Error: Failed to write image to V4L2 device&quot; &lt;&lt; std::endl;\n        }\n\n        imshow(&quot;Image&quot;, resizedImage);\n        waitKey(1);\n\n        namedWindow(&quot;Image&quot;, WINDOW_KEEPRATIO);\n    }\n\n    rclcpp::Subscription&lt;sensor_msgs::msg::Image&gt;::SharedPtr subscription_;\n};\n\nint main(int argc, char* argv[]) {\n    rclcpp::init(argc, argv);\n    auto node = std::make_shared&lt;ImageSubscriber&gt;();\n    rclcpp::spin(node);\n    rclcpp::shutdown();\n    return 0;\n}\n\n", "\nCurrent format - Width: 640, Height: 480, Pixelformat: YU12, Field: 1\nError: Could not write to V4L2 device. Error code: 22 - Invalid argument\nError: Failed to write image to V4L2 device\n"], "quote": [], "url": "https://stackoverflow.com/questions/78726597/convert-a-ros2-topic-to-a-v4l2-virtual-camera", "answer": [], "answer_code": []},
{"title": "No Point Cloud Output When using depth_image_proc/point_cloud_xyzrgb in ROS", "time": 1720166896, "post_content": ["I'm trying to publish a /calculated_veg topic of type sensor_msgs/Image into a point cloud named /calculated_veg/points using the depth_image_proc/point_cloud_xyzrgb package in ROS, but I am not getting any point cloud output. Here is my launch file:\n<launch>\n  <!-- Start the nodelet manager -->\n  <node pkg=\"nodelet\" type=\"nodelet\" name=\"nodelet_manager\" args=\"manager\"\n    output=\"screen\"/>\n  \n  <!-- Load the point_cloud_xyzrgb nodelet -->\n  <node pkg=\"nodelet\" type=\"nodelet\" name=\"point_cloud_xyzrgb\" args=\"load\n      depth_image_proc/point_cloud_xyzrgb nodelet_manager\" output=\"screen\">\n    <remap from=\"rgb/camera_info\" to=\"/camera/color/camera_info\"/>\n    <remap from=\"rgb/image_rect_color\" to=\"/calculated_veg\"/>\n    <remap from=\"depth_registered/image_rect\"\n      to=\"/camera/aligned_depth_to_color/image_raw\"/>\n    <remap from=\"depth_registered/points\" to=\"/calculated_veg/points\"/>\n  </node>\n</launch>\n\nAfter running this launch file, I do not see any point cloud being published on the /calculated_veg/points topic. I have verified that the /calculated_veg topic is publishing images correctly. Here is an example of the /calculated_veg image:\nan example of the /calculated_veg image\nAdditional Information:\n\nROS Distribution: ROS1 Noetic\nOperating System: Ubuntu Focal (20.04)\nThe /calculated_veg topic is calculated using the RGB image and the infrared image, which are already aligned to the RGB camera frame.\nAll images are obtained from the Intel RealSense D435i camera. To execute the camera, I use the following command:\n\nroslaunch realsense2_camera rs_camera.launch enable_infra1:=true align_depth:=true\n\nCan anyone help me identify what might be going wrong or suggest troubleshooting steps to resolve this issue? Thank you!"], "question_code": ["/calculated_veg", "sensor_msgs/Image", "/calculated_veg/points", "depth_image_proc/point_cloud_xyzrgb", "&lt;launch&gt;\n  &lt;!-- Start the nodelet manager --&gt;\n  &lt;node pkg=&quot;nodelet&quot; type=&quot;nodelet&quot; name=&quot;nodelet_manager&quot; args=&quot;manager&quot;\n    output=&quot;screen&quot;/&gt;\n  \n  &lt;!-- Load the point_cloud_xyzrgb nodelet --&gt;\n  &lt;node pkg=&quot;nodelet&quot; type=&quot;nodelet&quot; name=&quot;point_cloud_xyzrgb&quot; args=&quot;load\n      depth_image_proc/point_cloud_xyzrgb nodelet_manager&quot; output=&quot;screen&quot;&gt;\n    &lt;remap from=&quot;rgb/camera_info&quot; to=&quot;/camera/color/camera_info&quot;/&gt;\n    &lt;remap from=&quot;rgb/image_rect_color&quot; to=&quot;/calculated_veg&quot;/&gt;\n    &lt;remap from=&quot;depth_registered/image_rect&quot;\n      to=&quot;/camera/aligned_depth_to_color/image_raw&quot;/&gt;\n    &lt;remap from=&quot;depth_registered/points&quot; to=&quot;/calculated_veg/points&quot;/&gt;\n  &lt;/node&gt;\n&lt;/launch&gt;\n", "/calculated_veg/points", "/calculated_veg", "/calculated_veg", "roslaunch realsense2_camera rs_camera.launch enable_infra1:=true align_depth:=true\n"], "quote": [], "url": "https://stackoverflow.com/questions/78710356/no-point-cloud-output-when-using-depth-image-proc-point-cloud-xyzrgb-in-ros", "answer": [], "answer_code": []},
{"title": "ROS2 Generating Odometry with GPS and IMU Data and Visualizing in RViz", "time": 1717664895, "post_content": ["I'm a new robot developer and I am learning ROS2, and I'm working on a project where I want to make a robot go straight to a specific area using GPS and IMU data. Since there won't be any obstacles around the robot, I don't need additional sensors like LIDAR or cameras. However, the biggest challenge I'm facing is that I can't generate odometry with GPS and IMU data, and I can't visualize this data in RViz.\nCurrently, I'm using GPS and IMU sensors to determine the robot's position and orientation. However, I'm struggling to convert this data into odometry and then visualize it using RViz. I need your help to figure out the steps to ensure the robot goes smoothly to a specific area without odometry.\nI tried ekf with robot_localization but imu and gps data did not enter odometry. I tried to write it myself without success\nekf.yaml file:\n# For parameter descriptions, please refer to the template parameter files for each node.\n\nekf_filter_node_odom:\n  ros__parameters:\n    frequency: 30.0\n    two_d_mode: true # Recommended to use 2d mode for nav2 in mostly planar environments\n    print_diagnostics: true\n    debug: false\n    publish_tf: true\n\n    map_frame: map\n    odom_frame: odom\n    base_link_frame: base_link # the frame id used by the turtlebot's diff drive plugin\n    world_frame: odom\n\n    odom0: gps\n    odom0_config: [false, false, false,\n                  false, false, false,\n                  true,  true,  true,\n                  false, false, true,\n                  false, false, false]\n    odom0_queue_size: 10\n    odom0_differential: false\n    odom0_relative: false\n\n    imu0: imu\n    imu0_config: [false, false, false,\n                  false,  false,  true,\n                  false, false, false,\n                  false,  false,  false,\n                  false,  false,  false]\n    imu0_differential: false  # If using a real robot you might want to set this to true, since usually absolute measurements from real imu's are not very accurate\n    imu0_relative: false\n    imu0_queue_size: 10\n    imu0_remove_gravitational_acceleration: true\n\n    use_control: false\n\n    process_noise_covariance: [1e-3, 0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    1e-3,  0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    1e-3,  0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.3,   0.0,    0.0,     0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.3,   0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.01,  0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.5,    0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.5,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.1,   0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.3,   0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.3,   0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.3,   0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.3,   0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.3,   0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.3]\n\nekf_filter_node_map:\n  ros__parameters:\n    frequency: 30.0\n    two_d_mode: true  # Recommended to use 2d mode for nav2 in mostly planar environments\n    print_diagnostics: true\n    debug: false\n    publish_tf: true\n\n    map_frame: map\n    odom_frame: odom\n    base_link_frame: base_link # the frame id used by the turtlebot's diff drive plugin\n    world_frame: map\n\n    # odom0: gps\n    # odom0_config: [false, false, false,\n    #               false, false, false,\n    #               true,  true,  true,\n    #               false, false, true,\n    #               false, false, false]\n    # odom0_queue_size: 10\n    # odom0_differential: false\n    # odom0_relative: false\n\n    odom0: gps\n    odom0_config: [true,  true,  false,\n                  false, false, false,\n                  true,  true,  true,\n                  false, false, true,\n                  false, false, false]\n    odom0_queue_size: 10\n    odom0_differential: false\n    odom0_relative: false\n\n    imu0: imu\n    imu0_config: [false, false, false,\n                  false,  false,  true,\n                  false, false, false,\n                  false,  false,  false,\n                  false,  false,  false]\n    imu0_differential: false  # If using a real robot you might want to set this to true, since usually absolute measurements from real imu's are not very accurate\n    imu0_relative: false\n    imu0_queue_size: 10\n    imu0_remove_gravitational_acceleration: true\n\n    use_control: false\n\n    process_noise_covariance: [1.0,   0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    1.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    1e-3,   0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.3,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.3,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.01,   0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.5,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.5,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.1,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.3,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.3,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.3,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.3,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.3,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.3]\n\nnavsat_transform:\n  ros__parameters:\n    frequency: 30.0\n    delay: 3.0\n    magnetic_declination_radians: 0.0\n    yaw_offset: 0.0\n    zero_altitude: true\n    broadcast_utm_transform: true\n    publish_filtered_gps: true\n    use_odometry_yaw: true\n    wait_for_datum: false \n\nand launch.py file:\nimport os\nfrom ament_index_python.packages import get_package_share_directory\n\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import Command, LaunchConfiguration\n\nfrom launch_ros.actions import Node\nfrom launch_ros.parameter_descriptions import ParameterValue\nimport launch_ros\n\ndef generate_launch_description():\n   \n    start_ekf_local = Node(\n        package='robot_localization',\n        executable='ekf_node',\n        name='ekf_filter_node_odom',\n        output='screen',\n        parameters=[os.path.join(pkg_share, 'config/dual_ekf_navsat.yaml')],\n        remappings=[('odometry/filtered', 'odometry/local')]  \n        )\n    \n    start_ekf_global = Node(\n        package='robot_localization',\n        executable='ekf_node',\n        name='ekf_filter_node_map',\n        output='screen',\n        parameters=[os.path.join(pkg_share, 'config/dual_ekf_navsat.yaml')],\n        remappings=[('odometry/filtered', 'odometry/global')]\n        )\n    \n    navsat_transform= Node(\n        package='robot_localization',\n        executable='navsat_transform_node',\n        name='navsat_transform',\n        output='screen',\n        parameters=[os.path.join(pkg_share, 'config/dual_ekf_navsat.yaml')],\n        remappings=[('gps/fix', 'gps')]\n        )\n\n    return LaunchDescription([\n        start_ekf_local,\n        start_ekf_global,\n        navsat_transform\n    ])\n\nrqt-graph"], "question_code": ["# For parameter descriptions, please refer to the template parameter files for each node.\n\nekf_filter_node_odom:\n  ros__parameters:\n    frequency: 30.0\n    two_d_mode: true # Recommended to use 2d mode for nav2 in mostly planar environments\n    print_diagnostics: true\n    debug: false\n    publish_tf: true\n\n    map_frame: map\n    odom_frame: odom\n    base_link_frame: base_link # the frame id used by the turtlebot's diff drive plugin\n    world_frame: odom\n\n    odom0: gps\n    odom0_config: [false, false, false,\n                  false, false, false,\n                  true,  true,  true,\n                  false, false, true,\n                  false, false, false]\n    odom0_queue_size: 10\n    odom0_differential: false\n    odom0_relative: false\n\n    imu0: imu\n    imu0_config: [false, false, false,\n                  false,  false,  true,\n                  false, false, false,\n                  false,  false,  false,\n                  false,  false,  false]\n    imu0_differential: false  # If using a real robot you might want to set this to true, since usually absolute measurements from real imu's are not very accurate\n    imu0_relative: false\n    imu0_queue_size: 10\n    imu0_remove_gravitational_acceleration: true\n\n    use_control: false\n\n    process_noise_covariance: [1e-3, 0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    1e-3,  0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    1e-3,  0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.3,   0.0,    0.0,     0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.3,   0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.01,  0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.5,    0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.5,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.1,   0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.3,   0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.3,   0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.3,   0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.3,   0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.3,   0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.3]\n\nekf_filter_node_map:\n  ros__parameters:\n    frequency: 30.0\n    two_d_mode: true  # Recommended to use 2d mode for nav2 in mostly planar environments\n    print_diagnostics: true\n    debug: false\n    publish_tf: true\n\n    map_frame: map\n    odom_frame: odom\n    base_link_frame: base_link # the frame id used by the turtlebot's diff drive plugin\n    world_frame: map\n\n    # odom0: gps\n    # odom0_config: [false, false, false,\n    #               false, false, false,\n    #               true,  true,  true,\n    #               false, false, true,\n    #               false, false, false]\n    # odom0_queue_size: 10\n    # odom0_differential: false\n    # odom0_relative: false\n\n    odom0: gps\n    odom0_config: [true,  true,  false,\n                  false, false, false,\n                  true,  true,  true,\n                  false, false, true,\n                  false, false, false]\n    odom0_queue_size: 10\n    odom0_differential: false\n    odom0_relative: false\n\n    imu0: imu\n    imu0_config: [false, false, false,\n                  false,  false,  true,\n                  false, false, false,\n                  false,  false,  false,\n                  false,  false,  false]\n    imu0_differential: false  # If using a real robot you might want to set this to true, since usually absolute measurements from real imu's are not very accurate\n    imu0_relative: false\n    imu0_queue_size: 10\n    imu0_remove_gravitational_acceleration: true\n\n    use_control: false\n\n    process_noise_covariance: [1.0,   0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    1.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    1e-3,   0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.3,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.3,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.01,   0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.5,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.5,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.1,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.3,    0.0,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.3,    0.0,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.3,    0.0,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.3,    0.0,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.3,    0.0,\n                              0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.0,     0.0,     0.0,    0.0,    0.0,    0.0,    0.0,    0.0,    0.3]\n\nnavsat_transform:\n  ros__parameters:\n    frequency: 30.0\n    delay: 3.0\n    magnetic_declination_radians: 0.0\n    yaw_offset: 0.0\n    zero_altitude: true\n    broadcast_utm_transform: true\n    publish_filtered_gps: true\n    use_odometry_yaw: true\n    wait_for_datum: false \n", "import os\nfrom ament_index_python.packages import get_package_share_directory\n\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import Command, LaunchConfiguration\n\nfrom launch_ros.actions import Node\nfrom launch_ros.parameter_descriptions import ParameterValue\nimport launch_ros\n\ndef generate_launch_description():\n   \n    start_ekf_local = Node(\n        package='robot_localization',\n        executable='ekf_node',\n        name='ekf_filter_node_odom',\n        output='screen',\n        parameters=[os.path.join(pkg_share, 'config/dual_ekf_navsat.yaml')],\n        remappings=[('odometry/filtered', 'odometry/local')]  \n        )\n    \n    start_ekf_global = Node(\n        package='robot_localization',\n        executable='ekf_node',\n        name='ekf_filter_node_map',\n        output='screen',\n        parameters=[os.path.join(pkg_share, 'config/dual_ekf_navsat.yaml')],\n        remappings=[('odometry/filtered', 'odometry/global')]\n        )\n    \n    navsat_transform= Node(\n        package='robot_localization',\n        executable='navsat_transform_node',\n        name='navsat_transform',\n        output='screen',\n        parameters=[os.path.join(pkg_share, 'config/dual_ekf_navsat.yaml')],\n        remappings=[('gps/fix', 'gps')]\n        )\n\n    return LaunchDescription([\n        start_ekf_local,\n        start_ekf_global,\n        navsat_transform\n    ])\n"], "quote": [], "url": "https://stackoverflow.com/questions/78585578/ros2-generating-odometry-with-gps-and-imu-data-and-visualizing-in-rviz", "answer": [], "answer_code": []},
{"title": "Subscriber doesn't receive any messages", "time": 1717654338, "post_content": ["I am currently simulating a mecanum wheel robot in Gazebo. My goal is to control the individual wheel velocities based on a given target point. The issue I'm facing is that although I can control the velocities using the target point, the odometry subscriber I created is not updating the robot's coordinates in real-time, which is causing problems in the simulation.\nBelow are three files, including a Python file for controlling the movement of the car,a URDF file for the car, and controller.yaml\nPython file for controlling the movement of the car\n#! /usr/bin/env python\n\nimport traceback\nimport rospy\nfrom geometry_msgs.msg import Twist, Point\nfrom nav_msgs.msg import Odometry\nfrom std_msgs.msg import Float64\nfrom sensor_msgs.msg import LaserScan\nimport numpy as np\nimport math\nfrom tf import transformations\nfrom std_srvs.srv import *\n\nposition_ = Point(x=0.0, y=2.0, z=1.0)\nyaw_ = 0\n#goal\ndesired_position_ = Point()\ndesired_position_.x = 5\ndesired_position_.y = -8\ndesired_position_.z = 0\n\nstate_= 0\nactive_ = False\n# parameters\nyaw_precision_ = math.pi / 90 # +/- 2 degree allowed\ndist_precision_ = 0.3\n\n\nwidth = {\"fr\": 0.275, \"fl\": 0.275, \"rr\": 0.275, \"rl\": 0.275}\nlength = {\"fr\": 0.575, \"fl\": 0.575, \"rr\": 0.575, \"rl\": 0.575}\n\n\nfr_pub = None\nfl_pub = None\nrr_pub = None\nrl_pub = None\npub = None\nvf = 0\nvb = 0\nvl = 0\nvr = 0\n\n\nmat = np.matrix([[1, 1, (width[\"fr\"] + length[\"fr\"])],\n                 [1, -1, -(width[\"fl\"] + length[\"fl\"])],\n                 [1, -1, (width[\"rr\"] + length[\"rr\"])],\n                 [1, 1, -(width[\"rl\"] + length[\"rl\"])]])\n                 \n\ncmd_vel = np.matrix([0, 0, 0])\n\ndef cmdVelCB(data):\n    global cmd_vel\n    cmd_vel = np.matrix([data.linear.x, data.linear.y, data.angular.z])\n    \ndef normalize_angle(angle):\n    if (math.fabs(angle) > math.pi):\n        angle = angle -(2 * math.pi * angle) / (math.fabs(angle))\n    return angle\n    \ndef change_state(state):\n    global state_\n    state_ = state\n    print ('State changed to [%s]' % state_)\n\ndef go_to_point_switch(req):\n    global active_\n    active_ = req.data\n    res = SetBoolResponse()\n    res.success = True\n    res.message = 'Done'\n    return res\n\ndef go_to_point_omni(des_pos): # fixed the angle between car and goal\n    global yaw_, cmd_vel, yaw_precision_, state_, fr,fl, rl, rr, vb, vf, vl, vr, pub\n    print(\"vf:\", vf)\n    print(\"vb:\", vb)\n    print(\"vl:\", vl)\n    print(\"vr:\", vr)\n\n    err_yaw = normalize_angle(des_pos.z - yaw_)\n    err_pos_y = des_pos.y - position_.y\n    err_pos_x = des_pos.x - position_.x\n    robot_err_x = np.cos(yaw_) * err_pos_x + np.sin(yaw_) * err_pos_y\n    robot_err_y = -np.sin(yaw_) * err_pos_x + np.cos(yaw_) * err_pos_y\n    print(\"des_pos.x:\", des_pos.x)\n    print(\"des_pos.y:\", des_pos.y)\n    print(\"position_.x:\", position_.x)\n    print(\"position_.y\", position_.x)\n    print(\"des_pos.z:\", des_pos.z)\n    print(\"yaw_:\", yaw_)\n\n    print(\"err_yaw:\", err_yaw)\n    print(\"err_pos_x:\", err_pos_x)\n    print(\"err_pos_y:\", err_pos_y)\n    print(\"robot_err_x\", robot_err_x)\n    print(\"robot_err_y:\", robot_err_y)\n\n    twist_msg = Twist()\n    twist_msg.angular.z = 0\n    print(\"x,y,z:\", twist_msg.linear.x,twist_msg.linear.y,twist_msg.angular.z)\n    there_is_error = False\n    if math.fabs(robot_err_y) > dist_precision_:\n        if robot_err_y > 0:\n            twist_msg.linear.y = 5 + vr\n        else:\n            twist_msg.linear.y = -5 + vl\n        there_is_error = True\n        #twist_msg.angular.z = -0.3 if err_yaw > 0 else 0.3\n    if math.fabs(robot_err_x) > dist_precision_:\n        if robot_err_x > 0:\n            twist_msg.linear.x = 5 + vf\n        else:\n            twist_msg.linear.x = -5 + vb\n        there_is_error = True \n\n    cmd_vel = np.matrix([twist_msg.linear.x, twist_msg.linear.y, twist_msg.angular.z])\n    print(\"cmd_vel\", cmd_vel)\n    wheel_vel = (np.dot(mat, cmd_vel.T).A1).tolist()\n\n    wv = Float64()\n    wv.data = wheel_vel[0]\n    fr_pub.publish(wv)\n    wv.data = wheel_vel[1]\n    fl_pub.publish(wv)\n    wv.data = wheel_vel[2]\n    rr_pub.publish(wv)\n    wv.data = wheel_vel[3]\n    rl_pub.publish(wv)\n    pub.publish(twist_msg)\n    print(\"there_is_error: \", there_is_error)\n\n    if not there_is_error :\n        print ('Arrivaled')\n        change_state(1)\n\ndef LidarCallback(msg):\n    global vf, vb, vl, vr\n    dist_front = msg.ranges[180]\n    dist_right = msg.ranges[90]\n    dist_left = msg.ranges[270]\n    dist_back = msg.ranges[0]\n    safe_distance = 0.6\n\n\n    if dist_front < safe_distance:\n        vf = -0.5  \n    else:\n        vf = 0.5\n\n    if dist_right < safe_distance:\n        vr = -0.5  \n    else:\n        vr = 0.5\n\n    if dist_left < safe_distance:\n        vl = -0.5  \n    else:\n        vl = 0.5\n    if dist_back < safe_distance:\n        vb = -0.5 \n    else: \n        vb = 0.5\n\n\ndef done():\n    global cmd_vel,fr,fl, rl, rr, pub\n    twist_msg = Twist()\n    twist_msg.linear.x = 0\n    twist_msg.linear.y = 0\n    twist_msg.angular.z = 0\n    cmd_vel = np.matrix([twist_msg.linear.x , twist_msg.linear.y, twist_msg.angular.z])\n    # pub.publish(twist_msg)\n    wheel_vel = (np.dot(mat, cmd_vel.T).A1).tolist()\n    wv = Float64()\n    wv.data = wheel_vel[0]\n    fr_pub.publish(wv)\n    wv.data = wheel_vel[1]\n    fl_pub.publish(wv)\n    wv.data = wheel_vel[2]\n    rr_pub.publish(wv)\n    wv.data = wheel_vel[3]\n    rl_pub.publish(wv)\n\ndef clbk_odom(msg):\n    global position_\n    global yaw_\n    \n    # position\n    position_ = msg.pose.pose.position\n    # yaw\n    quaternion = (\n        msg.pose.pose.orientation.x,\n        msg.pose.pose.orientation.y,\n        msg.pose.pose.orientation.z,\n        msg.pose.pose.orientation.w)\n    euler = transformations.euler_from_quaternion(quaternion)\n    yaw_ = euler[2]\n    rospy.loginfo(\"Received PoseStamped message\")\n    rospy.loginfo(\"Position: x=%f, y=%f, z=%f\", position_.x, position_.y, position_.z)\n    rospy.loginfo(\"Orientation: x=%f, y=%f, z=%f, w=%f\", msg.pose.pose.orientation.x, msg.pose.pose.orientation.y, msg.pose.pose.orientation.z, msg.pose.pose.orientation.w)\n\ndef odom_callback(msg):\n    print(\"here\")\n    rospy.loginfo(\"Received odometry message:\")\n    rospy.loginfo(\"Header: %s\", msg.header)\n    rospy.loginfo(\"Child frame ID: %s\", msg.child_frame_id)\n    rospy.loginfo(\"Pose: %s\", msg.pose)\n    rospy.loginfo(\"Twist: %s\", msg.twist)\n\ndef process():\n    global fr_pub, fl_pub, rr_pub, rl_pub, state_, active_ ,pub\n\n    rospy.init_node('test_mecanum_robot', anonymous=False)\n    # loop_rate = rospy.Rate(10)\n    #for velocity\n    fr_pub = rospy.Publisher('/front_right_controller/command', Float64, queue_size=10)\n    fl_pub = rospy.Publisher('/front_left_controller/command', Float64, queue_size=10)\n    rr_pub = rospy.Publisher('/rear_right_controller/command', Float64, queue_size=10)\n    rl_pub = rospy.Publisher('/rear_left_controller/command', Float64, queue_size=10)\n    srv = rospy.Service('/switch', SetBool, go_to_point_switch)\n    rospy.Subscriber('/cmd_vel', Twist, cmdVelCB, queue_size=10)\n    rospy.Subscriber('/agv/laser/scan', LaserScan, LidarCallback, queue_size=10)\n    #for position\n    pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)\n    rospy.Subscriber('/odom', Odometry, odom_callback, queue_size=10)\n    rate = rospy.Rate(20)\n    while not rospy.is_shutdown():\n        rospy.loginfo(\"Before checking active_\")\n        if not active_:\n            rospy.loginfo(\"active_ is False\")\n            continue\n        else:\n            rospy.loginfo(\"After checking active_\")\n            if state_ == 0:\n                rospy.loginfo(\"State_ 0\")\n                go_to_point_omni(desired_position_)\n            elif state_ == 1: #arrival\n                rospy.loginfo(\"State_ 1\")\n                done()\n                pass\n            else:\n                rospy.loginfo(\"bye\")\n                rospy.logerr('Unknown state!')\n                pass\n        rate.sleep()\n\nif __name__ == '__main__':\n    try:\n        process()\n    except Exception as ex:\n        print(traceback.print_exc())\n\n\nURDF file for the car\n<?xml version=\"1.0\" ?>\n<robot name=\"mecanum_wheel_robot\" xmlns:xacro=\"http://ros.org/wiki/xacro\">\n\n <xacro:include filename=\"$(find ros_car)/urdf/mecanum_wheel_macro.xacro\" />\n <xacro:include filename=\"$(find ros_car)/urdf/sensor.gazebo.xacro\" />\n  \n <link name=\"dummy\"/>\n <joint name=\"dummy_joint\" type=\"fixed\">\n    <parent link=\"dummy\"/>\n    <child link=\"base_link\"/>\n </joint>\n  \n  <link name=\"base_link\">\n    <visual>\n      <geometry>\n        <box size=\"0.7 0.4 0.3\" />\n      </geometry>\n    </visual>\n    <collision>\n      <geometry>\n        <box size=\"0.7 0.4 0.3\" />\n      </geometry>\n    </collision>\n\n    <inertial>\n      <origin xyz=\"0 0 0\" />\n      <mass value=\"10.0\" />\n      <inertia ixx=\"0.83333\" ixy=\"0.0\" ixz=\"0.0\"\n              iyy=\"1.9333\" iyz=\"0.0\"\n              izz=\"2.1667\" />\n    </inertial>\n    \n  </link>\n\n\n  <link name=\"hokuyo\">\n     <visual>\n        <origin xyz=\"0.0 0 0\" rpy=\" 0 0 0\"/>\n        <geometry>\n          <mesh filename=\"package://ros_car/mesh/rplidar.dae\"/>\n        </geometry>\n     </visual>\n     <collision>\n        <origin xyz=\"0.0 0 0\" rpy=\" 0 0 0\"/>\n        <geometry>\n          <box size=\"0.2 0.2 0.2\"/>\n        </geometry>\n     </collision>\n     <inertial>\n        <mass value=\"0.1\"/>\n        <origin xyz=\"0.0 0 0\" rpy=\" 0 0 0\"/>\n        <inertia\n            ixx=\"1e-6\" ixy=\"0\" ixz=\"0\"\n            iyy=\"1e-6\" iyz=\"0\"\n            izz=\"1e-6\"\n        />\n     </inertial>\n  </link>\n  \n  <gazebo reference=\"base_link\">\n    <mu1 value=\"0.6\"/>\n    <mu2 value=\"0.6\"/>\n    <kp value=\"10000000.0\" />\n    <kd value=\"1.0\" />\n    <fdir1 value=\"0 1 0\"/>\n  </gazebo>\n\n  <xacro:mecanum_wheel name=\"front_right\" side=\"1\"  interface=\"hardware_interface/EffortJointInterface\"/>\n  <xacro:mecanum_wheel name=\"front_left\"  side=\"-1\" interface=\"hardware_interface/EffortJointInterface\"/>\n  <xacro:mecanum_wheel name=\"rear_right\"  side=\"-1\" interface=\"hardware_interface/EffortJointInterface\"/>\n  <xacro:mecanum_wheel name=\"rear_left\"   side=\"1\"  interface=\"hardware_interface/EffortJointInterface\"/>\n\n  <joint name=\"front_right_wheel_joint\" type=\"continuous\">    \n    <origin xyz=\"0.3 -0.25 -0.1\" rpy=\"0 0 ${pi/2}\" />\n    <axis xyz=\"1 0 0\" />\n    <parent link=\"base_link\" />\n    <child link=\"front_right_wheel_link\" />    \n  </joint>\n\n  <joint name=\"front_left_wheel_joint\" type=\"continuous\">\n    <origin xyz=\"0.3 0.25 -0.1\" rpy=\"0 0 ${pi/2}\" />\n    <axis xyz=\"1 0 0\" />\n    <parent link=\"base_link\" />\n    <child link=\"front_left_wheel_link\" />\n  </joint>\n\n  <joint name=\"rear_right_wheel_joint\" type=\"continuous\">\n    <origin xyz=\"-0.3 -0.25 -0.1\" rpy=\"0 0 ${pi/2}\" />\n    <axis xyz=\"1 0 0\" />\n    <parent link=\"base_link\" />\n    <child link=\"rear_right_wheel_link\" />\n  </joint>\n\n  <joint name=\"rear_left_wheel_joint\" type=\"continuous\">\n    <origin xyz=\"-0.3 0.25 -0.1\" rpy=\"0 0 ${pi/2}\" />\n    <axis xyz=\"1 0 0\" />\n    <parent link=\"base_link\" />\n    <child link=\"rear_left_wheel_link\" />\n  </joint>\n\n\n  <joint name=\"hokuyo_joint\" type=\"fixed\">\n     <origin xyz=\"-0.0 0 0.19\" rpy=\"0 0 3.1415926\"/>\n     <axis xyz=\"0 1 0\" rpy=\"0 0 0\"/>\n     <parent link=\"base_link\"/>\n     <child link=\"hokuyo\"/>\n     <limit effort=\"10000\" velocity=\"1000\"/>\n     <dynamics damping=\"1.0\" friction=\"1.0\"/>\n  </joint>\n\n  <gazebo>\n    <plugin name=\"gazebo_ros_control\" filename=\"libgazebo_ros_control.so\">\n      <robotNamespace>/</robotNamespace>\n      <robotSimType>gazebo_ros_control/DefaultRobotHWSim</robotSimType>\n      <legacyModeNS>true</legacyModeNS>\n    </plugin>\n  </gazebo>\n</robot>\n\ncontroller.yaml\njoint_state_controller:\n  type: \"joint_state_controller/JointStateController\"\n  publish_rate: 50 \n\nfront_right_controller:\n  type: effort_controllers/JointVelocityController\n  joint: front_right_wheel_joint  \n  pid: {p: 10.0, i: 0.01, d: 0.0}\n\nfront_left_controller:\n  type: effort_controllers/JointVelocityController\n  joint: front_left_wheel_joint  \n  pid: {p: 10.0, i: 0.01, d: 0.0}\n\nrear_right_controller:\n  type: effort_controllers/JointVelocityController\n  joint: rear_right_wheel_joint  \n  pid: {p: 10.0, i: 0.01, d: 0.0}\n\nrear_left_controller:\n  type: effort_controllers/JointVelocityController\n  joint: rear_left_wheel_joint  \n  pid: {p: 10.0, i: 0.01, d: 0.0}\n\nThese are my current main three pieces of code. I can currently control the movement of the four wheels, but I've attempted to create an Odometry subscriber. The issue is that it cannot read the coordinates, causing the car to not stop after reaching the destination. I've tried using rostopic info and rostopic echo to check. The results show that the odom subscriber is indeed set up, but it's not receiving any messages."], "question_code": ["Python file for controlling the movement of the car", "#! /usr/bin/env python\n\nimport traceback\nimport rospy\nfrom geometry_msgs.msg import Twist, Point\nfrom nav_msgs.msg import Odometry\nfrom std_msgs.msg import Float64\nfrom sensor_msgs.msg import LaserScan\nimport numpy as np\nimport math\nfrom tf import transformations\nfrom std_srvs.srv import *\n\nposition_ = Point(x=0.0, y=2.0, z=1.0)\nyaw_ = 0\n#goal\ndesired_position_ = Point()\ndesired_position_.x = 5\ndesired_position_.y = -8\ndesired_position_.z = 0\n\nstate_= 0\nactive_ = False\n# parameters\nyaw_precision_ = math.pi / 90 # +/- 2 degree allowed\ndist_precision_ = 0.3\n\n\nwidth = {&quot;fr&quot;: 0.275, &quot;fl&quot;: 0.275, &quot;rr&quot;: 0.275, &quot;rl&quot;: 0.275}\nlength = {&quot;fr&quot;: 0.575, &quot;fl&quot;: 0.575, &quot;rr&quot;: 0.575, &quot;rl&quot;: 0.575}\n\n\nfr_pub = None\nfl_pub = None\nrr_pub = None\nrl_pub = None\npub = None\nvf = 0\nvb = 0\nvl = 0\nvr = 0\n\n\nmat = np.matrix([[1, 1, (width[&quot;fr&quot;] + length[&quot;fr&quot;])],\n                 [1, -1, -(width[&quot;fl&quot;] + length[&quot;fl&quot;])],\n                 [1, -1, (width[&quot;rr&quot;] + length[&quot;rr&quot;])],\n                 [1, 1, -(width[&quot;rl&quot;] + length[&quot;rl&quot;])]])\n                 \n\ncmd_vel = np.matrix([0, 0, 0])\n\ndef cmdVelCB(data):\n    global cmd_vel\n    cmd_vel = np.matrix([data.linear.x, data.linear.y, data.angular.z])\n    \ndef normalize_angle(angle):\n    if (math.fabs(angle) &gt; math.pi):\n        angle = angle -(2 * math.pi * angle) / (math.fabs(angle))\n    return angle\n    \ndef change_state(state):\n    global state_\n    state_ = state\n    print ('State changed to [%s]' % state_)\n\ndef go_to_point_switch(req):\n    global active_\n    active_ = req.data\n    res = SetBoolResponse()\n    res.success = True\n    res.message = 'Done'\n    return res\n\ndef go_to_point_omni(des_pos): # fixed the angle between car and goal\n    global yaw_, cmd_vel, yaw_precision_, state_, fr,fl, rl, rr, vb, vf, vl, vr, pub\n    print(&quot;vf:&quot;, vf)\n    print(&quot;vb:&quot;, vb)\n    print(&quot;vl:&quot;, vl)\n    print(&quot;vr:&quot;, vr)\n\n    err_yaw = normalize_angle(des_pos.z - yaw_)\n    err_pos_y = des_pos.y - position_.y\n    err_pos_x = des_pos.x - position_.x\n    robot_err_x = np.cos(yaw_) * err_pos_x + np.sin(yaw_) * err_pos_y\n    robot_err_y = -np.sin(yaw_) * err_pos_x + np.cos(yaw_) * err_pos_y\n    print(&quot;des_pos.x:&quot;, des_pos.x)\n    print(&quot;des_pos.y:&quot;, des_pos.y)\n    print(&quot;position_.x:&quot;, position_.x)\n    print(&quot;position_.y&quot;, position_.x)\n    print(&quot;des_pos.z:&quot;, des_pos.z)\n    print(&quot;yaw_:&quot;, yaw_)\n\n    print(&quot;err_yaw:&quot;, err_yaw)\n    print(&quot;err_pos_x:&quot;, err_pos_x)\n    print(&quot;err_pos_y:&quot;, err_pos_y)\n    print(&quot;robot_err_x&quot;, robot_err_x)\n    print(&quot;robot_err_y:&quot;, robot_err_y)\n\n    twist_msg = Twist()\n    twist_msg.angular.z = 0\n    print(&quot;x,y,z:&quot;, twist_msg.linear.x,twist_msg.linear.y,twist_msg.angular.z)\n    there_is_error = False\n    if math.fabs(robot_err_y) &gt; dist_precision_:\n        if robot_err_y &gt; 0:\n            twist_msg.linear.y = 5 + vr\n        else:\n            twist_msg.linear.y = -5 + vl\n        there_is_error = True\n        #twist_msg.angular.z = -0.3 if err_yaw &gt; 0 else 0.3\n    if math.fabs(robot_err_x) &gt; dist_precision_:\n        if robot_err_x &gt; 0:\n            twist_msg.linear.x = 5 + vf\n        else:\n            twist_msg.linear.x = -5 + vb\n        there_is_error = True \n\n    cmd_vel = np.matrix([twist_msg.linear.x, twist_msg.linear.y, twist_msg.angular.z])\n    print(&quot;cmd_vel&quot;, cmd_vel)\n    wheel_vel = (np.dot(mat, cmd_vel.T).A1).tolist()\n\n    wv = Float64()\n    wv.data = wheel_vel[0]\n    fr_pub.publish(wv)\n    wv.data = wheel_vel[1]\n    fl_pub.publish(wv)\n    wv.data = wheel_vel[2]\n    rr_pub.publish(wv)\n    wv.data = wheel_vel[3]\n    rl_pub.publish(wv)\n    pub.publish(twist_msg)\n    print(&quot;there_is_error: &quot;, there_is_error)\n\n    if not there_is_error :\n        print ('Arrivaled')\n        change_state(1)\n\ndef LidarCallback(msg):\n    global vf, vb, vl, vr\n    dist_front = msg.ranges[180]\n    dist_right = msg.ranges[90]\n    dist_left = msg.ranges[270]\n    dist_back = msg.ranges[0]\n    safe_distance = 0.6\n\n\n    if dist_front &lt; safe_distance:\n        vf = -0.5  \n    else:\n        vf = 0.5\n\n    if dist_right &lt; safe_distance:\n        vr = -0.5  \n    else:\n        vr = 0.5\n\n    if dist_left &lt; safe_distance:\n        vl = -0.5  \n    else:\n        vl = 0.5\n    if dist_back &lt; safe_distance:\n        vb = -0.5 \n    else: \n        vb = 0.5\n\n\ndef done():\n    global cmd_vel,fr,fl, rl, rr, pub\n    twist_msg = Twist()\n    twist_msg.linear.x = 0\n    twist_msg.linear.y = 0\n    twist_msg.angular.z = 0\n    cmd_vel = np.matrix([twist_msg.linear.x , twist_msg.linear.y, twist_msg.angular.z])\n    # pub.publish(twist_msg)\n    wheel_vel = (np.dot(mat, cmd_vel.T).A1).tolist()\n    wv = Float64()\n    wv.data = wheel_vel[0]\n    fr_pub.publish(wv)\n    wv.data = wheel_vel[1]\n    fl_pub.publish(wv)\n    wv.data = wheel_vel[2]\n    rr_pub.publish(wv)\n    wv.data = wheel_vel[3]\n    rl_pub.publish(wv)\n\ndef clbk_odom(msg):\n    global position_\n    global yaw_\n    \n    # position\n    position_ = msg.pose.pose.position\n    # yaw\n    quaternion = (\n        msg.pose.pose.orientation.x,\n        msg.pose.pose.orientation.y,\n        msg.pose.pose.orientation.z,\n        msg.pose.pose.orientation.w)\n    euler = transformations.euler_from_quaternion(quaternion)\n    yaw_ = euler[2]\n    rospy.loginfo(&quot;Received PoseStamped message&quot;)\n    rospy.loginfo(&quot;Position: x=%f, y=%f, z=%f&quot;, position_.x, position_.y, position_.z)\n    rospy.loginfo(&quot;Orientation: x=%f, y=%f, z=%f, w=%f&quot;, msg.pose.pose.orientation.x, msg.pose.pose.orientation.y, msg.pose.pose.orientation.z, msg.pose.pose.orientation.w)\n\ndef odom_callback(msg):\n    print(&quot;here&quot;)\n    rospy.loginfo(&quot;Received odometry message:&quot;)\n    rospy.loginfo(&quot;Header: %s&quot;, msg.header)\n    rospy.loginfo(&quot;Child frame ID: %s&quot;, msg.child_frame_id)\n    rospy.loginfo(&quot;Pose: %s&quot;, msg.pose)\n    rospy.loginfo(&quot;Twist: %s&quot;, msg.twist)\n\ndef process():\n    global fr_pub, fl_pub, rr_pub, rl_pub, state_, active_ ,pub\n\n    rospy.init_node('test_mecanum_robot', anonymous=False)\n    # loop_rate = rospy.Rate(10)\n    #for velocity\n    fr_pub = rospy.Publisher('/front_right_controller/command', Float64, queue_size=10)\n    fl_pub = rospy.Publisher('/front_left_controller/command', Float64, queue_size=10)\n    rr_pub = rospy.Publisher('/rear_right_controller/command', Float64, queue_size=10)\n    rl_pub = rospy.Publisher('/rear_left_controller/command', Float64, queue_size=10)\n    srv = rospy.Service('/switch', SetBool, go_to_point_switch)\n    rospy.Subscriber('/cmd_vel', Twist, cmdVelCB, queue_size=10)\n    rospy.Subscriber('/agv/laser/scan', LaserScan, LidarCallback, queue_size=10)\n    #for position\n    pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)\n    rospy.Subscriber('/odom', Odometry, odom_callback, queue_size=10)\n    rate = rospy.Rate(20)\n    while not rospy.is_shutdown():\n        rospy.loginfo(&quot;Before checking active_&quot;)\n        if not active_:\n            rospy.loginfo(&quot;active_ is False&quot;)\n            continue\n        else:\n            rospy.loginfo(&quot;After checking active_&quot;)\n            if state_ == 0:\n                rospy.loginfo(&quot;State_ 0&quot;)\n                go_to_point_omni(desired_position_)\n            elif state_ == 1: #arrival\n                rospy.loginfo(&quot;State_ 1&quot;)\n                done()\n                pass\n            else:\n                rospy.loginfo(&quot;bye&quot;)\n                rospy.logerr('Unknown state!')\n                pass\n        rate.sleep()\n\nif __name__ == '__main__':\n    try:\n        process()\n    except Exception as ex:\n        print(traceback.print_exc())\n\n", "URDF file for the car", "&lt;?xml version=&quot;1.0&quot; ?&gt;\n&lt;robot name=&quot;mecanum_wheel_robot&quot; xmlns:xacro=&quot;http://ros.org/wiki/xacro&quot;&gt;\n\n &lt;xacro:include filename=&quot;$(find ros_car)/urdf/mecanum_wheel_macro.xacro&quot; /&gt;\n &lt;xacro:include filename=&quot;$(find ros_car)/urdf/sensor.gazebo.xacro&quot; /&gt;\n  \n &lt;link name=&quot;dummy&quot;/&gt;\n &lt;joint name=&quot;dummy_joint&quot; type=&quot;fixed&quot;&gt;\n    &lt;parent link=&quot;dummy&quot;/&gt;\n    &lt;child link=&quot;base_link&quot;/&gt;\n &lt;/joint&gt;\n  \n  &lt;link name=&quot;base_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;geometry&gt;\n        &lt;box size=&quot;0.7 0.4 0.3&quot; /&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;geometry&gt;\n        &lt;box size=&quot;0.7 0.4 0.3&quot; /&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n\n    &lt;inertial&gt;\n      &lt;origin xyz=&quot;0 0 0&quot; /&gt;\n      &lt;mass value=&quot;10.0&quot; /&gt;\n      &lt;inertia ixx=&quot;0.83333&quot; ixy=&quot;0.0&quot; ixz=&quot;0.0&quot;\n              iyy=&quot;1.9333&quot; iyz=&quot;0.0&quot;\n              izz=&quot;2.1667&quot; /&gt;\n    &lt;/inertial&gt;\n    \n  &lt;/link&gt;\n\n\n  &lt;link name=&quot;hokuyo&quot;&gt;\n     &lt;visual&gt;\n        &lt;origin xyz=&quot;0.0 0 0&quot; rpy=&quot; 0 0 0&quot;/&gt;\n        &lt;geometry&gt;\n          &lt;mesh filename=&quot;package://ros_car/mesh/rplidar.dae&quot;/&gt;\n        &lt;/geometry&gt;\n     &lt;/visual&gt;\n     &lt;collision&gt;\n        &lt;origin xyz=&quot;0.0 0 0&quot; rpy=&quot; 0 0 0&quot;/&gt;\n        &lt;geometry&gt;\n          &lt;box size=&quot;0.2 0.2 0.2&quot;/&gt;\n        &lt;/geometry&gt;\n     &lt;/collision&gt;\n     &lt;inertial&gt;\n        &lt;mass value=&quot;0.1&quot;/&gt;\n        &lt;origin xyz=&quot;0.0 0 0&quot; rpy=&quot; 0 0 0&quot;/&gt;\n        &lt;inertia\n            ixx=&quot;1e-6&quot; ixy=&quot;0&quot; ixz=&quot;0&quot;\n            iyy=&quot;1e-6&quot; iyz=&quot;0&quot;\n            izz=&quot;1e-6&quot;\n        /&gt;\n     &lt;/inertial&gt;\n  &lt;/link&gt;\n  \n  &lt;gazebo reference=&quot;base_link&quot;&gt;\n    &lt;mu1 value=&quot;0.6&quot;/&gt;\n    &lt;mu2 value=&quot;0.6&quot;/&gt;\n    &lt;kp value=&quot;10000000.0&quot; /&gt;\n    &lt;kd value=&quot;1.0&quot; /&gt;\n    &lt;fdir1 value=&quot;0 1 0&quot;/&gt;\n  &lt;/gazebo&gt;\n\n  &lt;xacro:mecanum_wheel name=&quot;front_right&quot; side=&quot;1&quot;  interface=&quot;hardware_interface/EffortJointInterface&quot;/&gt;\n  &lt;xacro:mecanum_wheel name=&quot;front_left&quot;  side=&quot;-1&quot; interface=&quot;hardware_interface/EffortJointInterface&quot;/&gt;\n  &lt;xacro:mecanum_wheel name=&quot;rear_right&quot;  side=&quot;-1&quot; interface=&quot;hardware_interface/EffortJointInterface&quot;/&gt;\n  &lt;xacro:mecanum_wheel name=&quot;rear_left&quot;   side=&quot;1&quot;  interface=&quot;hardware_interface/EffortJointInterface&quot;/&gt;\n\n  &lt;joint name=&quot;front_right_wheel_joint&quot; type=&quot;continuous&quot;&gt;    \n    &lt;origin xyz=&quot;0.3 -0.25 -0.1&quot; rpy=&quot;0 0 ${pi/2}&quot; /&gt;\n    &lt;axis xyz=&quot;1 0 0&quot; /&gt;\n    &lt;parent link=&quot;base_link&quot; /&gt;\n    &lt;child link=&quot;front_right_wheel_link&quot; /&gt;    \n  &lt;/joint&gt;\n\n  &lt;joint name=&quot;front_left_wheel_joint&quot; type=&quot;continuous&quot;&gt;\n    &lt;origin xyz=&quot;0.3 0.25 -0.1&quot; rpy=&quot;0 0 ${pi/2}&quot; /&gt;\n    &lt;axis xyz=&quot;1 0 0&quot; /&gt;\n    &lt;parent link=&quot;base_link&quot; /&gt;\n    &lt;child link=&quot;front_left_wheel_link&quot; /&gt;\n  &lt;/joint&gt;\n\n  &lt;joint name=&quot;rear_right_wheel_joint&quot; type=&quot;continuous&quot;&gt;\n    &lt;origin xyz=&quot;-0.3 -0.25 -0.1&quot; rpy=&quot;0 0 ${pi/2}&quot; /&gt;\n    &lt;axis xyz=&quot;1 0 0&quot; /&gt;\n    &lt;parent link=&quot;base_link&quot; /&gt;\n    &lt;child link=&quot;rear_right_wheel_link&quot; /&gt;\n  &lt;/joint&gt;\n\n  &lt;joint name=&quot;rear_left_wheel_joint&quot; type=&quot;continuous&quot;&gt;\n    &lt;origin xyz=&quot;-0.3 0.25 -0.1&quot; rpy=&quot;0 0 ${pi/2}&quot; /&gt;\n    &lt;axis xyz=&quot;1 0 0&quot; /&gt;\n    &lt;parent link=&quot;base_link&quot; /&gt;\n    &lt;child link=&quot;rear_left_wheel_link&quot; /&gt;\n  &lt;/joint&gt;\n\n\n  &lt;joint name=&quot;hokuyo_joint&quot; type=&quot;fixed&quot;&gt;\n     &lt;origin xyz=&quot;-0.0 0 0.19&quot; rpy=&quot;0 0 3.1415926&quot;/&gt;\n     &lt;axis xyz=&quot;0 1 0&quot; rpy=&quot;0 0 0&quot;/&gt;\n     &lt;parent link=&quot;base_link&quot;/&gt;\n     &lt;child link=&quot;hokuyo&quot;/&gt;\n     &lt;limit effort=&quot;10000&quot; velocity=&quot;1000&quot;/&gt;\n     &lt;dynamics damping=&quot;1.0&quot; friction=&quot;1.0&quot;/&gt;\n  &lt;/joint&gt;\n\n  &lt;gazebo&gt;\n    &lt;plugin name=&quot;gazebo_ros_control&quot; filename=&quot;libgazebo_ros_control.so&quot;&gt;\n      &lt;robotNamespace&gt;/&lt;/robotNamespace&gt;\n      &lt;robotSimType&gt;gazebo_ros_control/DefaultRobotHWSim&lt;/robotSimType&gt;\n      &lt;legacyModeNS&gt;true&lt;/legacyModeNS&gt;\n    &lt;/plugin&gt;\n  &lt;/gazebo&gt;\n&lt;/robot&gt;\n", "controller.yaml", "joint_state_controller:\n  type: &quot;joint_state_controller/JointStateController&quot;\n  publish_rate: 50 \n\nfront_right_controller:\n  type: effort_controllers/JointVelocityController\n  joint: front_right_wheel_joint  \n  pid: {p: 10.0, i: 0.01, d: 0.0}\n\nfront_left_controller:\n  type: effort_controllers/JointVelocityController\n  joint: front_left_wheel_joint  \n  pid: {p: 10.0, i: 0.01, d: 0.0}\n\nrear_right_controller:\n  type: effort_controllers/JointVelocityController\n  joint: rear_right_wheel_joint  \n  pid: {p: 10.0, i: 0.01, d: 0.0}\n\nrear_left_controller:\n  type: effort_controllers/JointVelocityController\n  joint: rear_left_wheel_joint  \n  pid: {p: 10.0, i: 0.01, d: 0.0}\n"], "quote": [], "url": "https://stackoverflow.com/questions/78584761/subscriber-doesnt-receive-any-messages", "answer": [], "answer_code": []},
{"title": "Robotics PD controller", "time": 1716566066, "post_content": ["I'd like to share my code. I'm having trouble understanding why my robot doesn't reach the desired positions when I increase the value of Kp. The robot has six degrees of freedom, and I'm using a PD control law to manipulate it.\nhttps://github.com/tommasoandina1/Doosan_h2515/blob/main/esempio2.py\nI want the actual joint positions of the robot to converge to the desired position\n\"In my robot's dynamics, the joint acceleration (ddq) is computed as follows: ddq = M^-1 * (tau - h), where M is the mass matrix, h is the bias force, and tau is the control law. The control law (tau) is defined as kp * (q_des - q) - kd * dq, where q is the joint position, dq is the joint velocity, and kp and kd are the proportional and derivative gains, respectively\nand q = dt * dq\ndq = dt * ddq"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/78529593/robotics-pd-controller", "answer": [], "answer_code": []},
{"title": "Apt fails to fetch data from reachable IP", "time": 1716370594, "post_content": ["I am trying to install some ROS packages on a machine that has several sensors, and is on the very same network than my working computer. While I can install them well on the latter, I am running on this message when I try to do it on the former:\nsudo apt install ros-humble-rviz-imu-plugin\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following NEW packages will be installed:\n  ros-humble-rviz-imu-plugin\n0 upgraded, 1 newly installed, 0 to remove and 409 not upgraded.\nNeed to get 169 kB of archives.\nAfter this operation, 935 kB of additional disk space will be used.\nErr:1 http://packages.ros.org/ros2/ubuntu jammy/main amd64 ros-humble-rviz-imu-plugin amd64 2.1.3-1jammy.20240126.015719\n  404  Not Found [IP: 64.50.236.52 80]\nE: Failed to fetch http://packages.ros.org/ros2/ubuntu/pool/main/r/ros-humble-rviz-imu-plugin/ros-humble-rviz-imu-plugin_2.1.3-1jammy.20240126.015719_amd64.deb  404  Not Found [IP: 64.50.236.52 80]\nE: Internal Error, ordering was unable to handle the media swap\n\n\nBoth machines are on the same network and I can ping that IP and the ROS packages server just fine from both machines:\nping -c 4 64.50.236.52                                                                                                                                                  \nPING 64.50.236.52 (64.50.236.52) 56(84) bytes of data.\n64 bytes from 64.50.236.52: icmp_seq=1 ttl=47 time=144 ms\n64 bytes from 64.50.236.52: icmp_seq=2 ttl=47 time=166 ms\n64 bytes from 64.50.236.52: icmp_seq=3 ttl=47 time=142 ms\n64 bytes from 64.50.236.52: icmp_seq=4 ttl=47 time=156 ms\n\n--- 64.50.236.52 ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3004ms\nrtt min/avg/max/mdev = 141.942/151.699/165.653/9.603 ms\n\n\nping -c 4 packages.ros.org                                                                                                                                       PING ftp.osuosl.org (64.50.233.100) 56(84) bytes of data.\n64 bytes from ftp-nyc.osuosl.org (64.50.233.100): icmp_seq=1 ttl=52 time=133 ms\n64 bytes from ftp-nyc.osuosl.org (64.50.233.100): icmp_seq=2 ttl=52 time=131 ms\n64 bytes from ftp-nyc.osuosl.org (64.50.233.100): icmp_seq=3 ttl=52 time=137 ms\n64 bytes from ftp-nyc.osuosl.org (64.50.233.100): icmp_seq=4 ttl=52 time=150 ms\n\n--- ftp.osuosl.org ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3004ms\nrtt min/avg/max/mdev = 130.888/137.782/149.783/7.286 ms\n\n\nI have deleted the contents of /etc/apt/sources.list.d on the failing machine and copied the contents of the working one, but to no avail.\nI have of course tried to sudo apt-get update and sudo apt install ros-humble-rviz-imu-plugin --fix-missing as well."], "question_code": ["sudo apt install ros-humble-rviz-imu-plugin\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following NEW packages will be installed:\n  ros-humble-rviz-imu-plugin\n0 upgraded, 1 newly installed, 0 to remove and 409 not upgraded.\nNeed to get 169 kB of archives.\nAfter this operation, 935 kB of additional disk space will be used.\nErr:1 http://packages.ros.org/ros2/ubuntu jammy/main amd64 ros-humble-rviz-imu-plugin amd64 2.1.3-1jammy.20240126.015719\n  404  Not Found [IP: 64.50.236.52 80]\nE: Failed to fetch http://packages.ros.org/ros2/ubuntu/pool/main/r/ros-humble-rviz-imu-plugin/ros-humble-rviz-imu-plugin_2.1.3-1jammy.20240126.015719_amd64.deb  404  Not Found [IP: 64.50.236.52 80]\nE: Internal Error, ordering was unable to handle the media swap\n\n", "ping -c 4 64.50.236.52                                                                                                                                                  \nPING 64.50.236.52 (64.50.236.52) 56(84) bytes of data.\n64 bytes from 64.50.236.52: icmp_seq=1 ttl=47 time=144 ms\n64 bytes from 64.50.236.52: icmp_seq=2 ttl=47 time=166 ms\n64 bytes from 64.50.236.52: icmp_seq=3 ttl=47 time=142 ms\n64 bytes from 64.50.236.52: icmp_seq=4 ttl=47 time=156 ms\n\n--- 64.50.236.52 ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3004ms\nrtt min/avg/max/mdev = 141.942/151.699/165.653/9.603 ms\n\n\nping -c 4 packages.ros.org                                                                                                                                       PING ftp.osuosl.org (64.50.233.100) 56(84) bytes of data.\n64 bytes from ftp-nyc.osuosl.org (64.50.233.100): icmp_seq=1 ttl=52 time=133 ms\n64 bytes from ftp-nyc.osuosl.org (64.50.233.100): icmp_seq=2 ttl=52 time=131 ms\n64 bytes from ftp-nyc.osuosl.org (64.50.233.100): icmp_seq=3 ttl=52 time=137 ms\n64 bytes from ftp-nyc.osuosl.org (64.50.233.100): icmp_seq=4 ttl=52 time=150 ms\n\n--- ftp.osuosl.org ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3004ms\nrtt min/avg/max/mdev = 130.888/137.782/149.783/7.286 ms\n\n", "sudo apt-get update", "sudo apt install ros-humble-rviz-imu-plugin --fix-missing"], "quote": [], "url": "https://stackoverflow.com/questions/78516569/apt-fails-to-fetch-data-from-reachable-ip", "answer": [], "answer_code": []},
{"title": "rosserial arduino multiarray callback does not run", "time": 1716041914, "post_content": ["Environment\nROS DISTRO: Noetic\nArduino Board: Arduino Mega2560\nProblem Description\nI tried to use the rosserial library for serial communication. I tested sending some data types, such as std_msgs/Int32 and std_msgs/Int16, and the communication worked fine, with the callback functions being triggered normally. However, when I tried to send data of the types std_msgs/Int16MultiArray and std_msgs/Int32MultiArray, the callback functions of the subscriber node on the Arduino did not get triggered.\nCode\nThe following code block is the content of the file int32MultiArrayTest.cpp.This program runs on ROS Noetic.\n#include <ros/ros.h>\n#include <std_msgs/Int32MultiArray.h>\n\nvoid sub_cb(const std_msgs::Int32MultiArray::ConstPtr &msg) {\n  ROS_INFO(\"Result: %d %d %d %d\", msg->data[0], msg->data[1], msg->data[2],\n           msg->data[3]);\n  //   ROS_INFO(\"Steps: %d\", msg->data);\n}\n\nint main(int argc, char **argv) {\n  ros::init(argc, argv, \"/int32_node\");\n  ros::NodeHandle nh;\n  ros::Publisher pub =\n      nh.advertise<std_msgs::Int32MultiArray>(\"/int32_topic\", 5);\n  ros::Subscriber sub =\n      nh.subscribe<std_msgs::Int32MultiArray>(\"/arduino_add\", 5, sub_cb);\n  ros::Rate loop_rate(1);\n  std_msgs::Int32MultiArray msg;\n  msg.data = {1, 2, 3, 4};\n  msg.layout.dim.push_back(std_msgs::MultiArrayDimension());\n  msg.layout.dim[0].size = 4;\n  msg.layout.dim[0].label=\"Steps\";\n  msg.layout.dim[0].stride=1;\n  while (ros::ok()) {\n    pub.publish(msg);\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  return 0;\n}\n\n\nThe following code block is the content of the file run_int32test.launch.\n<launch>\n    <node pkg=\"rosserial_arduino\" type=\"serial_node.py\" name=\"serial_interface\" respawn=\"true\"\n        output=\"screen\">\n        <param name=\"port\" value=\"/dev/ttyACM0\" />\n        <param name=\"baud\" value=\"9600\" />\n    </node>\n    <node pkg=\"scara_control\" type=\"int32test\" name=\"test_int32_arduino\" respawn=\"true\"\n        output=\"screen\">\n    </node>\n</launch>\n\n\nThe following code block is the content of the file rosSerialTest.ino.It runs on the Arduino Mega2560.\n#include <Arduino.h>\n#include <ros.h>\n#include <std_msgs/Int32MultiArray.h>\n\n#define LED_PIN 9\n\nstd_msgs::Int32MultiArray sum_msg;\n\nros::NodeHandle nh;\n\nros::Publisher pub(\"/arduino_add\", &sum_msg);\n\nlong steps[4] = {0, 0, 0, 0};\n\nvoid messageCb(const std_msgs::Int32MultiArray &msg) {\n  digitalWrite(LED_PIN, HIGH);\n  for (size_t i = 0; i < 4; i++)\n    steps[i] = msg.data[i];\n}\n\nros::Subscriber<std_msgs::Int32MultiArray> sub(\"/int32_topic\", &messageCb);\n\nvoid setup() {\n  pinMode(LED_PIN, LOW);\n  digitalWrite(LED_PIN, LOW);\n  nh.getHardware()->setBaud(9600);\n  nh.initNode();\n  nh.advertise(pub);\n  nh.subscribe(sub);\n  nh.spinOnce();\n  delay(1);\n}\n\nvoid loop() {\n  sum_msg.data = steps;\n  sum_msg.data_length = 4;\n  pub.publish(&sum_msg);\n  nh.spinOnce();\n  delay(1);\n}\n\nWhat I Have Tried\n\nI tried running the above code and got the following result.\n\n[INFO][1716035508.688977485]: Result: 0 0 0 0\n[INFO][1716035508.688985089]: Result: 0 0 0 0\n[INFO][1716035508.689395577]: Result: 0 0 0 0\n[INFO][1716035508.689496259]: Result: 0 0 0 0\n\n\nI tried changing the data type in the above code to std_msgs/Int16MultiArray, compiled and ran it, and got the following result.\n\n[INFO][1716035508.688977485]: Result: 0 0 0 0\n[INFO][1716035508.688985089]: Result: 0 0 0 0\n[INFO][1716035508.689395577]: Result: 0 0 0 0\n[INFO][1716035508.689496259]: Result: 0 0 0 0\n\n\nHowever, after waiting for a while (at least 2 minutes), the callback function of the subscriber node on the Arduino was triggered, and I got the following result.\n\n[INFO][1716035508.688977485]: Result: 1 2 3 4\n[INFO][1716035508.688985089]: Result: 1 2 3 4\n[INFO][1716035508.689395577]: Result: 1 2 3 4\n[INFO][1716035508.689496259]: Result: 1 2 3 4\n\n\nI tried having the Arduino only send data of type std_msgs/Int32MultiArray with a length of 4, and the data was successfully received by the host computer. However, when I tried having the host computer only send data of type std_msgs/Int32MultiArray with a length of 4, the Arduino was supposed to receive the data and trigger a subscription callback function to light up an LED. After running the program, I found that the callback function was not being triggered.\n\nThank You in Advance\nThank you all for your help! Any suggestions are greatly appreciated. I will make sure to update this post with the solution once I have resolved the issue, so others can benefit from it as well."], "question_code": ["#include &lt;ros/ros.h&gt;\n#include &lt;std_msgs/Int32MultiArray.h&gt;\n\nvoid sub_cb(const std_msgs::Int32MultiArray::ConstPtr &amp;msg) {\n  ROS_INFO(&quot;Result: %d %d %d %d&quot;, msg-&gt;data[0], msg-&gt;data[1], msg-&gt;data[2],\n           msg-&gt;data[3]);\n  //   ROS_INFO(&quot;Steps: %d&quot;, msg-&gt;data);\n}\n\nint main(int argc, char **argv) {\n  ros::init(argc, argv, &quot;/int32_node&quot;);\n  ros::NodeHandle nh;\n  ros::Publisher pub =\n      nh.advertise&lt;std_msgs::Int32MultiArray&gt;(&quot;/int32_topic&quot;, 5);\n  ros::Subscriber sub =\n      nh.subscribe&lt;std_msgs::Int32MultiArray&gt;(&quot;/arduino_add&quot;, 5, sub_cb);\n  ros::Rate loop_rate(1);\n  std_msgs::Int32MultiArray msg;\n  msg.data = {1, 2, 3, 4};\n  msg.layout.dim.push_back(std_msgs::MultiArrayDimension());\n  msg.layout.dim[0].size = 4;\n  msg.layout.dim[0].label=&quot;Steps&quot;;\n  msg.layout.dim[0].stride=1;\n  while (ros::ok()) {\n    pub.publish(msg);\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  return 0;\n}\n", "&lt;launch&gt;\n    &lt;node pkg=&quot;rosserial_arduino&quot; type=&quot;serial_node.py&quot; name=&quot;serial_interface&quot; respawn=&quot;true&quot;\n        output=&quot;screen&quot;&gt;\n        &lt;param name=&quot;port&quot; value=&quot;/dev/ttyACM0&quot; /&gt;\n        &lt;param name=&quot;baud&quot; value=&quot;9600&quot; /&gt;\n    &lt;/node&gt;\n    &lt;node pkg=&quot;scara_control&quot; type=&quot;int32test&quot; name=&quot;test_int32_arduino&quot; respawn=&quot;true&quot;\n        output=&quot;screen&quot;&gt;\n    &lt;/node&gt;\n&lt;/launch&gt;\n", "rosSerialTest.ino", "#include &lt;Arduino.h&gt;\n#include &lt;ros.h&gt;\n#include &lt;std_msgs/Int32MultiArray.h&gt;\n\n#define LED_PIN 9\n\nstd_msgs::Int32MultiArray sum_msg;\n\nros::NodeHandle nh;\n\nros::Publisher pub(&quot;/arduino_add&quot;, &amp;sum_msg);\n\nlong steps[4] = {0, 0, 0, 0};\n\nvoid messageCb(const std_msgs::Int32MultiArray &amp;msg) {\n  digitalWrite(LED_PIN, HIGH);\n  for (size_t i = 0; i &lt; 4; i++)\n    steps[i] = msg.data[i];\n}\n\nros::Subscriber&lt;std_msgs::Int32MultiArray&gt; sub(&quot;/int32_topic&quot;, &amp;messageCb);\n\nvoid setup() {\n  pinMode(LED_PIN, LOW);\n  digitalWrite(LED_PIN, LOW);\n  nh.getHardware()-&gt;setBaud(9600);\n  nh.initNode();\n  nh.advertise(pub);\n  nh.subscribe(sub);\n  nh.spinOnce();\n  delay(1);\n}\n\nvoid loop() {\n  sum_msg.data = steps;\n  sum_msg.data_length = 4;\n  pub.publish(&amp;sum_msg);\n  nh.spinOnce();\n  delay(1);\n}\n", "[INFO][1716035508.688977485]: Result: 0 0 0 0\n[INFO][1716035508.688985089]: Result: 0 0 0 0\n[INFO][1716035508.689395577]: Result: 0 0 0 0\n[INFO][1716035508.689496259]: Result: 0 0 0 0\n", "[INFO][1716035508.688977485]: Result: 0 0 0 0\n[INFO][1716035508.688985089]: Result: 0 0 0 0\n[INFO][1716035508.689395577]: Result: 0 0 0 0\n[INFO][1716035508.689496259]: Result: 0 0 0 0\n", "[INFO][1716035508.688977485]: Result: 1 2 3 4\n[INFO][1716035508.688985089]: Result: 1 2 3 4\n[INFO][1716035508.689395577]: Result: 1 2 3 4\n[INFO][1716035508.689496259]: Result: 1 2 3 4\n", "std_msgs/Int32MultiArray", "std_msgs/Int32MultiArray"], "quote": ["However, after waiting for a while (at least 2 minutes), the callback function of the subscriber node on the Arduino was triggered, and I got the following result."], "url": "https://stackoverflow.com/questions/78500006/rosserial-arduino-multiarray-callback-does-not-run", "answer": [], "answer_code": []},
{"title": "ArUco marker detection not working with ROS2 and PX4 SITL", "time": 1715785481, "post_content": ["I'm working on a project where I need to detect ArUco markers using ROS2 and PX4 SITL. I've implemented a Python script that subscribes to the camera topic and uses OpenCV to detect ArUco markers in the image stream. However, despite running the script, the markers are not being detected, and there are no errors displayed. The image window opens, but no markers are drawn\nHere's a breakdown of my setup and code:\nROS2 version: [Specify your ROS2 version]\nPX4 SITL version: [Specify your PX4 SITL version]\nPython version: [Specify your Python version]\n\nI'm using the following code to detect ArUco markers:\nclass ArucoNode(Node):\n    def __init__(self):\n        super().__init__('aruco_node')\n\n        self.declare_parameter(\"aruco_dictionary_name\", \"DICT_ARUCO_ORIGINAL\")\n        self.declare_parameter(\"aruco_marker_side_length\", 0.05)\n        self.declare_parameter(\"camera_calibration_parameters_filename\", \"./PX4-ROS2-Gazebo-YOLOv8/calibration_chessboard.yaml\")\n        self.declare_parameter(\"image_topic\", \"/camera\")\n        self.declare_parameter(\"aruco_marker_name\", \"aruco_marker\")\n\n        aruco_dictionary_name = self.get_parameter(\"aruco_dictionary_name\").get_parameter_value().string_value\n        self.aruco_marker_side_length = self.get_parameter(\"aruco_marker_side_length\").get_parameter_value().double_value\n        self.camera_calibration_parameters_filename = self.get_parameter(\n            \"camera_calibration_parameters_filename\").get_parameter_value().string_value\n        image_topic = self.get_parameter(\"image_topic\").get_parameter_value().string_value\n        self.aruco_marker_name = self.get_parameter(\"aruco_marker_name\").get_parameter_value().string_value\n\n        if ARUCO_DICT.get(aruco_dictionary_name, None) is None:\n            self.get_logger().info(\"[INFO] ArUCo tag of '{}' is not supported\".format(aruco_dictionary_name))\n\n        cv_file = cv2.FileStorage(self.camera_calibration_parameters_filename, cv2.FILE_STORAGE_READ) \n        self.mtx = cv_file.getNode('camera_matrix').mat()\n        self.dst = cv_file.getNode('distortion_coefficients').mat()\n        cv_file.release()\n\n        self.get_logger().info(\"[INFO] detecting '{}' markers...\".format(aruco_dictionary_name))\n        self.this_aruco_dictionary = cv2.aruco.Dictionary_get(ARUCO_DICT[aruco_dictionary_name])\n        self.this_aruco_parameters = cv2.aruco.DetectorParameters_create()\n\n        self.subscription = self.create_subscription(\n            Image, \n            image_topic, \n            self.listener_callback, \n            qos_profile=qos_profile_sensor_data)\n        self.subscription # prevent unused variable warning\n\n        self.publisher_aruco_marker_detected = self.create_publisher(Bool, 'aruco_marker_detected', 10)\n        self.publisher_offset_aruco_marker = self.create_publisher(Int32, 'aruco_marker_offset', 10)\n        self.offset_aruco_marker = 0\n\n        self.bridge = CvBridge()\n    def listener_callback(self, data):\n        self.get_logger().info(\"[INFO] Image received.\")\n        current_frame = self.bridge.imgmsg_to_cv2(data)\n\n        (corners, marker_ids, rejected) = cv2.aruco.detectMarkers(\n            current_frame, self.this_aruco_dictionary, parameters=self.this_aruco_parameters,\n            cameraMatrix=self.mtx, distCoeff=self.dst)\n\n        aruco_detected_flag = Bool()\n        aruco_detected_flag.data = False\n\n        aruco_center_offset_msg = Int32()\n        aruco_center_offset_msg.data = self.offset_aruco_marker\n\n        image_width = current_frame.shape[1]\n\n        if marker_ids is not None:\n            aruco_detected_flag.data = True\n\n            cv2.aruco.drawDetectedMarkers(current_frame, corners, marker_ids)\n\n            M = cv2.moments(corners[0][0])\n            cX = int(M[\"m10\"] / M[\"m00\"])\n            cY = int(M[\"m01\"] / M[\"m00\"])\n\n            self.offset_aruco_marker = cX - int(image_width/2)\n            aruco_center_offset_msg.data = self.offset_aruco_marker\n\n            cv2.putText(current_frame, \"Center Offset: \" + str(self.offset_aruco_marker), (cX - 40, cY - 40), \n                        cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2) \n\n        self.publisher_aruco_marker_detected.publish(aruco_detected_flag)\n        self.publisher_offset_aruco_marker.publish(aruco_center_offset_msg)\n\n\n           \n\nThe script runs without errors, but no markers are detected in the image window. I would appreciate any insights or suggestions on how to troubleshoot and resolve this issue.\nThank you in advance for your help!"], "question_code": ["ROS2 version: [Specify your ROS2 version]\nPX4 SITL version: [Specify your PX4 SITL version]\nPython version: [Specify your Python version]\n", "class ArucoNode(Node):\n    def __init__(self):\n        super().__init__('aruco_node')\n\n        self.declare_parameter(&quot;aruco_dictionary_name&quot;, &quot;DICT_ARUCO_ORIGINAL&quot;)\n        self.declare_parameter(&quot;aruco_marker_side_length&quot;, 0.05)\n        self.declare_parameter(&quot;camera_calibration_parameters_filename&quot;, &quot;./PX4-ROS2-Gazebo-YOLOv8/calibration_chessboard.yaml&quot;)\n        self.declare_parameter(&quot;image_topic&quot;, &quot;/camera&quot;)\n        self.declare_parameter(&quot;aruco_marker_name&quot;, &quot;aruco_marker&quot;)\n\n        aruco_dictionary_name = self.get_parameter(&quot;aruco_dictionary_name&quot;).get_parameter_value().string_value\n        self.aruco_marker_side_length = self.get_parameter(&quot;aruco_marker_side_length&quot;).get_parameter_value().double_value\n        self.camera_calibration_parameters_filename = self.get_parameter(\n            &quot;camera_calibration_parameters_filename&quot;).get_parameter_value().string_value\n        image_topic = self.get_parameter(&quot;image_topic&quot;).get_parameter_value().string_value\n        self.aruco_marker_name = self.get_parameter(&quot;aruco_marker_name&quot;).get_parameter_value().string_value\n\n        if ARUCO_DICT.get(aruco_dictionary_name, None) is None:\n            self.get_logger().info(&quot;[INFO] ArUCo tag of '{}' is not supported&quot;.format(aruco_dictionary_name))\n\n        cv_file = cv2.FileStorage(self.camera_calibration_parameters_filename, cv2.FILE_STORAGE_READ) \n        self.mtx = cv_file.getNode('camera_matrix').mat()\n        self.dst = cv_file.getNode('distortion_coefficients').mat()\n        cv_file.release()\n\n        self.get_logger().info(&quot;[INFO] detecting '{}' markers...&quot;.format(aruco_dictionary_name))\n        self.this_aruco_dictionary = cv2.aruco.Dictionary_get(ARUCO_DICT[aruco_dictionary_name])\n        self.this_aruco_parameters = cv2.aruco.DetectorParameters_create()\n\n        self.subscription = self.create_subscription(\n            Image, \n            image_topic, \n            self.listener_callback, \n            qos_profile=qos_profile_sensor_data)\n        self.subscription # prevent unused variable warning\n\n        self.publisher_aruco_marker_detected = self.create_publisher(Bool, 'aruco_marker_detected', 10)\n        self.publisher_offset_aruco_marker = self.create_publisher(Int32, 'aruco_marker_offset', 10)\n        self.offset_aruco_marker = 0\n\n        self.bridge = CvBridge()\n    def listener_callback(self, data):\n        self.get_logger().info(&quot;[INFO] Image received.&quot;)\n        current_frame = self.bridge.imgmsg_to_cv2(data)\n\n        (corners, marker_ids, rejected) = cv2.aruco.detectMarkers(\n            current_frame, self.this_aruco_dictionary, parameters=self.this_aruco_parameters,\n            cameraMatrix=self.mtx, distCoeff=self.dst)\n\n        aruco_detected_flag = Bool()\n        aruco_detected_flag.data = False\n\n        aruco_center_offset_msg = Int32()\n        aruco_center_offset_msg.data = self.offset_aruco_marker\n\n        image_width = current_frame.shape[1]\n\n        if marker_ids is not None:\n            aruco_detected_flag.data = True\n\n            cv2.aruco.drawDetectedMarkers(current_frame, corners, marker_ids)\n\n            M = cv2.moments(corners[0][0])\n            cX = int(M[&quot;m10&quot;] / M[&quot;m00&quot;])\n            cY = int(M[&quot;m01&quot;] / M[&quot;m00&quot;])\n\n            self.offset_aruco_marker = cX - int(image_width/2)\n            aruco_center_offset_msg.data = self.offset_aruco_marker\n\n            cv2.putText(current_frame, &quot;Center Offset: &quot; + str(self.offset_aruco_marker), (cX - 40, cY - 40), \n                        cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2) \n\n        self.publisher_aruco_marker_detected.publish(aruco_detected_flag)\n        self.publisher_offset_aruco_marker.publish(aruco_center_offset_msg)\n\n\n           \n"], "quote": [], "url": "https://stackoverflow.com/questions/78484843/aruco-marker-detection-not-working-with-ros2-and-px4-sitl", "answer": [], "answer_code": []},
{"title": "Trouble running ROS2 launch files from a non-interactive SSH command", "time": 1715575699, "post_content": ["I am writing a program that is supposed to remotely run ROS2 launch files on a connected robot via SSH. I am using Golang to connect to the robot via SSH and run ROS2 commands. So far this setup has worked, I have been able to run ROS2 commands such as\nros2 topic list and ros2 topic info, and they have returned the expected output. When I try to run a ros2 launch file however, no output is returned, and running commands on the robot to try and detect if the node is running (ros2 node list) show that the launched nodes are not running.\nMy code for executing SSH commands via go is:\nfunc (serverMsg *BaseWSServerMsg) executeArbitrarySSH(payload interface{}, c *websocket.Conn) {\n    type arbSSH struct {\n        Data     string `json:\"data,omitempty\"`\n        Port     int    `json:\"port,omitempty\"`\n        Username string `json:\"username,omitempty\"`\n        Password string `json:\"password,omitempty\"`\n        Hostname string `json:\"hostname,omitempty\"`\n        Type         string `json:\"type,omitempty\"`\n    }\n    marshalled, err := json.Marshal(payload)\n    if err != nil {\n        serverMsg.CreateAsError(http.StatusBadRequest, err.Error())\n        return\n    }\n\n    //load, ok := payload.(arbSSH)\n    var load arbSSH\n    err = json.Unmarshal(marshalled, &load)\n    if err != nil {\n        serverMsg.CreateAsError(http.StatusBadRequest, fmt.Sprintf(err.Error()))\n        return\n    }\n\n    config := &ssh.ClientConfig{\n        User: load.Username,\n        Auth: []ssh.AuthMethod{\n            ssh.Password(load.Password),\n        },\n        HostKeyCallback: ssh.InsecureIgnoreHostKey(),\n    }\n    client, err := ssh.Dial(\"tcp\", fmt.Sprintf(\"%s:%d\", load.Hostname, load.Port), config)\n    if err != nil {\n        serverMsg.CreateAsError(http.StatusInternalServerError, err.Error())\n        return\n    }\n    // Each ClientConn can support multiple interactive sessions,\n    session, err := client.NewSession()\n    if err != nil {\n        serverMsg.CreateAsError(http.StatusInternalServerError, err.Error())\n        return\n    }\n    if load.Type == \"output\" {\n        fmt.Println(\"Recieved Output command\")\n        defer client.Close()\n        defer session.Close()\n        stdout, err := session.Output(load.Data)\n        if err != nil {\n            serverMsg.CreateAsError(http.StatusInternalServerError, err.Error())\n            return\n        }\n        serverMsg.Payload = struct {\n            Data string `json:\"data,omitempty\"`\n        }{string(stdout)}\n    }\n}\n\nThis implementation of go ssh creates a new ssh terminal for each command run, so prior to running each command I source the needed files and create the required environment variables to ensure that ros runs correctly. To demonstrate this format, an example command I might run looks like:\nexport ROS_DOMAIN_ID=30 > /dev/null && source /opt/ros/humble/setup.bash > /dev/null && source ~/example_ws/install/local_setup.bash > /dev/null && ros2 launch example example.launch.py\n\nThis format has worked for all other ros commands I have tried so far as I mentioned above. I retested the exact launch commands I sent via go in a regular SSH terminal connected to my robot and they work just fine, launching the expected nodes and displaying output.\nI have tried adding '&' to the end of the command to make it run in the background, but that did not make it run correctly. I attempted using 'nohup' to run the command, however that also changed nothing.\nI have done further testing on running launch files through ssh to try and see if the problem stems from interactivity. I discovered that when running the command directly from ssh instead of using an interactive ssh terminal, as follows:\nssh username@ip_address \"export ROS_DOMAIN_ID=30 > /dev/null && source /opt/ros/humble/setup.bash > /dev/null && source ~/example_ws/install/local_setup.bash > /dev/null && ros2 launch example example.launch.py\"\n\nI discovered that the command would run, displaying the correct ROS_INFO output on my ssh terminal, however when trying to check if that node was running on the robot, by running ros2 node list and ros2 topic list no corresponding node would be displayed. The ROS_DOMAIN_ID is the same on both the robot and the ssh terminal command. I am wondering if this behaviour might be connected to the problem I am facing, and if so how do I bypass it?"], "question_code": ["ros2 topic list", "ros2 topic info", "ros2 node list", "func (serverMsg *BaseWSServerMsg) executeArbitrarySSH(payload interface{}, c *websocket.Conn) {\n    type arbSSH struct {\n        Data     string `json:&quot;data,omitempty&quot;`\n        Port     int    `json:&quot;port,omitempty&quot;`\n        Username string `json:&quot;username,omitempty&quot;`\n        Password string `json:&quot;password,omitempty&quot;`\n        Hostname string `json:&quot;hostname,omitempty&quot;`\n        Type         string `json:&quot;type,omitempty&quot;`\n    }\n    marshalled, err := json.Marshal(payload)\n    if err != nil {\n        serverMsg.CreateAsError(http.StatusBadRequest, err.Error())\n        return\n    }\n\n    //load, ok := payload.(arbSSH)\n    var load arbSSH\n    err = json.Unmarshal(marshalled, &amp;load)\n    if err != nil {\n        serverMsg.CreateAsError(http.StatusBadRequest, fmt.Sprintf(err.Error()))\n        return\n    }\n\n    config := &amp;ssh.ClientConfig{\n        User: load.Username,\n        Auth: []ssh.AuthMethod{\n            ssh.Password(load.Password),\n        },\n        HostKeyCallback: ssh.InsecureIgnoreHostKey(),\n    }\n    client, err := ssh.Dial(&quot;tcp&quot;, fmt.Sprintf(&quot;%s:%d&quot;, load.Hostname, load.Port), config)\n    if err != nil {\n        serverMsg.CreateAsError(http.StatusInternalServerError, err.Error())\n        return\n    }\n    // Each ClientConn can support multiple interactive sessions,\n    session, err := client.NewSession()\n    if err != nil {\n        serverMsg.CreateAsError(http.StatusInternalServerError, err.Error())\n        return\n    }\n    if load.Type == &quot;output&quot; {\n        fmt.Println(&quot;Recieved Output command&quot;)\n        defer client.Close()\n        defer session.Close()\n        stdout, err := session.Output(load.Data)\n        if err != nil {\n            serverMsg.CreateAsError(http.StatusInternalServerError, err.Error())\n            return\n        }\n        serverMsg.Payload = struct {\n            Data string `json:&quot;data,omitempty&quot;`\n        }{string(stdout)}\n    }\n}\n", "export ROS_DOMAIN_ID=30 &gt; /dev/null &amp;&amp; source /opt/ros/humble/setup.bash &gt; /dev/null &amp;&amp; source ~/example_ws/install/local_setup.bash &gt; /dev/null &amp;&amp; ros2 launch example example.launch.py\n", "ssh username@ip_address &quot;export ROS_DOMAIN_ID=30 &gt; /dev/null &amp;&amp; source /opt/ros/humble/setup.bash &gt; /dev/null &amp;&amp; source ~/example_ws/install/local_setup.bash &gt; /dev/null &amp;&amp; ros2 launch example example.launch.py&quot;\n", "ros2 node list", "ros2 topic list"], "quote": [], "url": "https://stackoverflow.com/questions/78470128/trouble-running-ros2-launch-files-from-a-non-interactive-ssh-command", "answer": [], "answer_code": []},
{"title": "Problems in Python", "time": 1715409970, "post_content": ["I'm applying a Proportional-Derivative controller to control my robot, but I don't understand why the robot's position doesn't reach the desired position. Can someone help me understand what the error might be?\nI want to observe the desired position (q_des) relative to the real position (q)\nThe error is related to the norm between the desired position q_des at the final time and the position obtained by my robot. Essentially, I want to provide my robot's joint torques with a PD control law to calculate tau:\ntau = Kp * (q_des - q) - Kd * dq,\nwhere q_des is the desired joint position, q is the actual position, dq is the actual joint velocity, and Kp and Kd are gains that you need to set. Where the accuracy of the simulation is evaluated by varying the time step dt of the simulator:\nq_next = q + dt * dq\ndq_next = dq + dt * ddq\nfrom adam.casadi.computations import KinDynComputations\nfrom adam.geometry import utils\nimport numpy as np\nimport casadi as cs\n#import icub_models\nfrom math import sqrt\n\nurdf_path =  \"/Users/tommasoandina/Desktop/doosan-robot2-master/dsr_description2/urdf/h2515.blue.urdf\" \n# The joint list\njoints_name_list = ['joint1', 'joint2', 'joint3', 'joint4', 'joint5', 'joint6']\n# Specify the root link\nroot_link = 'base'\n\nkinDyn = KinDynComputations(urdf_path, joints_name_list, root_link)\nnum_dof = kinDyn.NDoF\n\nH = cs.SX.sym('H', 4, 4)\n# The joint values\ns = cs.SX.sym('s', num_dof)\n# The base velocity\nv_b = cs.SX.sym('v_b', 6)\n# The joints velocity\ns_dot = cs.SX.sym('s_dot', num_dof)\n# The base acceleration\nv_b_dot = cs.SX.sym('v_b_dot', 6)\n# The joints acceleration\ns_ddot = cs.SX.sym('s_ddot', num_dof)\n\n# initialize\nmass_matrix_fun = kinDyn.mass_matrix_fun()\ncoriolis_term_fun = kinDyn.coriolis_term_fun()\ngravity_term_fun = kinDyn.gravity_term_fun()\nbias_force_fun = kinDyn.bias_force_fun()\nJacobian_fun = kinDyn.jacobian_fun(\"link6\")\n\nclass Controller:\n    def __init__(self, kp, kd, dt, q_des):\n        self.q_previous = 0.0\n        self.kp = kp\n        self.kd = kd\n        self.dt = dt\n        self.q_des = q_des\n        self.first_iter = True\n\n    def control(self, q, dq):\n        if self.first_iter:\n            self.q_previous = q\n            self.first_iter = False\n\n        self.q_previous = q\n        return self.kp * (self.q_des - q) - self.kd * dq\n\n\n   \nclass Simulator:\n    def __init__(self, q, dt, dq, ddq):\n        self.q = q\n        self.dt = dt\n        self.dq = dq\n        self.ddq = ddq\n\n    def simulate_q(self, tau, h2):\n        dq = self.simulate_dq(tau, h2)\n        self.q += self.dt * dq\n        return self.q\n    \n    def simulate_dq(self, tau, h2):\n        self.ddq = cs.inv(M2) @ (tau - h2)\n        self.dq += self.dt * self.ddq\n        return self.dq\n    \n    def simulate_ddq(self, M2, tau, h2):\n        self.ddq = cs.inv(M2) @ (tau - h2)\n        return self.ddq\n\n\n#Valori randomici\nq_des = (np.random.rand(num_dof) - 0.5) * 5\nxyz = (np.random.rand(3) - 0.5) * 5\nrpy = (np.random.rand(3) - 0.5) * 5\nH_b = utils.H_from_Pos_RPY(xyz, rpy)\nv_b = (np.random.rand(6) - 0.5) * 5\ns = (np.random.rand(len(joints_name_list)) - 0.5) * 5\ns_dot = (np.random.rand(len(joints_name_list)) - 0.5) * 5\n\n\n\n\n\nM = kinDyn.mass_matrix_fun()\nM2 = cs.DM(M(H_b, s))\nM2 = M2[:6, :6]\n\nh = kinDyn.bias_force_fun()\nh2 = cs.DM(h(H_b, s, v_b, s_dot))\nh2 = h2[:6]\n\n\nq_0 = np.zeros(num_dof)\n#q_0 = cs.SX.sym('q_0', num_dof)\nkp = 0.1 \nkd = sqrt(kp)\ndt = 1.0 / 16.0 * 1e-3\ntotal_time = 2.0 * 1e-3\n\n#dq = cs.SX.sym('dq', num_dof)\n#ddq = cs.SX.sym('ddq', num_dof)\n\ndq = np.zeros(num_dof)\nddq = np.zeros(num_dof)\n\n\nN = int(total_time / dt)\n\nctrl = Controller(kp, kd, dt, q_des)\nsimu = Simulator(q_0, dt, dq, ddq)\n\nfor i in range(N):\n    tau = ctrl.control(simu.q, simu.dq)\n    simu.simulate_q(tau, h2)\n    simu.simulate_ddq(M2, tau, h2)\n\nq_des_np = cs.DM(q_des).full().flatten()\nsimu_q_np = cs.DM(simu.q).full().flatten()\n\n# Calcola l'errore medio all'infinito tra i vettori NumPy\nerrore_medio_infinito = np.max(np.abs(q_des_np - simu_q_np))\n\nprint(q_des_np)\nprint(simu_q_np)\n\nprint(\"Errore medio all'infinito:\", errore_medio_infinito)"], "question_code": ["from adam.casadi.computations import KinDynComputations\nfrom adam.geometry import utils\nimport numpy as np\nimport casadi as cs\n#import icub_models\nfrom math import sqrt\n\nurdf_path =  &quot;/Users/tommasoandina/Desktop/doosan-robot2-master/dsr_description2/urdf/h2515.blue.urdf&quot; \n# The joint list\njoints_name_list = ['joint1', 'joint2', 'joint3', 'joint4', 'joint5', 'joint6']\n# Specify the root link\nroot_link = 'base'\n\nkinDyn = KinDynComputations(urdf_path, joints_name_list, root_link)\nnum_dof = kinDyn.NDoF\n\nH = cs.SX.sym('H', 4, 4)\n# The joint values\ns = cs.SX.sym('s', num_dof)\n# The base velocity\nv_b = cs.SX.sym('v_b', 6)\n# The joints velocity\ns_dot = cs.SX.sym('s_dot', num_dof)\n# The base acceleration\nv_b_dot = cs.SX.sym('v_b_dot', 6)\n# The joints acceleration\ns_ddot = cs.SX.sym('s_ddot', num_dof)\n\n# initialize\nmass_matrix_fun = kinDyn.mass_matrix_fun()\ncoriolis_term_fun = kinDyn.coriolis_term_fun()\ngravity_term_fun = kinDyn.gravity_term_fun()\nbias_force_fun = kinDyn.bias_force_fun()\nJacobian_fun = kinDyn.jacobian_fun(&quot;link6&quot;)\n\nclass Controller:\n    def __init__(self, kp, kd, dt, q_des):\n        self.q_previous = 0.0\n        self.kp = kp\n        self.kd = kd\n        self.dt = dt\n        self.q_des = q_des\n        self.first_iter = True\n\n    def control(self, q, dq):\n        if self.first_iter:\n            self.q_previous = q\n            self.first_iter = False\n\n        self.q_previous = q\n        return self.kp * (self.q_des - q) - self.kd * dq\n\n\n   \nclass Simulator:\n    def __init__(self, q, dt, dq, ddq):\n        self.q = q\n        self.dt = dt\n        self.dq = dq\n        self.ddq = ddq\n\n    def simulate_q(self, tau, h2):\n        dq = self.simulate_dq(tau, h2)\n        self.q += self.dt * dq\n        return self.q\n    \n    def simulate_dq(self, tau, h2):\n        self.ddq = cs.inv(M2) @ (tau - h2)\n        self.dq += self.dt * self.ddq\n        return self.dq\n    \n    def simulate_ddq(self, M2, tau, h2):\n        self.ddq = cs.inv(M2) @ (tau - h2)\n        return self.ddq\n\n\n#Valori randomici\nq_des = (np.random.rand(num_dof) - 0.5) * 5\nxyz = (np.random.rand(3) - 0.5) * 5\nrpy = (np.random.rand(3) - 0.5) * 5\nH_b = utils.H_from_Pos_RPY(xyz, rpy)\nv_b = (np.random.rand(6) - 0.5) * 5\ns = (np.random.rand(len(joints_name_list)) - 0.5) * 5\ns_dot = (np.random.rand(len(joints_name_list)) - 0.5) * 5\n\n\n\n\n\nM = kinDyn.mass_matrix_fun()\nM2 = cs.DM(M(H_b, s))\nM2 = M2[:6, :6]\n\nh = kinDyn.bias_force_fun()\nh2 = cs.DM(h(H_b, s, v_b, s_dot))\nh2 = h2[:6]\n\n\nq_0 = np.zeros(num_dof)\n#q_0 = cs.SX.sym('q_0', num_dof)\nkp = 0.1 \nkd = sqrt(kp)\ndt = 1.0 / 16.0 * 1e-3\ntotal_time = 2.0 * 1e-3\n\n#dq = cs.SX.sym('dq', num_dof)\n#ddq = cs.SX.sym('ddq', num_dof)\n\ndq = np.zeros(num_dof)\nddq = np.zeros(num_dof)\n\n\nN = int(total_time / dt)\n\nctrl = Controller(kp, kd, dt, q_des)\nsimu = Simulator(q_0, dt, dq, ddq)\n\nfor i in range(N):\n    tau = ctrl.control(simu.q, simu.dq)\n    simu.simulate_q(tau, h2)\n    simu.simulate_ddq(M2, tau, h2)\n\nq_des_np = cs.DM(q_des).full().flatten()\nsimu_q_np = cs.DM(simu.q).full().flatten()\n\n# Calcola l'errore medio all'infinito tra i vettori NumPy\nerrore_medio_infinito = np.max(np.abs(q_des_np - simu_q_np))\n\nprint(q_des_np)\nprint(simu_q_np)\n\nprint(&quot;Errore medio all'infinito:&quot;, errore_medio_infinito)\n"], "quote": [], "url": "https://stackoverflow.com/questions/78463632/problems-in-python", "answer": [], "answer_code": []},
{"title": "VS Code debugging on Ubuntu w ROS - build and runs but no breakpoints?", "time": 1715131735, "post_content": ["I'm building a running a ROS project from gitHub (https://github.com/niobegrzegorzdec/lsd_slam) which is setup specifically for Ubuntu 20.04 with ROS Noetic installed and a catkin workspace. I can build the project and run it fine from the term window. I can also build it and launch it from within VS Code using the ROS VS plugin. I can add printf statements to the code and see them execute when the code is launched.\nBut if I add breakpoints to the code in VS Code, they never break even at these printf statements that are clearly executing.\nI've scoured the ROS and other blogs to no avail (other than see this seems to be a very common issue). I know in my last job we were able to hit breakpoints in ros nodes so it seems possible. My guess is that there's some env variable or setup.bash missing to make the executable visible to gdb in VS code. Right now I know the ros node executables catkin built are located in catkin_ws/devel/lib//, but maybe VS isn't looking there for some reason.\nSo, when I build and run the program launches and displays the correct data. It also prints out messages I added to the code. But when I set a breakpoint at those print statements (or anywhere else) I get \"Module containing this breakpoint has not yet loaded or the breakpoint address could not be obtained.\" from VS Code.\nWhen I cloned another github project VS_Code_ROS and build it in the very same ROS/Catkin/VS environment, I can set breakpoints and break at them. But despite being a \"ROS\" program, it does not launch using ros commands like roslaunch. It's really just a classic C++ executable."], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/78445709/vs-code-debugging-on-ubuntu-w-ros-build-and-runs-but-no-breakpoints", "answer": [], "answer_code": []},
{"title": "ROS2 Humble colcon build error asked CMake to find a package configuration file provided by \"catkin\", but CMake did not find one", "time": 1714221363, "post_content": ["I have a project on ros noetic, I launched it in docker and everything works, but my task is to run the same project but already on ros 2 humble, I have compiled a docker file and am trying to make colcone build, but I get an error:\nroot@3d0146fbf226:~/src/mcu_interface# colcon build\nStarting >>> mcu_interface\n--- stderr: mcu_interface\nCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\nCompatibility with CMake < 2.8.12 will be removed from a future version of\nCMake.\nUpdate the VERSION argument  value or use a ... suffix to tell\nCMake that the project does not need compatibility with older versions.\nCMake Error at CMakeLists.txt:8 (find_package):\nBy not providing \"Findcatkin.cmake\" in CMAKE_MODULE_PATH this project has\nasked CMake to find a package configuration file provided by \"catkin\", but\nCMake did not find one.\nCould not find a package configuration file provided by \"catkin\" with any\nof the following names:\ncatkinConfig.cmake\ncatkin-config.cmake\n\nAdd the installation prefix of \"catkin\" to CMAKE_PREFIX_PATH or set\n\"catkin_DIR\" to a directory containing one of the above files.  If \"catkin\"\nprovides a separate development package or SDK, be sure it has been\ninstalled.\nI tried to find some information on the internet, but I did not find people who work in docker and want to switch between these versions of ros"], "question_code": ["catkinConfig.cmake\ncatkin-config.cmake\n"], "quote": [], "url": "https://stackoverflow.com/questions/78394990/ros2-humble-colcon-build-error-asked-cmake-to-find-a-package-configuration-file", "answer": [], "answer_code": []},
{"title": "ROS 2 Jazzy: Unable to Install Webots distributed package", "time": 1717760624, "post_content": ["I'm currently trying to install the distributed package for ros2_webots but keep receiving a package not found error.\nThis is what the error looks like:\n\u279c  ~ sudo apt install ros-jazzy-webots-ros2 \nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nE: Unable to locate package ros-jazzy-webots-ros2\n\nand when I look at the list of possible packages to install, all I see are:\n\u279c  ~ sudo apt install ros-jazzy-webots-ros2 \nros-jazzy-webots-ros2-importer     ros-jazzy-webots-ros2-msgs-dbgsym\nros-jazzy-webots-ros2-msgs         ros-jazzy-webots-ros2-tests      \n\nAny help would be greatly appreciated as it seems that I'm able to install every other ros2 jazzy package except webots!"], "question_code": ["\u279c  ~ sudo apt install ros-jazzy-webots-ros2 \nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nE: Unable to locate package ros-jazzy-webots-ros2\n", "\u279c  ~ sudo apt install ros-jazzy-webots-ros2 \nros-jazzy-webots-ros2-importer     ros-jazzy-webots-ros2-msgs-dbgsym\nros-jazzy-webots-ros2-msgs         ros-jazzy-webots-ros2-tests      \n"], "quote": [], "url": "https://stackoverflow.com/questions/78591714/ros-2-jazzy-unable-to-install-webots-distributed-package", "answer": ["I had the same problem. Instead of installing it like you did, I installed the webots from the source, as shown in this page https://docs.ros.org/en/jazzy/Tutorials/Advanced/Simulators/Webots/Installation-Ubuntu.html"], "answer_code": []},
{"title": "gazebo: error while loading shared libraries: libopenh264.so.5: cannot open shared object file: No such file or directory", "time": 1717486042, "post_content": ["When trying to use gazebo on ubuntu 20.04 with ros-noetic I got the error\ngazebo: error while loading shared libraries: libopenh264.so.5: cannot open shared object file: No such file or directory\n\nCan anyone help me with this issue?\nThanks in advance.\nI tried to simply run\ngazebo\n\nwhen running the command\napt search libopenh264\n\nI get\nSorting... Done\nFull Text Search... Done"], "question_code": ["gazebo: error while loading shared libraries: libopenh264.so.5: cannot open shared object file: No such file or directory\n", "gazebo\n", "apt search libopenh264\n", "Sorting... Done\nFull Text Search... Done\n\n"], "quote": [], "url": "https://stackoverflow.com/questions/78573924/gazebo-error-while-loading-shared-libraries-libopenh264-so-5-cannot-open-shar", "answer": ["wget http://ciscobinary.openh264.org/libopenh264-1.8.0-linux64.4.so.bz2\n\nbunzip2 libopenh264-1.8.0-linux64.4.so.bz2\n\nsudo mv libopenh264-1.8.0-linux64.4.so /usr/lib/x86_64-linux-gnu/libopenh264.so.5\n\nsudo ldconfig", "I fixed this issue by building openh264 from the source. I chose the version v2.0.0 which creates the libopenh264.so.5 shared object file. Newer versions created objects like libopenh264.so.7 and didn't work.\ngit clone -b v2.0.0 https://github.com/cisco/openh264\ncd openh264\nmake -j4\nsudo make install\nls /usr/local/lib\n# libopenh264.so.5 ........\nexport PKG_CONFIG_PATH=/usr/local/lib/pkgconfig\nls ${PKG_CONFIG_PATH}\n#openh264.pc"], "answer_code": ["wget http://ciscobinary.openh264.org/libopenh264-1.8.0-linux64.4.so.bz2\n\nbunzip2 libopenh264-1.8.0-linux64.4.so.bz2\n\nsudo mv libopenh264-1.8.0-linux64.4.so /usr/lib/x86_64-linux-gnu/libopenh264.so.5\n\nsudo ldconfig\n", "git clone -b v2.0.0 https://github.com/cisco/openh264\ncd openh264\nmake -j4\nsudo make install\nls /usr/local/lib\n# libopenh264.so.5 ........\nexport PKG_CONFIG_PATH=/usr/local/lib/pkgconfig\nls ${PKG_CONFIG_PATH}\n#openh264.pc\n"]},
{"title": "How to resolve \"context mismatch in svga_surface_destroy\"?", "time": 1715965684, "post_content": ["I tried to create a robot in Gazebo using .xacro, .gazebo, and .launch files, and everything seems fine. However, when I run Gazebo, I encounter the message context mismatch in svga_surface_destroy.\nFrom what I've found, it seems related to map creation. Since I plan to add LIDAR functionality for detection later on, I'm concerned that this issue might affect map creation. Currently, none of my three files contain any code related to map creation. How did this issue occur, and will it affect adding LIDAR functionality in the future? Here are the three files: .xacro, .gazebo, and .launch.\n.xacro\n<?xml version=\"1.0\"?>\n<!-- ###################################### -->\n<!-- DESCRIPTION OF THE 4-WHEELED ROBOT     -->\n<!-- ###################################### -->\n \n<robot name=\"mecanum_robot\" xmlns:xacro=\"http://www.ros.org/wiki/xacro\">\n \n  <!-- Body dimensions -->\n  <xacro:property name=\"body_link_x_dim\" value=\"1\"/>\n  <xacro:property name=\"body_link_y_dim\" value=\"0.6\"/>\n  <xacro:property name=\"body_link_z_dim\" value=\"0.3\"/>\n \n  <!-- Wheel dimensions -->\n  <xacro:property name=\"wheel_link_radius\" value=\"0.15\"/>\n  <xacro:property name=\"wheel_link_length\" value=\"0.1\"/>\n  <xacro:property name=\"wheel_link_z_location\" value=\"-0.1\"/>\n \n  <!-- Material density -->\n  <xacro:property name=\"body_density\" value=\"2710.0\"/>\n  <xacro:property name=\"wheel_density\" value=\"2710.0\"/>\n \n  <!-- Pi constant -->\n  <xacro:property name=\"pi_constant\" value=\"3.14159265\"/>\n \n  <!-- Robot body and wheel mass -->\n  <xacro:property name=\"body_mass\" value=\"${body_density*body_link_x_dim*body_link_y_dim*body_link_z_dim}\"/>\n  <xacro:property name=\"wheel_mass\" value=\"${wheel_density*pi_constant*wheel_link_radius*wheel_link_radius*wheel_link_length}\"/>\n \n  <!-- Moments of inertia of the wheel -->\n  <xacro:property name=\"Iz_wheel\" value=\"${0.5*wheel_mass*wheel_link_radius*wheel_link_radius}\"/>\n  <xacro:property name=\"I_wheel\" value=\"${(1.0/12.0)*wheel_mass*(3.0*wheel_link_radius*wheel_link_radius+wheel_link_length*wheel_link_length)}\"/>\n \n  <!-- This macro defines the complete inertial section of the wheel -->\n  <!-- It is used later in the code                                   -->\n  <xacro:macro name=\"inertia_wheel\">\n    <inertial>\n      <origin rpy=\"0 0 0\" xyz=\"0 0 0\"/>\n      <mass value=\"${wheel_mass}\"/>\n      <inertia ixx=\"${I_wheel}\" ixy=\"0\" ixz=\"0\" iyy=\"${I_wheel}\" iyz=\"0\" izz=\"${Iz_wheel}\" />\n    </inertial>\n  </xacro:macro>\n \n  <!-- Include the file that defines extra Gazebo options and motion control driver -->\n  <xacro:include filename=\"$(find ros_car)/urdf/robot.gazebo\" />\n \n  <!-- ###################################### -->\n  <!-- DEFINE LINKS, JOINTS    -->\n  <!-- ###################################### -->\n \n  <!-- Dummy link otherwise Gazebo will complain -->\n  <link name=\"dummy\"/>\n  <joint name=\"dummy_joint\" type=\"fixed\">\n    <parent link=\"dummy\"/>\n    <child link=\"body_link\"/>\n  </joint>\n \n  <!-- ###################################### -->\n  <!-- START: BODY link of the robot    -->\n  <!-- ###################################### -->\n  <link name=\"body_link\">\n    <visual>\n      <geometry>\n        <box size=\"${body_link_x_dim} ${body_link_y_dim} ${body_link_z_dim}\" />\n      </geometry>\n      <origin rpy=\"0 0 0\" xyz=\"0 0 0\"/>\n    </visual>\n    <collision>\n      <geometry>\n        <box size=\"${body_link_x_dim} ${body_link_y_dim} ${body_link_z_dim}\" />\n      </geometry>\n      <origin rpy=\"0 0 0\" xyz=\"0 0 0\"/>\n    </collision>\n    <inertial>\n      <origin rpy=\"0 0 0\" xyz=\"0 0 0\"/>\n      <mass value=\"${body_mass}\"/>\n      <inertia ixx=\"${(1/12)*body_mass*(body_link_y_dim*body_link_y_dim+body_link_z_dim*body_link_z_dim)}\"\n               ixy=\"0\" ixz=\"0\"\n               iyy=\"${(1/12)*body_mass*(body_link_x_dim*body_link_x_dim+body_link_z_dim*body_link_z_dim)}\"\n               iyz=\"0\"\n               izz=\"${(1/12)*body_mass*(body_link_x_dim*body_link_x_dim+body_link_y_dim*body_link_y_dim)}\" />\n    </inertial>\n  </link>\n  <!-- ###################################### -->\n  <!-- END: BODY link of the robot    -->\n  <!-- ###################################### -->\n \n  <!-- ###################################### -->\n  <!-- START: Back right wheel of the robot and the joint -->\n  <!-- ###################################### -->\n  <joint name=\"wheel1_joint\" type=\"continuous\">\n    <parent link=\"body_link\"/>\n    <child link=\"wheel1_link\"/>\n    <origin xyz=\"${-body_link_x_dim/2+1.2*wheel_link_radius} ${-body_link_y_dim/2-wheel_link_length/2} ${wheel_link_z_location}\" rpy=\"0 0 0\"/>\n    <axis xyz=\"0 1 0\"/>\n    <limit effort=\"1000\" velocity=\"1000\"/>\n    <dynamics damping=\"1.0\" friction=\"1.0\"/>\n  </joint>\n \n  <link name=\"wheel1_link\">\n    <visual>\n      <origin rpy=\"1.570795 0 0\" xyz=\"0 0 0\"/>\n      <geometry>\n        <cylinder length=\"${wheel_link_length}\" radius=\"${wheel_link_radius}\"/>\n      </geometry>\n    </visual>\n    <collision>\n      <origin rpy=\"1.570795 0 0\" xyz=\"0 0 0\"/>\n      <geometry>\n        <cylinder length=\"${wheel_link_length}\" radius=\"${wheel_link_radius}\"/>\n      </geometry>\n    </collision>\n    <xacro:inertia_wheel/>\n  </link>\n  <!-- ###################################### -->\n  <!-- END: Back right wheel of the robot and the joint -->\n  <!-- ###################################### -->\n \n  <!-- ###################################### -->\n  <!-- START: Back left wheel of the robot and the joint -->\n  <!-- ###################################### -->\n  <joint name=\"wheel2_joint\" type=\"continuous\">\n    <parent link=\"body_link\"/>\n    <child link=\"wheel2_link\"/>\n    <origin xyz=\"${-body_link_x_dim/2+1.2*wheel_link_radius} ${body_link_y_dim/2+wheel_link_length/2} ${wheel_link_z_location}\" rpy=\"0 0 0\"/>\n    <axis xyz=\"0 1 0\"/>\n    <limit effort=\"1000\" velocity=\"1000\"/>\n    <dynamics damping=\"1.0\" friction=\"1.0\"/>\n  </joint>\n \n  <link name=\"wheel2_link\">\n    <visual>\n      <origin rpy=\"1.570795 0 0\" xyz=\"0 0 0\"/>\n      <geometry>\n        <cylinder length=\"${wheel_link_length}\" radius=\"${wheel_link_radius}\"/>\n      </geometry>\n    </visual>\n    <collision>\n      <origin rpy=\"1.570795 0 0\" xyz=\"0 0 0\"/>\n      <geometry>\n        <cylinder length=\"${wheel_link_length}\" radius=\"${wheel_link_radius}\"/>\n      </geometry>\n    </collision>\n    <xacro:inertia_wheel/>\n  </link>\n  <!-- ###################################### -->\n  <!-- END: Back left wheel of the robot and the joint -->\n  <!-- ###################################### -->\n \n  <!-- ###################################### -->\n  <!-- START: Front right wheel of the robot and the joint -->\n  <!-- ###################################### -->\n  <joint name=\"wheel3_joint\" type=\"continuous\">\n    <parent link=\"body_link\"/>\n    <child link=\"wheel3_link\"/>\n    <origin xyz=\"${body_link_x_dim/2-1.2*wheel_link_radius} ${-body_link_y_dim/2-wheel_link_length/2} ${wheel_link_z_location}\" rpy=\"0 0 0\"/>\n    <axis xyz=\"0 1 0\"/>\n    <limit effort=\"1000\" velocity=\"1000\"/>\n    <dynamics damping=\"1.0\" friction=\"1.0\"/>\n  </joint>\n \n  <link name=\"wheel3_link\">\n    <visual>\n      <origin rpy=\"1.570795 0 0\" xyz=\"0 0 0\"/>\n      <geometry>\n        <cylinder length=\"${wheel_link_length}\" radius=\"${wheel_link_radius}\"/>\n      </geometry>\n    </visual>\n    <collision>\n      <origin rpy=\"1.570795 0 0\" xyz=\"0 0 0\"/>\n      <geometry>\n        <cylinder length=\"${wheel_link_length}\" radius=\"${wheel_link_radius}\"/>\n      </geometry>\n    </collision>\n    <xacro:inertia_wheel/>\n  </link>\n  <!-- ###################################### -->\n  <!-- END: Front right wheel of the robot and the joint -->\n  <!-- ###################################### -->\n \n  <!-- ###################################### -->\n  <!-- START: Front left wheel of the robot and the joint -->\n  <!-- ###################################### -->\n \n  <joint name=\"wheel4_joint\" type=\"continuous\">\n    <parent link=\"body_link\"/>\n    <child link=\"wheel4_link\"/>\n    <origin xyz=\"${body_link_x_dim/2-1.2*wheel_link_radius} ${body_link_y_dim/2+wheel_link_length/2} ${wheel_link_z_location}\" rpy=\"0 0 0\"/>\n    <axis xyz=\"0 1 0\"/>\n    <limit effort=\"1000\" velocity=\"1000\"/>\n    <dynamics damping=\"1.0\" friction=\"1.0\"/>\n  </joint>\n \n  <link name=\"wheel4_link\">\n    <visual>\n      <origin rpy=\"1.570795 0 0\" xyz=\"0 0 0\"/>\n      <geometry>\n        <cylinder length=\"${wheel_link_length}\" radius=\"${wheel_link_radius}\"/>\n      </geometry>\n    </visual>\n    <collision>\n      <origin rpy=\"1.570795 0 0\" xyz=\"0 0 0\"/>\n      <geometry>\n        <cylinder length=\"${wheel_link_length}\" radius=\"${wheel_link_radius}\"/>\n      </geometry>\n    </collision>\n    <xacro:inertia_wheel/>\n  </link>\n<!-- ###################################### -->\n<!-- END: Front left wheel of the robot and the joint -->\n<!-- ###################################### -->\n \n</robot>\n\n.gazebo\n<?xml version=\"1.0\" ?>\n<!-- #################################################### -->\n<!-- GAZEBO ADDITIONAL DESCRIPTION OF THE 4-WHEELED ROBOT -->\n<!-- #################################################### -->\n<robot>\n \n  <!-- mu1 and mu2 are friction coefficients -->\n  <gazebo reference=\"body_link\">\n    <mu1>0.2</mu1>\n    <mu2>0.2</mu2>\n    <material>Gazebo/Red</material>\n  </gazebo>\n \n  <gazebo reference=\"wheel1_link\">\n    <mu1>0.2</mu1>\n    <mu2>0.2</mu2>\n    <material>Gazebo/Yellow</material>\n  </gazebo>\n \n  <gazebo reference=\"wheel2_link\">\n    <mu1>0.2</mu1>\n    <mu2>0.2</mu2>\n    <material>Gazebo/Yellow</material>\n  </gazebo>\n \n  <gazebo reference=\"wheel3_link\">\n    <mu1>0.2</mu1>\n    <mu2>0.2</mu2>\n    <material>Gazebo/Yellow</material>\n  </gazebo>\n \n  <gazebo reference=\"wheel4_link\">\n    <mu1>0.2</mu1>\n    <mu2>0.2</mu2>\n    <material>Gazebo/Yellow</material>\n  </gazebo>\n \n  <!-- Controller for the 4-wheeled robot -->\n  <gazebo>\n    <plugin name=\"skid_steer_drive_controller\" filename=\"libgazebo_ros_skid_steer_drive.so\">\n      <!-- Control update rate in Hz -->\n      <updateRate>100.0</updateRate>\n      <!-- Leave this empty otherwise, there will be problems with sending control commands -->\n      <robotNamespace> </robotNamespace>\n      <!-- Robot kinematics -->\n      <leftFrontJoint>wheel4_joint</leftFrontJoint>\n      <rightFrontJoint>wheel3_joint</rightFrontJoint>\n      <leftRearJoint>wheel2_joint</leftRearJoint>\n      <rightRearJoint>wheel1_joint</rightRearJoint>\n      <wheelSeparation>${body_link_y_dim+wheel_link_length}</wheelSeparation>\n      <wheelDiameter>${wheel_link_radius}</wheelDiameter>\n \n      <!-- Maximum torque which the wheels can produce, in Nm, defaults to 5 Nm -->\n      <torque>1000</torque>\n \n      <!-- Topic to receive geometry_msgs/Twist message commands, defaults to 'cmd_vel' -->\n      <commandTopic>cmd_vel</commandTopic>\n      <!-- Topic to publish nav_msgs/Odometry messages, defaults to 'odom' -->\n      <odometryTopic>odom</odometryTopic>\n      <!-- Odometry frame, defaults to 'odom' -->\n      <odometryFrame>odom</odometryFrame>\n      <!-- Robot frame to calculate odometry from, defaults to 'base_footprint' -->\n      <robotBaseFrame>dummy</robotBaseFrame>\n      <!-- Set to true to publish transforms for the wheel links, defaults to false -->\n      <publishWheelTF>true</publishWheelTF>\n      <!-- Set to true to publish transforms for the wheel links, defaults to true -->\n      <publishOdom>true</publishOdom>\n      <!-- Set to true to publish sensor_msgs/JointState on /joint_state for the wheel joints, defaults to false -->\n      <publishWheelJointState>true</publishWheelJointState>\n      <!-- This part is required by Gazebo -->\n      <covariance_x>0.0001</covariance_x>\n      <covariance_y>0.0001</covariance_y>\n      <covariance_yaw>0.01</covariance_yaw>\n    </plugin>\n  </gazebo>\n \n</robot>\n\n.launch\n<?xml version=\"1.0\" ?>\n<!-- #################################################### -->\n<!-- LAUNCH FILE FOR THE GAZEBO SIMULATION OF THE 4-WHEELED ROBOT -->\n<!-- #################################################### -->\n \n<launch>\n \n  <include file=\"$(find gazebo_ros)/launch/empty_world.launch\">\n    <arg name=\"paused\" value=\"false\"/>\n    <arg name=\"use_sim_time\" value=\"true\"/>\n    <arg name=\"gui\" value=\"true\"/>\n    <arg name=\"headless\" value=\"true\"/>\n    <arg name=\"debug\" value=\"false\"/>\n  </include>\n \n<!-- Load the robot description -->\n    <param name=\"robot_description\" command=\"$(find xacro)/xacro '$(find ros_car)/urdf/robot.xacro'\"/>\n<!-- Robot state publisher node -->\n    <node name=\"robot_state_publisher\" pkg=\"robot_state_publisher\" type=\"robot_state_publisher\" />\n \n<!-- Spawn the model -->\n<node name=\"urdf_spawn\" pkg=\"gazebo_ros\" type=\"spawn_model\" respawn=\"false\" output=\"screen\" args=\"-urdf -model ros_car -param robot_description\" />\n \n</launch>"], "question_code": ["context mismatch in svga_surface_destroy", ".xacro", "&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!-- ###################################### --&gt;\n&lt;!-- DESCRIPTION OF THE 4-WHEELED ROBOT     --&gt;\n&lt;!-- ###################################### --&gt;\n \n&lt;robot name=&quot;mecanum_robot&quot; xmlns:xacro=&quot;http://www.ros.org/wiki/xacro&quot;&gt;\n \n  &lt;!-- Body dimensions --&gt;\n  &lt;xacro:property name=&quot;body_link_x_dim&quot; value=&quot;1&quot;/&gt;\n  &lt;xacro:property name=&quot;body_link_y_dim&quot; value=&quot;0.6&quot;/&gt;\n  &lt;xacro:property name=&quot;body_link_z_dim&quot; value=&quot;0.3&quot;/&gt;\n \n  &lt;!-- Wheel dimensions --&gt;\n  &lt;xacro:property name=&quot;wheel_link_radius&quot; value=&quot;0.15&quot;/&gt;\n  &lt;xacro:property name=&quot;wheel_link_length&quot; value=&quot;0.1&quot;/&gt;\n  &lt;xacro:property name=&quot;wheel_link_z_location&quot; value=&quot;-0.1&quot;/&gt;\n \n  &lt;!-- Material density --&gt;\n  &lt;xacro:property name=&quot;body_density&quot; value=&quot;2710.0&quot;/&gt;\n  &lt;xacro:property name=&quot;wheel_density&quot; value=&quot;2710.0&quot;/&gt;\n \n  &lt;!-- Pi constant --&gt;\n  &lt;xacro:property name=&quot;pi_constant&quot; value=&quot;3.14159265&quot;/&gt;\n \n  &lt;!-- Robot body and wheel mass --&gt;\n  &lt;xacro:property name=&quot;body_mass&quot; value=&quot;${body_density*body_link_x_dim*body_link_y_dim*body_link_z_dim}&quot;/&gt;\n  &lt;xacro:property name=&quot;wheel_mass&quot; value=&quot;${wheel_density*pi_constant*wheel_link_radius*wheel_link_radius*wheel_link_length}&quot;/&gt;\n \n  &lt;!-- Moments of inertia of the wheel --&gt;\n  &lt;xacro:property name=&quot;Iz_wheel&quot; value=&quot;${0.5*wheel_mass*wheel_link_radius*wheel_link_radius}&quot;/&gt;\n  &lt;xacro:property name=&quot;I_wheel&quot; value=&quot;${(1.0/12.0)*wheel_mass*(3.0*wheel_link_radius*wheel_link_radius+wheel_link_length*wheel_link_length)}&quot;/&gt;\n \n  &lt;!-- This macro defines the complete inertial section of the wheel --&gt;\n  &lt;!-- It is used later in the code                                   --&gt;\n  &lt;xacro:macro name=&quot;inertia_wheel&quot;&gt;\n    &lt;inertial&gt;\n      &lt;origin rpy=&quot;0 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;mass value=&quot;${wheel_mass}&quot;/&gt;\n      &lt;inertia ixx=&quot;${I_wheel}&quot; ixy=&quot;0&quot; ixz=&quot;0&quot; iyy=&quot;${I_wheel}&quot; iyz=&quot;0&quot; izz=&quot;${Iz_wheel}&quot; /&gt;\n    &lt;/inertial&gt;\n  &lt;/xacro:macro&gt;\n \n  &lt;!-- Include the file that defines extra Gazebo options and motion control driver --&gt;\n  &lt;xacro:include filename=&quot;$(find ros_car)/urdf/robot.gazebo&quot; /&gt;\n \n  &lt;!-- ###################################### --&gt;\n  &lt;!-- DEFINE LINKS, JOINTS    --&gt;\n  &lt;!-- ###################################### --&gt;\n \n  &lt;!-- Dummy link otherwise Gazebo will complain --&gt;\n  &lt;link name=&quot;dummy&quot;/&gt;\n  &lt;joint name=&quot;dummy_joint&quot; type=&quot;fixed&quot;&gt;\n    &lt;parent link=&quot;dummy&quot;/&gt;\n    &lt;child link=&quot;body_link&quot;/&gt;\n  &lt;/joint&gt;\n \n  &lt;!-- ###################################### --&gt;\n  &lt;!-- START: BODY link of the robot    --&gt;\n  &lt;!-- ###################################### --&gt;\n  &lt;link name=&quot;body_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;geometry&gt;\n        &lt;box size=&quot;${body_link_x_dim} ${body_link_y_dim} ${body_link_z_dim}&quot; /&gt;\n      &lt;/geometry&gt;\n      &lt;origin rpy=&quot;0 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;geometry&gt;\n        &lt;box size=&quot;${body_link_x_dim} ${body_link_y_dim} ${body_link_z_dim}&quot; /&gt;\n      &lt;/geometry&gt;\n      &lt;origin rpy=&quot;0 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n    &lt;/collision&gt;\n    &lt;inertial&gt;\n      &lt;origin rpy=&quot;0 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;mass value=&quot;${body_mass}&quot;/&gt;\n      &lt;inertia ixx=&quot;${(1/12)*body_mass*(body_link_y_dim*body_link_y_dim+body_link_z_dim*body_link_z_dim)}&quot;\n               ixy=&quot;0&quot; ixz=&quot;0&quot;\n               iyy=&quot;${(1/12)*body_mass*(body_link_x_dim*body_link_x_dim+body_link_z_dim*body_link_z_dim)}&quot;\n               iyz=&quot;0&quot;\n               izz=&quot;${(1/12)*body_mass*(body_link_x_dim*body_link_x_dim+body_link_y_dim*body_link_y_dim)}&quot; /&gt;\n    &lt;/inertial&gt;\n  &lt;/link&gt;\n  &lt;!-- ###################################### --&gt;\n  &lt;!-- END: BODY link of the robot    --&gt;\n  &lt;!-- ###################################### --&gt;\n \n  &lt;!-- ###################################### --&gt;\n  &lt;!-- START: Back right wheel of the robot and the joint --&gt;\n  &lt;!-- ###################################### --&gt;\n  &lt;joint name=&quot;wheel1_joint&quot; type=&quot;continuous&quot;&gt;\n    &lt;parent link=&quot;body_link&quot;/&gt;\n    &lt;child link=&quot;wheel1_link&quot;/&gt;\n    &lt;origin xyz=&quot;${-body_link_x_dim/2+1.2*wheel_link_radius} ${-body_link_y_dim/2-wheel_link_length/2} ${wheel_link_z_location}&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;axis xyz=&quot;0 1 0&quot;/&gt;\n    &lt;limit effort=&quot;1000&quot; velocity=&quot;1000&quot;/&gt;\n    &lt;dynamics damping=&quot;1.0&quot; friction=&quot;1.0&quot;/&gt;\n  &lt;/joint&gt;\n \n  &lt;link name=&quot;wheel1_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;origin rpy=&quot;1.570795 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=&quot;${wheel_link_length}&quot; radius=&quot;${wheel_link_radius}&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;origin rpy=&quot;1.570795 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=&quot;${wheel_link_length}&quot; radius=&quot;${wheel_link_radius}&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;xacro:inertia_wheel/&gt;\n  &lt;/link&gt;\n  &lt;!-- ###################################### --&gt;\n  &lt;!-- END: Back right wheel of the robot and the joint --&gt;\n  &lt;!-- ###################################### --&gt;\n \n  &lt;!-- ###################################### --&gt;\n  &lt;!-- START: Back left wheel of the robot and the joint --&gt;\n  &lt;!-- ###################################### --&gt;\n  &lt;joint name=&quot;wheel2_joint&quot; type=&quot;continuous&quot;&gt;\n    &lt;parent link=&quot;body_link&quot;/&gt;\n    &lt;child link=&quot;wheel2_link&quot;/&gt;\n    &lt;origin xyz=&quot;${-body_link_x_dim/2+1.2*wheel_link_radius} ${body_link_y_dim/2+wheel_link_length/2} ${wheel_link_z_location}&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;axis xyz=&quot;0 1 0&quot;/&gt;\n    &lt;limit effort=&quot;1000&quot; velocity=&quot;1000&quot;/&gt;\n    &lt;dynamics damping=&quot;1.0&quot; friction=&quot;1.0&quot;/&gt;\n  &lt;/joint&gt;\n \n  &lt;link name=&quot;wheel2_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;origin rpy=&quot;1.570795 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=&quot;${wheel_link_length}&quot; radius=&quot;${wheel_link_radius}&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;origin rpy=&quot;1.570795 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=&quot;${wheel_link_length}&quot; radius=&quot;${wheel_link_radius}&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;xacro:inertia_wheel/&gt;\n  &lt;/link&gt;\n  &lt;!-- ###################################### --&gt;\n  &lt;!-- END: Back left wheel of the robot and the joint --&gt;\n  &lt;!-- ###################################### --&gt;\n \n  &lt;!-- ###################################### --&gt;\n  &lt;!-- START: Front right wheel of the robot and the joint --&gt;\n  &lt;!-- ###################################### --&gt;\n  &lt;joint name=&quot;wheel3_joint&quot; type=&quot;continuous&quot;&gt;\n    &lt;parent link=&quot;body_link&quot;/&gt;\n    &lt;child link=&quot;wheel3_link&quot;/&gt;\n    &lt;origin xyz=&quot;${body_link_x_dim/2-1.2*wheel_link_radius} ${-body_link_y_dim/2-wheel_link_length/2} ${wheel_link_z_location}&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;axis xyz=&quot;0 1 0&quot;/&gt;\n    &lt;limit effort=&quot;1000&quot; velocity=&quot;1000&quot;/&gt;\n    &lt;dynamics damping=&quot;1.0&quot; friction=&quot;1.0&quot;/&gt;\n  &lt;/joint&gt;\n \n  &lt;link name=&quot;wheel3_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;origin rpy=&quot;1.570795 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=&quot;${wheel_link_length}&quot; radius=&quot;${wheel_link_radius}&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;origin rpy=&quot;1.570795 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=&quot;${wheel_link_length}&quot; radius=&quot;${wheel_link_radius}&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;xacro:inertia_wheel/&gt;\n  &lt;/link&gt;\n  &lt;!-- ###################################### --&gt;\n  &lt;!-- END: Front right wheel of the robot and the joint --&gt;\n  &lt;!-- ###################################### --&gt;\n \n  &lt;!-- ###################################### --&gt;\n  &lt;!-- START: Front left wheel of the robot and the joint --&gt;\n  &lt;!-- ###################################### --&gt;\n \n  &lt;joint name=&quot;wheel4_joint&quot; type=&quot;continuous&quot;&gt;\n    &lt;parent link=&quot;body_link&quot;/&gt;\n    &lt;child link=&quot;wheel4_link&quot;/&gt;\n    &lt;origin xyz=&quot;${body_link_x_dim/2-1.2*wheel_link_radius} ${body_link_y_dim/2+wheel_link_length/2} ${wheel_link_z_location}&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;axis xyz=&quot;0 1 0&quot;/&gt;\n    &lt;limit effort=&quot;1000&quot; velocity=&quot;1000&quot;/&gt;\n    &lt;dynamics damping=&quot;1.0&quot; friction=&quot;1.0&quot;/&gt;\n  &lt;/joint&gt;\n \n  &lt;link name=&quot;wheel4_link&quot;&gt;\n    &lt;visual&gt;\n      &lt;origin rpy=&quot;1.570795 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=&quot;${wheel_link_length}&quot; radius=&quot;${wheel_link_radius}&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n      &lt;origin rpy=&quot;1.570795 0 0&quot; xyz=&quot;0 0 0&quot;/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=&quot;${wheel_link_length}&quot; radius=&quot;${wheel_link_radius}&quot;/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;xacro:inertia_wheel/&gt;\n  &lt;/link&gt;\n&lt;!-- ###################################### --&gt;\n&lt;!-- END: Front left wheel of the robot and the joint --&gt;\n&lt;!-- ###################################### --&gt;\n \n&lt;/robot&gt;\n", ".gazebo", "&lt;?xml version=&quot;1.0&quot; ?&gt;\n&lt;!-- #################################################### --&gt;\n&lt;!-- GAZEBO ADDITIONAL DESCRIPTION OF THE 4-WHEELED ROBOT --&gt;\n&lt;!-- #################################################### --&gt;\n&lt;robot&gt;\n \n  &lt;!-- mu1 and mu2 are friction coefficients --&gt;\n  &lt;gazebo reference=&quot;body_link&quot;&gt;\n    &lt;mu1&gt;0.2&lt;/mu1&gt;\n    &lt;mu2&gt;0.2&lt;/mu2&gt;\n    &lt;material&gt;Gazebo/Red&lt;/material&gt;\n  &lt;/gazebo&gt;\n \n  &lt;gazebo reference=&quot;wheel1_link&quot;&gt;\n    &lt;mu1&gt;0.2&lt;/mu1&gt;\n    &lt;mu2&gt;0.2&lt;/mu2&gt;\n    &lt;material&gt;Gazebo/Yellow&lt;/material&gt;\n  &lt;/gazebo&gt;\n \n  &lt;gazebo reference=&quot;wheel2_link&quot;&gt;\n    &lt;mu1&gt;0.2&lt;/mu1&gt;\n    &lt;mu2&gt;0.2&lt;/mu2&gt;\n    &lt;material&gt;Gazebo/Yellow&lt;/material&gt;\n  &lt;/gazebo&gt;\n \n  &lt;gazebo reference=&quot;wheel3_link&quot;&gt;\n    &lt;mu1&gt;0.2&lt;/mu1&gt;\n    &lt;mu2&gt;0.2&lt;/mu2&gt;\n    &lt;material&gt;Gazebo/Yellow&lt;/material&gt;\n  &lt;/gazebo&gt;\n \n  &lt;gazebo reference=&quot;wheel4_link&quot;&gt;\n    &lt;mu1&gt;0.2&lt;/mu1&gt;\n    &lt;mu2&gt;0.2&lt;/mu2&gt;\n    &lt;material&gt;Gazebo/Yellow&lt;/material&gt;\n  &lt;/gazebo&gt;\n \n  &lt;!-- Controller for the 4-wheeled robot --&gt;\n  &lt;gazebo&gt;\n    &lt;plugin name=&quot;skid_steer_drive_controller&quot; filename=&quot;libgazebo_ros_skid_steer_drive.so&quot;&gt;\n      &lt;!-- Control update rate in Hz --&gt;\n      &lt;updateRate&gt;100.0&lt;/updateRate&gt;\n      &lt;!-- Leave this empty otherwise, there will be problems with sending control commands --&gt;\n      &lt;robotNamespace&gt; &lt;/robotNamespace&gt;\n      &lt;!-- Robot kinematics --&gt;\n      &lt;leftFrontJoint&gt;wheel4_joint&lt;/leftFrontJoint&gt;\n      &lt;rightFrontJoint&gt;wheel3_joint&lt;/rightFrontJoint&gt;\n      &lt;leftRearJoint&gt;wheel2_joint&lt;/leftRearJoint&gt;\n      &lt;rightRearJoint&gt;wheel1_joint&lt;/rightRearJoint&gt;\n      &lt;wheelSeparation&gt;${body_link_y_dim+wheel_link_length}&lt;/wheelSeparation&gt;\n      &lt;wheelDiameter&gt;${wheel_link_radius}&lt;/wheelDiameter&gt;\n \n      &lt;!-- Maximum torque which the wheels can produce, in Nm, defaults to 5 Nm --&gt;\n      &lt;torque&gt;1000&lt;/torque&gt;\n \n      &lt;!-- Topic to receive geometry_msgs/Twist message commands, defaults to 'cmd_vel' --&gt;\n      &lt;commandTopic&gt;cmd_vel&lt;/commandTopic&gt;\n      &lt;!-- Topic to publish nav_msgs/Odometry messages, defaults to 'odom' --&gt;\n      &lt;odometryTopic&gt;odom&lt;/odometryTopic&gt;\n      &lt;!-- Odometry frame, defaults to 'odom' --&gt;\n      &lt;odometryFrame&gt;odom&lt;/odometryFrame&gt;\n      &lt;!-- Robot frame to calculate odometry from, defaults to 'base_footprint' --&gt;\n      &lt;robotBaseFrame&gt;dummy&lt;/robotBaseFrame&gt;\n      &lt;!-- Set to true to publish transforms for the wheel links, defaults to false --&gt;\n      &lt;publishWheelTF&gt;true&lt;/publishWheelTF&gt;\n      &lt;!-- Set to true to publish transforms for the wheel links, defaults to true --&gt;\n      &lt;publishOdom&gt;true&lt;/publishOdom&gt;\n      &lt;!-- Set to true to publish sensor_msgs/JointState on /joint_state for the wheel joints, defaults to false --&gt;\n      &lt;publishWheelJointState&gt;true&lt;/publishWheelJointState&gt;\n      &lt;!-- This part is required by Gazebo --&gt;\n      &lt;covariance_x&gt;0.0001&lt;/covariance_x&gt;\n      &lt;covariance_y&gt;0.0001&lt;/covariance_y&gt;\n      &lt;covariance_yaw&gt;0.01&lt;/covariance_yaw&gt;\n    &lt;/plugin&gt;\n  &lt;/gazebo&gt;\n \n&lt;/robot&gt;\n", ".launch", "&lt;?xml version=&quot;1.0&quot; ?&gt;\n&lt;!-- #################################################### --&gt;\n&lt;!-- LAUNCH FILE FOR THE GAZEBO SIMULATION OF THE 4-WHEELED ROBOT --&gt;\n&lt;!-- #################################################### --&gt;\n \n&lt;launch&gt;\n \n  &lt;include file=&quot;$(find gazebo_ros)/launch/empty_world.launch&quot;&gt;\n    &lt;arg name=&quot;paused&quot; value=&quot;false&quot;/&gt;\n    &lt;arg name=&quot;use_sim_time&quot; value=&quot;true&quot;/&gt;\n    &lt;arg name=&quot;gui&quot; value=&quot;true&quot;/&gt;\n    &lt;arg name=&quot;headless&quot; value=&quot;true&quot;/&gt;\n    &lt;arg name=&quot;debug&quot; value=&quot;false&quot;/&gt;\n  &lt;/include&gt;\n \n&lt;!-- Load the robot description --&gt;\n    &lt;param name=&quot;robot_description&quot; command=&quot;$(find xacro)/xacro '$(find ros_car)/urdf/robot.xacro'&quot;/&gt;\n&lt;!-- Robot state publisher node --&gt;\n    &lt;node name=&quot;robot_state_publisher&quot; pkg=&quot;robot_state_publisher&quot; type=&quot;robot_state_publisher&quot; /&gt;\n \n&lt;!-- Spawn the model --&gt;\n&lt;node name=&quot;urdf_spawn&quot; pkg=&quot;gazebo_ros&quot; type=&quot;spawn_model&quot; respawn=&quot;false&quot; output=&quot;screen&quot; args=&quot;-urdf -model ros_car -param robot_description&quot; /&gt;\n \n&lt;/launch&gt;\n"], "quote": [], "url": "https://stackoverflow.com/questions/78497034/how-to-resolve-context-mismatch-in-svga-surface-destroy", "answer": ["It's not a critical issue. You will only observe this warning with the VMWare SVGA3D driver on Linux. It's not related to either python nor ROS, nor any of your configuration, but is caused by UI framework / rendering backend for the visualization you are using.\nIt's only a informational message by the backing OpenGL driver, that the application was using multiple OpenGL context instances (that's legal), has been exchanging resources between those instances (that's also legal), but ultimately ended up issuing the destruction of the resource not in the original, owning OpenGL context (which is not exactly legal, but widely accepted).\nThis does not cause a resource leak (it has been detected and corrected by the driver), nor will it cause a crash. It's also a safe operation on essentially any OpenGL driver I'm aware of.\nIt still warrants a warning as the incorrect application of context sharing may result in the implicit teardown of resources on the teardown of the owning context, even when still in use by the other context on another thread."], "answer_code": ["VMWare SVGA3D"]},
{"title": "How could I accomplish the equivalent of a ROS service in ZeroMQ?", "time": 1719481863, "post_content": ["In short: How could I realize something like a \"Service\" from ROS in ZMQ?\n\nROS2 is typically based on subscribers and publishers to topics, in the same way that ZeroMQ uses them: messages are published under a path and only clients that are subscribed to (a base of) that path receive it.\nBut ROS2 also has a concept called services (docs), where a request is pushed to an address and a server-like thing listening to that address will send a reply. A nice GIF:\n\nWhat is great about this concept, is the service client doesn't need to know who hosts the service. They are matched only by a name.\nIn ZMQ I am hoping to achieve something similar: I have a bunch of functions (services?) that I want to distribute over a set of sockets (servers). I want those services to connect to a single client and have this client make calls without the client having to know is going to be connected beforehand (e.g. by calling a service by name only).\nSo the client might make calls to:\n/machine/valve\n/machine/leds\n/global/state\n\nAnd will receive replies from them. But maybe from a single or 2 or 3 different nodes, depending on what's running.\n\nOne option would be to use PUB-SUB and SUB-PUB in ZMQ for these kind of commands. The client would also bind a subscriber to listen to confirmations published for the commands. But some limitations are:i) the publisher won't know if there are no subscribers,ii) there is no way to tell if the published message got dropped,iii) there is no way to prevent multiple nodes listening to the same topic, resulting in double execution of functions.\nThe other option is REQ-REP, where the client binds a REQ for each feature and nodes connect with REQ. The main downside here is the client already has to split up the functionality beforehand."], "question_code": ["/machine/valve\n/machine/leds\n/global/state\n", "PUB-SUB", "SUB-PUB", "REQ-REP", "REQ", "REQ"], "quote": [], "url": "https://stackoverflow.com/questions/78676853/how-could-i-accomplish-the-equivalent-of-a-ros-service-in-zeromq", "answer": ["It's been a little while but I wanted to share my full demo, based on S.Zobov's answer.\nSo I have a REQ client, a REQ service and a ROUTER-ROUTER broker. The service registers itself by sending a request to the router, which the router leaves unanswered. When a client makes a request, the right service request is now answered and the service will send a new request. The broker sends the response back to the client.\n\nNote that for the REQ nodes the address in the multipart message is implicit.\nThere could be any number of clients for any number of services. The limit is a service can handle only a single client at the same time.\nThis <path> that a client uses could be anything that the broker resolves. The easiest would be to give the service sockets explicit names and use those directly.\nClient code:\nimport zmq\nimport sys\nfrom time import sleep\n\n\ndef main():\n    if len(sys.argv) < 2:\n        raise RuntimeError(\"Pass <url> as CLI argument\")\n\n    url = sys.argv[1]\n\n    context = zmq.Context()\n    socket = context.socket(zmq.REQ)\n    socket.setsockopt(zmq.RCVTIMEO, 1000)  # milliseconds\n    socket.setsockopt(zmq.REQ_RELAXED, 1)  # Allow skipping a reply\n    socket.connect(\"tcp://localhost:5555\")\n\n    prefix = f\"{url}:\".encode()\n\n    count = 1\n\n    while True:\n        msg = f\"question {count}\"\n        print(f\"Sending `{msg}`...\")\n        socket.send(prefix + msg.encode())\n\n        try:\n            reply = socket.recv()\n            print(\"Received:\", reply)\n        except zmq.Again:\n            print(\"ERROR - Timed out\")\n\n        count += 1\n\n        sleep(0.5)\n\n\nif __name__ == \"__main__\":\n    main()\n\nService code:\nimport zmq\nimport sys\nimport signal\n\n\ndef main():\n    if len(sys.argv) < 2:\n        raise RuntimeError(\"Pass <url> as CLI argument\")\n\n    signal.signal(signal.SIGINT, signal.SIG_DFL)\n\n    url = sys.argv[1]\n\n    context = zmq.Context()\n    socket = context.socket(zmq.REQ)\n    socket.identity = url.encode()  # Set socket identification to URL\n    socket.connect(\"tcp://localhost:5556\")\n\n    print(f\"Registering at broker...\")\n    socket.send(b\"READY\")\n\n    while True:\n        query = socket.recv()\n        address_client, _, payload = query.partition(b\":\")\n        print(\"Received:\", payload)\n        answer = f\"{url} answer to '{payload.decode()}'\"\n        print(f\"Sending `{answer}`...\")\n        socket.send(address_client + b\":\" + answer.encode())\n\n\nif __name__ == \"__main__\":\n    main()\n\nBroker code:\nfrom typing import Set, Dict, Tuple\nfrom time import time\nimport zmq\nimport signal\n\n\ndef main():\n    signal.signal(signal.SIGINT, signal.SIG_DFL)\n\n    context = zmq.Context()\n    socket_frontend = context.socket(zmq.ROUTER)  # Listen for clients\n    socket_frontend.bind(\"tcp://*:5555\")\n    socket_backend = context.socket(zmq.ROUTER)  # Listen for services (\"workers\")\n    socket_backend.bind(\"tcp://*:5556\")\n\n    services: Set[bytes] = set()  # List of registered services]\n    outstanding_requests: Dict[bytes, float] = {}\n    # ^ {service_address: (client_address, time()) - to detect dropped services\n\n    poller = zmq.Poller()\n    poller.register(socket_backend, zmq.POLLIN)\n    poller.register(socket_frontend, zmq.POLLIN)\n\n    while True:\n        sockets = dict(poller.poll(timeout=50))  # Sockets with incoming data\n\n        if socket_backend in sockets:\n            request = socket_backend.recv_multipart()\n            address_service, _, data = request[:3]\n\n            if address_service in outstanding_requests:\n                outstanding_requests.pop(address_service)  # Remove from open list\n\n            if data == b\"READY\":\n                if address_service in services:\n                    raise RuntimeError(\n                        f\"URL `{address_service.decode()}` already registered!\"\n                    )\n\n                services.add(address_service)\n                print(\"Registered new service:\", address_service)\n            else:\n                address_client, _, payload = data.partition(b\":\")\n\n                # Forward the service reply to the original client:\n                socket_frontend.send_multipart([address_client, b\"\", payload])\n\n        if socket_frontend in sockets:\n            request = socket_frontend.recv_multipart()\n            address_client, _, data = request[:3]\n            address_service, _, payload = data.partition(b\":\")\n\n            if address_service not in services:\n                print(f\"URL `{address_service.decode()}` called by client is not found\")\n                socket_frontend.send_multipart([address_client, b\"\", b\"NOT-FOUND\"])\n            else:\n                new_data = address_client + b\":\" + payload\n\n                # Forward request to worker that identifies itself with the URL:\n                socket_backend.send_multipart([address_service, b\"\", new_data])\n                if address_service not in outstanding_requests:\n                    outstanding_requests[address_service] = time()\n\n        # Detect dropped services:\n        for address_service in list(outstanding_requests.keys()):\n            last_request = outstanding_requests[address_service]\n            if time() - last_request > 0.5:\n                # Looks the service is not responsive, de-register it\n                services.remove(address_service)\n                outstanding_requests.pop(address_service)\n                print(f\"De-registered service: {address_service}\")\n\n\nif __name__ == \"__main__\":\n    main()", "The question you asked is a little broad, but I think there are a few ways how you can implement your architecture.\n\nUse XPUB/XSUB with a handcrafted proxy that will dispatch a response to the correct sockets.\n\n\n\nUse ROUTER/DEALER with REQ/REP.\n\n\nIn both cases, I recommend reading zguide, at least the first five chapters, since it covers most of the concepts you need to know to implement your requirements."], "answer_code": ["REQ", "REQ", "ROUTER", "ROUTER", "REQ", "&lt;path&gt;", "import zmq\nimport sys\nfrom time import sleep\n\n\ndef main():\n    if len(sys.argv) &lt; 2:\n        raise RuntimeError(&quot;Pass &lt;url&gt; as CLI argument&quot;)\n\n    url = sys.argv[1]\n\n    context = zmq.Context()\n    socket = context.socket(zmq.REQ)\n    socket.setsockopt(zmq.RCVTIMEO, 1000)  # milliseconds\n    socket.setsockopt(zmq.REQ_RELAXED, 1)  # Allow skipping a reply\n    socket.connect(&quot;tcp://localhost:5555&quot;)\n\n    prefix = f&quot;{url}:&quot;.encode()\n\n    count = 1\n\n    while True:\n        msg = f&quot;question {count}&quot;\n        print(f&quot;Sending `{msg}`...&quot;)\n        socket.send(prefix + msg.encode())\n\n        try:\n            reply = socket.recv()\n            print(&quot;Received:&quot;, reply)\n        except zmq.Again:\n            print(&quot;ERROR - Timed out&quot;)\n\n        count += 1\n\n        sleep(0.5)\n\n\nif __name__ == &quot;__main__&quot;:\n    main()\n", "import zmq\nimport sys\nimport signal\n\n\ndef main():\n    if len(sys.argv) &lt; 2:\n        raise RuntimeError(&quot;Pass &lt;url&gt; as CLI argument&quot;)\n\n    signal.signal(signal.SIGINT, signal.SIG_DFL)\n\n    url = sys.argv[1]\n\n    context = zmq.Context()\n    socket = context.socket(zmq.REQ)\n    socket.identity = url.encode()  # Set socket identification to URL\n    socket.connect(&quot;tcp://localhost:5556&quot;)\n\n    print(f&quot;Registering at broker...&quot;)\n    socket.send(b&quot;READY&quot;)\n\n    while True:\n        query = socket.recv()\n        address_client, _, payload = query.partition(b&quot;:&quot;)\n        print(&quot;Received:&quot;, payload)\n        answer = f&quot;{url} answer to '{payload.decode()}'&quot;\n        print(f&quot;Sending `{answer}`...&quot;)\n        socket.send(address_client + b&quot;:&quot; + answer.encode())\n\n\nif __name__ == &quot;__main__&quot;:\n    main()\n", "from typing import Set, Dict, Tuple\nfrom time import time\nimport zmq\nimport signal\n\n\ndef main():\n    signal.signal(signal.SIGINT, signal.SIG_DFL)\n\n    context = zmq.Context()\n    socket_frontend = context.socket(zmq.ROUTER)  # Listen for clients\n    socket_frontend.bind(&quot;tcp://*:5555&quot;)\n    socket_backend = context.socket(zmq.ROUTER)  # Listen for services (&quot;workers&quot;)\n    socket_backend.bind(&quot;tcp://*:5556&quot;)\n\n    services: Set[bytes] = set()  # List of registered services]\n    outstanding_requests: Dict[bytes, float] = {}\n    # ^ {service_address: (client_address, time()) - to detect dropped services\n\n    poller = zmq.Poller()\n    poller.register(socket_backend, zmq.POLLIN)\n    poller.register(socket_frontend, zmq.POLLIN)\n\n    while True:\n        sockets = dict(poller.poll(timeout=50))  # Sockets with incoming data\n\n        if socket_backend in sockets:\n            request = socket_backend.recv_multipart()\n            address_service, _, data = request[:3]\n\n            if address_service in outstanding_requests:\n                outstanding_requests.pop(address_service)  # Remove from open list\n\n            if data == b&quot;READY&quot;:\n                if address_service in services:\n                    raise RuntimeError(\n                        f&quot;URL `{address_service.decode()}` already registered!&quot;\n                    )\n\n                services.add(address_service)\n                print(&quot;Registered new service:&quot;, address_service)\n            else:\n                address_client, _, payload = data.partition(b&quot;:&quot;)\n\n                # Forward the service reply to the original client:\n                socket_frontend.send_multipart([address_client, b&quot;&quot;, payload])\n\n        if socket_frontend in sockets:\n            request = socket_frontend.recv_multipart()\n            address_client, _, data = request[:3]\n            address_service, _, payload = data.partition(b&quot;:&quot;)\n\n            if address_service not in services:\n                print(f&quot;URL `{address_service.decode()}` called by client is not found&quot;)\n                socket_frontend.send_multipart([address_client, b&quot;&quot;, b&quot;NOT-FOUND&quot;])\n            else:\n                new_data = address_client + b&quot;:&quot; + payload\n\n                # Forward request to worker that identifies itself with the URL:\n                socket_backend.send_multipart([address_service, b&quot;&quot;, new_data])\n                if address_service not in outstanding_requests:\n                    outstanding_requests[address_service] = time()\n\n        # Detect dropped services:\n        for address_service in list(outstanding_requests.keys()):\n            last_request = outstanding_requests[address_service]\n            if time() - last_request &gt; 0.5:\n                # Looks the service is not responsive, de-register it\n                services.remove(address_service)\n                outstanding_requests.pop(address_service)\n                print(f&quot;De-registered service: {address_service}&quot;)\n\n\nif __name__ == &quot;__main__&quot;:\n    main()\n"]},
{"title": "pcl_conversions fails to convert from sensor_msgs::PointCloud2 to pcl::PointCloud2 on Jetson (arm architecture)", "time": 1717766878, "post_content": ["I am trying to use the pcl_conversions library to convert the pointcloud from sensor_msgs::msg::PointCloud2 to pcl::PCLPointCloud2.\nI am working on a Jetson (ARM architecture) with Jetpack 5.0, in a docker container with Ubuntu 20.04, gcc and g++ version 9.4.0, cmake version 3.22.3 and ROS 2 Foxy.\nI have installed the library with the usual command apt install libpcl-dev and the version installed is the 1.10.\nThe part of the code that gives compiling error is the following:\nvoid GlobalPlanner::pointCloudCallback(const sensor_msgs::msg::PointCloud2::SharedPtr msg) {\n\n  pcl::PCLPointCloud2::Ptr pcl_pc2(new pcl::PCLPointCloud2);\n\n  pcl_conversions::toPCL(*msg, *pcl_pc2);\n  \n}\n\nand the error is\nerror: no matching function for call to \u2018toPCL(const SharedPtr&, pcl::PCLPointCloud2::Ptr&)\u2019\n  239 |   pcl_conversions::toPCL(msg, pcl_pc2);\n      |                                      ^\nIn file included from /home/user/D4A/ras/ros2/ras_node_ws/src/navigation/include/global_planner.h:19,\n                 from /home/user/D4A/ras/ros2/ras_node_ws/src/navigation/src/global_planner.cpp:1:\n/usr/include/pcl_conversions/pcl_conversions.h:86:8: note: candidate: \u2018void pcl_conversions::toPCL(const ros::Time&, pcl::uint64_t&)\u2019\n   86 |   void toPCL(const ros::Time &stamp, pcl::uint64_t &pcl_stamp)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:86:31: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const ros::Time&\u2019\n   86 |   void toPCL(const ros::Time &stamp, pcl::uint64_t &pcl_stamp)\n      |              ~~~~~~~~~~~~~~~~~^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:100:17: note: candidate: \u2018pcl::uint64_t pcl_conversions::toPCL(const ros::Time&)\u2019\n  100 |   pcl::uint64_t toPCL(const ros::Time &stamp)\n      |                 ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:100:17: note:   candidate expects 1 argument, 2 provided\n/usr/include/pcl_conversions/pcl_conversions.h:118:8: note: candidate: \u2018void pcl_conversions::toPCL(const Header&, pcl::PCLHeader&)\u2019\n  118 |   void toPCL(const std_msgs::Header &header, pcl::PCLHeader &pcl_header)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:118:38: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const Header&\u2019 {aka \u2018const std_msgs::Header_<std::allocator<void> >&\u2019}\n  118 |   void toPCL(const std_msgs::Header &header, pcl::PCLHeader &pcl_header)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:134:18: note: candidate: \u2018pcl::PCLHeader pcl_conversions::toPCL(const Header&)\u2019\n  134 |   pcl::PCLHeader toPCL(const std_msgs::Header &header)\n      |                  ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:134:18: note:   candidate expects 1 argument, 2 provided\n/usr/include/pcl_conversions/pcl_conversions.h:180:8: note: candidate: \u2018void pcl_conversions::toPCL(const Image&, pcl::PCLImage&)\u2019\n  180 |   void toPCL(const sensor_msgs::Image &image, pcl::PCLImage &pcl_image)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:180:40: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const Image&\u2019 {aka \u2018const sensor_msgs::Image_<std::allocator<void> >&\u2019}\n  180 |   void toPCL(const sensor_msgs::Image &image, pcl::PCLImage &pcl_image)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:216:8: note: candidate: \u2018void pcl_conversions::toPCL(const PointField&, pcl::PCLPointField&)\u2019\n  216 |   void toPCL(const sensor_msgs::PointField &pf, pcl::PCLPointField &pcl_pf)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:216:45: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const PointField&\u2019 {aka \u2018const sensor_msgs::PointField_<std::allocator<void> >&\u2019}\n  216 |   void toPCL(const sensor_msgs::PointField &pf, pcl::PCLPointField &pcl_pf)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n/usr/include/pcl_conversions/pcl_conversions.h:225:8: note: candidate: \u2018void pcl_conversions::toPCL(const std::vector<sensor_msgs::PointField_<std::allocator<void> > >&, std::vector<pcl::PCLPointField>&)\u2019\n  225 |   void toPCL(const std::vector<sensor_msgs::PointField> &pfs, std::vector<pcl::PCLPointField> &pcl_pfs)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:225:58: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const std::vector<sensor_msgs::PointField_<std::allocator<void> > >&\u2019\n  225 |   void toPCL(const std::vector<sensor_msgs::PointField> &pfs, std::vector<pcl::PCLPointField> &pcl_pfs)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~\n/usr/include/pcl_conversions/pcl_conversions.h:278:8: note: candidate: \u2018void pcl_conversions::toPCL(const PointCloud2&, pcl::PCLPointCloud2&)\u2019\n  278 |   void toPCL(const sensor_msgs::PointCloud2 &pc2, pcl::PCLPointCloud2 &pcl_pc2)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:278:46: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const PointCloud2&\u2019 {aka \u2018const sensor_msgs::PointCloud2_<std::allocator<void> >&\u2019}\n  278 |   void toPCL(const sensor_msgs::PointCloud2 &pc2, pcl::PCLPointCloud2 &pcl_pc2)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~\n/usr/include/pcl_conversions/pcl_conversions.h:308:8: note: candidate: \u2018void pcl_conversions::toPCL(const PointIndices&, pcl::PointIndices&)\u2019\n  308 |   void toPCL(const pcl_msgs::PointIndices &pi, pcl::PointIndices &pcl_pi)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:308:44: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const PointIndices&\u2019 {aka \u2018const pcl_msgs::PointIndices_<std::allocator<void> >&\u2019}\n  308 |   void toPCL(const pcl_msgs::PointIndices &pi, pcl::PointIndices &pcl_pi)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n/usr/include/pcl_conversions/pcl_conversions.h:338:8: note: candidate: \u2018void pcl_conversions::toPCL(const ModelCoefficients&, pcl::ModelCoefficients&)\u2019\n  338 |   void toPCL(const pcl_msgs::ModelCoefficients &mc, pcl::ModelCoefficients &pcl_mc)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:338:49: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const ModelCoefficients&\u2019 {aka \u2018const pcl_msgs::ModelCoefficients_<std::allocator<void> >&\u2019}\n  338 |   void toPCL(const pcl_msgs::ModelCoefficients &mc, pcl::ModelCoefficients &pcl_mc)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n/usr/include/pcl_conversions/pcl_conversions.h:388:8: note: candidate: \u2018void pcl_conversions::toPCL(const Vertices&, pcl::Vertices&)\u2019\n  388 |   void toPCL(const pcl_msgs::Vertices &vert, pcl::Vertices &pcl_vert)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:388:40: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const Vertices&\u2019 {aka \u2018const pcl_msgs::Vertices_<std::allocator<void> >&\u2019}\n  388 |   void toPCL(const pcl_msgs::Vertices &vert, pcl::Vertices &pcl_vert)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~\n/usr/include/pcl_conversions/pcl_conversions.h:394:8: note: candidate: \u2018void pcl_conversions::toPCL(const std::vector<pcl_msgs::Vertices_<std::allocator<void> > >&, std::vector<pcl::Vertices>&)\u2019\n  394 |   void toPCL(const std::vector<pcl_msgs::Vertices> &verts, std::vector<pcl::Vertices> &pcl_verts)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:394:53: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const std::vector<pcl_msgs::Vertices_<std::allocator<void> > >&\u2019\n  394 |   void toPCL(const std::vector<pcl_msgs::Vertices> &verts, std::vector<pcl::Vertices> &pcl_verts)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:440:8: note: candidate: \u2018void pcl_conversions::toPCL(const PolygonMesh&, pcl::PolygonMesh&)\u2019\n  440 |   void toPCL(const pcl_msgs::PolygonMesh &mesh, pcl::PolygonMesh &pcl_mesh)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:440:43: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr<sensor_msgs::msg::PointCloud2_<std::allocator<void> > >\u2019} to \u2018const PolygonMesh&\u2019 {aka \u2018const pcl_msgs::PolygonMesh_<std::allocator<void> >&\u2019}\n  440 |   void toPCL(const pcl_msgs::PolygonMesh &mesh, pcl::PolygonMesh &pcl_mesh)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~\n\n\nThis is strange to me because one of the templates listed in the error is exactly the one that I am using\nvoid pcl_conversions::toPCL( const sensor_msgs::PointCloud2& pc2, pcl::PCLPointCloud2& pcl_pc2)\n\nI have used the same code, with the same Dockerfile (with different architecture) on my laptop and everything worked.\nAnother strange thing is that, on the Jetson, I had also to manually install the pcl_conversions library with apt install libpcl-conversions-dev (version 1.10).\nI tried to use different functions but I need this specific one.\nI also tried to write a custom function to transform the two types but is not the best solution.\nHow can I try to solve this problem?\nThanks"], "question_code": ["sensor_msgs::msg::PointCloud2", "pcl::PCLPointCloud2", "apt install libpcl-dev", "void GlobalPlanner::pointCloudCallback(const sensor_msgs::msg::PointCloud2::SharedPtr msg) {\n\n  pcl::PCLPointCloud2::Ptr pcl_pc2(new pcl::PCLPointCloud2);\n\n  pcl_conversions::toPCL(*msg, *pcl_pc2);\n  \n}\n", "error: no matching function for call to \u2018toPCL(const SharedPtr&amp;, pcl::PCLPointCloud2::Ptr&amp;)\u2019\n  239 |   pcl_conversions::toPCL(msg, pcl_pc2);\n      |                                      ^\nIn file included from /home/user/D4A/ras/ros2/ras_node_ws/src/navigation/include/global_planner.h:19,\n                 from /home/user/D4A/ras/ros2/ras_node_ws/src/navigation/src/global_planner.cpp:1:\n/usr/include/pcl_conversions/pcl_conversions.h:86:8: note: candidate: \u2018void pcl_conversions::toPCL(const ros::Time&amp;, pcl::uint64_t&amp;)\u2019\n   86 |   void toPCL(const ros::Time &amp;stamp, pcl::uint64_t &amp;pcl_stamp)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:86:31: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const ros::Time&amp;\u2019\n   86 |   void toPCL(const ros::Time &amp;stamp, pcl::uint64_t &amp;pcl_stamp)\n      |              ~~~~~~~~~~~~~~~~~^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:100:17: note: candidate: \u2018pcl::uint64_t pcl_conversions::toPCL(const ros::Time&amp;)\u2019\n  100 |   pcl::uint64_t toPCL(const ros::Time &amp;stamp)\n      |                 ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:100:17: note:   candidate expects 1 argument, 2 provided\n/usr/include/pcl_conversions/pcl_conversions.h:118:8: note: candidate: \u2018void pcl_conversions::toPCL(const Header&amp;, pcl::PCLHeader&amp;)\u2019\n  118 |   void toPCL(const std_msgs::Header &amp;header, pcl::PCLHeader &amp;pcl_header)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:118:38: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const Header&amp;\u2019 {aka \u2018const std_msgs::Header_&lt;std::allocator&lt;void&gt; &gt;&amp;\u2019}\n  118 |   void toPCL(const std_msgs::Header &amp;header, pcl::PCLHeader &amp;pcl_header)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:134:18: note: candidate: \u2018pcl::PCLHeader pcl_conversions::toPCL(const Header&amp;)\u2019\n  134 |   pcl::PCLHeader toPCL(const std_msgs::Header &amp;header)\n      |                  ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:134:18: note:   candidate expects 1 argument, 2 provided\n/usr/include/pcl_conversions/pcl_conversions.h:180:8: note: candidate: \u2018void pcl_conversions::toPCL(const Image&amp;, pcl::PCLImage&amp;)\u2019\n  180 |   void toPCL(const sensor_msgs::Image &amp;image, pcl::PCLImage &amp;pcl_image)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:180:40: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const Image&amp;\u2019 {aka \u2018const sensor_msgs::Image_&lt;std::allocator&lt;void&gt; &gt;&amp;\u2019}\n  180 |   void toPCL(const sensor_msgs::Image &amp;image, pcl::PCLImage &amp;pcl_image)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:216:8: note: candidate: \u2018void pcl_conversions::toPCL(const PointField&amp;, pcl::PCLPointField&amp;)\u2019\n  216 |   void toPCL(const sensor_msgs::PointField &amp;pf, pcl::PCLPointField &amp;pcl_pf)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:216:45: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const PointField&amp;\u2019 {aka \u2018const sensor_msgs::PointField_&lt;std::allocator&lt;void&gt; &gt;&amp;\u2019}\n  216 |   void toPCL(const sensor_msgs::PointField &amp;pf, pcl::PCLPointField &amp;pcl_pf)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n/usr/include/pcl_conversions/pcl_conversions.h:225:8: note: candidate: \u2018void pcl_conversions::toPCL(const std::vector&lt;sensor_msgs::PointField_&lt;std::allocator&lt;void&gt; &gt; &gt;&amp;, std::vector&lt;pcl::PCLPointField&gt;&amp;)\u2019\n  225 |   void toPCL(const std::vector&lt;sensor_msgs::PointField&gt; &amp;pfs, std::vector&lt;pcl::PCLPointField&gt; &amp;pcl_pfs)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:225:58: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const std::vector&lt;sensor_msgs::PointField_&lt;std::allocator&lt;void&gt; &gt; &gt;&amp;\u2019\n  225 |   void toPCL(const std::vector&lt;sensor_msgs::PointField&gt; &amp;pfs, std::vector&lt;pcl::PCLPointField&gt; &amp;pcl_pfs)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~\n/usr/include/pcl_conversions/pcl_conversions.h:278:8: note: candidate: \u2018void pcl_conversions::toPCL(const PointCloud2&amp;, pcl::PCLPointCloud2&amp;)\u2019\n  278 |   void toPCL(const sensor_msgs::PointCloud2 &amp;pc2, pcl::PCLPointCloud2 &amp;pcl_pc2)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:278:46: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const PointCloud2&amp;\u2019 {aka \u2018const sensor_msgs::PointCloud2_&lt;std::allocator&lt;void&gt; &gt;&amp;\u2019}\n  278 |   void toPCL(const sensor_msgs::PointCloud2 &amp;pc2, pcl::PCLPointCloud2 &amp;pcl_pc2)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~\n/usr/include/pcl_conversions/pcl_conversions.h:308:8: note: candidate: \u2018void pcl_conversions::toPCL(const PointIndices&amp;, pcl::PointIndices&amp;)\u2019\n  308 |   void toPCL(const pcl_msgs::PointIndices &amp;pi, pcl::PointIndices &amp;pcl_pi)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:308:44: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const PointIndices&amp;\u2019 {aka \u2018const pcl_msgs::PointIndices_&lt;std::allocator&lt;void&gt; &gt;&amp;\u2019}\n  308 |   void toPCL(const pcl_msgs::PointIndices &amp;pi, pcl::PointIndices &amp;pcl_pi)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n/usr/include/pcl_conversions/pcl_conversions.h:338:8: note: candidate: \u2018void pcl_conversions::toPCL(const ModelCoefficients&amp;, pcl::ModelCoefficients&amp;)\u2019\n  338 |   void toPCL(const pcl_msgs::ModelCoefficients &amp;mc, pcl::ModelCoefficients &amp;pcl_mc)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:338:49: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const ModelCoefficients&amp;\u2019 {aka \u2018const pcl_msgs::ModelCoefficients_&lt;std::allocator&lt;void&gt; &gt;&amp;\u2019}\n  338 |   void toPCL(const pcl_msgs::ModelCoefficients &amp;mc, pcl::ModelCoefficients &amp;pcl_mc)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n/usr/include/pcl_conversions/pcl_conversions.h:388:8: note: candidate: \u2018void pcl_conversions::toPCL(const Vertices&amp;, pcl::Vertices&amp;)\u2019\n  388 |   void toPCL(const pcl_msgs::Vertices &amp;vert, pcl::Vertices &amp;pcl_vert)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:388:40: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const Vertices&amp;\u2019 {aka \u2018const pcl_msgs::Vertices_&lt;std::allocator&lt;void&gt; &gt;&amp;\u2019}\n  388 |   void toPCL(const pcl_msgs::Vertices &amp;vert, pcl::Vertices &amp;pcl_vert)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~\n/usr/include/pcl_conversions/pcl_conversions.h:394:8: note: candidate: \u2018void pcl_conversions::toPCL(const std::vector&lt;pcl_msgs::Vertices_&lt;std::allocator&lt;void&gt; &gt; &gt;&amp;, std::vector&lt;pcl::Vertices&gt;&amp;)\u2019\n  394 |   void toPCL(const std::vector&lt;pcl_msgs::Vertices&gt; &amp;verts, std::vector&lt;pcl::Vertices&gt; &amp;pcl_verts)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:394:53: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const std::vector&lt;pcl_msgs::Vertices_&lt;std::allocator&lt;void&gt; &gt; &gt;&amp;\u2019\n  394 |   void toPCL(const std::vector&lt;pcl_msgs::Vertices&gt; &amp;verts, std::vector&lt;pcl::Vertices&gt; &amp;pcl_verts)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:440:8: note: candidate: \u2018void pcl_conversions::toPCL(const PolygonMesh&amp;, pcl::PolygonMesh&amp;)\u2019\n  440 |   void toPCL(const pcl_msgs::PolygonMesh &amp;mesh, pcl::PolygonMesh &amp;pcl_mesh)\n      |        ^~~~~\n/usr/include/pcl_conversions/pcl_conversions.h:440:43: note:   no known conversion for argument 1 from \u2018const SharedPtr\u2019 {aka \u2018const std::shared_ptr&lt;sensor_msgs::msg::PointCloud2_&lt;std::allocator&lt;void&gt; &gt; &gt;\u2019} to \u2018const PolygonMesh&amp;\u2019 {aka \u2018const pcl_msgs::PolygonMesh_&lt;std::allocator&lt;void&gt; &gt;&amp;\u2019}\n  440 |   void toPCL(const pcl_msgs::PolygonMesh &amp;mesh, pcl::PolygonMesh &amp;pcl_mesh)\n      |              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~\n\n", "void pcl_conversions::toPCL( const sensor_msgs::PointCloud2&amp; pc2, pcl::PCLPointCloud2&amp; pcl_pc2)\n", "apt install libpcl-conversions-dev"], "quote": [], "url": "https://stackoverflow.com/questions/78592220/pcl-conversions-fails-to-convert-from-sensor-msgspointcloud2-to-pclpointclou", "answer": ["I think libpcl-conversions-dev is the wrong package. It seems like a ROS 1 version. I believe what you need is ros-foxy-pcl-conversions"], "answer_code": ["libpcl-conversions-dev", "ros-foxy-pcl-conversions"]},
{"title": "Publisher send the messages but subscribers cannot receive correctly in ROS", "time": 1718243325, "post_content": ["this is my publisher:\ntarget_pub_ = nh_.advertise<geometry_msgs::PoseStamped>(\"/move_base_simple/goal\", 10);\n...\nvoid fsm::pubNewTarget(double next_target_[3])\n{\n    geometry_msgs::PoseStamped goal;\n    goal.header.stamp = ros::Time::now();\n    goal.header.frame_id = \"world\";\n\n    goal.pose.position.x = next_target_[0];\n    goal.pose.position.y = next_target_[1];\n    goal.pose.position.z = next_target_[2];\n    goal.pose.orientation.x = 0;\n    goal.pose.orientation.y = 0;\n    goal.pose.orientation.z = 0;\n    goal.pose.orientation.w = 1;\n\n    target_pub_.publish(goal);\n    ROS_INFO(\"Published next target to /move_base_simple/goal: %f,%f,%f\",goal.pose.position.x,goal.pose.position.y,goal.pose.position.z);\n\n    cur_target_ = Eigen::Vector3d(next_target_[0], next_target_[1], next_target_[2]);\n}\n\nand this is my subscriber:\nwaypoint_sub_ = nh.subscribe(\"/move_base_simple/goal\", 1, &EGOReplanFSM::waypointCallback, this);//(in a class)\n...\nvoid EGOReplanFSM::waypointCallback(const geometry_msgs::PoseStampedPtr &msg)\n  {\n    if (msg->pose.position.z < -0.1)\n      return;\n\n    cout << \"Triggered!\" << endl;\n    // trigger_ = true;\n    init_pt_ = odom_pos_;\n\n    Eigen::Vector3d end_wp(msg->pose.position.x, msg->pose.position.y, msg->pose.position.z);\n    ROS_INFO(\"target: %f,%f,%f\",end_wp(0), end_wp(1), end_wp(2));\n\n    planNextWaypoint(end_wp);\n  }\n\nThere isn't other code about this subscriber and this publisher.\nthe result is like this:\n[ INFO] [1718241065.242124381, 4061.818000000]: Published next target to /move_base_simple/goal: 1.800000,0.000000,1.600000\n[ INFO] [1718241081.398708229, 4077.926000000]: Published next target to /move_base_simple/goal: 1.800000,1.600000,1.600000\n[ INFO] [1718241147.840353409, 4138.438000000]: Published next target to /move_base_simple/goal: 1.800000,-1.600000,1.600000\n[ INFO] [1718241065.242303178, 4061.818000000]: target: 1.800000,0.000000,1.600000\n[ INFO] [1718241081.398879554, 4077.926000000]: target: 1.800000,1.600000,1.600000\n[ INFO] [1718241091.883711821, 4088.330000000]: target: 642719.066674,4671808.218637,0.000000\n\nHow does it happen? Why the third message is wrong?\nI tried rostopic echo /move_base_simple/goal this is the result:\nWARNING: no messages received and simulated time is active.\nIs /clock being published?\nheader: \n  seq: 1\n  stamp: \n    secs: 3359\n    nsecs: 182000000\n  frame_id: \"world\"\npose: \n  position: \n    x: 1.8\n    y: 1.6\n    z: 1.6\n  orientation: \n    x: 0.0\n    y: 0.0\n    z: 0.0\n    w: 1.0\n---\nheader: \n  seq: 150\n  stamp: \n    secs: 3368\n    nsecs: 330504441\n  frame_id: \"map\"\npose: \n  position: \n    x: 642719.0517464812\n    y: 4671808.218661448\n    z: 0.0\n  orientation: \n    x: 0.0\n    y: 0.0\n    z: 0.0\n    w: 1.0\n---\nheader: \n  seq: 151\n  stamp: \n    secs: 3369\n    nsecs: 478522309\n  frame_id: \"map\"\npose: \n  position: \n    x: 642719.0680617385\n    y: 4671808.256290132\n    z: 0.0\n  orientation: \n    x: 0.0\n    y: 0.0\n    z: 0.0\n    w: 1.0\n---\nheader: \n  seq: 152\n  stamp: \n    secs: 3370\n    nsecs: 522523667\n  frame_id: \"map\"\npose: \n  position: \n    x: 642719.0755269051\n    y: 4671808.256290132\n    z: 0.0\n  orientation: \n    x: 0.0\n    y: 0.0\n    z: 0.0\n    w: 1.0"], "question_code": ["target_pub_ = nh_.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/move_base_simple/goal&quot;, 10);\n...\nvoid fsm::pubNewTarget(double next_target_[3])\n{\n    geometry_msgs::PoseStamped goal;\n    goal.header.stamp = ros::Time::now();\n    goal.header.frame_id = &quot;world&quot;;\n\n    goal.pose.position.x = next_target_[0];\n    goal.pose.position.y = next_target_[1];\n    goal.pose.position.z = next_target_[2];\n    goal.pose.orientation.x = 0;\n    goal.pose.orientation.y = 0;\n    goal.pose.orientation.z = 0;\n    goal.pose.orientation.w = 1;\n\n    target_pub_.publish(goal);\n    ROS_INFO(&quot;Published next target to /move_base_simple/goal: %f,%f,%f&quot;,goal.pose.position.x,goal.pose.position.y,goal.pose.position.z);\n\n    cur_target_ = Eigen::Vector3d(next_target_[0], next_target_[1], next_target_[2]);\n}\n", "waypoint_sub_ = nh.subscribe(&quot;/move_base_simple/goal&quot;, 1, &amp;EGOReplanFSM::waypointCallback, this);//(in a class)\n...\nvoid EGOReplanFSM::waypointCallback(const geometry_msgs::PoseStampedPtr &amp;msg)\n  {\n    if (msg-&gt;pose.position.z &lt; -0.1)\n      return;\n\n    cout &lt;&lt; &quot;Triggered!&quot; &lt;&lt; endl;\n    // trigger_ = true;\n    init_pt_ = odom_pos_;\n\n    Eigen::Vector3d end_wp(msg-&gt;pose.position.x, msg-&gt;pose.position.y, msg-&gt;pose.position.z);\n    ROS_INFO(&quot;target: %f,%f,%f&quot;,end_wp(0), end_wp(1), end_wp(2));\n\n    planNextWaypoint(end_wp);\n  }\n", "[ INFO] [1718241065.242124381, 4061.818000000]: Published next target to /move_base_simple/goal: 1.800000,0.000000,1.600000\n[ INFO] [1718241081.398708229, 4077.926000000]: Published next target to /move_base_simple/goal: 1.800000,1.600000,1.600000\n[ INFO] [1718241147.840353409, 4138.438000000]: Published next target to /move_base_simple/goal: 1.800000,-1.600000,1.600000\n[ INFO] [1718241065.242303178, 4061.818000000]: target: 1.800000,0.000000,1.600000\n[ INFO] [1718241081.398879554, 4077.926000000]: target: 1.800000,1.600000,1.600000\n[ INFO] [1718241091.883711821, 4088.330000000]: target: 642719.066674,4671808.218637,0.000000\n", "WARNING: no messages received and simulated time is active.\nIs /clock being published?\nheader: \n  seq: 1\n  stamp: \n    secs: 3359\n    nsecs: 182000000\n  frame_id: &quot;world&quot;\npose: \n  position: \n    x: 1.8\n    y: 1.6\n    z: 1.6\n  orientation: \n    x: 0.0\n    y: 0.0\n    z: 0.0\n    w: 1.0\n---\nheader: \n  seq: 150\n  stamp: \n    secs: 3368\n    nsecs: 330504441\n  frame_id: &quot;map&quot;\npose: \n  position: \n    x: 642719.0517464812\n    y: 4671808.218661448\n    z: 0.0\n  orientation: \n    x: 0.0\n    y: 0.0\n    z: 0.0\n    w: 1.0\n---\nheader: \n  seq: 151\n  stamp: \n    secs: 3369\n    nsecs: 478522309\n  frame_id: &quot;map&quot;\npose: \n  position: \n    x: 642719.0680617385\n    y: 4671808.256290132\n    z: 0.0\n  orientation: \n    x: 0.0\n    y: 0.0\n    z: 0.0\n    w: 1.0\n---\nheader: \n  seq: 152\n  stamp: \n    secs: 3370\n    nsecs: 522523667\n  frame_id: &quot;map&quot;\npose: \n  position: \n    x: 642719.0755269051\n    y: 4671808.256290132\n    z: 0.0\n  orientation: \n    x: 0.0\n    y: 0.0\n    z: 0.0\n    w: 1.0\n"], "quote": [], "url": "https://stackoverflow.com/questions/78615524/publisher-send-the-messages-but-subscribers-cannot-receive-correctly-in-ros", "answer": ["Somehow the frame-id of rostopic echo /move_base_simple/goal shows the frames world an map.\nTry rosinfo /move_base_simple/goal to find wich nodes are publishing to /move_Base_simple/goal."], "answer_code": ["rostopic echo /move_base_simple/goal", "rosinfo /move_base_simple/goal"]},
{"title": "Spawn service failed", "time": 1718021273, "post_content": ["I`m trying to spawn a urdf model of a robot arm in gazebo and getting this error when I'm launching my launch file.\nI have launched some other urdf model they didn't cause much problem.I can't find where i am doing wrong,I have done onshape-to-robot-bullet it is working with this urdf.\nI am new in this so can anyone plz tell me what i am doing wrong??\ni am getting an error-\nFATAL] [1718019695.660225431, 0.226000000]: Package[] does not have a path\n[ERROR] [1718019695.660902, 0.226000]: Spawn service failed. Exiting.\n[spawn_urdf-4] process has died [pid 65428, exit code 1, cmd /opt/ros/noetic/lib/gazebo_ros/spawn_model -x 0.00 -y 0.00 -z 0.00 -Y 0.00 -param robot_description -urdf -model onshape -J base 0.0 -J J1 0.0 -J J2 0.0 -J J3 0.0 -J J4 0.0 -J J5 0.0 -J J7 0.0 -J J8 0.0 __name:=spawn_urdf __log:=/home/puru/.ros/log/222c7472-26f4-11ef-9e10-cdb59c040e69/spawn_urdf-4.log].\nlog file: /home/puru/.ros/log/222c7472-26f4-11ef-9e10-cdb59c040e69/spawn_urdf-4*.log\n\nhere is my launch file\n<launch>\n   <arg name=\"arg_x\" default=\"0.00\" />\n   <arg name=\"arg_y\" default=\"0.00\" />\n   <arg name=\"arg_z\" default=\"0.00\" />\n   <arg name=\"arg_R\" default=\"0.00\" />\n   <arg name=\"arg_P\" default=\"0.00\" />\n   <arg name=\"arg_Y\" default=\"0.00\" />\n\n\n<!--Urdf file path-->\n   <param name=\"robot_description\" textfile=\"$(find robot_simulation)/robo_hand/robot.urdf\"/>\n   \n   <!--spawn a empty gazebo world-->\n   <include file=\"$(find gazebo_ros)/launch/empty_world.launch\" />\n   <node name=\"tf_footprint_base\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"0 0 0 0 0 0 part1 base_footprint 40\" />\n\n\n   <!--spawn model-->\n   <node name=\"spawn_urdf\" pkg=\"gazebo_ros\" type=\"spawn_model\" args=\"-x $(arg arg_x) -y $(arg arg_y) -z $(arg arg_z) -Y $(arg arg_Y) -param robot_description -urdf -model onshape -J base 0.0 -J J1 0.0 -J J2 0.0 -J J3 0.0 -J J4 0.0 -J J5 0.0 -J J7 0.0 -J J8 0.0\" />\n\n\n   <!--Load and launch the joint trajectory controller-->\n   <rosparam file =\"$(find robot_simulation)/config/joint_trajectory_controller.yaml\" command=\"load\"/>\n\n   <node name= \"controller_spawner\" pkg= \"controller_manager\" type=\"spawner\" respawn=\"false\" output=\"screen\" args=\"joint_state_controller robot_arm_controller hand_ee_controller\"/>\n\n\n   <!-- Robot State Publisher for TF of each joint: publishes all the current states of the joint, then RViz can visualize -->\n\n   <node name=\"robot_state_publisher\" pkg=\"robot_state_publisher\" type=\"robot_state_publisher\" respawn=\"false\" output=\"screen\"/>\n\n</launch>\n\nand here is my urdf file\n<robot name=\"onshape\">\n    \n    <link name=\"world\"/>\n    \n    <joint name=\"base_joint\" type=\"fixed\">\n        <parent link=\"world\"/>\n        <child link=\"part1\"/>\n        <origin rpy=\"0 0 0\" xyz=\"0.0 0.0 0.0\"/>\n    </joint>\n    \n    <link name=\"part1\">\n    <visual>\n        <origin xyz=\"-3.4694469519536141888e-18 0 0\" rpy=\"0.32265717217483891321 -0.069385932021737206643 -0.011296483062610399029\" />\n        <geometry>\n            <mesh filename=\"package:///part1.stl\"/>\n        </geometry>\n        <material name=\"part1_material\">\n            <color rgba=\"0.25098039215686274161 0.25098039215686274161 0.25098039215686274161 1.0\"/>\n        </material>\n    </visual>\n    <collision>\n        <origin xyz=\"-3.4694469519536141888e-18 0 0\" rpy=\"0.32265717217483891321 -0.069385932021737206643 -0.011296483062610399029\" />\n        <geometry>\n            <mesh filename=\"package:///part1.stl\"/>\n        </geometry>\n    </collision>\n    <inertial>\n        <origin xyz=\"-0.0012805753579643462583 -0.011016660629217271336 0.037515390001028138534\" rpy=\"0 0 0\"/>\n        <mass value=\"7.1875848665246033775\" />\n        <inertia ixx=\"0.045297703676770335879\" ixy=\"0.0017840038416941296929\"  ixz=\"-0.0021797906212168887199\" iyy=\"0.048864317605051173221\" iyz=\"-0.011176954156986391997\" izz=\"0.078627058046879902409\" />\n    </inertial>\n</link>\n\n<link name=\"part2\">\n<visual>\n    <origin xyz=\"2.4815221297845596725e-18 1.9382986721854770188e-18 0\" rpy=\"-3.141592653589793116 4.6706927436886977151e-17 3.2982806408847512753e-18\" />\n    <geometry>\n        <mesh filename=\"package:///part2.stl\"/>\n    </geometry>\n    <material name=\"part2_material\">\n        <color rgba=\"0.77647058823529413463 0.7568627450980391913 0.73725490196078435901 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"2.4815221297845596725e-18 1.9382986721854770188e-18 0\" rpy=\"-3.141592653589793116 4.6706927436886977151e-17 3.2982806408847512753e-18\" />\n    <geometry>\n        <mesh filename=\"package:///part2.stl\"/>\n    </geometry>\n</collision>\n<inertial>\n    <origin xyz=\"-0.056976512075502590282 0.0027067425703694225278 -0.082849898982706379758\" rpy=\"0 0 0\"/>\n    <mass value=\"2.8798845212323498366\" />\n    <inertia ixx=\"0.014881029060141267445\" ixy=\"0.0005744946258076310229\"  ixz=\"-0.01130629902339419339\" iyy=\"0.029629354802626656218\" iyz=\"0.00050369024034264736536\" izz=\"0.020220800009744580722\" />\n</inertial>\n</link>\n\n<link name=\"part3\">\n<visual>\n    <origin xyz=\"0 2.7755575615628913511e-17 0\" rpy=\"-3.7506783542939203786e-20 -8.8743673327280038896e-18 7.6013036972471816961e-18\" />\n    <geometry>\n        <mesh filename=\"package:///part3.stl\"/>\n    </geometry>\n    <material name=\"part3_material\">\n        <color rgba=\"0.25098039215686274161 0.25098039215686274161 0.25098039215686274161 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"0 2.7755575615628913511e-17 0\" rpy=\"-3.7506783542939203786e-20 -8.8743673327280038896e-18 7.6013036972471816961e-18\" />\n    <geometry>\n        <mesh filename=\"package:///part3.stl\"/>\n    </geometry>\n</collision>\n<inertial>\n    <origin xyz=\"-0.14018296191340778867 -0.0081202387835428019303 0.015311056033016684844\" rpy=\"0 0 0\"/>\n    <mass value=\"1.1430996664229595705\" />\n    <inertia ixx=\"0.00076194947476914927972\" ixy=\"-0.0002163608373031530223\"  ixz=\"-9.9897566532977007396e-05\" iyy=\"0.021889090949777346984\" iyz=\"-3.8861596724872822018e-05\" izz=\"0.022305318338384585303\" />\n</inertial>\n</link>\n\n<link name=\"part4\">\n<visual>\n    <origin xyz=\"-0.049999999999999947264 0.044999999999999928946 -0.048000000000000000999\" rpy=\"-1.570796326794896558 3.3713739677471981044e-18 -2.1095519483509206812e-17\" />\n    <geometry>\n        <mesh filename=\"package:///part4.stl\"/>\n    </geometry>\n    <material name=\"part4_material\">\n        <color rgba=\"0.79607843137254896693 0.82352941176470584317 0.9372549019607843146 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"-0.049999999999999947264 0.044999999999999928946 -0.048000000000000000999\" rpy=\"-1.570796326794896558 3.3713739677471981044e-18 -2.1095519483509206812e-17\" />\n    <geometry>\n        <mesh filename=\"package:///part4.stl\"/>\n    </geometry>\n</collision>\n<inertial>\n    <origin xyz=\"0.034615093436350663492 0.038537106974319876307 -0.04615997250553626613\" rpy=\"0 0 0\"/>\n    <mass value=\"1.6158525875678280137\" />\n    <inertia ixx=\"0.0022074722855731734351\" ixy=\"-0.00036149006639220559968\"  ixz=\"0.00010291587993125624967\" iyy=\"0.0078248759878263348527\" iyz=\"0.00015452864972509414219\" izz=\"0.0083117281805881355894\" />\n</inertial>\n</link>\n\n<link name=\"part5\">\n<visual>\n    <origin xyz=\"3.4694469519536141888e-18 0 0.0050000000000000321965\" rpy=\"1.570796326794896558 1.570796326794896558 0\" />\n    <geometry>\n        <mesh filename=\"package:///part5.stl\"/>\n    </geometry>\n    <material name=\"part5_material\">\n        <color rgba=\"0.77647058823529413463 0.7568627450980391913 0.73725490196078435901 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"3.4694469519536141888e-18 0 0.0050000000000000321965\" rpy=\"1.570796326794896558 1.570796326794896558 0\" />\n    <geometry>\n        <mesh filename=\"package:///part5.stl\"/>\n    </geometry>\n</collision>\n<inertial>\n    <origin xyz=\"2.296209484802755807e-17 1.0429349772845609436e-17 0.07965355910797956851\" rpy=\"0 0 0\"/>\n    <mass value=\"0.76134524066724451608\" />\n    <inertia ixx=\"0.0024657507175976549688\" ixy=\"3.9603891489128208543e-11\"  ixz=\"7.6843053034528262362e-21\" iyy=\"0.0026674883734285675593\" iyz=\"6.3011139360900376271e-20\" izz=\"0.00069980749681859905423\" />\n</inertial>\n</link>\n\n<link name=\"part6\">\n<visual>\n    <origin xyz=\"-0.042000000000000037303 -5.5511151231257827021e-17 -1.3877787807814456755e-17\" rpy=\"1.570796326794896558 1.570796326794896558 0\" />\n    <geometry>\n        <mesh filename=\"package:///part6.stl\"/>\n    </geometry>\n    <material name=\"part6_material\">\n        <color rgba=\"0.77647058823529413463 0.7568627450980391913 0.73725490196078435901 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"-0.042000000000000037303 -5.5511151231257827021e-17 -1.3877787807814456755e-17\" rpy=\"1.570796326794896558 1.570796326794896558 0\" />\n    <geometry>\n        <mesh filename=\"package:///part6.stl\"/>\n    </geometry>\n</collision>\n<inertial>\n    <origin xyz=\"-0.059477422323748987965 -5.6643505845066669741e-17 -1.1476450207922689876e-17\" rpy=\"0 0 0\"/>\n    <mass value=\"0.39696194910041004977\" />\n    <inertia ixx=\"0.00027739828305348911098\" ixy=\"1.9884141339072156575e-20\"  ixz=\"3.2463991766502403197e-22\" iyy=\"0.00040803651958911535272\" iyz=\"-2.792385807766648833e-21\" izz=\"0.00041164747096656729725\" />\n</inertial>\n</link>\n\n<link name=\"part7\">\n<visual>\n    <origin xyz=\"0 -3.4694469519536141888e-18 0.0099999999999999533706\" rpy=\"1.570796326794896558 1.570796326794896558 0\" />\n    <geometry>\n        <mesh filename=\"package:///part7.stl\"/>\n    </geometry>\n    <material name=\"part7_material\">\n        <color rgba=\"0.56862745098039213509 0.54901960784313730279 0.50980392156862741615 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"0 -3.4694469519536141888e-18 0.0099999999999999533706\" rpy=\"1.570796326794896558 1.570796326794896558 0\" />\n    <geometry>\n        <mesh filename=\"package:///part7.stl\"/>\n    </geometry>\n</collision>\n<inertial>\n    <origin xyz=\"-1.2926944099447946692e-19 -3.1275151494821297233e-18 -0.0062844669745950390571\" rpy=\"0 0 0\"/>\n    <mass value=\"0.095529530381998281618\" />\n    <inertia ixx=\"4.0005586732361312101e-05\" ixy=\"-2.4656268595522464085e-22\"  ixz=\"1.7806595967162966037e-21\" iyy=\"4.7583367322132944183e-05\" iyz=\"-2.0676986397054393346e-21\" izz=\"5.0210847316137543464e-05\" />\n</inertial>\n</link>\n\n<link name=\"part9\">\n<visual>\n    <origin xyz=\"-0.038437349788629754377 0.063553165001418110425 -0.013000000000000684619\" rpy=\"1.570796326794896336 1.5707963267948958919 0\" />\n    <geometry>\n        <mesh filename=\"package:///part8.stl\"/>\n    </geometry>\n    <material name=\"part8_material\">\n        <color rgba=\"1 0.96078431372549022438 0.89019607843137249503 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"-0.038437349788629754377 0.063553165001418110425 -0.013000000000000684619\" rpy=\"1.570796326794896336 1.5707963267948958919 0\" />\n    <geometry>\n        <mesh filename=\"package:///part8.stl\"/>\n    </geometry>\n</collision>\n<visual>\n    <origin xyz=\"0 0 -0.01299999999999999073\" rpy=\"-8.829476863248877021e-18 -2.6628065485658611949e-18 -3.5189746478553312204e-17\" />\n    <geometry>\n        <mesh filename=\"package:///part9.stl\"/>\n    </geometry>\n    <material name=\"part9_material\">\n        <color rgba=\"0.79607843137254896693 0.82352941176470584317 0.9372549019607843146 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"0 0 -0.01299999999999999073\" rpy=\"-8.829476863248877021e-18 -2.6628065485658611949e-18 -3.5189746478553312204e-17\" />\n    <geometry>\n        <mesh filename=\"package:///part9.stl\"/>\n    </geometry>\n</collision>\n<inertial>\n    <origin xyz=\"0.019097045128395627456 0.04930456388435456444 -0.013000000000000535433\" rpy=\"0 0 0\"/>\n    <mass value=\"0.045258281756665255657\" />\n    <inertia ixx=\"5.522294637954104575e-05\" ixy=\"-1.4855240157670293133e-05\"  ixz=\"1.5213025994755179093e-19\" iyy=\"7.1527397674249912433e-06\" iyz=\"-2.9789676359037378066e-20\" izz=\"5.9954066756448529444e-05\" />\n</inertial>\n</link>\n\n<joint name=\"J7\" type=\"revolute\">\n    <origin xyz=\"-0.040809511095868222785 0.01299999999999999073 -0.022892057511395225156\" rpy=\"-1.570796326794896558 0.10407608628378127447 2.1645097273896630037e-15\" />\n    <parent link=\"part7\" />\n    <child link=\"part9\" />\n    <axis xyz=\"0 0 1\"/>\n    <limit effort=\"1\" velocity=\"20\" lower=\"-0.0508254296197560507\" upper=\"1.4854961776254267392\"/>\n    <joint_properties friction=\"0.0\"/>\n</joint>\n\n<link name=\"part9_2\">\n<visual>\n    <origin xyz=\"0.038437349788628449865 0.063553165001418443492 0.013000000000001173811\" rpy=\"1.57079632679489678 -1.5707963267948903408 0\" />\n    <geometry>\n        <mesh filename=\"package:///part8.stl\"/>\n    </geometry>\n    <material name=\"part8_material\">\n        <color rgba=\"1 0.96078431372549022438 0.89019607843137249503 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"0.038437349788628449865 0.063553165001418443492 0.013000000000001173811\" rpy=\"1.57079632679489678 -1.5707963267948903408 0\" />\n    <geometry>\n        <mesh filename=\"package:///part8.stl\"/>\n    </geometry>\n</collision>\n<visual>\n    <origin xyz=\"-5.5511151231257827021e-17 0 0.012999999999999994199\" rpy=\"1.8669361206154621951e-17 -4.1846222463962295292e-18 -1.1061622554016257027e-17\" />\n    <geometry>\n        <mesh filename=\"package:///part9.stl\"/>\n    </geometry>\n    <material name=\"part9_material\">\n        <color rgba=\"0.79607843137254896693 0.82352941176470584317 0.9372549019607843146 1.0\"/>\n    </material>\n</visual>\n<collision>\n    <origin xyz=\"-5.5511151231257827021e-17 0 0.012999999999999994199\" rpy=\"1.8669361206154621951e-17 -4.1846222463962295292e-18 -1.1061622554016257027e-17\" />\n    <geometry>\n        <mesh filename=\"package:///part9.stl\"/>\n    </geometry>\n</collision>\n<inertial>\n    <origin xyz=\"-0.019097045128394322944 0.049304563884354772607 0.013000000000000908398\" rpy=\"0 0 0\"/>\n    <mass value=\"0.045258281756665255657\" />\n    <inertia ixx=\"5.5222946379536119407e-05\" ixy=\"1.485524015766974595e-05\"  ixz=\"6.51183823337792082e-19\" iyy=\"7.1527397674250640881e-06\" iyz=\"1.2029403278356184806e-19\" izz=\"5.9954066756446103541e-05\" />\n</inertial>\n</link>\n\n<joint name=\"J8\" type=\"revolute\">\n    <origin xyz=\"0.040809511095868222785 -0.013000000000000004607 -0.022892057511395225156\" rpy=\"-1.570796326794896558 -0.10407608628378151039 8.4711537068837356757e-15\" />\n    <parent link=\"part7\" />\n    <child link=\"part9_2\" />\n    <axis xyz=\"0 0 1\"/>\n    <limit effort=\"1\" velocity=\"20\" lower=\"-1.4854961776254267392\" upper=\"0.0508254296197560507\"/>\n    <joint_properties friction=\"0.0\"/>\n</joint>\n\n<joint name=\"J5\" type=\"revolute\">\n    <origin xyz=\"-0.10400000000000086953 -6.6613381477509392425e-16 -1.1171619185290637688e-15\" rpy=\"1.570796326794896558 -2.200659911653516123e-14 1.5707963267948941155\" />\n    <parent link=\"part6\" />\n    <child link=\"part7\" />\n    <axis xyz=\"0 0 1\"/>\n    <limit effort=\"1\" velocity=\"20\" lower=\"-6.283185307179586232\" upper=\"6.283185307179586232\"/>\n    <joint_properties friction=\"0.0\"/>\n</joint>\n\n<joint name=\"J4\" type=\"revolute\">\n    <origin xyz=\"-7.0429773124658368033e-16 -1.1102230246251565404e-16 0.13800000000000009481\" rpy=\"1.570796326794896558 8.8953965671821529256e-16 -1.5707963267948921171\" />\n    <parent link=\"part5\" />\n    <child link=\"part6\" />\n    <axis xyz=\"0 0 1\"/>\n    <limit effort=\"1\" velocity=\"20\" lower=\"-3.5779249665883754439\" upper=\"0.43633231299858238339\"/>\n    <joint_properties friction=\"0.0\"/>\n</joint>\n\n<joint name=\"J3\" type=\"revolute\">\n    <origin xyz=\"0.22099999999999983546 0.045000000000000928146 -0.047999999999998099742\" rpy=\"3.5360923724163181315e-17 1.5707963267948925612 0\" />\n    <parent link=\"part4\" />\n    <child link=\"part5\" />\n    <axis xyz=\"0 0 1\"/>\n    <limit effort=\"1\" velocity=\"20\" lower=\"-3.141592653589793116\" upper=\"3.141592653589793116\"/>\n    <joint_properties friction=\"0.0\"/>\n</joint>\n\n<joint name=\"J2\" type=\"revolute\">\n    <origin xyz=\"-0.34999999999999981126 -4.7184478546569152968e-16 -1.0408340855860842566e-17\" rpy=\"-7.9084394517820163515e-16 8.181256381192978572e-16 -2.0089744681964760709\" />\n    <parent link=\"part3\" />\n    <child link=\"part4\" />\n    <axis xyz=\"0 0 1\"/>\n    <limit effort=\"1\" velocity=\"20\" lower=\"-2.4434609527920612138\" upper=\"1.8849555921538758696\"/>\n    <joint_properties friction=\"0.0\"/>\n</joint>\n\n<joint name=\"J1\" type=\"revolute\">\n    <origin xyz=\"-0.14999999999999980016 -0.019999999999999993477 -0.16000000000000128009\" rpy=\"-1.570796326794896558 -1.1326181853933210419 3.1415926535897922278\" />\n    <parent link=\"part2\" />\n    <child link=\"part3\" />\n    <axis xyz=\"0 0 1\"/>\n    <limit effort=\"1\" velocity=\"20\" lower=\"-2.1745329251994329478\" upper=\"1.3906585039886590671\"/>\n    <joint_properties friction=\"0.0\"/>\n</joint>\n\n<joint name=\"base\" type=\"revolute\">\n    <origin xyz=\"-0.0058237426852963229684 -0.026571278200745222786 0.079473588039763426449\" rpy=\"3.0684444271150290717 -0.32185277620319291403 1.5826756446767937803\" />\n    <parent link=\"part1\" />\n    <child link=\"part2\" />\n    <axis xyz=\"0 0 1\"/>\n    <limit effort=\"1\" velocity=\"20\" lower=\"-3.141592653589793116\" upper=\"3.141592653589793116\"/>\n    <joint_properties friction=\"0.0\"/>\n</joint>\n\n\n<transmission name=\"link_b_trans\">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name=\"base\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n    </joint>\n    <actuator name=\"link_b_motor\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n        <mechanicalReduction>1</mechanicalReduction>\n    </actuator>\n</transmission>\n\n<transmission name=\"link_1_trans\">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name=\"J1\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n    </joint>\n    <actuator name=\"link_1_motor\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n        <mechanicalReduction>1</mechanicalReduction>\n    </actuator>\n</transmission>\n\n<transmission name=\"link_2_trans\">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name=\"J2\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n    </joint>\n    <actuator name=\"link_2_motor\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n        <mechanicalReduction>1</mechanicalReduction>\n    </actuator>\n</transmission>\n\n<transmission name=\"link_3_trans\">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name=\"J3\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n    </joint>\n    <actuator name=\"link_3_motor\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n        <mechanicalReduction>1</mechanicalReduction>\n    </actuator>\n</transmission>\n\n<transmission name=\"link_4_trans\">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name=\"J4\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n    </joint>\n    <actuator name=\"link_4_motor\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n        <mechanicalReduction>1</mechanicalReduction>\n    </actuator>\n</transmission>\n\n<transmission name=\"link_5_trans\">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name=\"J5\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n    </joint>\n    <actuator name=\"link_5_motor\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n        <mechanicalReduction>1</mechanicalReduction>\n    </actuator>\n</transmission>\n\n<transmission name=\"link_7_trans\">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name=\"J7\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n    </joint>\n    <actuator name=\"link_7_motor\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n        <mechanicalReduction>1</mechanicalReduction>\n    </actuator>\n</transmission>\n\n<transmission name=\"link_8_trans\">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name=\"J8\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n    </joint>\n    <actuator name=\"link_8_motor\">\n        <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n        <mechanicalReduction>1</mechanicalReduction>\n    </actuator>\n</transmission>\n\n<gazebo>\n    <plugin name=\"control\" filename=\"libgazebo_ros_control.so\">\n        <robotNamespace>/</robotNamespace>\n    </plugin>\n</gazebo>\n\n<gazebo reference=\"part1\">\n    <selfCollide>true</selfCollide>\n</gazebo>\n\n<gazebo reference=\"part2\">\n    <selfCollide>true</selfCollide>\n</gazebo>\n\n<gazebo reference=\"part3\">\n    <selfCollide>true</selfCollide>\n</gazebo>\n\n<gazebo reference=\"part4\">\n    <selfCollide>true</selfCollide>\n</gazebo>\n\n<gazebo reference=\"part5\">\n    <selfCollide>true</selfCollide>\n</gazebo>\n\n<gazebo reference=\"part6\">\n    <selfCollide>true</selfCollide>\n</gazebo>\n\n<gazebo reference=\"part7\">\n    <selfCollide>true</selfCollide>\n</gazebo>\n\n<gazebo reference=\"part9\">\n    <selfCollide>true</selfCollide>\n</gazebo>\n\n<gazebo reference=\"part9_2\">\n    <selfCollide>true</selfCollide>\n</gazebo>\n\n\n</robot>"], "question_code": ["FATAL] [1718019695.660225431, 0.226000000]: Package[] does not have a path\n[ERROR] [1718019695.660902, 0.226000]: Spawn service failed. Exiting.\n[spawn_urdf-4] process has died [pid 65428, exit code 1, cmd /opt/ros/noetic/lib/gazebo_ros/spawn_model -x 0.00 -y 0.00 -z 0.00 -Y 0.00 -param robot_description -urdf -model onshape -J base 0.0 -J J1 0.0 -J J2 0.0 -J J3 0.0 -J J4 0.0 -J J5 0.0 -J J7 0.0 -J J8 0.0 __name:=spawn_urdf __log:=/home/puru/.ros/log/222c7472-26f4-11ef-9e10-cdb59c040e69/spawn_urdf-4.log].\nlog file: /home/puru/.ros/log/222c7472-26f4-11ef-9e10-cdb59c040e69/spawn_urdf-4*.log\n", "&lt;launch&gt;\n   &lt;arg name=&quot;arg_x&quot; default=&quot;0.00&quot; /&gt;\n   &lt;arg name=&quot;arg_y&quot; default=&quot;0.00&quot; /&gt;\n   &lt;arg name=&quot;arg_z&quot; default=&quot;0.00&quot; /&gt;\n   &lt;arg name=&quot;arg_R&quot; default=&quot;0.00&quot; /&gt;\n   &lt;arg name=&quot;arg_P&quot; default=&quot;0.00&quot; /&gt;\n   &lt;arg name=&quot;arg_Y&quot; default=&quot;0.00&quot; /&gt;\n\n\n&lt;!--Urdf file path--&gt;\n   &lt;param name=&quot;robot_description&quot; textfile=&quot;$(find robot_simulation)/robo_hand/robot.urdf&quot;/&gt;\n   \n   &lt;!--spawn a empty gazebo world--&gt;\n   &lt;include file=&quot;$(find gazebo_ros)/launch/empty_world.launch&quot; /&gt;\n   &lt;node name=&quot;tf_footprint_base&quot; pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; args=&quot;0 0 0 0 0 0 part1 base_footprint 40&quot; /&gt;\n\n\n   &lt;!--spawn model--&gt;\n   &lt;node name=&quot;spawn_urdf&quot; pkg=&quot;gazebo_ros&quot; type=&quot;spawn_model&quot; args=&quot;-x $(arg arg_x) -y $(arg arg_y) -z $(arg arg_z) -Y $(arg arg_Y) -param robot_description -urdf -model onshape -J base 0.0 -J J1 0.0 -J J2 0.0 -J J3 0.0 -J J4 0.0 -J J5 0.0 -J J7 0.0 -J J8 0.0&quot; /&gt;\n\n\n   &lt;!--Load and launch the joint trajectory controller--&gt;\n   &lt;rosparam file =&quot;$(find robot_simulation)/config/joint_trajectory_controller.yaml&quot; command=&quot;load&quot;/&gt;\n\n   &lt;node name= &quot;controller_spawner&quot; pkg= &quot;controller_manager&quot; type=&quot;spawner&quot; respawn=&quot;false&quot; output=&quot;screen&quot; args=&quot;joint_state_controller robot_arm_controller hand_ee_controller&quot;/&gt;\n\n\n   &lt;!-- Robot State Publisher for TF of each joint: publishes all the current states of the joint, then RViz can visualize --&gt;\n\n   &lt;node name=&quot;robot_state_publisher&quot; pkg=&quot;robot_state_publisher&quot; type=&quot;robot_state_publisher&quot; respawn=&quot;false&quot; output=&quot;screen&quot;/&gt;\n\n&lt;/launch&gt;\n", "&lt;robot name=&quot;onshape&quot;&gt;\n    \n    &lt;link name=&quot;world&quot;/&gt;\n    \n    &lt;joint name=&quot;base_joint&quot; type=&quot;fixed&quot;&gt;\n        &lt;parent link=&quot;world&quot;/&gt;\n        &lt;child link=&quot;part1&quot;/&gt;\n        &lt;origin rpy=&quot;0 0 0&quot; xyz=&quot;0.0 0.0 0.0&quot;/&gt;\n    &lt;/joint&gt;\n    \n    &lt;link name=&quot;part1&quot;&gt;\n    &lt;visual&gt;\n        &lt;origin xyz=&quot;-3.4694469519536141888e-18 0 0&quot; rpy=&quot;0.32265717217483891321 -0.069385932021737206643 -0.011296483062610399029&quot; /&gt;\n        &lt;geometry&gt;\n            &lt;mesh filename=&quot;package:///part1.stl&quot;/&gt;\n        &lt;/geometry&gt;\n        &lt;material name=&quot;part1_material&quot;&gt;\n            &lt;color rgba=&quot;0.25098039215686274161 0.25098039215686274161 0.25098039215686274161 1.0&quot;/&gt;\n        &lt;/material&gt;\n    &lt;/visual&gt;\n    &lt;collision&gt;\n        &lt;origin xyz=&quot;-3.4694469519536141888e-18 0 0&quot; rpy=&quot;0.32265717217483891321 -0.069385932021737206643 -0.011296483062610399029&quot; /&gt;\n        &lt;geometry&gt;\n            &lt;mesh filename=&quot;package:///part1.stl&quot;/&gt;\n        &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;inertial&gt;\n        &lt;origin xyz=&quot;-0.0012805753579643462583 -0.011016660629217271336 0.037515390001028138534&quot; rpy=&quot;0 0 0&quot;/&gt;\n        &lt;mass value=&quot;7.1875848665246033775&quot; /&gt;\n        &lt;inertia ixx=&quot;0.045297703676770335879&quot; ixy=&quot;0.0017840038416941296929&quot;  ixz=&quot;-0.0021797906212168887199&quot; iyy=&quot;0.048864317605051173221&quot; iyz=&quot;-0.011176954156986391997&quot; izz=&quot;0.078627058046879902409&quot; /&gt;\n    &lt;/inertial&gt;\n&lt;/link&gt;\n\n&lt;link name=&quot;part2&quot;&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;2.4815221297845596725e-18 1.9382986721854770188e-18 0&quot; rpy=&quot;-3.141592653589793116 4.6706927436886977151e-17 3.2982806408847512753e-18&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part2.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part2_material&quot;&gt;\n        &lt;color rgba=&quot;0.77647058823529413463 0.7568627450980391913 0.73725490196078435901 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;2.4815221297845596725e-18 1.9382986721854770188e-18 0&quot; rpy=&quot;-3.141592653589793116 4.6706927436886977151e-17 3.2982806408847512753e-18&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part2.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;inertial&gt;\n    &lt;origin xyz=&quot;-0.056976512075502590282 0.0027067425703694225278 -0.082849898982706379758&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;mass value=&quot;2.8798845212323498366&quot; /&gt;\n    &lt;inertia ixx=&quot;0.014881029060141267445&quot; ixy=&quot;0.0005744946258076310229&quot;  ixz=&quot;-0.01130629902339419339&quot; iyy=&quot;0.029629354802626656218&quot; iyz=&quot;0.00050369024034264736536&quot; izz=&quot;0.020220800009744580722&quot; /&gt;\n&lt;/inertial&gt;\n&lt;/link&gt;\n\n&lt;link name=&quot;part3&quot;&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;0 2.7755575615628913511e-17 0&quot; rpy=&quot;-3.7506783542939203786e-20 -8.8743673327280038896e-18 7.6013036972471816961e-18&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part3.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part3_material&quot;&gt;\n        &lt;color rgba=&quot;0.25098039215686274161 0.25098039215686274161 0.25098039215686274161 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;0 2.7755575615628913511e-17 0&quot; rpy=&quot;-3.7506783542939203786e-20 -8.8743673327280038896e-18 7.6013036972471816961e-18&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part3.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;inertial&gt;\n    &lt;origin xyz=&quot;-0.14018296191340778867 -0.0081202387835428019303 0.015311056033016684844&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;mass value=&quot;1.1430996664229595705&quot; /&gt;\n    &lt;inertia ixx=&quot;0.00076194947476914927972&quot; ixy=&quot;-0.0002163608373031530223&quot;  ixz=&quot;-9.9897566532977007396e-05&quot; iyy=&quot;0.021889090949777346984&quot; iyz=&quot;-3.8861596724872822018e-05&quot; izz=&quot;0.022305318338384585303&quot; /&gt;\n&lt;/inertial&gt;\n&lt;/link&gt;\n\n&lt;link name=&quot;part4&quot;&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;-0.049999999999999947264 0.044999999999999928946 -0.048000000000000000999&quot; rpy=&quot;-1.570796326794896558 3.3713739677471981044e-18 -2.1095519483509206812e-17&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part4.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part4_material&quot;&gt;\n        &lt;color rgba=&quot;0.79607843137254896693 0.82352941176470584317 0.9372549019607843146 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;-0.049999999999999947264 0.044999999999999928946 -0.048000000000000000999&quot; rpy=&quot;-1.570796326794896558 3.3713739677471981044e-18 -2.1095519483509206812e-17&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part4.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;inertial&gt;\n    &lt;origin xyz=&quot;0.034615093436350663492 0.038537106974319876307 -0.04615997250553626613&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;mass value=&quot;1.6158525875678280137&quot; /&gt;\n    &lt;inertia ixx=&quot;0.0022074722855731734351&quot; ixy=&quot;-0.00036149006639220559968&quot;  ixz=&quot;0.00010291587993125624967&quot; iyy=&quot;0.0078248759878263348527&quot; iyz=&quot;0.00015452864972509414219&quot; izz=&quot;0.0083117281805881355894&quot; /&gt;\n&lt;/inertial&gt;\n&lt;/link&gt;\n\n&lt;link name=&quot;part5&quot;&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;3.4694469519536141888e-18 0 0.0050000000000000321965&quot; rpy=&quot;1.570796326794896558 1.570796326794896558 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part5.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part5_material&quot;&gt;\n        &lt;color rgba=&quot;0.77647058823529413463 0.7568627450980391913 0.73725490196078435901 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;3.4694469519536141888e-18 0 0.0050000000000000321965&quot; rpy=&quot;1.570796326794896558 1.570796326794896558 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part5.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;inertial&gt;\n    &lt;origin xyz=&quot;2.296209484802755807e-17 1.0429349772845609436e-17 0.07965355910797956851&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;mass value=&quot;0.76134524066724451608&quot; /&gt;\n    &lt;inertia ixx=&quot;0.0024657507175976549688&quot; ixy=&quot;3.9603891489128208543e-11&quot;  ixz=&quot;7.6843053034528262362e-21&quot; iyy=&quot;0.0026674883734285675593&quot; iyz=&quot;6.3011139360900376271e-20&quot; izz=&quot;0.00069980749681859905423&quot; /&gt;\n&lt;/inertial&gt;\n&lt;/link&gt;\n\n&lt;link name=&quot;part6&quot;&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;-0.042000000000000037303 -5.5511151231257827021e-17 -1.3877787807814456755e-17&quot; rpy=&quot;1.570796326794896558 1.570796326794896558 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part6.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part6_material&quot;&gt;\n        &lt;color rgba=&quot;0.77647058823529413463 0.7568627450980391913 0.73725490196078435901 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;-0.042000000000000037303 -5.5511151231257827021e-17 -1.3877787807814456755e-17&quot; rpy=&quot;1.570796326794896558 1.570796326794896558 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part6.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;inertial&gt;\n    &lt;origin xyz=&quot;-0.059477422323748987965 -5.6643505845066669741e-17 -1.1476450207922689876e-17&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;mass value=&quot;0.39696194910041004977&quot; /&gt;\n    &lt;inertia ixx=&quot;0.00027739828305348911098&quot; ixy=&quot;1.9884141339072156575e-20&quot;  ixz=&quot;3.2463991766502403197e-22&quot; iyy=&quot;0.00040803651958911535272&quot; iyz=&quot;-2.792385807766648833e-21&quot; izz=&quot;0.00041164747096656729725&quot; /&gt;\n&lt;/inertial&gt;\n&lt;/link&gt;\n\n&lt;link name=&quot;part7&quot;&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;0 -3.4694469519536141888e-18 0.0099999999999999533706&quot; rpy=&quot;1.570796326794896558 1.570796326794896558 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part7.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part7_material&quot;&gt;\n        &lt;color rgba=&quot;0.56862745098039213509 0.54901960784313730279 0.50980392156862741615 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;0 -3.4694469519536141888e-18 0.0099999999999999533706&quot; rpy=&quot;1.570796326794896558 1.570796326794896558 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part7.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;inertial&gt;\n    &lt;origin xyz=&quot;-1.2926944099447946692e-19 -3.1275151494821297233e-18 -0.0062844669745950390571&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;mass value=&quot;0.095529530381998281618&quot; /&gt;\n    &lt;inertia ixx=&quot;4.0005586732361312101e-05&quot; ixy=&quot;-2.4656268595522464085e-22&quot;  ixz=&quot;1.7806595967162966037e-21&quot; iyy=&quot;4.7583367322132944183e-05&quot; iyz=&quot;-2.0676986397054393346e-21&quot; izz=&quot;5.0210847316137543464e-05&quot; /&gt;\n&lt;/inertial&gt;\n&lt;/link&gt;\n\n&lt;link name=&quot;part9&quot;&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;-0.038437349788629754377 0.063553165001418110425 -0.013000000000000684619&quot; rpy=&quot;1.570796326794896336 1.5707963267948958919 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part8.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part8_material&quot;&gt;\n        &lt;color rgba=&quot;1 0.96078431372549022438 0.89019607843137249503 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;-0.038437349788629754377 0.063553165001418110425 -0.013000000000000684619&quot; rpy=&quot;1.570796326794896336 1.5707963267948958919 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part8.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;0 0 -0.01299999999999999073&quot; rpy=&quot;-8.829476863248877021e-18 -2.6628065485658611949e-18 -3.5189746478553312204e-17&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part9.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part9_material&quot;&gt;\n        &lt;color rgba=&quot;0.79607843137254896693 0.82352941176470584317 0.9372549019607843146 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;0 0 -0.01299999999999999073&quot; rpy=&quot;-8.829476863248877021e-18 -2.6628065485658611949e-18 -3.5189746478553312204e-17&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part9.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;inertial&gt;\n    &lt;origin xyz=&quot;0.019097045128395627456 0.04930456388435456444 -0.013000000000000535433&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;mass value=&quot;0.045258281756665255657&quot; /&gt;\n    &lt;inertia ixx=&quot;5.522294637954104575e-05&quot; ixy=&quot;-1.4855240157670293133e-05&quot;  ixz=&quot;1.5213025994755179093e-19&quot; iyy=&quot;7.1527397674249912433e-06&quot; iyz=&quot;-2.9789676359037378066e-20&quot; izz=&quot;5.9954066756448529444e-05&quot; /&gt;\n&lt;/inertial&gt;\n&lt;/link&gt;\n\n&lt;joint name=&quot;J7&quot; type=&quot;revolute&quot;&gt;\n    &lt;origin xyz=&quot;-0.040809511095868222785 0.01299999999999999073 -0.022892057511395225156&quot; rpy=&quot;-1.570796326794896558 0.10407608628378127447 2.1645097273896630037e-15&quot; /&gt;\n    &lt;parent link=&quot;part7&quot; /&gt;\n    &lt;child link=&quot;part9&quot; /&gt;\n    &lt;axis xyz=&quot;0 0 1&quot;/&gt;\n    &lt;limit effort=&quot;1&quot; velocity=&quot;20&quot; lower=&quot;-0.0508254296197560507&quot; upper=&quot;1.4854961776254267392&quot;/&gt;\n    &lt;joint_properties friction=&quot;0.0&quot;/&gt;\n&lt;/joint&gt;\n\n&lt;link name=&quot;part9_2&quot;&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;0.038437349788628449865 0.063553165001418443492 0.013000000000001173811&quot; rpy=&quot;1.57079632679489678 -1.5707963267948903408 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part8.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part8_material&quot;&gt;\n        &lt;color rgba=&quot;1 0.96078431372549022438 0.89019607843137249503 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;0.038437349788628449865 0.063553165001418443492 0.013000000000001173811&quot; rpy=&quot;1.57079632679489678 -1.5707963267948903408 0&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part8.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;visual&gt;\n    &lt;origin xyz=&quot;-5.5511151231257827021e-17 0 0.012999999999999994199&quot; rpy=&quot;1.8669361206154621951e-17 -4.1846222463962295292e-18 -1.1061622554016257027e-17&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part9.stl&quot;/&gt;\n    &lt;/geometry&gt;\n    &lt;material name=&quot;part9_material&quot;&gt;\n        &lt;color rgba=&quot;0.79607843137254896693 0.82352941176470584317 0.9372549019607843146 1.0&quot;/&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n&lt;collision&gt;\n    &lt;origin xyz=&quot;-5.5511151231257827021e-17 0 0.012999999999999994199&quot; rpy=&quot;1.8669361206154621951e-17 -4.1846222463962295292e-18 -1.1061622554016257027e-17&quot; /&gt;\n    &lt;geometry&gt;\n        &lt;mesh filename=&quot;package:///part9.stl&quot;/&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n&lt;inertial&gt;\n    &lt;origin xyz=&quot;-0.019097045128394322944 0.049304563884354772607 0.013000000000000908398&quot; rpy=&quot;0 0 0&quot;/&gt;\n    &lt;mass value=&quot;0.045258281756665255657&quot; /&gt;\n    &lt;inertia ixx=&quot;5.5222946379536119407e-05&quot; ixy=&quot;1.485524015766974595e-05&quot;  ixz=&quot;6.51183823337792082e-19&quot; iyy=&quot;7.1527397674250640881e-06&quot; iyz=&quot;1.2029403278356184806e-19&quot; izz=&quot;5.9954066756446103541e-05&quot; /&gt;\n&lt;/inertial&gt;\n&lt;/link&gt;\n\n&lt;joint name=&quot;J8&quot; type=&quot;revolute&quot;&gt;\n    &lt;origin xyz=&quot;0.040809511095868222785 -0.013000000000000004607 -0.022892057511395225156&quot; rpy=&quot;-1.570796326794896558 -0.10407608628378151039 8.4711537068837356757e-15&quot; /&gt;\n    &lt;parent link=&quot;part7&quot; /&gt;\n    &lt;child link=&quot;part9_2&quot; /&gt;\n    &lt;axis xyz=&quot;0 0 1&quot;/&gt;\n    &lt;limit effort=&quot;1&quot; velocity=&quot;20&quot; lower=&quot;-1.4854961776254267392&quot; upper=&quot;0.0508254296197560507&quot;/&gt;\n    &lt;joint_properties friction=&quot;0.0&quot;/&gt;\n&lt;/joint&gt;\n\n&lt;joint name=&quot;J5&quot; type=&quot;revolute&quot;&gt;\n    &lt;origin xyz=&quot;-0.10400000000000086953 -6.6613381477509392425e-16 -1.1171619185290637688e-15&quot; rpy=&quot;1.570796326794896558 -2.200659911653516123e-14 1.5707963267948941155&quot; /&gt;\n    &lt;parent link=&quot;part6&quot; /&gt;\n    &lt;child link=&quot;part7&quot; /&gt;\n    &lt;axis xyz=&quot;0 0 1&quot;/&gt;\n    &lt;limit effort=&quot;1&quot; velocity=&quot;20&quot; lower=&quot;-6.283185307179586232&quot; upper=&quot;6.283185307179586232&quot;/&gt;\n    &lt;joint_properties friction=&quot;0.0&quot;/&gt;\n&lt;/joint&gt;\n\n&lt;joint name=&quot;J4&quot; type=&quot;revolute&quot;&gt;\n    &lt;origin xyz=&quot;-7.0429773124658368033e-16 -1.1102230246251565404e-16 0.13800000000000009481&quot; rpy=&quot;1.570796326794896558 8.8953965671821529256e-16 -1.5707963267948921171&quot; /&gt;\n    &lt;parent link=&quot;part5&quot; /&gt;\n    &lt;child link=&quot;part6&quot; /&gt;\n    &lt;axis xyz=&quot;0 0 1&quot;/&gt;\n    &lt;limit effort=&quot;1&quot; velocity=&quot;20&quot; lower=&quot;-3.5779249665883754439&quot; upper=&quot;0.43633231299858238339&quot;/&gt;\n    &lt;joint_properties friction=&quot;0.0&quot;/&gt;\n&lt;/joint&gt;\n\n&lt;joint name=&quot;J3&quot; type=&quot;revolute&quot;&gt;\n    &lt;origin xyz=&quot;0.22099999999999983546 0.045000000000000928146 -0.047999999999998099742&quot; rpy=&quot;3.5360923724163181315e-17 1.5707963267948925612 0&quot; /&gt;\n    &lt;parent link=&quot;part4&quot; /&gt;\n    &lt;child link=&quot;part5&quot; /&gt;\n    &lt;axis xyz=&quot;0 0 1&quot;/&gt;\n    &lt;limit effort=&quot;1&quot; velocity=&quot;20&quot; lower=&quot;-3.141592653589793116&quot; upper=&quot;3.141592653589793116&quot;/&gt;\n    &lt;joint_properties friction=&quot;0.0&quot;/&gt;\n&lt;/joint&gt;\n\n&lt;joint name=&quot;J2&quot; type=&quot;revolute&quot;&gt;\n    &lt;origin xyz=&quot;-0.34999999999999981126 -4.7184478546569152968e-16 -1.0408340855860842566e-17&quot; rpy=&quot;-7.9084394517820163515e-16 8.181256381192978572e-16 -2.0089744681964760709&quot; /&gt;\n    &lt;parent link=&quot;part3&quot; /&gt;\n    &lt;child link=&quot;part4&quot; /&gt;\n    &lt;axis xyz=&quot;0 0 1&quot;/&gt;\n    &lt;limit effort=&quot;1&quot; velocity=&quot;20&quot; lower=&quot;-2.4434609527920612138&quot; upper=&quot;1.8849555921538758696&quot;/&gt;\n    &lt;joint_properties friction=&quot;0.0&quot;/&gt;\n&lt;/joint&gt;\n\n&lt;joint name=&quot;J1&quot; type=&quot;revolute&quot;&gt;\n    &lt;origin xyz=&quot;-0.14999999999999980016 -0.019999999999999993477 -0.16000000000000128009&quot; rpy=&quot;-1.570796326794896558 -1.1326181853933210419 3.1415926535897922278&quot; /&gt;\n    &lt;parent link=&quot;part2&quot; /&gt;\n    &lt;child link=&quot;part3&quot; /&gt;\n    &lt;axis xyz=&quot;0 0 1&quot;/&gt;\n    &lt;limit effort=&quot;1&quot; velocity=&quot;20&quot; lower=&quot;-2.1745329251994329478&quot; upper=&quot;1.3906585039886590671&quot;/&gt;\n    &lt;joint_properties friction=&quot;0.0&quot;/&gt;\n&lt;/joint&gt;\n\n&lt;joint name=&quot;base&quot; type=&quot;revolute&quot;&gt;\n    &lt;origin xyz=&quot;-0.0058237426852963229684 -0.026571278200745222786 0.079473588039763426449&quot; rpy=&quot;3.0684444271150290717 -0.32185277620319291403 1.5826756446767937803&quot; /&gt;\n    &lt;parent link=&quot;part1&quot; /&gt;\n    &lt;child link=&quot;part2&quot; /&gt;\n    &lt;axis xyz=&quot;0 0 1&quot;/&gt;\n    &lt;limit effort=&quot;1&quot; velocity=&quot;20&quot; lower=&quot;-3.141592653589793116&quot; upper=&quot;3.141592653589793116&quot;/&gt;\n    &lt;joint_properties friction=&quot;0.0&quot;/&gt;\n&lt;/joint&gt;\n\n\n&lt;transmission name=&quot;link_b_trans&quot;&gt;\n    &lt;type&gt;transmission_interface/SimpleTransmission&lt;/type&gt;\n    &lt;joint name=&quot;base&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n    &lt;/joint&gt;\n    &lt;actuator name=&quot;link_b_motor&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n        &lt;mechanicalReduction&gt;1&lt;/mechanicalReduction&gt;\n    &lt;/actuator&gt;\n&lt;/transmission&gt;\n\n&lt;transmission name=&quot;link_1_trans&quot;&gt;\n    &lt;type&gt;transmission_interface/SimpleTransmission&lt;/type&gt;\n    &lt;joint name=&quot;J1&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n    &lt;/joint&gt;\n    &lt;actuator name=&quot;link_1_motor&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n        &lt;mechanicalReduction&gt;1&lt;/mechanicalReduction&gt;\n    &lt;/actuator&gt;\n&lt;/transmission&gt;\n\n&lt;transmission name=&quot;link_2_trans&quot;&gt;\n    &lt;type&gt;transmission_interface/SimpleTransmission&lt;/type&gt;\n    &lt;joint name=&quot;J2&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n    &lt;/joint&gt;\n    &lt;actuator name=&quot;link_2_motor&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n        &lt;mechanicalReduction&gt;1&lt;/mechanicalReduction&gt;\n    &lt;/actuator&gt;\n&lt;/transmission&gt;\n\n&lt;transmission name=&quot;link_3_trans&quot;&gt;\n    &lt;type&gt;transmission_interface/SimpleTransmission&lt;/type&gt;\n    &lt;joint name=&quot;J3&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n    &lt;/joint&gt;\n    &lt;actuator name=&quot;link_3_motor&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n        &lt;mechanicalReduction&gt;1&lt;/mechanicalReduction&gt;\n    &lt;/actuator&gt;\n&lt;/transmission&gt;\n\n&lt;transmission name=&quot;link_4_trans&quot;&gt;\n    &lt;type&gt;transmission_interface/SimpleTransmission&lt;/type&gt;\n    &lt;joint name=&quot;J4&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n    &lt;/joint&gt;\n    &lt;actuator name=&quot;link_4_motor&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n        &lt;mechanicalReduction&gt;1&lt;/mechanicalReduction&gt;\n    &lt;/actuator&gt;\n&lt;/transmission&gt;\n\n&lt;transmission name=&quot;link_5_trans&quot;&gt;\n    &lt;type&gt;transmission_interface/SimpleTransmission&lt;/type&gt;\n    &lt;joint name=&quot;J5&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n    &lt;/joint&gt;\n    &lt;actuator name=&quot;link_5_motor&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n        &lt;mechanicalReduction&gt;1&lt;/mechanicalReduction&gt;\n    &lt;/actuator&gt;\n&lt;/transmission&gt;\n\n&lt;transmission name=&quot;link_7_trans&quot;&gt;\n    &lt;type&gt;transmission_interface/SimpleTransmission&lt;/type&gt;\n    &lt;joint name=&quot;J7&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n    &lt;/joint&gt;\n    &lt;actuator name=&quot;link_7_motor&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n        &lt;mechanicalReduction&gt;1&lt;/mechanicalReduction&gt;\n    &lt;/actuator&gt;\n&lt;/transmission&gt;\n\n&lt;transmission name=&quot;link_8_trans&quot;&gt;\n    &lt;type&gt;transmission_interface/SimpleTransmission&lt;/type&gt;\n    &lt;joint name=&quot;J8&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n    &lt;/joint&gt;\n    &lt;actuator name=&quot;link_8_motor&quot;&gt;\n        &lt;hardwareInterface&gt;hardware_interface/PositionJointInterface&lt;/hardwareInterface&gt;\n        &lt;mechanicalReduction&gt;1&lt;/mechanicalReduction&gt;\n    &lt;/actuator&gt;\n&lt;/transmission&gt;\n\n&lt;gazebo&gt;\n    &lt;plugin name=&quot;control&quot; filename=&quot;libgazebo_ros_control.so&quot;&gt;\n        &lt;robotNamespace&gt;/&lt;/robotNamespace&gt;\n    &lt;/plugin&gt;\n&lt;/gazebo&gt;\n\n&lt;gazebo reference=&quot;part1&quot;&gt;\n    &lt;selfCollide&gt;true&lt;/selfCollide&gt;\n&lt;/gazebo&gt;\n\n&lt;gazebo reference=&quot;part2&quot;&gt;\n    &lt;selfCollide&gt;true&lt;/selfCollide&gt;\n&lt;/gazebo&gt;\n\n&lt;gazebo reference=&quot;part3&quot;&gt;\n    &lt;selfCollide&gt;true&lt;/selfCollide&gt;\n&lt;/gazebo&gt;\n\n&lt;gazebo reference=&quot;part4&quot;&gt;\n    &lt;selfCollide&gt;true&lt;/selfCollide&gt;\n&lt;/gazebo&gt;\n\n&lt;gazebo reference=&quot;part5&quot;&gt;\n    &lt;selfCollide&gt;true&lt;/selfCollide&gt;\n&lt;/gazebo&gt;\n\n&lt;gazebo reference=&quot;part6&quot;&gt;\n    &lt;selfCollide&gt;true&lt;/selfCollide&gt;\n&lt;/gazebo&gt;\n\n&lt;gazebo reference=&quot;part7&quot;&gt;\n    &lt;selfCollide&gt;true&lt;/selfCollide&gt;\n&lt;/gazebo&gt;\n\n&lt;gazebo reference=&quot;part9&quot;&gt;\n    &lt;selfCollide&gt;true&lt;/selfCollide&gt;\n&lt;/gazebo&gt;\n\n&lt;gazebo reference=&quot;part9_2&quot;&gt;\n    &lt;selfCollide&gt;true&lt;/selfCollide&gt;\n&lt;/gazebo&gt;\n\n\n&lt;/robot&gt;\n"], "quote": [], "url": "https://stackoverflow.com/questions/78602206/spawn-service-failed", "answer": ["got it! there was a mistake in urdf file,i have given wrong path of the stl file."], "answer_code": []},
{"title": "catkin_make error - ros-noetic-catkin-virtualenv", "time": 1719936191, "post_content": ["I installed ros-noetic-catkin-virtualenv using the command sudo apt install ros-noetic-catkin-virtualenv. Then I did catkin_make, it started giving me the following error message:\nCMake Error at /opt/ros/noetic/share/catkin_virtualenv/cmake/catkin_install_python.cmake:30 (message):\n  range_sensor_layer loaded catkin_virtualenv, but never invoked\n  'catkin_generate_virtualenv'\nCall Stack (most recent call first):\n  ros_lecture/externals/navigation_layers/range_sensor_layer/CMakeLists.txt:59 (catkin_install_python)\n\nAny help or suggestion would be much appreciated!\nI already read them\nCmake error - catkin_virtualenv\nMixing non virtualenv packages with virtualenv packages"], "question_code": ["sudo apt install ros-noetic-catkin-virtualenv", "catkin_make", "CMake Error at /opt/ros/noetic/share/catkin_virtualenv/cmake/catkin_install_python.cmake:30 (message):\n  range_sensor_layer loaded catkin_virtualenv, but never invoked\n  'catkin_generate_virtualenv'\nCall Stack (most recent call first):\n  ros_lecture/externals/navigation_layers/range_sensor_layer/CMakeLists.txt:59 (catkin_install_python)\n"], "quote": [], "url": "https://stackoverflow.com/questions/78698179/catkin-make-error-ros-noetic-catkin-virtualenv", "answer": ["According to the README, the build tools supported are catkin-tools, colcon, catkin_make_isolated but not catkin_make.\nI suggest you may uninstall ros-noetic-catkin-virtualenv if it is not required in your project. Otherwise, you need to run catkin_make_isolated for your build."], "answer_code": ["catkin-tools", "colcon", "catkin_make_isolated", "catkin_make", "ros-noetic-catkin-virtualenv", "catkin_make_isolated"]},
{"title": "ESP32S3 Dev Kit keeps crashing when trying to receive serial commands", "time": 1720344255, "post_content": ["I'm trying to use a code I got from the internet to control 2 motors by receiving commands through serial communication, the goal is to have the ESP32 connected with a Raspberry Pi 4 that's running ROS2 Foxy in Ubuntu 20.04. I modified the code a bit to work with the ESP32 since it was made for arduino boards (I'm also using ZS-X11H BLDC motor drivers since I'm using hoverboard motors). I'm getting this in the serial monitor:\nmode:DIO, clock div:1\nload:0x3fce3818,len:0x508\nload:0x403c9700,len:0x4\nload:0x403c9704,len:0xad0\nload:0x403cc700,len:0x29e4\nentry 0x403c9880\nESP-ROM:esp32s3-20210327\n/*********************************************************************\n *  ROSArduinoBridge\n \n    A set of simple serial commands to control a differential drive\n    robot and receive back sensor and odometry data. Default \n    configuration assumes use of an Arduino Mega + Pololu motor\n    controller shield + Robogaia Mega Encoder shield.  Edit the\n    readEncoder() and setMotorSpeed() wrapper functions if using \n    different motor controller or encoder method.\n\n    Created for the Pi Robot Project: http://www.pirobot.org\n    and the Home Brew Robotics Club (HBRC): http://hbrobotics.org\n    \n    Authors: Patrick Goebel, James Nugen\n\n    Inspired and modeled after the ArbotiX driver by Michael Ferguson\n    \n    Software License Agreement (BSD License)\n\n    Copyright (c) 2012, Patrick Goebel.\n    All rights reserved.\n\n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions\n    are met:\n\n     * Redistributions of source code must retain the above copyright\n       notice, this list of conditions and the following disclaimer.\n     * Redistributions in binary form must reproduce the above\n       copyright notice, this list of conditions and/or other materials\n       provided with the distribution.\n\n    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n    \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n    LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n    FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n    COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n    INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n    BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n    LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n    CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n    LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN\n    ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n *  POSSIBILITY OF SUCH DAMAGE.\n *********************************************************************/\n\n#define USE_BASE      // Enable the base controller code\n// #undef USE_BASE     // Disable the base controller code\n\n/* Define the motor controller and encoder library you are using */\n#ifdef USE_BASE\n   /* The Pololu VNH5019 dual motor driver shield */\n   //#define POLOLU_VNH5019\n\n   /* The Pololu MC33926 dual motor driver shield */\n   //#define POLOLU_MC33926\n\n   /* The RoboGaia encoder shield */\n   //#define ROBOGAIA\n   \n   /* Encoders directly attached to Arduino board */\n   #define ARDUINO_ENC_COUNTER\n\n   /* ZS-X11H Motor driver*/\n   #define ZS_X11H_MOTOR_DRIVER\n#endif\n\n//#define USE_SERVOS  // Enable use of PWM servos as defined in servos.h\n#undef USE_SERVOS     // Disable use of PWM servos\n\n/* Serial port baud rate */\n#define BAUDRATE     115200\n\n/* Maximum PWM signal */\n#define MAX_PWM        255\n\n#include <Arduino.h>\n\n/* Include definition of serial commands */\n#include \"commands.h\"\n\n/* Sensor functions */\n#include \"sensors.h\"\n\n/* Include servo support if required */\n#ifdef USE_SERVOS\n   #include <Servo.h>\n   #include \"servos.h\"\n#endif\n\n#ifdef USE_BASE\n  /* Motor driver function definitions */\n  #include \"motor_driver.h\"\n\n  /* Encoder driver function definitions */\n  #include \"encoder_driver.h\"\n\n  /* PID parameters and functions */\n  #include \"diff_controller.h\"\n\n  /* Run the PID loop at 30 times per second */\n  #define PID_RATE           30     // Hz\n\n  /* Convert the rate into an interval */\n  const int PID_INTERVAL = 1000 / PID_RATE;\n  \n  /* Track the next time we make a PID calculation */\n  unsigned long nextPID = PID_INTERVAL;\n\n  /* Stop the robot if it hasn't received a movement command\n   in this number of milliseconds */\n  #define AUTO_STOP_INTERVAL 2000\n  long lastMotorCommand = AUTO_STOP_INTERVAL;\n#endif\n\n/* Variable initialization */\n\n// A pair of varibles to help parse serial commands (thanks Fergs)\nint arg = 0;\nint cmdIndex = 0;\n\n// Variable to hold an input character\nchar chr;\n\n// Variable to hold the current single-character command\nchar cmd;\n\n// Character arrays to hold the first and second arguments\nchar argv1[16];\nchar argv2[16];\n\n// The arguments converted to integers\nlong arg1;\nlong arg2;\n\n/* Clear the current command parameters */\nvoid resetCommand() {\n  cmd = NULL;\n  memset(argv1, 0, sizeof(argv1));\n  memset(argv2, 0, sizeof(argv2));\n  arg1 = 0;\n  arg2 = 0;\n  arg = 0;\n  cmdIndex = 0;\n}\n\n/* Run a command.  Commands are defined in commands.h */\nint runCommand() {\n  int i = 0;\n  char *p = argv1;\n  char *str;\n  int pid_args[4];\n  arg1 = atoi(argv1);\n  arg2 = atoi(argv2);\n  \n  switch(cmd) {\n  case GET_BAUDRATE:\n    Serial0.println(BAUDRATE);\n    break;\n  case ANALOG_READ:\n    Serial0.println(analogRead(arg1));\n    break;\n  case DIGITAL_READ:\n    Serial0.println(digitalRead(arg1));\n    break;\n  case ANALOG_WRITE:\n    analogWrite(arg1, arg2);\n    Serial0.println(\"OK\"); \n    break;\n  case DIGITAL_WRITE:\n    if (arg2 == 0) digitalWrite(arg1, LOW);\n    else if (arg2 == 1) digitalWrite(arg1, HIGH);\n    Serial0.println(\"OK\"); \n    break;\n  case PIN_MODE:\n    if (arg2 == 0) pinMode(arg1, INPUT);\n    else if (arg2 == 1) pinMode(arg1, OUTPUT);\n    Serial0.println(\"OK\");\n    break;\n  case PING:\n    Serial0.println(Ping(arg1));\n    break;\n#ifdef USE_SERVOS\n  case SERVO_WRITE:\n    servos[arg1].setTargetPosition(arg2);\n    Serial0.println(\"OK\");\n    break;\n  case SERVO_READ:\n    Serial0.println(servos[arg1].getServo().read());\n    break;\n#endif\n    \n#ifdef USE_BASE\n  case READ_ENCODERS:\n    Serial0.print(readEncoderLeft());\n    Serial0.print(\" \");\n    Serial0.println(readEncoderRight());\n    break;\n   case RESET_ENCODERS:\n    resetEncoders();\n    resetPID();\n    Serial0.println(\"OK\");\n    break;\n  case MOTOR_SPEEDS:\n    /* Reset the auto stop timer */\n    lastMotorCommand = millis();\n    if (arg1 == 0 && arg2 == 0) {\n      setMotorSpeeds(0, 0);\n      resetPID();\n      moving = 0;\n    }\n    else moving = 1;\n    leftPID.TargetTicksPerFrame = arg1;\n    rightPID.TargetTicksPerFrame = arg2;\n    Serial0.println(\"OK\"); \n    break;\n  case MOTOR_RAW_PWM:\n    /* Reset the auto stop timer */\n    lastMotorCommand = millis();\n    resetPID();\n    moving = 0; // Sneaky way to temporarily disable the PID\n    setMotorSpeeds(arg1, arg2);\n    Serial0.println(\"OK\"); \n    break;\n  case UPDATE_PID:\n    while ((str = strtok_r(p, \":\", &p)) != nullptr) {\n       pid_args[i] = atoi(str);\n       i++;\n    }\n    Kp = pid_args[0];\n    Kd = pid_args[1];\n    Ki = pid_args[2];\n    Ko = pid_args[3];\n    Serial0.println(\"OK\");\n    break;\n#endif\n  default:\n    Serial0.println(\"Invalid Command\");\n    break;\n  }\n  yield(); // Add yield to allow other tasks to run\n}\n\n/* Setup function--runs once at startup. */\nvoid setup() {\n  Serial0.begin(BAUDRATE);\n\n// Initialize the motor controller if used */\n#ifdef USE_BASE\n  initMotorController();\n  resetPID();\n  initEncoders();  // Initialize encoders\n#endif\n\n/* Attach servos if used */\n  #ifdef USE_SERVOS\n    int i;\n    for (i = 0; i < N_SERVOS; i++) {\n      servos[i].initServo(\n          servoPins[i],\n          stepDelay[i],\n          servoInitPosition[i]);\n    }\n  #endif\n}\n\n/* Enter the main loop.  Read and parse input from the serial port\n   and run any valid commands. Run a PID calculation at the target\n   interval and check for auto-stop conditions.\n*/\nvoid loop() {\n  while (Serial0.available() > 0) {\n    \n    // Read the next character\n    chr = Serial0.read();\n\n    // Terminate a command with a CR\n    if (chr == 13) {\n      if (arg == 1) argv1[cmdIndex] = NULL;\n      else if (arg == 2) argv2[cmdIndex] = NULL;\n      runCommand();\n      resetCommand();\n    }\n    // Use spaces to delimit parts of the command\n    else if (chr == ' ') {\n      // Step through the arguments\n      if (arg == 0) arg = 1;\n      else if (arg == 1)  {\n        argv1[cmdIndex] = NULL;\n        arg = 2;\n        cmdIndex = 0;\n      }\n      continue;\n    }\n    else {\n      if (arg == 0) {\n        // The first arg is the single-letter command\n        cmd = chr;\n      }\n      else if (arg == 1) {\n        // Subsequent args are the command parameters\n        argv1[cmdIndex] = chr;\n        cmdIndex++;\n      }\n      else if (arg == 2) {\n        argv2[cmdIndex] = chr;\n        cmdIndex++;\n      }\n    }\n    yield(); // Add yield to allow other tasks to run\n  }\n\n#ifdef USE_BASE\n  /* Are we due for another PID calculation? */\n  if (millis() > nextPID) {\n    updatePID();\n    nextPID += PID_INTERVAL;\n  }\n  \n  /* Have we exceeded the auto-stop interval? */\n  if ((millis() - lastMotorCommand) > AUTO_STOP_INTERVAL) {\n    setMotorSpeeds(0, 0);\n    resetPID();\n    moving = 0;\n  }\n  yield(); // Add yield to allow other tasks to run\n#endif\n}\n\nBeen looking online for solutions, like adding yield() or using Serial0 instead of Serial, but no fix. It's 5 am and I'm in desperate need of a solution, I need to show this project in 2 weeks to pass my mobile robotics class, the pressure build-up is insane. Here's the main code, for the other files of the program, they're attached in a .zip file in this discussion (https://github.com/espressif/arduino-esp32/discussions/9993) since I don't want to have to show a humongous text."], "question_code": ["/*********************************************************************\n *  ROSArduinoBridge\n \n    A set of simple serial commands to control a differential drive\n    robot and receive back sensor and odometry data. Default \n    configuration assumes use of an Arduino Mega + Pololu motor\n    controller shield + Robogaia Mega Encoder shield.  Edit the\n    readEncoder() and setMotorSpeed() wrapper functions if using \n    different motor controller or encoder method.\n\n    Created for the Pi Robot Project: http://www.pirobot.org\n    and the Home Brew Robotics Club (HBRC): http://hbrobotics.org\n    \n    Authors: Patrick Goebel, James Nugen\n\n    Inspired and modeled after the ArbotiX driver by Michael Ferguson\n    \n    Software License Agreement (BSD License)\n\n    Copyright (c) 2012, Patrick Goebel.\n    All rights reserved.\n\n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions\n    are met:\n\n     * Redistributions of source code must retain the above copyright\n       notice, this list of conditions and the following disclaimer.\n     * Redistributions in binary form must reproduce the above\n       copyright notice, this list of conditions and/or other materials\n       provided with the distribution.\n\n    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n    &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n    LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n    FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n    COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n    INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n    BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n    LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n    CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n    LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN\n    ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n *  POSSIBILITY OF SUCH DAMAGE.\n *********************************************************************/\n\n#define USE_BASE      // Enable the base controller code\n// #undef USE_BASE     // Disable the base controller code\n\n/* Define the motor controller and encoder library you are using */\n#ifdef USE_BASE\n   /* The Pololu VNH5019 dual motor driver shield */\n   //#define POLOLU_VNH5019\n\n   /* The Pololu MC33926 dual motor driver shield */\n   //#define POLOLU_MC33926\n\n   /* The RoboGaia encoder shield */\n   //#define ROBOGAIA\n   \n   /* Encoders directly attached to Arduino board */\n   #define ARDUINO_ENC_COUNTER\n\n   /* ZS-X11H Motor driver*/\n   #define ZS_X11H_MOTOR_DRIVER\n#endif\n\n//#define USE_SERVOS  // Enable use of PWM servos as defined in servos.h\n#undef USE_SERVOS     // Disable use of PWM servos\n\n/* Serial port baud rate */\n#define BAUDRATE     115200\n\n/* Maximum PWM signal */\n#define MAX_PWM        255\n\n#include &lt;Arduino.h&gt;\n\n/* Include definition of serial commands */\n#include &quot;commands.h&quot;\n\n/* Sensor functions */\n#include &quot;sensors.h&quot;\n\n/* Include servo support if required */\n#ifdef USE_SERVOS\n   #include &lt;Servo.h&gt;\n   #include &quot;servos.h&quot;\n#endif\n\n#ifdef USE_BASE\n  /* Motor driver function definitions */\n  #include &quot;motor_driver.h&quot;\n\n  /* Encoder driver function definitions */\n  #include &quot;encoder_driver.h&quot;\n\n  /* PID parameters and functions */\n  #include &quot;diff_controller.h&quot;\n\n  /* Run the PID loop at 30 times per second */\n  #define PID_RATE           30     // Hz\n\n  /* Convert the rate into an interval */\n  const int PID_INTERVAL = 1000 / PID_RATE;\n  \n  /* Track the next time we make a PID calculation */\n  unsigned long nextPID = PID_INTERVAL;\n\n  /* Stop the robot if it hasn't received a movement command\n   in this number of milliseconds */\n  #define AUTO_STOP_INTERVAL 2000\n  long lastMotorCommand = AUTO_STOP_INTERVAL;\n#endif\n\n/* Variable initialization */\n\n// A pair of varibles to help parse serial commands (thanks Fergs)\nint arg = 0;\nint cmdIndex = 0;\n\n// Variable to hold an input character\nchar chr;\n\n// Variable to hold the current single-character command\nchar cmd;\n\n// Character arrays to hold the first and second arguments\nchar argv1[16];\nchar argv2[16];\n\n// The arguments converted to integers\nlong arg1;\nlong arg2;\n\n/* Clear the current command parameters */\nvoid resetCommand() {\n  cmd = NULL;\n  memset(argv1, 0, sizeof(argv1));\n  memset(argv2, 0, sizeof(argv2));\n  arg1 = 0;\n  arg2 = 0;\n  arg = 0;\n  cmdIndex = 0;\n}\n\n/* Run a command.  Commands are defined in commands.h */\nint runCommand() {\n  int i = 0;\n  char *p = argv1;\n  char *str;\n  int pid_args[4];\n  arg1 = atoi(argv1);\n  arg2 = atoi(argv2);\n  \n  switch(cmd) {\n  case GET_BAUDRATE:\n    Serial0.println(BAUDRATE);\n    break;\n  case ANALOG_READ:\n    Serial0.println(analogRead(arg1));\n    break;\n  case DIGITAL_READ:\n    Serial0.println(digitalRead(arg1));\n    break;\n  case ANALOG_WRITE:\n    analogWrite(arg1, arg2);\n    Serial0.println(&quot;OK&quot;); \n    break;\n  case DIGITAL_WRITE:\n    if (arg2 == 0) digitalWrite(arg1, LOW);\n    else if (arg2 == 1) digitalWrite(arg1, HIGH);\n    Serial0.println(&quot;OK&quot;); \n    break;\n  case PIN_MODE:\n    if (arg2 == 0) pinMode(arg1, INPUT);\n    else if (arg2 == 1) pinMode(arg1, OUTPUT);\n    Serial0.println(&quot;OK&quot;);\n    break;\n  case PING:\n    Serial0.println(Ping(arg1));\n    break;\n#ifdef USE_SERVOS\n  case SERVO_WRITE:\n    servos[arg1].setTargetPosition(arg2);\n    Serial0.println(&quot;OK&quot;);\n    break;\n  case SERVO_READ:\n    Serial0.println(servos[arg1].getServo().read());\n    break;\n#endif\n    \n#ifdef USE_BASE\n  case READ_ENCODERS:\n    Serial0.print(readEncoderLeft());\n    Serial0.print(&quot; &quot;);\n    Serial0.println(readEncoderRight());\n    break;\n   case RESET_ENCODERS:\n    resetEncoders();\n    resetPID();\n    Serial0.println(&quot;OK&quot;);\n    break;\n  case MOTOR_SPEEDS:\n    /* Reset the auto stop timer */\n    lastMotorCommand = millis();\n    if (arg1 == 0 &amp;&amp; arg2 == 0) {\n      setMotorSpeeds(0, 0);\n      resetPID();\n      moving = 0;\n    }\n    else moving = 1;\n    leftPID.TargetTicksPerFrame = arg1;\n    rightPID.TargetTicksPerFrame = arg2;\n    Serial0.println(&quot;OK&quot;); \n    break;\n  case MOTOR_RAW_PWM:\n    /* Reset the auto stop timer */\n    lastMotorCommand = millis();\n    resetPID();\n    moving = 0; // Sneaky way to temporarily disable the PID\n    setMotorSpeeds(arg1, arg2);\n    Serial0.println(&quot;OK&quot;); \n    break;\n  case UPDATE_PID:\n    while ((str = strtok_r(p, &quot;:&quot;, &amp;p)) != nullptr) {\n       pid_args[i] = atoi(str);\n       i++;\n    }\n    Kp = pid_args[0];\n    Kd = pid_args[1];\n    Ki = pid_args[2];\n    Ko = pid_args[3];\n    Serial0.println(&quot;OK&quot;);\n    break;\n#endif\n  default:\n    Serial0.println(&quot;Invalid Command&quot;);\n    break;\n  }\n  yield(); // Add yield to allow other tasks to run\n}\n\n/* Setup function--runs once at startup. */\nvoid setup() {\n  Serial0.begin(BAUDRATE);\n\n// Initialize the motor controller if used */\n#ifdef USE_BASE\n  initMotorController();\n  resetPID();\n  initEncoders();  // Initialize encoders\n#endif\n\n/* Attach servos if used */\n  #ifdef USE_SERVOS\n    int i;\n    for (i = 0; i &lt; N_SERVOS; i++) {\n      servos[i].initServo(\n          servoPins[i],\n          stepDelay[i],\n          servoInitPosition[i]);\n    }\n  #endif\n}\n\n/* Enter the main loop.  Read and parse input from the serial port\n   and run any valid commands. Run a PID calculation at the target\n   interval and check for auto-stop conditions.\n*/\nvoid loop() {\n  while (Serial0.available() &gt; 0) {\n    \n    // Read the next character\n    chr = Serial0.read();\n\n    // Terminate a command with a CR\n    if (chr == 13) {\n      if (arg == 1) argv1[cmdIndex] = NULL;\n      else if (arg == 2) argv2[cmdIndex] = NULL;\n      runCommand();\n      resetCommand();\n    }\n    // Use spaces to delimit parts of the command\n    else if (chr == ' ') {\n      // Step through the arguments\n      if (arg == 0) arg = 1;\n      else if (arg == 1)  {\n        argv1[cmdIndex] = NULL;\n        arg = 2;\n        cmdIndex = 0;\n      }\n      continue;\n    }\n    else {\n      if (arg == 0) {\n        // The first arg is the single-letter command\n        cmd = chr;\n      }\n      else if (arg == 1) {\n        // Subsequent args are the command parameters\n        argv1[cmdIndex] = chr;\n        cmdIndex++;\n      }\n      else if (arg == 2) {\n        argv2[cmdIndex] = chr;\n        cmdIndex++;\n      }\n    }\n    yield(); // Add yield to allow other tasks to run\n  }\n\n#ifdef USE_BASE\n  /* Are we due for another PID calculation? */\n  if (millis() &gt; nextPID) {\n    updatePID();\n    nextPID += PID_INTERVAL;\n  }\n  \n  /* Have we exceeded the auto-stop interval? */\n  if ((millis() - lastMotorCommand) &gt; AUTO_STOP_INTERVAL) {\n    setMotorSpeeds(0, 0);\n    resetPID();\n    moving = 0;\n  }\n  yield(); // Add yield to allow other tasks to run\n#endif\n}\n"], "quote": [], "url": "https://stackoverflow.com/questions/78716902/esp32s3-dev-kit-keeps-crashing-when-trying-to-receive-serial-commands", "answer": ["Have you tried to use SoftwareSerial library, for ESP32 there is specific library named: https://github.com/plerup/espsoftwareserial\nI hope this will solve problem, good luck!"], "answer_code": []},
{"title": "Issues with Aligning Infrared and RGB Images from Intel RealSense D435i in ROS", "time": 1720094422, "post_content": ["I am working on a project to align infrared and RGB images from an Intel RealSense D435i camera using ROS. My goal is to subscribe to the RGB and infrared image topics and publish the aligned infrared image to match the RGB image frame. However, I am facing an issue where the aligned images do not completely overlap.\nHere is the code I am using:\n#!/usr/bin/env python3\nimport rospy\nimport message_filters\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom cv_bridge import CvBridge, CvBridgeError\nimport cv2\nimport numpy as np\nimport tf\n\nclass ImageAligner:\n    def __init__(self):\n        self.bridge = CvBridge()\n        self.tf_listener = tf.TransformListener()\n        \n        self.rgb_image_sub = message_filters.Subscriber(\"/camera/color/image_raw\", Image)\n        self.infra_image_sub = message_filters.Subscriber(\"/camera/infra1/image_rect_raw\", Image)\n        self.rgb_info_sub = message_filters.Subscriber(\"/camera/color/camera_info\", CameraInfo)\n        self.infra_info_sub = message_filters.Subscriber(\"/camera/infra1/camera_info\", CameraInfo)\n        \n        self.ts = message_filters.ApproximateTimeSynchronizer([self.rgb_image_sub, self.infra_image_sub, self.rgb_info_sub, self.infra_info_sub], 10, 0.1)\n        self.ts.registerCallback(self.align_image)\n        \n        self.aligned_infra_pub = rospy.Publisher(\"/camera/aligned_infra1_to_color/image_raw\", Image, queue_size=10)\n        self.aligned_infra_info_pub = rospy.Publisher('camera/aligned_infra1_to_color/camera_info', CameraInfo, queue_size=10)\n    \n    def align_image(self, rgb_image, infra_image, rgb_info, infra_info):\n        rospy.loginfo(\"Callback triggered.\")\n        try:\n            rgb_cv_image = self.bridge.imgmsg_to_cv2(rgb_image, \"bgr8\")\n            infra_cv_image = self.bridge.imgmsg_to_cv2(infra_image, \"mono8\")\n            rospy.loginfo(\"Converted images to OpenCV format. RGB size: {}, Infra size: {}\".format(rgb_cv_image.shape, infra_cv_image.shape))\n            \n            K_rgb = np.array(rgb_info.K).reshape((3, 3)).astype(np.float32)\n            K_infra = np.array(infra_info.K).reshape((3, 3)).astype(np.float32)\n            rospy.loginfo(\"Obtained camera matrices.\")\n            \n            try:\n                self.tf_listener.waitForTransform(\"camera_color_optical_frame\", \"camera_infra1_optical_frame\", rospy.Time(0), rospy.Duration(1.0))\n                (trans, rot) = self.tf_listener.lookupTransform(\"camera_color_optical_frame\", \"camera_infra1_optical_frame\", rospy.Time(0))\n                rospy.loginfo(\"Transformation from infrared to RGB camera obtained.\")\n            except (tf.Exception, tf.LookupException, tf.ConnectivityException) as e:\n                rospy.logerr(\"Failed to get transformation from infrared to RGB camera: {}\".format(e))\n                return\n            \n            rot_matrix = tf.transformations.quaternion_matrix(rot)[:3, :3].astype(np.float32)\n            trans_matrix = np.array(trans).reshape((3, 1)).astype(np.float32)\n            rospy.loginfo(\"Rotation matrix: {}\".format(rot_matrix))\n            rospy.loginfo(\"Translation matrix: {}\".format(trans_matrix))  \n            \n            n = rot_matrix[:, 2]\n            d = np.linalg.norm(n)\n            rospy.loginfo(\"Normal vector: {}\".format(n))\n            rospy.loginfo(\"Distance from camera: {}\".format(d))\n            \n            h_matrix = np.dot(K_rgb, np.dot((rot_matrix-trans_matrix*np.transpose(n)/d), np.linalg.inv(K_infra)))\n            rospy.loginfo(\"Computed homography matrix.\")\n            \n            infra_aligned = cv2.warpPerspective(infra_cv_image, h_matrix, (rgb_cv_image.shape[1], rgb_cv_image.shape[0]))\n            rospy.loginfo(\"Warped infrared image to RGB perspective. Size: {}\".format(infra_aligned.shape))\n            \n            if infra_aligned is not None and infra_aligned.size > 0:\n                infra_aligned_msg = self.bridge.cv2_to_imgmsg(infra_aligned, \"mono8\")\n                rospy.loginfo(\"Converted aligned infrared image to ROS format.\")\n                self.aligned_infra_pub.publish(infra_aligned_msg)\n                rospy.loginfo(\"Published aligned infrared image.\")\n            else:\n                rospy.logwarn(\"Aligned infrared image is empty. Skipping publish.\")\n            \n            self.aligned_camera_info(infra_info)\n                \n        except CvBridgeError as e:\n            rospy.logerr(\"CvBridge Error: {0}\".format(e))\n        except Exception as e:\n            rospy.logerr(\"Error in aligning images: {0}\".format(e))\n            \n    def aligned_camera_info(self, infra_info):\n        if infra_info is None:\n            return\n\n        aligned_camera_info = infra_info\n        aligned_camera_info.header.frame_id = 'camera_color_optical_frame'\n        \n        self.aligned_infra_info_pub.publish(aligned_camera_info)\n\nif __name__ == '__main__':\n    rospy.init_node('image_aligner', anonymous=True)\n    ImageAligner()\n    try:\n        rospy.spin()\n    except KeyboardInterrupt:\n        rospy.loginfo(\"Shutting down image aligner node.\")\n\n\nThe images are not completely overlapping after alignment. I suspect the issue might be with the homography matrix calculation or the transformation between the camera frames.\nRGB image\nInfrared image (Original)\nAligned infrared image\nDetails:\n\nI am using the /camera/color/image_raw topic for RGB images and the /camera/infra1/image_rect_raw topic for infrared images.\nThe homography matrix is computed using the camera matrices and the transformation between the infrared and RGB cameras.\n\nQuestions:\n\nIs there an error in the homography matrix calculation?\nAre there any additional steps needed to ensure the images completely overlap?\nIs there a better approach to align these images using ROS and OpenCV?\n\nAny guidance or suggestions to resolve this issue would be greatly appreciated."], "question_code": ["#!/usr/bin/env python3\nimport rospy\nimport message_filters\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom cv_bridge import CvBridge, CvBridgeError\nimport cv2\nimport numpy as np\nimport tf\n\nclass ImageAligner:\n    def __init__(self):\n        self.bridge = CvBridge()\n        self.tf_listener = tf.TransformListener()\n        \n        self.rgb_image_sub = message_filters.Subscriber(&quot;/camera/color/image_raw&quot;, Image)\n        self.infra_image_sub = message_filters.Subscriber(&quot;/camera/infra1/image_rect_raw&quot;, Image)\n        self.rgb_info_sub = message_filters.Subscriber(&quot;/camera/color/camera_info&quot;, CameraInfo)\n        self.infra_info_sub = message_filters.Subscriber(&quot;/camera/infra1/camera_info&quot;, CameraInfo)\n        \n        self.ts = message_filters.ApproximateTimeSynchronizer([self.rgb_image_sub, self.infra_image_sub, self.rgb_info_sub, self.infra_info_sub], 10, 0.1)\n        self.ts.registerCallback(self.align_image)\n        \n        self.aligned_infra_pub = rospy.Publisher(&quot;/camera/aligned_infra1_to_color/image_raw&quot;, Image, queue_size=10)\n        self.aligned_infra_info_pub = rospy.Publisher('camera/aligned_infra1_to_color/camera_info', CameraInfo, queue_size=10)\n    \n    def align_image(self, rgb_image, infra_image, rgb_info, infra_info):\n        rospy.loginfo(&quot;Callback triggered.&quot;)\n        try:\n            rgb_cv_image = self.bridge.imgmsg_to_cv2(rgb_image, &quot;bgr8&quot;)\n            infra_cv_image = self.bridge.imgmsg_to_cv2(infra_image, &quot;mono8&quot;)\n            rospy.loginfo(&quot;Converted images to OpenCV format. RGB size: {}, Infra size: {}&quot;.format(rgb_cv_image.shape, infra_cv_image.shape))\n            \n            K_rgb = np.array(rgb_info.K).reshape((3, 3)).astype(np.float32)\n            K_infra = np.array(infra_info.K).reshape((3, 3)).astype(np.float32)\n            rospy.loginfo(&quot;Obtained camera matrices.&quot;)\n            \n            try:\n                self.tf_listener.waitForTransform(&quot;camera_color_optical_frame&quot;, &quot;camera_infra1_optical_frame&quot;, rospy.Time(0), rospy.Duration(1.0))\n                (trans, rot) = self.tf_listener.lookupTransform(&quot;camera_color_optical_frame&quot;, &quot;camera_infra1_optical_frame&quot;, rospy.Time(0))\n                rospy.loginfo(&quot;Transformation from infrared to RGB camera obtained.&quot;)\n            except (tf.Exception, tf.LookupException, tf.ConnectivityException) as e:\n                rospy.logerr(&quot;Failed to get transformation from infrared to RGB camera: {}&quot;.format(e))\n                return\n            \n            rot_matrix = tf.transformations.quaternion_matrix(rot)[:3, :3].astype(np.float32)\n            trans_matrix = np.array(trans).reshape((3, 1)).astype(np.float32)\n            rospy.loginfo(&quot;Rotation matrix: {}&quot;.format(rot_matrix))\n            rospy.loginfo(&quot;Translation matrix: {}&quot;.format(trans_matrix))  \n            \n            n = rot_matrix[:, 2]\n            d = np.linalg.norm(n)\n            rospy.loginfo(&quot;Normal vector: {}&quot;.format(n))\n            rospy.loginfo(&quot;Distance from camera: {}&quot;.format(d))\n            \n            h_matrix = np.dot(K_rgb, np.dot((rot_matrix-trans_matrix*np.transpose(n)/d), np.linalg.inv(K_infra)))\n            rospy.loginfo(&quot;Computed homography matrix.&quot;)\n            \n            infra_aligned = cv2.warpPerspective(infra_cv_image, h_matrix, (rgb_cv_image.shape[1], rgb_cv_image.shape[0]))\n            rospy.loginfo(&quot;Warped infrared image to RGB perspective. Size: {}&quot;.format(infra_aligned.shape))\n            \n            if infra_aligned is not None and infra_aligned.size &gt; 0:\n                infra_aligned_msg = self.bridge.cv2_to_imgmsg(infra_aligned, &quot;mono8&quot;)\n                rospy.loginfo(&quot;Converted aligned infrared image to ROS format.&quot;)\n                self.aligned_infra_pub.publish(infra_aligned_msg)\n                rospy.loginfo(&quot;Published aligned infrared image.&quot;)\n            else:\n                rospy.logwarn(&quot;Aligned infrared image is empty. Skipping publish.&quot;)\n            \n            self.aligned_camera_info(infra_info)\n                \n        except CvBridgeError as e:\n            rospy.logerr(&quot;CvBridge Error: {0}&quot;.format(e))\n        except Exception as e:\n            rospy.logerr(&quot;Error in aligning images: {0}&quot;.format(e))\n            \n    def aligned_camera_info(self, infra_info):\n        if infra_info is None:\n            return\n\n        aligned_camera_info = infra_info\n        aligned_camera_info.header.frame_id = 'camera_color_optical_frame'\n        \n        self.aligned_infra_info_pub.publish(aligned_camera_info)\n\nif __name__ == '__main__':\n    rospy.init_node('image_aligner', anonymous=True)\n    ImageAligner()\n    try:\n        rospy.spin()\n    except KeyboardInterrupt:\n        rospy.loginfo(&quot;Shutting down image aligner node.&quot;)\n\n"], "quote": [], "url": "https://stackoverflow.com/questions/78706986/issues-with-aligning-infrared-and-rgb-images-from-intel-realsense-d435i-in-ros", "answer": ["in order to align the images acquired by 2 different cameras you need the following information:\n\nrgb camera intrinsic matrix (3x3)\nir camera intrinsic matrix (3x3)\nextrinsic matrix representing the transformation between the rgb and the ir camera (4x4)\nrgb image size\n\nThis python code will align the ir image, returnig an image overlappable to the rgb image:\nimport numpy as np\n\ndef align(\n    intrinsics_ir, intrinsics_rgb, extrinsics_rgb2ir, ir_image, rgb_image_shape\n) -> np.ndarray:\n    width, height = rgb_image_shape\n    out = np.zeros((height, width)) / 0\n    y, x = np.meshgrid(\n        np.arange(ir_image.shape[0]), np.arange(ir_image.shape[1]), indexing=\"ij\"\n    )\n    x = x.reshape(1, -1)\n    y = y.reshape(1, -1)\n    z = ir_image.reshape(1, -1)\n    x = (x - intrinsics_ir[0, 2]) / intrinsics_ir[0, 0]\n    y = (y - intrinsics_ir[1, 2]) / intrinsics_ir[1, 1]\n    pts = np.vstack((x * z, y * z, z))\n    pts = extrinsics_rgb2ir[:3, :3] @ pts + extrinsics_rgb2ir[:3, 3:]\n    pts = intrinsics_rgb @ pts\n    px = np.round(pts[0, :] / pts[2, :])\n    py = np.round(pts[1, :] / pts[2, :])\n    mask = (px >= 0) * (py >= 0) * (px < width) * (py < height)\n    out[py[mask].astype(int), px[mask].astype(int)] = pts[2, mask]\n    return out"], "answer_code": ["import numpy as np\n\ndef align(\n    intrinsics_ir, intrinsics_rgb, extrinsics_rgb2ir, ir_image, rgb_image_shape\n) -&gt; np.ndarray:\n    width, height = rgb_image_shape\n    out = np.zeros((height, width)) / 0\n    y, x = np.meshgrid(\n        np.arange(ir_image.shape[0]), np.arange(ir_image.shape[1]), indexing=&quot;ij&quot;\n    )\n    x = x.reshape(1, -1)\n    y = y.reshape(1, -1)\n    z = ir_image.reshape(1, -1)\n    x = (x - intrinsics_ir[0, 2]) / intrinsics_ir[0, 0]\n    y = (y - intrinsics_ir[1, 2]) / intrinsics_ir[1, 1]\n    pts = np.vstack((x * z, y * z, z))\n    pts = extrinsics_rgb2ir[:3, :3] @ pts + extrinsics_rgb2ir[:3, 3:]\n    pts = intrinsics_rgb @ pts\n    px = np.round(pts[0, :] / pts[2, :])\n    py = np.round(pts[1, :] / pts[2, :])\n    mask = (px &gt;= 0) * (py &gt;= 0) * (px &lt; width) * (py &lt; height)\n    out[py[mask].astype(int), px[mask].astype(int)] = pts[2, mask]\n    return out\n"]},
{"title": "ROS2 Node Publishing GPS Data Drifts Out of Bounds After Several Seconds", "time": 1723802469, "post_content": ["ROS2 Node: GPS and IMU Data Publishing - Position Drift Issue After Initial Accuracy\nI'm developing a ROS2 node that reads GPS and IMU data from a file and publishes it to various ROS2 topics (sensor_msgs::msg::NavSatFix, geometry_msgs::msg::PoseWithCovarianceStamped, and sensor_msgs::msg::Imu). The node performs as expected at startup, with accurate data and correct pose behavior. However, after a few seconds, the published data starts to drift out of bounds, and the system begins displaying incorrect positions.\nProblem Description:\n\nExpected Behavior: The GPS and pose data should remain accurate and within the expected area throughout the runtime.\nActual Behavior: Initially, the object/vehicle is correctly positioned and appears to turn around as expected. After a few seconds, the position data starts to drift, and the object/vehicle eventually moves outside the expected bounds.\nEnvironment: ROS2, using a combination of GPS and IMU data for navigation and localization.\n\nCode Overview:\nBelow is a simplified version of my node. The full node reads from a file, converts latitude/longitude to UTM coordinates, and publishes GPS, pose, and IMU data to the respective topics.\nCODE:\nhttps://codefile.io/f/d0yZrBEtTL\nTroubleshooting Attempted:\n\nTime Synchronization: Ensured the time difference (time - last_time) and the ROS time are correctly calculated.\nLoop Delays: Checked the loop's processing time and reduced the sleep duration to avoid timing issues.\nCoordinate Conversion: Verified that the UTM conversion is accurate and that the local coordinates are calculated relative to a correct origin.\nCovariance Settings: Reviewed the covariance values to ensure they accurately represent sensor uncertainties.\n\nSpecific Questions:\n\nWhy does the system appear to function correctly at the beginning but starts drifting out of bounds after a few seconds?\nCould there be a cumulative timing or precision error in my loop that's causing this drift? How can I mitigate it?\nWhat are some best practices to ensure the GPS and pose data remain accurate over time when processing and publishing data in a loop like this?\n\nAdditional Context:\n\nThe problem seems to be time-related, as the drift occurs gradually after the node has been running for a few seconds.\nI'm using standard ROS2 tools and libraries, with the GPS data being simulated from a pre-recorded dataset.\n\nAny insights or suggestions on how to debug or resolve this issue would be greatly appreciated!"], "question_code": ["sensor_msgs::msg::NavSatFix", "geometry_msgs::msg::PoseWithCovarianceStamped", "sensor_msgs::msg::Imu"], "quote": [], "url": "https://stackoverflow.com/questions/78878604/ros2-node-publishing-gps-data-drifts-out-of-bounds-after-several-seconds", "answer": ["GPS gives accurate results at low frequency, while IMU gives results at high frequency and the amount of error increases over time, so I think the reason for the drift is due to the IMU.\nPossible causes and solutions:\n\nThere may be a timestep error. Check the GPS and IMU timestamps and make sure they are in the same time range.\n\nThe IMU may not be properly calibrated. Review the IMU outputs and update your Bias values.\n\nTry running gyro and acceleration data through the Mahony orientation filter and using Kalman in a way that is compatible with GPS. This will allow the accumulated errors to be tolerated by GPS.\n\n\nNote: Gyroscope data may cause drift, reduce Gyroscope confidence to avoid this\nIn this section you can find sample codes for IMU filtering."], "answer_code": []},
{"title": "TypeError: cannot unpack non-iterable NoneType object how can \u0131 solve this problem", "time": 1720973411, "post_content": ["from .colour_segmentation import segment_lanes\nfrom ...config import config\nfrom .midlane_estimation import estimate_midlane\nimport cv2\nimport numpy as np\nfrom .data_extraction import FetchInfoAndDisplay\nfrom .cleaning import GetYellowInnerEdge, ExtendShortLane\n\n\n# this is my lane_detection file\ndef detect_lanes(img):\n    \n    img_cropped = img[config.CropHeight_resized:,:]\n\n    mid_lane_mask, mid_lane_edge,outer_lane_edge, outerlane_side_sep,outerlane_points = segment_lanes(img_cropped,config.minArea_resized)\n\n    estimated_midlane = estimate_midlane(mid_lane_edge,config.MaxDist_resized)\n\n    OuterLane_OneSide, Outer_cnts_oneSide,Mid_cnts, Offset_correction  = GetYellowInnerEdge(outer_lane_edge, estimated_midlane, outerlane_points)\n\n    extended_midlane, extended_outerlane = ExtendShortLane(estimated_midlane,Mid_cnts,Outer_cnts_oneSide, OuterLane_OneSide)\n    \n    Distance , Curvature = FetchInfoAndDisplay(mid_lane_edge, extended_midlane, extended_outerlane, img_cropped, Offset_correction=Offset_correction)\n\n\n    \n\n    cv2.imshow(\"mid_lane_mask\", mid_lane_mask)\n    cv2.imshow(\"mid_lane_edge\", mid_lane_edge)\n    cv2.imshow(\"outer_lane_edge\", outer_lane_edge)\n    cv2.imshow(\"outerlane_side_sep\", outerlane_side_sep)\n    cv2.imshow(\"estimated_midlane\", estimated_midlane)\n\n    cv2.imshow(\"OuterLane_OneSide\", OuterLane_OneSide)\n    cv2.imshow(\"extended_midlane\", extended_midlane)\n    cv2.imshow(\"extended_outerlane\", extended_outerlane)\n\n    cv2.waitKey(1)\n\nand this is my func\ndef ExtendShortLane(MidLane,Mid_cnts,Outer_cnts,OuterLane):\n    if(Mid_cnts and Outer_cnts):\n        Mid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n        Outer_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n        Image_bottom = MidLane.shape[0]\n        total_no_of_cnts_midlane = Mid_cnts_Rowsorted.shape[0]\n        total_no_of_cnts_outerlane = Outer_cnts_Rowsorted.shape[0]\n\n\n        BottomPoint_Mid = Mid_cnts_Rowsorted[total_no_of_cnts_midlane-1,:]\n        if (BottomPoint_Mid[1] < Image_bottom):\n            MidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255,2)\n\n\n        BottomPoint_Outer = Outer_cnts_Rowsorted[total_no_of_cnts_outerlane-1,:]\n        if (BottomPoint_Outer[1] < Image_bottom):\n            if(total_no_of_cnts_outerlane>20):\n                shift=20\n            else:\n                shift=2\n            RefLast10Points = Outer_cnts_Rowsorted[total_no_of_cnts_outerlane-shift:total_no_of_cnts_outerlane] \n\n            if(len(RefLast10Points)>1):\n                Ref_x = RefLast10Points[:,0] #cols\n                Ref_y = RefLast10Points[:,1] #rows\n                Ref_parameters = np.polyfit(Ref_x, Ref_y,1)\n                Ref_slope = Ref_parameters[0]\n                Ref_yiCntercept = Ref_parameters[1]\n\n                if(Ref_slope < 0):\n                    Ref_LineTouchPoint_col = 0\n                    Ref_LineTouchPoint_row = Ref_yiCntercept\n                else:\n                    Ref_LineTouchPoint_col = OuterLane.shape[1]-1\n                    Ref_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n                Ref_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#col,row\n                Ref_BottomPoint_tup = tuple(BottomPoint_Outer)\n                OuterLane =cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n                 \n                if(Ref_LineTouchPoint_row < Image_bottom):\n                    Ref_TouchPoint_Ref = (Ref_LineTouchPoint_col, Image_bottom)     \n                    OuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255,2)      \n        return MidLane,OuterLane\n\nwhy it is return None\n\nlane assist. please help me"], "question_code": ["from .colour_segmentation import segment_lanes\nfrom ...config import config\nfrom .midlane_estimation import estimate_midlane\nimport cv2\nimport numpy as np\nfrom .data_extraction import FetchInfoAndDisplay\nfrom .cleaning import GetYellowInnerEdge, ExtendShortLane\n\n\n# this is my lane_detection file\ndef detect_lanes(img):\n    \n    img_cropped = img[config.CropHeight_resized:,:]\n\n    mid_lane_mask, mid_lane_edge,outer_lane_edge, outerlane_side_sep,outerlane_points = segment_lanes(img_cropped,config.minArea_resized)\n\n    estimated_midlane = estimate_midlane(mid_lane_edge,config.MaxDist_resized)\n\n    OuterLane_OneSide, Outer_cnts_oneSide,Mid_cnts, Offset_correction  = GetYellowInnerEdge(outer_lane_edge, estimated_midlane, outerlane_points)\n\n    extended_midlane, extended_outerlane = ExtendShortLane(estimated_midlane,Mid_cnts,Outer_cnts_oneSide, OuterLane_OneSide)\n    \n    Distance , Curvature = FetchInfoAndDisplay(mid_lane_edge, extended_midlane, extended_outerlane, img_cropped, Offset_correction=Offset_correction)\n\n\n    \n\n    cv2.imshow(&quot;mid_lane_mask&quot;, mid_lane_mask)\n    cv2.imshow(&quot;mid_lane_edge&quot;, mid_lane_edge)\n    cv2.imshow(&quot;outer_lane_edge&quot;, outer_lane_edge)\n    cv2.imshow(&quot;outerlane_side_sep&quot;, outerlane_side_sep)\n    cv2.imshow(&quot;estimated_midlane&quot;, estimated_midlane)\n\n    cv2.imshow(&quot;OuterLane_OneSide&quot;, OuterLane_OneSide)\n    cv2.imshow(&quot;extended_midlane&quot;, extended_midlane)\n    cv2.imshow(&quot;extended_outerlane&quot;, extended_outerlane)\n\n    cv2.waitKey(1)\n", "def ExtendShortLane(MidLane,Mid_cnts,Outer_cnts,OuterLane):\n    if(Mid_cnts and Outer_cnts):\n        Mid_cnts_Rowsorted = Cord_Sort(Mid_cnts,&quot;rows&quot;)\n        Outer_cnts_Rowsorted = Cord_Sort(Outer_cnts,&quot;rows&quot;)\n        Image_bottom = MidLane.shape[0]\n        total_no_of_cnts_midlane = Mid_cnts_Rowsorted.shape[0]\n        total_no_of_cnts_outerlane = Outer_cnts_Rowsorted.shape[0]\n\n\n        BottomPoint_Mid = Mid_cnts_Rowsorted[total_no_of_cnts_midlane-1,:]\n        if (BottomPoint_Mid[1] &lt; Image_bottom):\n            MidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255,2)\n\n\n        BottomPoint_Outer = Outer_cnts_Rowsorted[total_no_of_cnts_outerlane-1,:]\n        if (BottomPoint_Outer[1] &lt; Image_bottom):\n            if(total_no_of_cnts_outerlane&gt;20):\n                shift=20\n            else:\n                shift=2\n            RefLast10Points = Outer_cnts_Rowsorted[total_no_of_cnts_outerlane-shift:total_no_of_cnts_outerlane] \n\n            if(len(RefLast10Points)&gt;1):\n                Ref_x = RefLast10Points[:,0] #cols\n                Ref_y = RefLast10Points[:,1] #rows\n                Ref_parameters = np.polyfit(Ref_x, Ref_y,1)\n                Ref_slope = Ref_parameters[0]\n                Ref_yiCntercept = Ref_parameters[1]\n\n                if(Ref_slope &lt; 0):\n                    Ref_LineTouchPoint_col = 0\n                    Ref_LineTouchPoint_row = Ref_yiCntercept\n                else:\n                    Ref_LineTouchPoint_col = OuterLane.shape[1]-1\n                    Ref_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n                Ref_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#col,row\n                Ref_BottomPoint_tup = tuple(BottomPoint_Outer)\n                OuterLane =cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n                 \n                if(Ref_LineTouchPoint_row &lt; Image_bottom):\n                    Ref_TouchPoint_Ref = (Ref_LineTouchPoint_col, Image_bottom)     \n                    OuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255,2)      \n        return MidLane,OuterLane\n"], "quote": [], "url": "https://stackoverflow.com/questions/78746844/typeerror-cannot-unpack-non-iterable-nonetype-object-how-can-%c4%b1-solve-this-probl", "answer": ["Your function returns values only if the if(Mid_cnts and Outer_cnts): condition is satisfied. Otherwise it returns None\nI suspect you either forgot to write the else block for that condition, or the return instruction should be out of the if block"], "answer_code": ["if(Mid_cnts and Outer_cnts):", "None", "else", "return", "if"]},
{"title": "Displaying gazebo realsense image using ROS, depth image looks weird and having different size from the raw", "time": 1724135323, "post_content": ["Trying to display images captured by realsense in my gazebo simulation onto an opencv window. But the depth image is showing colorful despite rviz showing black and white. And the raw and depth image from the same cam have different size despite not resizing. I want the simulation to have the same output as the real scene realsense cam do. How can I fix it? Down below is my image displaying python codes and the launch file and the picture of the output images. Just in case here's the git:\n\nhttps://github.com/brian2lee/forklift_test/tree/main\n\nThe realsense d435 add-on used in gazebo:\n\nhttps://github.com/issaiass/realsense2_description\nhttps://github.com/issaiass/realsense_gazebo_plugin\n\nEdit: The colored depth map has been solved by @Christoph Rackwitz, updated the code, now showing normal depth map but the size problem remains.\nimages (from top left, 1.opencv raw 2. opencv depth 3. rviz depth):\n\nim_show.py:\n#!/usr/bin/env python3\nimport rospy\nimport cv2\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\n\nclass ImageConverter:\n\n    def __init__(self):\n        self.bridge = CvBridge()\n        self.image_sub = rospy.Subscriber(\"/camera/color/image_raw\", Image, self.callback)\n\n    def callback(self, data):\n        try:\n            # Convert the ROS Image message to a CV2 image\n            cv_image = self.bridge.imgmsg_to_cv2(data, \"bgr8\")\n        except CvBridgeError as e:\n            print(e)\n            return\n\n        # Display the image in an OpenCV window\n        cv2.imshow(\"Camera Image\", cv_image)\n        cv2.waitKey(3)\n\ndef main():\n    rospy.init_node('image_converter', anonymous=True)\n    ic = ImageConverter()\n\n    try:\n        rospy.spin()\n    except KeyboardInterrupt:\n        print(\"Shutting down\")\n    cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main()\n\nimg_show_depth.py:\n#!/usr/bin/env python3\nimport rospy\nimport cv2\nimport numpy as np\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\n\nclass DepthImageConverter:\n\n    def __init__(self):\n        self.bridge = CvBridge()\n        self.image_sub = rospy.Subscriber(\"/camera/depth/image_raw\", Image, self.callback)\n\n    def callback(self, data):\n        try:\n            # Convert the ROS Image message to a CV2 depth image\n            cv_image = self.bridge.imgmsg_to_cv2(data, desired_encoding=\"passthrough\")\n        except CvBridgeError as e:\n            print(e)\n            return\n\n        # Normalize the depth image to fall within 0-255 and convert it to uint8\n        cv_image_norm = cv2.normalize(cv_image, None, 0, 255, cv2.NORM_MINMAX)\n        depth_map = cv_image_norm.astype(np.uint8)\n\n        # Display the depth image in an OpenCV window\n        cv2.imshow(\"Depth Image\", depth_map)\n        cv2.waitKey(3)\n\ndef main():\n    rospy.init_node('depth_image_converter', anonymous=True)\n    dic = DepthImageConverter()\n\n    try:\n        rospy.spin()\n    except KeyboardInterrupt:\n        print(\"Shutting down\")\n    cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main()\n\ngazebo.launch:\n<?xml version=\"1.0\"?>\n<launch>\n\n    <param name=\"robot_description\" command=\"xacro '$(find forklift)/urdf/forklift.urdf.xacro'\"/>\n    <param name=\"pallet_obj\" command=\"xacro '$(find pallet)/urdf/pallet.urdf.xacro'\"/>\n    \n    <node name=\"robot_state_publisher\" pkg=\"robot_state_publisher\" type=\"robot_state_publisher\"/>\n    <node name=\"joint_state_publisher_gui\" pkg=\"joint_state_publisher_gui\" type=\"joint_state_publisher_gui\"/>\n\n    <include file=\"$(find gazebo_ros)/launch/empty_world.launch\">\n        <arg name=\"world_name\" value=\"$(find env_world)/world/test.world\"/>\n\n        <arg name=\"paused\" value=\"false\"/>\n        <arg name=\"use_sim_time\" value=\"true\"/>\n        <arg name=\"gui\" value=\"true\"/>\n        <arg name=\"headless\" value=\"false\"/>\n        <arg name=\"debug\" value=\"false\"/>\n        \n    </include>\n\n    <node name=\"spawning_forklift\" pkg=\"gazebo_ros\" type=\"spawn_model\" args=\"-urdf -model forklift -param robot_description -z 0.160253\"/> \n    <node name=\"spawning_pallet\" pkg=\"gazebo_ros\" type=\"spawn_model\" args=\"-urdf -model pallet -param pallet_obj -x 5 -z 0.001500  \"/> \n    \n    \n    <node name=\"rviz\" pkg=\"rviz\" type=\"rviz\" args=\"-d $(find forklift)/rviz/cam.rviz\" required=\"true\" />\n    <!--\n    <?  default rviz   ?>\n    <node name=\"rviz\" pkg=\"rviz\" type=\"rviz\" args=\"-d $(find realsense2_description)/rviz/urdf.rviz\" required=\"true\" />\n-->\n\n    <node name=\"img\" pkg=\"img\" type=\"img_show.py\" output=\"screen\" args=\"$(find img)/src/img_show.py\"/>\n    <node name=\"img_depth\" pkg=\"img\" type=\"img_show_depth.py\" output=\"screen\" args=\"$(find img)/src/img_show_depth.py\"/>\n    <!--\n    <node name=\"img_both\" pkg=\"img\" type=\"img_show_both.py\" output=\"screen\" args=\"$(find img)/src/img_show_both.py\"/>\n-->\n</launch>"], "question_code": ["im_show.py", "#!/usr/bin/env python3\nimport rospy\nimport cv2\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\n\nclass ImageConverter:\n\n    def __init__(self):\n        self.bridge = CvBridge()\n        self.image_sub = rospy.Subscriber(&quot;/camera/color/image_raw&quot;, Image, self.callback)\n\n    def callback(self, data):\n        try:\n            # Convert the ROS Image message to a CV2 image\n            cv_image = self.bridge.imgmsg_to_cv2(data, &quot;bgr8&quot;)\n        except CvBridgeError as e:\n            print(e)\n            return\n\n        # Display the image in an OpenCV window\n        cv2.imshow(&quot;Camera Image&quot;, cv_image)\n        cv2.waitKey(3)\n\ndef main():\n    rospy.init_node('image_converter', anonymous=True)\n    ic = ImageConverter()\n\n    try:\n        rospy.spin()\n    except KeyboardInterrupt:\n        print(&quot;Shutting down&quot;)\n    cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main()\n", "img_show_depth.py", "#!/usr/bin/env python3\nimport rospy\nimport cv2\nimport numpy as np\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\n\nclass DepthImageConverter:\n\n    def __init__(self):\n        self.bridge = CvBridge()\n        self.image_sub = rospy.Subscriber(&quot;/camera/depth/image_raw&quot;, Image, self.callback)\n\n    def callback(self, data):\n        try:\n            # Convert the ROS Image message to a CV2 depth image\n            cv_image = self.bridge.imgmsg_to_cv2(data, desired_encoding=&quot;passthrough&quot;)\n        except CvBridgeError as e:\n            print(e)\n            return\n\n        # Normalize the depth image to fall within 0-255 and convert it to uint8\n        cv_image_norm = cv2.normalize(cv_image, None, 0, 255, cv2.NORM_MINMAX)\n        depth_map = cv_image_norm.astype(np.uint8)\n\n        # Display the depth image in an OpenCV window\n        cv2.imshow(&quot;Depth Image&quot;, depth_map)\n        cv2.waitKey(3)\n\ndef main():\n    rospy.init_node('depth_image_converter', anonymous=True)\n    dic = DepthImageConverter()\n\n    try:\n        rospy.spin()\n    except KeyboardInterrupt:\n        print(&quot;Shutting down&quot;)\n    cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main()\n", "gazebo.launch", "&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;launch&gt;\n\n    &lt;param name=&quot;robot_description&quot; command=&quot;xacro '$(find forklift)/urdf/forklift.urdf.xacro'&quot;/&gt;\n    &lt;param name=&quot;pallet_obj&quot; command=&quot;xacro '$(find pallet)/urdf/pallet.urdf.xacro'&quot;/&gt;\n    \n    &lt;node name=&quot;robot_state_publisher&quot; pkg=&quot;robot_state_publisher&quot; type=&quot;robot_state_publisher&quot;/&gt;\n    &lt;node name=&quot;joint_state_publisher_gui&quot; pkg=&quot;joint_state_publisher_gui&quot; type=&quot;joint_state_publisher_gui&quot;/&gt;\n\n    &lt;include file=&quot;$(find gazebo_ros)/launch/empty_world.launch&quot;&gt;\n        &lt;arg name=&quot;world_name&quot; value=&quot;$(find env_world)/world/test.world&quot;/&gt;\n\n        &lt;arg name=&quot;paused&quot; value=&quot;false&quot;/&gt;\n        &lt;arg name=&quot;use_sim_time&quot; value=&quot;true&quot;/&gt;\n        &lt;arg name=&quot;gui&quot; value=&quot;true&quot;/&gt;\n        &lt;arg name=&quot;headless&quot; value=&quot;false&quot;/&gt;\n        &lt;arg name=&quot;debug&quot; value=&quot;false&quot;/&gt;\n        \n    &lt;/include&gt;\n\n    &lt;node name=&quot;spawning_forklift&quot; pkg=&quot;gazebo_ros&quot; type=&quot;spawn_model&quot; args=&quot;-urdf -model forklift -param robot_description -z 0.160253&quot;/&gt; \n    &lt;node name=&quot;spawning_pallet&quot; pkg=&quot;gazebo_ros&quot; type=&quot;spawn_model&quot; args=&quot;-urdf -model pallet -param pallet_obj -x 5 -z 0.001500  &quot;/&gt; \n    \n    \n    &lt;node name=&quot;rviz&quot; pkg=&quot;rviz&quot; type=&quot;rviz&quot; args=&quot;-d $(find forklift)/rviz/cam.rviz&quot; required=&quot;true&quot; /&gt;\n    &lt;!--\n    &lt;?  default rviz   ?&gt;\n    &lt;node name=&quot;rviz&quot; pkg=&quot;rviz&quot; type=&quot;rviz&quot; args=&quot;-d $(find realsense2_description)/rviz/urdf.rviz&quot; required=&quot;true&quot; /&gt;\n--&gt;\n\n    &lt;node name=&quot;img&quot; pkg=&quot;img&quot; type=&quot;img_show.py&quot; output=&quot;screen&quot; args=&quot;$(find img)/src/img_show.py&quot;/&gt;\n    &lt;node name=&quot;img_depth&quot; pkg=&quot;img&quot; type=&quot;img_show_depth.py&quot; output=&quot;screen&quot; args=&quot;$(find img)/src/img_show_depth.py&quot;/&gt;\n    &lt;!--\n    &lt;node name=&quot;img_both&quot; pkg=&quot;img&quot; type=&quot;img_show_both.py&quot; output=&quot;screen&quot; args=&quot;$(find img)/src/img_show_both.py&quot;/&gt;\n--&gt;\n&lt;/launch&gt;\n"], "quote": ["https://github.com/brian2lee/forklift_test/tree/main", "https://github.com/issaiass/realsense2_description\nhttps://github.com/issaiass/realsense_gazebo_plugin"], "url": "https://stackoverflow.com/questions/78890898/displaying-gazebo-realsense-image-using-ros-depth-image-looks-weird-and-having", "answer": ["The colorization happens because you call applyColorMap().\nYour code shows no resizing of the images, no setup to make the windows resizable, and no fixed sizes going into the creation of any images. From what you present so far, I cannot nobody can say what's going on there. You should look into your ROS and gazebo parts."], "answer_code": ["applyColorMap()"]},
{"title": "VSCode C++ Extension cannot locate \"physics::ModelPtr\" from gazebo library", "time": 1720643432, "post_content": ["I am trying to use VSCode to write ROS program. However, the C++ Extension seems to have trouble finding the physics::ModelPtr. Does anyone know how to fix this?\nHere is my code:\n#include <gazebo/gazebo.hh>\n#include <gazebo/physics/physics.hh>\n#include <ros/ros.h>\n#include <geometry_msgs/Pose.h>\n\nnamespace gazebo\n{\n  class camera_pose_control : public ModelPlugin\n  {\n    private: physics::ModelPtr model;\n    private: ros::NodeHandle nh;\n    private: ros::Subscriber poseSub;\n\n    public: void Load(physics::ModelPtr _model, sdf::ElementPtr _sdf)\n    {\n      std::cout << \"Loading Camera Pose Control Plugin\\n\" << std::endl;\n      this->model = _model;\n\n      // ROS Node and Subscriber\n      int argc = 0;\n      char **argv = NULL;\n      ros::init(argc, argv, \"gazebo_client\", ros::init_options::NoSigintHandler);\n      ROS_INFO(\"ROS node initialized within Gazebo Plugin\");\n      poseSub = nh.subscribe(\"camera/pose\", 10, &camera_pose_control::OnPoseReceived, this);\n    }\n\n    // Callback function to set the model pose\n    public: void OnPoseReceived(const geometry_msgs::PoseConstPtr &msg)\n    {\n      ignition::math::Pose3d newPose(msg->position.x, msg->position.y, msg->position.z,\n                                     msg->orientation.w, msg->orientation.x, msg->orientation.y, msg->orientation.z);\n      this->model->SetWorldPose(newPose);\n    }\n  };\n  GZ_REGISTER_MODEL_PLUGIN(camera_pose_control)\n}\n\nHere is my c_cpp_properties.json:\n{\n    \"configurations\": [\n        {\n            \"browse\": {\n                \"databaseFilename\": \"${default}\",\n                \"limitSymbolsToIncludedHeaders\": false\n            },\n            \"includePath\": [\n                \"/opt/ros/noetic/include/**\",\n                \"/root/ml_project_ws/src/ml_project/include/**\",\n                \"/usr/include/**\",\n                \"/usr/lib/x86_64-linux-gnu/gazebo-11/**\"\n            ],\n            \"name\": \"ROS\",\n            \"intelliSenseMode\": \"gcc-x64\",\n            \"compilerPath\": \"/usr/bin/gcc\",\n            \"cStandard\": \"gnu11\",\n            \"cppStandard\": \"c++14\"\n        }\n    ],\n    \"version\": 4\n}"], "question_code": ["physics::ModelPtr", "#include &lt;gazebo/gazebo.hh&gt;\n#include &lt;gazebo/physics/physics.hh&gt;\n#include &lt;ros/ros.h&gt;\n#include &lt;geometry_msgs/Pose.h&gt;\n\nnamespace gazebo\n{\n  class camera_pose_control : public ModelPlugin\n  {\n    private: physics::ModelPtr model;\n    private: ros::NodeHandle nh;\n    private: ros::Subscriber poseSub;\n\n    public: void Load(physics::ModelPtr _model, sdf::ElementPtr _sdf)\n    {\n      std::cout &lt;&lt; &quot;Loading Camera Pose Control Plugin\\n&quot; &lt;&lt; std::endl;\n      this-&gt;model = _model;\n\n      // ROS Node and Subscriber\n      int argc = 0;\n      char **argv = NULL;\n      ros::init(argc, argv, &quot;gazebo_client&quot;, ros::init_options::NoSigintHandler);\n      ROS_INFO(&quot;ROS node initialized within Gazebo Plugin&quot;);\n      poseSub = nh.subscribe(&quot;camera/pose&quot;, 10, &amp;camera_pose_control::OnPoseReceived, this);\n    }\n\n    // Callback function to set the model pose\n    public: void OnPoseReceived(const geometry_msgs::PoseConstPtr &amp;msg)\n    {\n      ignition::math::Pose3d newPose(msg-&gt;position.x, msg-&gt;position.y, msg-&gt;position.z,\n                                     msg-&gt;orientation.w, msg-&gt;orientation.x, msg-&gt;orientation.y, msg-&gt;orientation.z);\n      this-&gt;model-&gt;SetWorldPose(newPose);\n    }\n  };\n  GZ_REGISTER_MODEL_PLUGIN(camera_pose_control)\n}\n", "{\n    &quot;configurations&quot;: [\n        {\n            &quot;browse&quot;: {\n                &quot;databaseFilename&quot;: &quot;${default}&quot;,\n                &quot;limitSymbolsToIncludedHeaders&quot;: false\n            },\n            &quot;includePath&quot;: [\n                &quot;/opt/ros/noetic/include/**&quot;,\n                &quot;/root/ml_project_ws/src/ml_project/include/**&quot;,\n                &quot;/usr/include/**&quot;,\n                &quot;/usr/lib/x86_64-linux-gnu/gazebo-11/**&quot;\n            ],\n            &quot;name&quot;: &quot;ROS&quot;,\n            &quot;intelliSenseMode&quot;: &quot;gcc-x64&quot;,\n            &quot;compilerPath&quot;: &quot;/usr/bin/gcc&quot;,\n            &quot;cStandard&quot;: &quot;gnu11&quot;,\n            &quot;cppStandard&quot;: &quot;c++14&quot;\n        }\n    ],\n    &quot;version&quot;: 4\n}\n"], "quote": [], "url": "https://stackoverflow.com/questions/78732620/vscode-c-extension-cannot-locate-physicsmodelptr-from-gazebo-library", "answer": ["I've had the same problem and has been rather frustrating but I've managed to fix it on my machine. Hopefully this will work for others.\nGo to your C++ Configurations and change the C++ standard to at least C++17. After changing this, intellisense started working and I could locate all files.\nTLDR Change C++ standard to C++17"], "answer_code": []},
{"title": "ROS1 slam_toolbox map has lots of ghosted walls", "time": 1723162138, "post_content": ["I am using slam_toolbox on ROS1 noetic with a ydlidar. I've tried running slam_toolbox on the robot itself as well as on the remote computer. I am using the asynch online scenario.\nIt is working but there's something weird about the map being created.\n\nIt is relatively correct but you can see in many places where a wall is doubled, and that corresponds often to a situation where I rotated the robot during mapping.\n\nAny immediate idea on what's going on?\nIs there any specific guideline about how fast to move the robot during mapping, avoiding going over a specific spot again, etc?\nIs this expected and should I try offline?"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/78850789/ros1-slam-toolbox-map-has-lots-of-ghosted-walls", "answer": ["Any sort of movement based distortion will come down to a few factors. Here, this can be due to how the lidar is actually mounted. Movement/sway in the physical device can cause odd looking maps when all transforms assume static offsets; and this can be made worse the higher the sample rate.\nFor \"double walls\" where they have the same orientation but are offset, this indicates a problem with your frame transforms. For example, if you're not producing odometry quick enough your pointcloud will be transformed off an incorrect RPY. In a proper system rotation speed is irrelevant (so long as it's not much greater than your sample rate).\nIt's hard to say without seeing code (and the room you're trying to map), but I would be pretty confident in saying 1) your transforms are wrong (maybe not updating quick enough) and 2) you're probably not doing enough z-plane filtering on the PointCloud2 msg (hence you might be seeing the floor)."], "answer_code": ["PointCloud2"]},
{"title": "Create Custom microROS Messages in PlatformIO", "time": 1724142318, "post_content": ["I am trying to create a ROS service on my NodeMCU Esp32S. Therefore I am using the micro_ros_platformio library.\nAfter including everything into PlatformIO (as shown in the libraries readme), I was able to successfully run my first programs.\nBecause the message for the service I want to offer does not exist in the standard messages in the way I need it, I had to create a custom service message.\n\nSince I then had to create a custom service message for my application, I created a new workspace custom_interfaces_ws with a new ROS2 package custom_message, containing both a msgand a srv folder and build them like you usually would build ROS2 messages.\nAfter creating the messages, I referenced them in my platformio.ini:\n[env:nodemcu-32s]\nplatform = espressif32\nboard = nodemcu-32s\nframework = arduino\nboard_microros_distro = humble\nboard_microros_transport = wifi\nlib_deps = \n    https://github.com/micro-ROS/micro_ros_platformio\n\nextra_scripts = \n    pre:read_config.py\n\nmonitor_speed = 115200\n\nbuild_flags = \n    -I/home/nash/dev/ros_custom_interfaces_ws/install/custom_messages/include\n    -I/home/nash/dev/ros_custom_interfaces_ws/install/custom_messages/include/custom_messages\n    -L/home/nash/dev/ros_custom_interfaces_ws/install/custom_messages/lib\n    -lcustom_messages__rosidl_typesupport_c\n    -lcustom_messages__rosidl_typesupport_introspection_c\n\nRunning this led me to the problem, that the file format of my .so files was not recognized\nand returned the following error:\n\n/home/nash/dev/ros_custom_interfaces_ws/install/custom_messages/lib/libcustom_messages__rosidl_typesupport_c.so: file not recognized: file format not recognized\ncollect2: error: ld returned 1 exit status\n*** [.pio/build/nodemcu-32s/firmware.elf] Error 1\n\n(which was somehow expectable, since I was just building the messages on my machine)\n\nSince my first approach failed, I tried to stick to the micro ros tutorial on how to include custom messages.\nI created a new firmware with the ros2 run micro_ros_setup create_firmware_ws.sh freertos esp32 command, created a new package with my custom messages in the firmware/mcu_ws folder and configured the firmware by running ros2 run micro_ros_setup configure_firmware.sh ping_pong --transport serial.\nThe reason why I ran the configuration step with the ping pong app is, because you can't build the firmware in the next step, without running the configuration step before. But because I didn't create a custom application (since I am running everything over PlatformIO, but need the libraries to be build for the esp32 platform), I was hoping to build the firmware with my custom messages in it and afterwards reference the built messages PlatformIO, like I did in my first approach. This also didn't work out.\n\nIs it even possible to create custom messages solely with the PlatformIO build tools or to create custom messages for microROS, using the micro_ros_platformio library?"], "question_code": ["custom_interfaces_ws", "custom_message", "msg", "srv", "[env:nodemcu-32s]\nplatform = espressif32\nboard = nodemcu-32s\nframework = arduino\nboard_microros_distro = humble\nboard_microros_transport = wifi\nlib_deps = \n    https://github.com/micro-ROS/micro_ros_platformio\n\nextra_scripts = \n    pre:read_config.py\n\nmonitor_speed = 115200\n\nbuild_flags = \n    -I/home/nash/dev/ros_custom_interfaces_ws/install/custom_messages/include\n    -I/home/nash/dev/ros_custom_interfaces_ws/install/custom_messages/include/custom_messages\n    -L/home/nash/dev/ros_custom_interfaces_ws/install/custom_messages/lib\n    -lcustom_messages__rosidl_typesupport_c\n    -lcustom_messages__rosidl_typesupport_introspection_c\n", "\n/home/nash/dev/ros_custom_interfaces_ws/install/custom_messages/lib/libcustom_messages__rosidl_typesupport_c.so: file not recognized: file format not recognized\ncollect2: error: ld returned 1 exit status\n*** [.pio/build/nodemcu-32s/firmware.elf] Error 1\n", "ros2 run micro_ros_setup create_firmware_ws.sh freertos esp32", "ros2 run micro_ros_setup configure_firmware.sh ping_pong --transport serial"], "quote": [], "url": "https://stackoverflow.com/questions/78891355/create-custom-microros-messages-in-platformio", "answer": ["You can create a directory named extra_packages on the main tree of your platformio code. Then on that directory, add the 'custom_message' folder that also resides on the custom_interfaces_ws directory. Delete the .pio directory and then build your project. Then you should be able to use your custom msg and srv files from your code. https://github.com/micro-ROS/micro_ros_arduino/blob/jazzy/examples/micro-ros_addtwoints_service/micro-ros_addtwoints_service.ino shows how to run a custom service from microROS using Arduino framework"], "answer_code": ["extra_packages", "custom_interfaces_ws", ".pio"]},
{"title": "Encountering issues when trying to run .launch file with ROS 2 Humble", "time": 1713866097, "post_content": ["My launch file is the following:\n`\n\n\n<!-- Load the URDF model into Gazebo -->\n<param name=\"robot_description\" textfile=\"$(find mower_sim)/urdf/mower.urdf\"/>\n\n<!-- Spawn the URDF model in Gazebo -->\n<node name=\"spawn_urdf\" pkg=\"gazebo_ros\" executable=\"spawn_entity.py\" output=\"screen\"\n    args=\"-entity mower -file $(arg robot_description) -x 0 -y 0 -z 0\"/>\n\n<!-- Start your BCD node -->\n<node name=\"bcd_node\" pkg=\"mower_sim\" executable=\"bcd_node\" output=\"screen\"/>\n\n`\nand the .urdf file is:\n\n[INFO] [launch]: All log files can be found below /home/name/.ros/log/2024-04-22-15-13-04-182156-name-Compaq-CQ58-Notebook-PC-8898\n[INFO] [launch]: Default logging verbosity is set to INFO\n[ERROR] [launch]: Caught exception in launch (see debug for traceback): Caught exception when trying to load file of format [launch]: Attribute exec of type <class 'str'> not found in Entity node\n\nWhen I try to run the launch file, I get the above error.\nI tried removing/adding the .py from bcd_node but it didn't seem to make a difference. I am thinking it may be something with my URDF file. I also made sure that gazebo_ros is installed on my machine."], "question_code": ["&lt;!-- Load the URDF model into Gazebo --&gt;\n&lt;param name=&quot;robot_description&quot; textfile=&quot;$(find mower_sim)/urdf/mower.urdf&quot;/&gt;\n\n&lt;!-- Spawn the URDF model in Gazebo --&gt;\n&lt;node name=&quot;spawn_urdf&quot; pkg=&quot;gazebo_ros&quot; executable=&quot;spawn_entity.py&quot; output=&quot;screen&quot;\n    args=&quot;-entity mower -file $(arg robot_description) -x 0 -y 0 -z 0&quot;/&gt;\n\n&lt;!-- Start your BCD node --&gt;\n&lt;node name=&quot;bcd_node&quot; pkg=&quot;mower_sim&quot; executable=&quot;bcd_node&quot; output=&quot;screen&quot;/&gt;\n"], "quote": ["[INFO] [launch]: All log files can be found below /home/name/.ros/log/2024-04-22-15-13-04-182156-name-Compaq-CQ58-Notebook-PC-8898\n[INFO] [launch]: Default logging verbosity is set to INFO\n[ERROR] [launch]: Caught exception in launch (see debug for traceback): Caught exception when trying to load file of format [launch]: Attribute exec of type <class 'str'> not found in Entity node"], "url": "https://stackoverflow.com/questions/78371421/encountering-issues-when-trying-to-run-launch-file-with-ros-2-humble", "answer": ["The error you are encountering is quite clear:\nYou \"node\" statement in your xml misses the \"exec\" field. This is probably the result of your launch file being previously used in ROS1. ROS2 requires this, see e.g. from the official tutorials on launch:\n<launch> <node pkg=\"demo_nodes_cpp\" exec=\"talker\" name=\"talker\"/> </launch>"], "answer_code": ["&lt;launch&gt; &lt;node pkg=&quot;demo_nodes_cpp&quot; exec=&quot;talker&quot; name=&quot;talker&quot;/&gt; &lt;/launch&gt;"]},
{"title": "Connect DJI Ryze Tello drone to WSL through ROS", "time": 1715007270, "post_content": ["I am a beginner programmer in Python and I am currently carrying a project that involves connecting a Tello drone to WSL (Ubuntu 22.04), using ROS2 (Humble distro).\nI am using the DJItelloPy library, and here is my test code.\nimport logging\nfrom djitellopy import Tello\nTello.LOGGER.setLevel(logging.DEBUG)\n\ntello = Tello()\ntello.connect()\nprint(tello.get_battery())\n\nI connected to the drone's wifi, no Windows firewall enabled, I ran the code in WSL, but I get an error:\nFile \"/home/maeri_n/.local/lib/python3.10/site-packages/djitellopy/tello.py\", line 533, in connect\n    raise Exception('Did not receive a state packet from the Tello')\nException: Did not receive a state packet from the Tello\n\nI even forwarded the required ports (8889, 8890, 11111) to WSL, but same error. I do not know if there could be some other problem blocking the connection.\nMoreover, the drone perfectly connects to Windows, since this code to display the drone's video frames works perfectly in Windows (I use VSCode):\nimport logging\nfrom djitellopy import tello, Tello\nimport cv2\nTello.LOGGER.setLevel(logging.DEBUG)\n\ndef video_tello(drone):\n    while True:\n        frame = drone.get_frame_read().frame\n        cv2.imshow(\"Frame\",frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    cv2.destroyAllWindows()\n    drone.end()\n\ndef main():\n    drone = tello.Tello()\n\n    drone.connect()\n\n    drone.streamon()\n\n    video_tello(drone)\n\nmain()\n\nI am eagerly waiting for feedbacks."], "question_code": ["import logging\nfrom djitellopy import Tello\nTello.LOGGER.setLevel(logging.DEBUG)\n\ntello = Tello()\ntello.connect()\nprint(tello.get_battery())\n", "File &quot;/home/maeri_n/.local/lib/python3.10/site-packages/djitellopy/tello.py&quot;, line 533, in connect\n    raise Exception('Did not receive a state packet from the Tello')\nException: Did not receive a state packet from the Tello\n", "import logging\nfrom djitellopy import tello, Tello\nimport cv2\nTello.LOGGER.setLevel(logging.DEBUG)\n\ndef video_tello(drone):\n    while True:\n        frame = drone.get_frame_read().frame\n        cv2.imshow(&quot;Frame&quot;,frame)\n        if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n            break\n    cv2.destroyAllWindows()\n    drone.end()\n\ndef main():\n    drone = tello.Tello()\n\n    drone.connect()\n\n    drone.streamon()\n\n    video_tello(drone)\n\nmain()\n"], "quote": [], "url": "https://stackoverflow.com/questions/78437449/connect-dji-ryze-tello-drone-to-wsl-through-ros", "answer": ["I had the exact problem with you, and I also tried forwarding ports with\nnetsh interface portproxy add v4tov4 listenport=8890 listenaddress=0.0.0.0 connectport=8890 connectaddress=<WSL_IP_Address>\n\nBut it seems to only forward tcp port. So I tried setting networkingMode=mirrored in .wslconfig and it worked!\nHere is the  document\nI think it sets the ip of wsl to be the same as windows in some way, so there is no more port forwarding issue."], "answer_code": ["netsh interface portproxy add v4tov4 listenport=8890 listenaddress=0.0.0.0 connectport=8890 connectaddress=&lt;WSL_IP_Address&gt;\n", "networkingMode=mirrored"]},
{"title": "Unable to execute specific package with rosrun", "time": 1715540968, "post_content": ["I'm a beginner who has just started learning ROS. Currently, I'm following tutorials on creating Publishers in ROS. However, it mentions that packages can be executed with rosrun, but the problem is that whenever I try to run it, it gives an error saying:\n\ncouldn't find executable named.\n\nI have tried using chmod +x and chmod 777 methods, and I have also set up the environment path correctly, but the problem still persists.\nrobot_sys\n\u251c\u2500\u2500 build\n\u2502   \u251c\u2500\u2500 atomic_configure\n\u2502   \u2502   \u251c\u2500\u2500 env.sh\n\u2502   \u2502   \u251c\u2500\u2500 local_setup.bash\n\u2502   \u2502   \u251c\u2500\u2500 local_setup.sh\n\u2502   \u2502   \u251c\u2500\u2500 local_setup.zsh\n\u2502   \u2502   \u251c\u2500\u2500 setup.bash\n\u2502   \u2502   \u251c\u2500\u2500 setup.sh\n\u2502   \u2502   \u251c\u2500\u2500 _setup_util.py\n\u2502   \u2502   \u2514\u2500\u2500 setup.zsh\n\u2502   \u251c\u2500\u2500 bin\n\u2502   \u251c\u2500\u2500 catkin\n\u2502   \u2502   \u2514\u2500\u2500 catkin_generated\n\u2502   \u2502       \u2514\u2500\u2500 version\n\u2502   \u2502           \u2514\u2500\u2500 package.cmake\n\u2502   \u251c\u2500\u2500 catkin_generated\n\u2502   \u2502   \u251c\u2500\u2500 env_cached.sh\n\u2502   \u2502   \u251c\u2500\u2500 generate_cached_setup.py\n\u2502   \u2502   \u251c\u2500\u2500 installspace\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 env.sh\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_setup.bash\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_setup.sh\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_setup.zsh\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 setup.bash\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 setup.sh\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 _setup_util.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 setup.zsh\n\u2502   \u2502   \u251c\u2500\u2500 order_packages.cmake\n\u2502   \u2502   \u251c\u2500\u2500 order_packages.py\n\u2502   \u2502   \u251c\u2500\u2500 setup_cached.sh\n\u2502   \u2502   \u2514\u2500\u2500 stamps\n\u2502   \u2502       \u2514\u2500\u2500 Project\n\u2502   \u2502           \u251c\u2500\u2500 interrogate_setup_dot_py.py.stamp\n\u2502   \u2502           \u251c\u2500\u2500 order_packages.cmake.em.stamp\n\u2502   \u2502           \u251c\u2500\u2500 package.xml.stamp\n\u2502   \u2502           \u2514\u2500\u2500 _setup_util.py.stamp\n\u2502   \u251c\u2500\u2500 CATKIN_IGNORE\n\u2502   \u251c\u2500\u2500 catkin_make.cache\n\u2502   \u251c\u2500\u2500 CMakeCache.txt\n\u2502   \u251c\u2500\u2500 CMakeFiles\n\u2502   \u2502   \u251c\u2500\u2500 3.16.3\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeCCompiler.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeCXXCompiler.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDetermineCompilerABI_C.bin\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDetermineCompilerABI_CXX.bin\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeSystem.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CompilerIdC\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 a.out\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeCCompilerId.c\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 tmp\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 CompilerIdCXX\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 a.out\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 CMakeCXXCompilerId.cpp\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 tmp\n\u2502   \u2502   \u251c\u2500\u2500 clean_test_results.dir\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.make\n\u2502   \u2502   \u251c\u2500\u2500 cmake.check_cache\n\u2502   \u2502   \u251c\u2500\u2500 CMakeDirectoryInformation.cmake\n\u2502   \u2502   \u251c\u2500\u2500 CMakeError.log\n\u2502   \u2502   \u251c\u2500\u2500 CMakeOutput.log\n\u2502   \u2502   \u251c\u2500\u2500 CMakeRuleHashes.txt\n\u2502   \u2502   \u251c\u2500\u2500 CMakeTmp\n\u2502   \u2502   \u251c\u2500\u2500 download_extra_data.dir\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.make\n\u2502   \u2502   \u251c\u2500\u2500 doxygen.dir\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.make\n\u2502   \u2502   \u251c\u2500\u2500 Makefile2\n\u2502   \u2502   \u251c\u2500\u2500 Makefile.cmake\n\u2502   \u2502   \u251c\u2500\u2500 progress.marks\n\u2502   \u2502   \u251c\u2500\u2500 run_tests.dir\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.make\n\u2502   \u2502   \u251c\u2500\u2500 TargetDirectories.txt\n\u2502   \u2502   \u2514\u2500\u2500 tests.dir\n\u2502   \u2502       \u251c\u2500\u2500 build.make\n\u2502   \u2502       \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502       \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502       \u2514\u2500\u2500 progress.make\n\u2502   \u251c\u2500\u2500 cmake_install.cmake\n\u2502   \u251c\u2500\u2500 CTestConfiguration.ini\n\u2502   \u251c\u2500\u2500 CTestCustom.cmake\n\u2502   \u251c\u2500\u2500 CTestTestfile.cmake\n\u2502   \u251c\u2500\u2500 gtest\n\u2502   \u2502   \u251c\u2500\u2500 CMakeFiles\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDirectoryInformation.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.marks\n\u2502   \u2502   \u251c\u2500\u2500 cmake_install.cmake\n\u2502   \u2502   \u251c\u2500\u2500 CTestTestfile.cmake\n\u2502   \u2502   \u251c\u2500\u2500 googlemock\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeFiles\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDirectoryInformation.cmake\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gmock.dir\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 depend.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 flags.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 link.txt\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 progress.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 src\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gmock_main.dir\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 depend.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 flags.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 link.txt\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 progress.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 src\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.marks\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_install.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CTestTestfile.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 Makefile\n\u2502   \u2502   \u251c\u2500\u2500 googletest\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeFiles\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDirectoryInformation.cmake\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gtest.dir\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 depend.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 flags.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 link.txt\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 progress.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 src\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gtest_main.dir\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 depend.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 flags.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 link.txt\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 progress.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 src\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.marks\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_install.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CTestTestfile.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 Makefile\n\u2502   \u2502   \u251c\u2500\u2500 lib\n\u2502   \u2502   \u2514\u2500\u2500 Makefile\n\u2502   \u251c\u2500\u2500 Makefile\n\u2502   \u251c\u2500\u2500 ros_test\n\u2502   \u2502   \u251c\u2500\u2500 catkin_generated\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 installspace\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ros_testConfig.cmake\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ros_testConfig-version.cmake\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ros_test.pc\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ordered_paths.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 package.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pkg.develspace.context.pc.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pkg.installspace.context.pc.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 stamps\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 ros_test\n\u2502   \u2502   \u2502           \u251c\u2500\u2500 package.xml.stamp\n\u2502   \u2502   \u2502           \u2514\u2500\u2500 pkg.pc.em.stamp\n\u2502   \u2502   \u2514\u2500\u2500 CMakeFiles\n\u2502   \u2514\u2500\u2500 test_results\n\u251c\u2500\u2500 devel\n\u2502   \u251c\u2500\u2500 cmake.lock\n\u2502   \u251c\u2500\u2500 env.sh\n\u2502   \u251c\u2500\u2500 lib\n\u2502   \u2502   \u2514\u2500\u2500 pkgconfig\n\u2502   \u2502       \u2514\u2500\u2500 ros_test.pc\n\u2502   \u251c\u2500\u2500 local_setup.bash\n\u2502   \u251c\u2500\u2500 local_setup.sh\n\u2502   \u251c\u2500\u2500 local_setup.zsh\n\u2502   \u251c\u2500\u2500 setup.bash\n\u2502   \u251c\u2500\u2500 setup.sh\n\u2502   \u251c\u2500\u2500 _setup_util.py\n\u2502   \u251c\u2500\u2500 setup.zsh\n\u2502   \u2514\u2500\u2500 share\n\u2502       \u2514\u2500\u2500 ros_test\n\u2502           \u2514\u2500\u2500 cmake\n\u2502               \u251c\u2500\u2500 ros_testConfig.cmake\n\u2502               \u2514\u2500\u2500 ros_testConfig-version.cmake\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 CMakeLists.txt -> /opt/ros/noetic/share/catkin/cmake/toplevel.cmake\n    \u2514\u2500\u2500 ros_test\n        \u251c\u2500\u2500 CMakeLists.txt\n        \u251c\u2500\u2500 include\n        \u2502   \u2514\u2500\u2500 ros_test\n        \u251c\u2500\u2500 package.xml\n        \u2514\u2500\u2500 src\n            \u2514\u2500\u2500 talker.py\n\nThe above is my file hierarchy.\ncmake_minimum_required(VERSION 3.0.2)\nproject(ros_test)\n\n## Compile as C++11, supported in ROS Kinetic and newer\n# add_compile_options(-std=c++11)\n\n## Find catkin macros and libraries\n## if COMPONENTS list like find_package(catkin REQUIRED COMPONENTS xyz)\n## is used, also find other catkin packages\nfind_package(catkin REQUIRED COMPONENTS\n  roscpp\n  rospy\n  std_msgs\n)\n\n## System dependencies are found with CMake's conventions\n# find_package(Boost REQUIRED COMPONENTS system)\n\n\n## Uncomment this if the package has a setup.py. This macro ensures\n## modules and global scripts declared therein get installed\n## See http://ros.org/doc/api/catkin/html/user_guide/setup_dot_py.html\n# catkin_python_setup()\n\n################################################\n## Declare ROS messages, services and actions ##\n################################################\n\n## To declare and build messages, services or actions from within this\n## package, follow these steps:\n## * Let MSG_DEP_SET be the set of packages whose message types you use in\n##   your messages/services/actions (e.g. std_msgs, actionlib_msgs, ...).\n## * In the file package.xml:\n##   * add a build_depend tag for \"message_generation\"\n##   * add a build_depend and a exec_depend tag for each package in MSG_DEP_SET\n##   * If MSG_DEP_SET isn't empty the following dependency has been pulled in\n##     but can be declared for certainty nonetheless:\n##     * add a exec_depend tag for \"message_runtime\"\n## * In this file (CMakeLists.txt):\n##   * add \"message_generation\" and every package in MSG_DEP_SET to\n##     find_package(catkin REQUIRED COMPONENTS ...)\n##   * add \"message_runtime\" and every package in MSG_DEP_SET to\n##     catkin_package(CATKIN_DEPENDS ...)\n##   * uncomment the add_*_files sections below as needed\n##     and list every .msg/.srv/.action file to be processed\n##   * uncomment the generate_messages entry below\n##   * add every package in MSG_DEP_SET to generate_messages(DEPENDENCIES ...)\n\n## Generate messages in the 'msg' folder\n# add_message_files(\n#   FILES\n#   Message1.msg\n#   Message2.msg\n# )\n\n## Generate services in the 'srv' folder\n# add_service_files(\n#   FILES\n#   Service1.srv\n#   Service2.srv\n# )\n\n## Generate actions in the 'action' folder\n# add_action_files(\n#   FILES\n#   Action1.action\n#   Action2.action\n# )\n\n## Generate added messages and services with any dependencies listed here\n# generate_messages(\n#   DEPENDENCIES\n#   std_msgs\n# )\n\n################################################\n## Declare ROS dynamic reconfigure parameters ##\n################################################\n\n## To declare and build dynamic reconfigure parameters within this\n## package, follow these steps:\n## * In the file package.xml:\n##   * add a build_depend and a exec_depend tag for \"dynamic_reconfigure\"\n## * In this file (CMakeLists.txt):\n##   * add \"dynamic_reconfigure\" to\n##     find_package(catkin REQUIRED COMPONENTS ...)\n##   * uncomment the \"generate_dynamic_reconfigure_options\" section below\n##     and list every .cfg file to be processed\n\n## Generate dynamic reconfigure parameters in the 'cfg' folder\n# generate_dynamic_reconfigure_options(\n#   cfg/DynReconf1.cfg\n#   cfg/DynReconf2.cfg\n# )\n\n###################################\n## catkin specific configuration ##\n###################################\n## The catkin_package macro generates cmake config files for your package\n## Declare things to be passed to dependent projects\n## INCLUDE_DIRS: uncomment this if your package contains header files\n## LIBRARIES: libraries you create in this project that dependent projects also need\n## CATKIN_DEPENDS: catkin_packages dependent projects also need\n## DEPENDS: system dependencies of this project that dependent projects also need\ncatkin_package(\n  INCLUDE_DIRS include\n  LIBRARIES ros_test\n  CATKIN_DEPENDS roscpp rospy std_msgs\n  DEPENDS system_lib\n)\n\n###########\n## Build ##\n###########\n\n## Specify additional locations of header files\n## Your package locations should be listed before other locations\ninclude_directories(\n# include\n  ${catkin_INCLUDE_DIRS}\n)\n\n## Declare a C++ library\nadd_library(${PROJECT_NAME}\n   src/${PROJECT_NAME}/ros_test.cpp\n)\n\n## Add cmake target dependencies of the library\n## as an example, code may need to be generated before libraries\n## either from message generation or dynamic reconfigure\n# add_dependencies(${PROJECT_NAME} ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\n\n## Declare a C++ executable\n## With catkin_make all packages are built within a single CMake context\n## The recommended prefix ensures that target names across packages don't collide\nadd_executable(${PROJECT_NAME}_node src/ros_test_node.cpp)\n\n## Rename C++ executable without prefix\n## The above recommended prefix causes long target names, the following renames the\n## target back to the shorter version for ease of user use\n## e.g. \"rosrun someones_pkg node\" instead of \"rosrun someones_pkg someones_pkg_node\"\n# set_target_properties(${PROJECT_NAME}_node PROPERTIES OUTPUT_NAME node PREFIX \"\")\n\n## Add cmake target dependencies of the executable\n## same as for the library above\n# add_dependencies(${PROJECT_NAME}_node ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\n\n## Specify libraries to link a library or executable target against\ntarget_link_libraries(${PROJECT_NAME}_node\n#   ${catkin_LIBRARIES}\n)\n\n#############\n## Install ##\n#############\n\n# all install targets should use catkin DESTINATION variables\n# See http://ros.org/doc/api/catkin/html/adv_user_guide/variables.html\n\n## Mark executable scripts (Python etc.) for installation\n## in contrast to setup.py, you can choose the destination\n# catkin_install_python(PROGRAMS\n#   scripts/my_python_script\n#   DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n# )\n\n## Mark executables for installation\n## See http://docs.ros.org/melodic/api/catkin/html/howto/format1/building_executables.html\n# install(TARGETS ${PROJECT_NAME}_node\n#   RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n# )\n\n## Mark libraries for installation\n## See http://docs.ros.org/melodic/api/catkin/html/howto/format1/building_libraries.html\n# install(TARGETS ${PROJECT_NAME}\n#   ARCHIVE DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#   LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#   RUNTIME DESTINATION ${CATKIN_GLOBAL_BIN_DESTINATION}\n# )\n\n## Mark cpp header files for installation\n# install(DIRECTORY include/${PROJECT_NAME}/\n#   DESTINATION ${CATKIN_PACKAGE_INCLUDE_DESTINATION}\n#   FILES_MATCHING PATTERN \"*.h\"\n#   PATTERN \".svn\" EXCLUDE\n# )\n\n## Mark other files for installation (e.g. launch and bag files, etc.)\n# install(FILES\n#   # myfile1\n#   # myfile2\n#   DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}\n# )\n\n#############\n## Testing ##\n#############\n\n## Add gtest based cpp test target and link libraries\n# catkin_add_gtest(${PROJECT_NAME}-test test/test_ros_test.cpp)\n# if(TARGET ${PROJECT_NAME}-test)\n#   target_link_libraries(${PROJECT_NAME}-test ${PROJECT_NAME})\n# endif()\n\n## Add folders to be run by python nosetests\n# catkin_add_nosetests(test) \n\nThe second file I sent is my CMakeLists.txt.\nI've tried adjusting the contents of the CMakeLists file and found that the add_library part seems to be different from the node I want to execute. As you can see in the file hierarchy, within the ros_test directory, there is a src folder, and inside it, talker.py is the file I want to run with rosrun. I've tried adjusting it, but I'm not sure exactly how to change it.If you know the solution, I would greatly appreciate your guidance. Thank you very much.\nHere is the software section I'm using.\n\n\n\nSoftware\nVersion\n\n\n\n\nubuntu\n20.04\n\n\nros\nnoetic\n\n\npython compiler\nvscode"], "question_code": ["robot_sys\n\u251c\u2500\u2500 build\n\u2502   \u251c\u2500\u2500 atomic_configure\n\u2502   \u2502   \u251c\u2500\u2500 env.sh\n\u2502   \u2502   \u251c\u2500\u2500 local_setup.bash\n\u2502   \u2502   \u251c\u2500\u2500 local_setup.sh\n\u2502   \u2502   \u251c\u2500\u2500 local_setup.zsh\n\u2502   \u2502   \u251c\u2500\u2500 setup.bash\n\u2502   \u2502   \u251c\u2500\u2500 setup.sh\n\u2502   \u2502   \u251c\u2500\u2500 _setup_util.py\n\u2502   \u2502   \u2514\u2500\u2500 setup.zsh\n\u2502   \u251c\u2500\u2500 bin\n\u2502   \u251c\u2500\u2500 catkin\n\u2502   \u2502   \u2514\u2500\u2500 catkin_generated\n\u2502   \u2502       \u2514\u2500\u2500 version\n\u2502   \u2502           \u2514\u2500\u2500 package.cmake\n\u2502   \u251c\u2500\u2500 catkin_generated\n\u2502   \u2502   \u251c\u2500\u2500 env_cached.sh\n\u2502   \u2502   \u251c\u2500\u2500 generate_cached_setup.py\n\u2502   \u2502   \u251c\u2500\u2500 installspace\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 env.sh\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_setup.bash\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_setup.sh\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_setup.zsh\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 setup.bash\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 setup.sh\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 _setup_util.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 setup.zsh\n\u2502   \u2502   \u251c\u2500\u2500 order_packages.cmake\n\u2502   \u2502   \u251c\u2500\u2500 order_packages.py\n\u2502   \u2502   \u251c\u2500\u2500 setup_cached.sh\n\u2502   \u2502   \u2514\u2500\u2500 stamps\n\u2502   \u2502       \u2514\u2500\u2500 Project\n\u2502   \u2502           \u251c\u2500\u2500 interrogate_setup_dot_py.py.stamp\n\u2502   \u2502           \u251c\u2500\u2500 order_packages.cmake.em.stamp\n\u2502   \u2502           \u251c\u2500\u2500 package.xml.stamp\n\u2502   \u2502           \u2514\u2500\u2500 _setup_util.py.stamp\n\u2502   \u251c\u2500\u2500 CATKIN_IGNORE\n\u2502   \u251c\u2500\u2500 catkin_make.cache\n\u2502   \u251c\u2500\u2500 CMakeCache.txt\n\u2502   \u251c\u2500\u2500 CMakeFiles\n\u2502   \u2502   \u251c\u2500\u2500 3.16.3\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeCCompiler.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeCXXCompiler.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDetermineCompilerABI_C.bin\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDetermineCompilerABI_CXX.bin\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeSystem.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CompilerIdC\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 a.out\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeCCompilerId.c\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 tmp\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 CompilerIdCXX\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 a.out\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 CMakeCXXCompilerId.cpp\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 tmp\n\u2502   \u2502   \u251c\u2500\u2500 clean_test_results.dir\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.make\n\u2502   \u2502   \u251c\u2500\u2500 cmake.check_cache\n\u2502   \u2502   \u251c\u2500\u2500 CMakeDirectoryInformation.cmake\n\u2502   \u2502   \u251c\u2500\u2500 CMakeError.log\n\u2502   \u2502   \u251c\u2500\u2500 CMakeOutput.log\n\u2502   \u2502   \u251c\u2500\u2500 CMakeRuleHashes.txt\n\u2502   \u2502   \u251c\u2500\u2500 CMakeTmp\n\u2502   \u2502   \u251c\u2500\u2500 download_extra_data.dir\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.make\n\u2502   \u2502   \u251c\u2500\u2500 doxygen.dir\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.make\n\u2502   \u2502   \u251c\u2500\u2500 Makefile2\n\u2502   \u2502   \u251c\u2500\u2500 Makefile.cmake\n\u2502   \u2502   \u251c\u2500\u2500 progress.marks\n\u2502   \u2502   \u251c\u2500\u2500 run_tests.dir\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.make\n\u2502   \u2502   \u251c\u2500\u2500 TargetDirectories.txt\n\u2502   \u2502   \u2514\u2500\u2500 tests.dir\n\u2502   \u2502       \u251c\u2500\u2500 build.make\n\u2502   \u2502       \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502       \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502       \u2514\u2500\u2500 progress.make\n\u2502   \u251c\u2500\u2500 cmake_install.cmake\n\u2502   \u251c\u2500\u2500 CTestConfiguration.ini\n\u2502   \u251c\u2500\u2500 CTestCustom.cmake\n\u2502   \u251c\u2500\u2500 CTestTestfile.cmake\n\u2502   \u251c\u2500\u2500 gtest\n\u2502   \u2502   \u251c\u2500\u2500 CMakeFiles\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDirectoryInformation.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.marks\n\u2502   \u2502   \u251c\u2500\u2500 cmake_install.cmake\n\u2502   \u2502   \u251c\u2500\u2500 CTestTestfile.cmake\n\u2502   \u2502   \u251c\u2500\u2500 googlemock\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeFiles\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDirectoryInformation.cmake\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gmock.dir\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 depend.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 flags.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 link.txt\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 progress.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 src\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gmock_main.dir\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 depend.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 flags.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 link.txt\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 progress.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 src\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.marks\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_install.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CTestTestfile.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 Makefile\n\u2502   \u2502   \u251c\u2500\u2500 googletest\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeFiles\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 CMakeDirectoryInformation.cmake\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gtest.dir\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 depend.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 flags.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 link.txt\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 progress.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 src\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gtest_main.dir\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 build.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_clean.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DependInfo.cmake\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 depend.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 flags.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 link.txt\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 progress.make\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 src\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 progress.marks\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cmake_install.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 CTestTestfile.cmake\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 Makefile\n\u2502   \u2502   \u251c\u2500\u2500 lib\n\u2502   \u2502   \u2514\u2500\u2500 Makefile\n\u2502   \u251c\u2500\u2500 Makefile\n\u2502   \u251c\u2500\u2500 ros_test\n\u2502   \u2502   \u251c\u2500\u2500 catkin_generated\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 installspace\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ros_testConfig.cmake\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ros_testConfig-version.cmake\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ros_test.pc\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ordered_paths.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 package.cmake\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pkg.develspace.context.pc.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pkg.installspace.context.pc.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 stamps\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 ros_test\n\u2502   \u2502   \u2502           \u251c\u2500\u2500 package.xml.stamp\n\u2502   \u2502   \u2502           \u2514\u2500\u2500 pkg.pc.em.stamp\n\u2502   \u2502   \u2514\u2500\u2500 CMakeFiles\n\u2502   \u2514\u2500\u2500 test_results\n\u251c\u2500\u2500 devel\n\u2502   \u251c\u2500\u2500 cmake.lock\n\u2502   \u251c\u2500\u2500 env.sh\n\u2502   \u251c\u2500\u2500 lib\n\u2502   \u2502   \u2514\u2500\u2500 pkgconfig\n\u2502   \u2502       \u2514\u2500\u2500 ros_test.pc\n\u2502   \u251c\u2500\u2500 local_setup.bash\n\u2502   \u251c\u2500\u2500 local_setup.sh\n\u2502   \u251c\u2500\u2500 local_setup.zsh\n\u2502   \u251c\u2500\u2500 setup.bash\n\u2502   \u251c\u2500\u2500 setup.sh\n\u2502   \u251c\u2500\u2500 _setup_util.py\n\u2502   \u251c\u2500\u2500 setup.zsh\n\u2502   \u2514\u2500\u2500 share\n\u2502       \u2514\u2500\u2500 ros_test\n\u2502           \u2514\u2500\u2500 cmake\n\u2502               \u251c\u2500\u2500 ros_testConfig.cmake\n\u2502               \u2514\u2500\u2500 ros_testConfig-version.cmake\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 CMakeLists.txt -&gt; /opt/ros/noetic/share/catkin/cmake/toplevel.cmake\n    \u2514\u2500\u2500 ros_test\n        \u251c\u2500\u2500 CMakeLists.txt\n        \u251c\u2500\u2500 include\n        \u2502   \u2514\u2500\u2500 ros_test\n        \u251c\u2500\u2500 package.xml\n        \u2514\u2500\u2500 src\n            \u2514\u2500\u2500 talker.py\n", "cmake_minimum_required(VERSION 3.0.2)\nproject(ros_test)\n\n## Compile as C++11, supported in ROS Kinetic and newer\n# add_compile_options(-std=c++11)\n\n## Find catkin macros and libraries\n## if COMPONENTS list like find_package(catkin REQUIRED COMPONENTS xyz)\n## is used, also find other catkin packages\nfind_package(catkin REQUIRED COMPONENTS\n  roscpp\n  rospy\n  std_msgs\n)\n\n## System dependencies are found with CMake's conventions\n# find_package(Boost REQUIRED COMPONENTS system)\n\n\n## Uncomment this if the package has a setup.py. This macro ensures\n## modules and global scripts declared therein get installed\n## See http://ros.org/doc/api/catkin/html/user_guide/setup_dot_py.html\n# catkin_python_setup()\n\n################################################\n## Declare ROS messages, services and actions ##\n################################################\n\n## To declare and build messages, services or actions from within this\n## package, follow these steps:\n## * Let MSG_DEP_SET be the set of packages whose message types you use in\n##   your messages/services/actions (e.g. std_msgs, actionlib_msgs, ...).\n## * In the file package.xml:\n##   * add a build_depend tag for &quot;message_generation&quot;\n##   * add a build_depend and a exec_depend tag for each package in MSG_DEP_SET\n##   * If MSG_DEP_SET isn't empty the following dependency has been pulled in\n##     but can be declared for certainty nonetheless:\n##     * add a exec_depend tag for &quot;message_runtime&quot;\n## * In this file (CMakeLists.txt):\n##   * add &quot;message_generation&quot; and every package in MSG_DEP_SET to\n##     find_package(catkin REQUIRED COMPONENTS ...)\n##   * add &quot;message_runtime&quot; and every package in MSG_DEP_SET to\n##     catkin_package(CATKIN_DEPENDS ...)\n##   * uncomment the add_*_files sections below as needed\n##     and list every .msg/.srv/.action file to be processed\n##   * uncomment the generate_messages entry below\n##   * add every package in MSG_DEP_SET to generate_messages(DEPENDENCIES ...)\n\n## Generate messages in the 'msg' folder\n# add_message_files(\n#   FILES\n#   Message1.msg\n#   Message2.msg\n# )\n\n## Generate services in the 'srv' folder\n# add_service_files(\n#   FILES\n#   Service1.srv\n#   Service2.srv\n# )\n\n## Generate actions in the 'action' folder\n# add_action_files(\n#   FILES\n#   Action1.action\n#   Action2.action\n# )\n\n## Generate added messages and services with any dependencies listed here\n# generate_messages(\n#   DEPENDENCIES\n#   std_msgs\n# )\n\n################################################\n## Declare ROS dynamic reconfigure parameters ##\n################################################\n\n## To declare and build dynamic reconfigure parameters within this\n## package, follow these steps:\n## * In the file package.xml:\n##   * add a build_depend and a exec_depend tag for &quot;dynamic_reconfigure&quot;\n## * In this file (CMakeLists.txt):\n##   * add &quot;dynamic_reconfigure&quot; to\n##     find_package(catkin REQUIRED COMPONENTS ...)\n##   * uncomment the &quot;generate_dynamic_reconfigure_options&quot; section below\n##     and list every .cfg file to be processed\n\n## Generate dynamic reconfigure parameters in the 'cfg' folder\n# generate_dynamic_reconfigure_options(\n#   cfg/DynReconf1.cfg\n#   cfg/DynReconf2.cfg\n# )\n\n###################################\n## catkin specific configuration ##\n###################################\n## The catkin_package macro generates cmake config files for your package\n## Declare things to be passed to dependent projects\n## INCLUDE_DIRS: uncomment this if your package contains header files\n## LIBRARIES: libraries you create in this project that dependent projects also need\n## CATKIN_DEPENDS: catkin_packages dependent projects also need\n## DEPENDS: system dependencies of this project that dependent projects also need\ncatkin_package(\n  INCLUDE_DIRS include\n  LIBRARIES ros_test\n  CATKIN_DEPENDS roscpp rospy std_msgs\n  DEPENDS system_lib\n)\n\n###########\n## Build ##\n###########\n\n## Specify additional locations of header files\n## Your package locations should be listed before other locations\ninclude_directories(\n# include\n  ${catkin_INCLUDE_DIRS}\n)\n\n## Declare a C++ library\nadd_library(${PROJECT_NAME}\n   src/${PROJECT_NAME}/ros_test.cpp\n)\n\n## Add cmake target dependencies of the library\n## as an example, code may need to be generated before libraries\n## either from message generation or dynamic reconfigure\n# add_dependencies(${PROJECT_NAME} ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\n\n## Declare a C++ executable\n## With catkin_make all packages are built within a single CMake context\n## The recommended prefix ensures that target names across packages don't collide\nadd_executable(${PROJECT_NAME}_node src/ros_test_node.cpp)\n\n## Rename C++ executable without prefix\n## The above recommended prefix causes long target names, the following renames the\n## target back to the shorter version for ease of user use\n## e.g. &quot;rosrun someones_pkg node&quot; instead of &quot;rosrun someones_pkg someones_pkg_node&quot;\n# set_target_properties(${PROJECT_NAME}_node PROPERTIES OUTPUT_NAME node PREFIX &quot;&quot;)\n\n## Add cmake target dependencies of the executable\n## same as for the library above\n# add_dependencies(${PROJECT_NAME}_node ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\n\n## Specify libraries to link a library or executable target against\ntarget_link_libraries(${PROJECT_NAME}_node\n#   ${catkin_LIBRARIES}\n)\n\n#############\n## Install ##\n#############\n\n# all install targets should use catkin DESTINATION variables\n# See http://ros.org/doc/api/catkin/html/adv_user_guide/variables.html\n\n## Mark executable scripts (Python etc.) for installation\n## in contrast to setup.py, you can choose the destination\n# catkin_install_python(PROGRAMS\n#   scripts/my_python_script\n#   DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n# )\n\n## Mark executables for installation\n## See http://docs.ros.org/melodic/api/catkin/html/howto/format1/building_executables.html\n# install(TARGETS ${PROJECT_NAME}_node\n#   RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n# )\n\n## Mark libraries for installation\n## See http://docs.ros.org/melodic/api/catkin/html/howto/format1/building_libraries.html\n# install(TARGETS ${PROJECT_NAME}\n#   ARCHIVE DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#   LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#   RUNTIME DESTINATION ${CATKIN_GLOBAL_BIN_DESTINATION}\n# )\n\n## Mark cpp header files for installation\n# install(DIRECTORY include/${PROJECT_NAME}/\n#   DESTINATION ${CATKIN_PACKAGE_INCLUDE_DESTINATION}\n#   FILES_MATCHING PATTERN &quot;*.h&quot;\n#   PATTERN &quot;.svn&quot; EXCLUDE\n# )\n\n## Mark other files for installation (e.g. launch and bag files, etc.)\n# install(FILES\n#   # myfile1\n#   # myfile2\n#   DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}\n# )\n\n#############\n## Testing ##\n#############\n\n## Add gtest based cpp test target and link libraries\n# catkin_add_gtest(${PROJECT_NAME}-test test/test_ros_test.cpp)\n# if(TARGET ${PROJECT_NAME}-test)\n#   target_link_libraries(${PROJECT_NAME}-test ${PROJECT_NAME})\n# endif()\n\n## Add folders to be run by python nosetests\n# catkin_add_nosetests(test) \n"], "quote": ["couldn't find executable named."], "url": "https://stackoverflow.com/questions/78469026/unable-to-execute-specific-package-with-rosrun", "answer": ["There are multiple issues here. First, your CMakeLists.txt is incorrect. It's setup to build a cpp file called ros_test.cpp, which doesn't exist. Secondly, if you want to have it build a package for the python script you mentioned, you should add/uncomment the following lines:\ncatkin_install_python(PROGRAMS\n  scripts/talker.py\n  DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n)\n\nFinally, make sure you re-build and source the local setup.bash file."], "answer_code": ["CMakeLists.txt", "ros_test.cpp", "catkin_install_python(PROGRAMS\n  scripts/talker.py\n  DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n)\n", "setup.bash"]},
{"title": "Docker ENTRYPOINT not working as intended", "time": 1714600330, "post_content": ["I'm new to docker and I'm having an issue with the ENTRYPOINT argument in the dockerfile. I'm working on a project called F1Tenth and I am using their premade docker image. I am running it on a jetson nano and I am trying to figure out how to source these two files (/opt/ros/foxy/setup.bash and install/local_setup.bash) for ROS2. After some research I figured the best thing to try was to run a script that sources these and have that script run using ENTRYPOINT. I tried A BUNCH of things but nothing is working, when the container starts I still need to manually source the files in the terminal. I need this to work because the jetson is going to be attached to an RC car and it needs to be headless and no ssh.\nHere is my entrypoint.sh (its inside of the docker image dir)\n#!/bin/bash\nsource /opt/ors/foxy/setup.bash\nsource install/local_setup.bash\nexec \"$@\"\n\nHere is my DockerFile:\nFROM ros:foxy\n\nSHELL \\[\"/bin/bash\", \"-c\"\\]\n\n# dependencies\n\nRUN apt-get update --fix-missing && \\\napt-get install -y git \\\nnano \\\nvim \\\npython3-pip \\\nlibeigen3-dev \\\ntmux \\\nros-foxy-rviz2\nRUN apt-get -y dist-upgrade\nRUN pip3 install transforms3d\n\n# f1tenth gym\n\nRUN git clone https://github.com/f1tenth/f1tenth_gym\nRUN cd f1tenth_gym && \\\npip3 install -e .\n\n# ros2 gym bridge\n\nRUN mkdir -p sim_ws/src/f1tenth_gym_ros\nCOPY . /sim_ws/src/f1tenth_gym_ros\nRUN source /opt/ros/foxy/setup.bash && \\\ncd sim_ws/ && \\\napt-get update --fix-missing && \\\nrosdep install -i --from-path src --rosdistro foxy -y && \\\ncolcon build\n\nWORKDIR '/sim_ws'\nCOPY entrypoint.sh /entrypoint.sh\nRUN chmod +x /entrypoint.sh\nENTRYPOINT [\"./entrypoint.sh\"]\nCMD [\"/bin/bash\"]\n\nI've tried various other DockerFile setups. Maybe I'm misunderstanding the point of ENTRYPOINT"], "question_code": ["/opt/ros/foxy/setup.bash", "install/local_setup.bash", "#!/bin/bash\nsource /opt/ors/foxy/setup.bash\nsource install/local_setup.bash\nexec &quot;$@&quot;\n", "FROM ros:foxy\n\nSHELL \\[&quot;/bin/bash&quot;, &quot;-c&quot;\\]\n\n# dependencies\n\nRUN apt-get update --fix-missing &amp;&amp; \\\napt-get install -y git \\\nnano \\\nvim \\\npython3-pip \\\nlibeigen3-dev \\\ntmux \\\nros-foxy-rviz2\nRUN apt-get -y dist-upgrade\nRUN pip3 install transforms3d\n\n# f1tenth gym\n\nRUN git clone https://github.com/f1tenth/f1tenth_gym\nRUN cd f1tenth_gym &amp;&amp; \\\npip3 install -e .\n\n# ros2 gym bridge\n\nRUN mkdir -p sim_ws/src/f1tenth_gym_ros\nCOPY . /sim_ws/src/f1tenth_gym_ros\nRUN source /opt/ros/foxy/setup.bash &amp;&amp; \\\ncd sim_ws/ &amp;&amp; \\\napt-get update --fix-missing &amp;&amp; \\\nrosdep install -i --from-path src --rosdistro foxy -y &amp;&amp; \\\ncolcon build\n\nWORKDIR '/sim_ws'\nCOPY entrypoint.sh /entrypoint.sh\nRUN chmod +x /entrypoint.sh\nENTRYPOINT [&quot;./entrypoint.sh&quot;]\nCMD [&quot;/bin/bash&quot;]\n"], "quote": [], "url": "https://stackoverflow.com/questions/78416125/docker-entrypoint-not-working-as-intended", "answer": ["In your entrypoint.sh you reference /opt/ors/foxy/setup.bash but I could only find /opt/ros/foxy/setup.bash on the image (they differ in the second part of the path). I'm assuming that this is a typo and you meant the latter file. It's also the path that you mention in your text.\nSo I suggest changing your entrypoint.sh as follows:\n#!/bin/bash\n\nsource /opt/ros/foxy/setup.bash\nsource install/local_setup.bash\n\nexec \"$@\"\n\nI've fiddled with the Dockerfile a bit too. You don't need to change SHELL if you source /opt/ros/foxy/setup.sh rather than /opt/ros/foxy/setup.bash. Also moved the WORKDIR earlier which means you don't need to cd sim_ws/.\nYou don't need to make these changes though and the updated entrypoint.sh should be sufficient for the image to build and run successfully.\nFROM ros:foxy\n\nRUN apt-get update --fix-missing && \\\n    apt-get install -y git \\\n        nano \\\n        vim \\\n        python3-pip \\\n        libeigen3-dev \\\n        tmux \\\n        ros-foxy-rviz2 && \\\n    apt-get -y dist-upgrade && \\\n    pip3 install transforms3d\n\nRUN git clone https://github.com/f1tenth/f1tenth_gym\nRUN cd f1tenth_gym && \\\n    pip3 install -e .\n\nRUN mkdir -p sim_ws/src/f1tenth_gym_ros\nCOPY . /sim_ws/src/f1tenth_gym_ros\n\nWORKDIR /sim_ws\n\nRUN . /opt/ros/foxy/setup.sh && \\\n    apt-get update --fix-missing && \\\n    rosdep install -i --from-path src --rosdistro foxy -y && \\\n    colcon build\n\nCOPY entrypoint.sh .\nRUN chmod +x entrypoint.sh\n\nENTRYPOINT [\"./entrypoint.sh\"]\nCMD [\"/bin/bash\"]\n\nI also note that you were sourcing the /opt/ros/foxy/setup.bash script twice, once in the Dockerfile itself and then again via the entrypoint.sh script. Is this intentional? Is it really necessary?"], "answer_code": ["entrypoint.sh", "/opt/ors/foxy/setup.bash", "/opt/ros/foxy/setup.bash", "entrypoint.sh", "#!/bin/bash\n\nsource /opt/ros/foxy/setup.bash\nsource install/local_setup.bash\n\nexec &quot;$@&quot;\n", "Dockerfile", "SHELL", "/opt/ros/foxy/setup.sh", "/opt/ros/foxy/setup.bash", "WORKDIR", "cd sim_ws/", "entrypoint.sh", "FROM ros:foxy\n\nRUN apt-get update --fix-missing &amp;&amp; \\\n    apt-get install -y git \\\n        nano \\\n        vim \\\n        python3-pip \\\n        libeigen3-dev \\\n        tmux \\\n        ros-foxy-rviz2 &amp;&amp; \\\n    apt-get -y dist-upgrade &amp;&amp; \\\n    pip3 install transforms3d\n\nRUN git clone https://github.com/f1tenth/f1tenth_gym\nRUN cd f1tenth_gym &amp;&amp; \\\n    pip3 install -e .\n\nRUN mkdir -p sim_ws/src/f1tenth_gym_ros\nCOPY . /sim_ws/src/f1tenth_gym_ros\n\nWORKDIR /sim_ws\n\nRUN . /opt/ros/foxy/setup.sh &amp;&amp; \\\n    apt-get update --fix-missing &amp;&amp; \\\n    rosdep install -i --from-path src --rosdistro foxy -y &amp;&amp; \\\n    colcon build\n\nCOPY entrypoint.sh .\nRUN chmod +x entrypoint.sh\n\nENTRYPOINT [&quot;./entrypoint.sh&quot;]\nCMD [&quot;/bin/bash&quot;]\n", "/opt/ros/foxy/setup.bash", "Dockerfile", "entrypoint.sh"]},
{"title": "Problem with Docker image ROS noetic on Fedora-40", "time": 1715950863, "post_content": ["After installing Fedor\u0430-40 OS on the workstation and running roscore in Docker container, I get a problem. After a few seconds, the RAM and swap are 90% occupied. The Gnome's graphical interface does not respond. After stopping (Ctrl+C) roscore, the memory is released and the system performance is restored. ROS - noetic version, image based on Ubuntu Focal 20.04\nI tried changing the type of the ROS image - the result is the same."], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/78495838/problem-with-docker-image-ros-noetic-on-fedora-40", "answer": ["This is related to the number of open file descriptors.\nAlready reported and resolved here.\nOn Fedora 40 Workstation, roslaunch was opening a lot more files than what was allowed leading to RAM + Swap running out and crashing GNOME.\nResolved this by setting hard and soft limits for allowed file descriptors in /etc/docker/daemon.json.\n{\n    \"default-ulimits\": {\n        \"nofile\": {\n            \"Name\": \"nofile\",\n            \"Hard\": 524288,\n            \"Soft\": 1024\n        }\n    }\n}\n\nHard limit: The absolute maximum number of open file descriptors allowed.\nSoft limit: The threshold at which the kernel will start sending warnings to discourage opening more files.\nThis is a global change for all containers, you can also pass it as docker run arguments:\ndocker run --ulimit nofile=1024:524288 <image-name>"], "answer_code": ["roslaunch", "/etc/docker/daemon.json", "{\n    &quot;default-ulimits&quot;: {\n        &quot;nofile&quot;: {\n            &quot;Name&quot;: &quot;nofile&quot;,\n            &quot;Hard&quot;: 524288,\n            &quot;Soft&quot;: 1024\n        }\n    }\n}\n", "Hard limit", "Soft limit", "docker run --ulimit nofile=1024:524288 &lt;image-name&gt;"]},
{"title": "how to install libgeographiclib-dev", "time": 1715157217, "post_content": ["rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO --skip-keys libgeographiclib-dev\nexecuting command [sudo -H apt-get install -y libgeographiclib-dev]\n[sudo] password for ck:\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nPackage libgeographiclib-dev is not available, but is referred to by another package.\nThis may mean that the package is missing, has been obsoleted, or is only available from another source\nHowever the following packages replace it:\nlibgeographic-dev:i386 libgeographic-dev\nE: Package 'libgeographiclib-dev' has no installation candidate\nERROR: the following rosdeps failed to install\napt: command [sudo -H apt-get install -y libgeographiclib-dev] failed\nI have installed libgeographic-dev and it still gives me an error.\nrosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\nrosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO --skip-keys libgeographiclib-dev #no use"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/78447107/how-to-install-libgeographiclib-dev", "answer": ["Run update command to update package repositories and get latest package information.\nsudo apt-get update -y\n\nRun the install command with -y flag to quickly install the packages and dependencies.\nsudo apt-get install -y libgeographiclib-dev"], "answer_code": ["sudo apt-get update -y\n", "sudo apt-get install -y libgeographiclib-dev\n"]},
{"title": "ROS2 rate blocked", "time": 1715857932, "post_content": ["I am having an issue with a ROS2 python script that I am not able to understand. I implemented a server for an action node. In the callback of the goal, I am calculating some data with a given time frame (just integrate a variable). this is the code\ndef execute_callback(self, goal_handle):\n        \n        # Fill the data\n        print( \"Received new goal\" )\n   \n        curr_pos = goal_handle.request.initial_position\n        goal_pos = goal_handle.request.goal_position\n        vel = goal_handle.request.linear_velocity\n        \n        \n        dist = math.fabs( curr_pos - goal_pos ) \n\n        rate = self.create_rate(50)\n        step_t = 1.0/50.0\n        \n        feedback_msg = LinearControl.Feedback()        \n        \n        while dist > 1e-2:\n            print(\"dist: \", dist)\n            print(\"curr_pos: \", curr_pos)\n           \n            curr_pos = curr_pos + vel*step_t\n            dist = math.fabs( curr_pos - goal_pos ) \n            feedback_msg.distance = dist\n            goal_handle.publish_feedback( feedback_msg )\n        \n            rate.sleep() \n            \n        print(\"Motion done\")\n        \n\nHowever, the code is blocked after the rate.sleep, it is like if is never released. My question is, is it allowed to used the rate object into an action server? The rest of the code is pretty similar the classical way of creating an action server in python. It works in the case I change the rate with a classical time.sleep."], "question_code": ["def execute_callback(self, goal_handle):\n        \n        # Fill the data\n        print( &quot;Received new goal&quot; )\n   \n        curr_pos = goal_handle.request.initial_position\n        goal_pos = goal_handle.request.goal_position\n        vel = goal_handle.request.linear_velocity\n        \n        \n        dist = math.fabs( curr_pos - goal_pos ) \n\n        rate = self.create_rate(50)\n        step_t = 1.0/50.0\n        \n        feedback_msg = LinearControl.Feedback()        \n        \n        while dist &gt; 1e-2:\n            print(&quot;dist: &quot;, dist)\n            print(&quot;curr_pos: &quot;, curr_pos)\n           \n            curr_pos = curr_pos + vel*step_t\n            dist = math.fabs( curr_pos - goal_pos ) \n            feedback_msg.distance = dist\n            goal_handle.publish_feedback( feedback_msg )\n        \n            rate.sleep() \n            \n        print(&quot;Motion done&quot;)\n        \n"], "quote": [], "url": "https://stackoverflow.com/questions/78489448/ros2-rate-blocked", "answer": ["In this case, using Rate.sleep inside the action will cause a deadlock. This is because both the action callback and the sleep callback are being handled by the same mutually exclusive callback group. That is, the sleep call must wait for the action callback to complete before waking up. But of course this is impossible!\nMore explanation can be found in the Using Callback Groups documentation."], "answer_code": ["Rate.sleep", "sleep"]},
{"title": "roslaunch running error process has died [pid 4185027, exit code -8,", "time": 1724221535, "post_content": ["When I run roslaunch, an error occurs. After running dozens of normal cycles, an error is reported:\n\n[local_planner/dwa_planner-7] process has died [pid 4185027, exit code -8, cmd /home/oem/dwa_simulation/devel/lib/dwa_planner/dwa_planner /cmd_vel:=/cmd_vel_1 /local_map:=/local_map /move_base_simple/goal:=/goal_pose /odom:=/odom /dist_to_goal_th:=/dist_to_goal_th /scan:=/scan_2 /footprint:=/footprint /path:=/path /target_velocity:=/target_velocity __name:=dwa_planner __log:=/home/oem/.ros/log/1d0fce4a-5f65-11ef-9f18-253e39130628/local_planner-dwa_planner-7.log].\n\nI checked the breakpoints and found that the error occurred in ros::spinOnce();\nRun to loop_rate.sleep();. I think there is a problem there? How should I fix it?\nI have tried to check whether the topic is successfully mapped and the topic is initialized, and both are normal.\nThe original code link is https://github.com/amslabtech/dwa_planner.git."], "question_code": ["ros::spinOnce();", "loop_rate.sleep();"], "quote": ["[local_planner/dwa_planner-7] process has died [pid 4185027, exit code -8, cmd /home/oem/dwa_simulation/devel/lib/dwa_planner/dwa_planner /cmd_vel:=/cmd_vel_1 /local_map:=/local_map /move_base_simple/goal:=/goal_pose /odom:=/odom /dist_to_goal_th:=/dist_to_goal_th /scan:=/scan_2 /footprint:=/footprint /path:=/path /target_velocity:=/target_velocity __name:=dwa_planner __log:=/home/oem/.ros/log/1d0fce4a-5f65-11ef-9f18-253e39130628/local_planner-dwa_planner-7.log]."], "url": "https://stackoverflow.com/questions/78895416/roslaunch-running-error-process-has-died-pid-4185027-exit-code-8", "answer": ["We will probably need more information to identify where your error occurred, but I'll explain where you may want to look and why.\nWhen a ROS node calls ros::spinOnce(), it hands control of the current thread to ROS, so that ROS can call any callbacks waiting to be called (read more). In your case, these callbacks were set up in the DWAPlanner constructor:\n  dist_to_goal_th_sub_ = nh_.subscribe(\"/dist_to_goal_th\", 1, &DWAPlanner::dist_to_goal_th_callback, this);\n  edge_on_global_path_sub_ = nh_.subscribe(\"/path\", 1, &DWAPlanner::edge_on_global_path_callback, this);\n  footprint_sub_ = nh_.subscribe(\"/footprint\", 1, &DWAPlanner::footprint_callback, this);\n  goal_sub_ = nh_.subscribe(\"/move_base_simple/goal\", 1, &DWAPlanner::goal_callback, this);\n  local_map_sub_ = nh_.subscribe(\"/local_map\", 1, &DWAPlanner::local_map_callback, this);\n  odom_sub_ = nh_.subscribe(\"/odom\", 1, &DWAPlanner::odom_callback, this);\n  scan_sub_ = nh_.subscribe(\"/scan\", 1, &DWAPlanner::scan_callback, this);\n  target_velocity_sub_ = nh_.subscribe(\"/target_velocity\", 1, &DWAPlanner::target_velocity_callback, this);\n\nSo, if an error occurred during ros::spinOnce(), the error could have originated from any of those callbacks (i.e., any of the ..._callback functions of the DWAPlanner class).\nTo identify the culprit, you could add breakpoints to the beginning of each callback, or use ROS_DEBUG to log when the callbacks are entered and exited."], "answer_code": ["ros::spinOnce()", "DWAPlanner", "  dist_to_goal_th_sub_ = nh_.subscribe(&quot;/dist_to_goal_th&quot;, 1, &amp;DWAPlanner::dist_to_goal_th_callback, this);\n  edge_on_global_path_sub_ = nh_.subscribe(&quot;/path&quot;, 1, &amp;DWAPlanner::edge_on_global_path_callback, this);\n  footprint_sub_ = nh_.subscribe(&quot;/footprint&quot;, 1, &amp;DWAPlanner::footprint_callback, this);\n  goal_sub_ = nh_.subscribe(&quot;/move_base_simple/goal&quot;, 1, &amp;DWAPlanner::goal_callback, this);\n  local_map_sub_ = nh_.subscribe(&quot;/local_map&quot;, 1, &amp;DWAPlanner::local_map_callback, this);\n  odom_sub_ = nh_.subscribe(&quot;/odom&quot;, 1, &amp;DWAPlanner::odom_callback, this);\n  scan_sub_ = nh_.subscribe(&quot;/scan&quot;, 1, &amp;DWAPlanner::scan_callback, this);\n  target_velocity_sub_ = nh_.subscribe(&quot;/target_velocity&quot;, 1, &amp;DWAPlanner::target_velocity_callback, this);\n", "ros::spinOnce()", "..._callback", "DWAPlanner", "ROS_DEBUG"]},
{"title": "How do I use positional argument to initialize Pose from geometry_msgs of ROS?", "time": 1727147638, "post_content": ["In the documentation, it says that I can initialize with \"complete set of field values, in .msg order\".\nWhat does this mean? And how do I implement it in Python and C++?"], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79016849/how-do-i-use-positional-argument-to-initialize-pose-from-geometry-msgs-of-ros", "answer": ["This simply means you can pass __init__ arguments in the order they appear in the .msg file. You would find the exact definition in the geometry_msgs Pose docs here. This is more typically seen as a python paradigm, and uses the * unpacking operator. Such as the following example:\ndef unpacking_func(*args):\n    print(f'I was passed {len(args)} items, they are: ')\n    for item in args:\n        print(item)\nunpacking_func('first', 'second', 'third')\n\nA specific example for the Pose you linked would look like this:\n# NOTE: These are just empty values\nposition = geometry_msgs.Point()\nquaternion = geometry_msgs.Quaternion()\npose = geometry_msgs.Pose(position, quaternion)\n\nAs a final point I'd note that you linked Diamondback docs, which has been EOL for a long time. This should all hold true for newer distros, but obviously there's no guarantee."], "answer_code": ["__init__", ".msg", "*", "def unpacking_func(*args):\n    print(f'I was passed {len(args)} items, they are: ')\n    for item in args:\n        print(item)\nunpacking_func('first', 'second', 'third')\n", "# NOTE: These are just empty values\nposition = geometry_msgs.Point()\nquaternion = geometry_msgs.Quaternion()\npose = geometry_msgs.Pose(position, quaternion)\n"]},
{"title": "rmw_cyclonedds_cpp on windows using humble distro", "time": 1727464031, "post_content": ["I'am using Humble ROS distro for connecting two machines through CYCLONE middleware, but I'am not able to generate rmw_cyclonedds_cpp.ddl that seems to be used by the env variable RMW_IMPLEMENTATION=rmw_cyclonedds_cpp,\nI follow this ref page : GitHub - eclipse-cyclonedds/cyclonedds: Eclipse Cyclone DDS project\nand tested there examples that works for me. but enabling the  RMW_IMPLEMENTATION=rmw_cyclonedds_cpp  and running the ros2 run demo_nodes_cpp talker return this error :\n[ERROR] [1727463586.665113300] [rcl]: \nError getting RMW implementation identifier / RMW implementation not \ninstalled (expected identifier of 'rmw_cyclonedds_cpp'), \nwith error message 'failed to load shared library 'rmw_cyclonedds_cpp.dll' \ndue to LoadLibrary error: 126, \nat D:\\a\\_work\\1\\s\\ws\\src\\rcutils\\src\\shared_library.c:159, \nat D:\\a\\_work\\1\\s\\ws\\src\\rmw_implementation\\rmw_implementation\\src\\functions.cpp:67', exiting with 1., \nat D:\\a\\_work\\1\\s\\ws\\src\\rcl\\rcl\\src\\rcl\\rmw_implementation_identifier_check.c:145\n\nam i missing something  ?  thanks"], "question_code": ["[ERROR] [1727463586.665113300] [rcl]: \nError getting RMW implementation identifier / RMW implementation not \ninstalled (expected identifier of 'rmw_cyclonedds_cpp'), \nwith error message 'failed to load shared library 'rmw_cyclonedds_cpp.dll' \ndue to LoadLibrary error: 126, \nat D:\\a\\_work\\1\\s\\ws\\src\\rcutils\\src\\shared_library.c:159, \nat D:\\a\\_work\\1\\s\\ws\\src\\rmw_implementation\\rmw_implementation\\src\\functions.cpp:67', exiting with 1., \nat D:\\a\\_work\\1\\s\\ws\\src\\rcl\\rcl\\src\\rcl\\rmw_implementation_identifier_check.c:145\n"], "quote": [], "url": "https://stackoverflow.com/questions/79032630/rmw-cyclonedds-cpp-on-windows-using-humble-distro", "answer": ["I can't speak to Humble, I'm afraid, but I can confirm that rmw_cyclonedds_cpp is available using the pre-built binary distribution for Jazzy on Windows 10.\nSetting RMW_IMPLEMENTATION=rmw_cyclonedds_cpp is sufficient to make it work.  (Also, it seems to work much better than fastrtps on Windows... switching to cyclone resolved a bunch of difficult-to-troubleshoot issues.)"], "answer_code": ["rmw_cyclonedds_cpp", "RMW_IMPLEMENTATION=rmw_cyclonedds_cpp", "fastrtps"]},
{"title": "Why do we need to specify the object in std::bind() to describe it as a functor?", "time": 1727242634, "post_content": ["I have been getting started with ROS and came across the following subscriber code:-\n#include <memory>\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/string.hpp\"\nusing std::placeholders::_1;\n\nclass MinimalSubscriber : public rclcpp::Node\n{\npublic:\n  MinimalSubscriber()\n  : Node(\"minimal_subscriber\")\n  {\n    subscription_ = this->create_subscription<std_msgs::msg::String>(\n      \"topic\", 10, std::bind(&MinimalSubscriber::topic_callback, this, _1));\n  }\n\nprivate:\n  void topic_callback(const std_msgs::msg::String::SharedPtr msg) const\n  {\n    RCLCPP_INFO(this->get_logger(), \"I heard: '%s'\", msg->data.c_str());\n  }\n  rclcpp::Subscription<std_msgs::msg::String>::SharedPtr subscription_;\n};\n\nint main(int argc, char * argv[])\n{\n  rclcpp::init(argc, argv);\n  rclcpp::spin(std::make_shared<MinimalSubscriber>());\n  rclcpp::shutdown();\n  return 0;\n}\n\nMy confusion is specifically regarding the syntax\nsubscription_ = this->create_subscription<std_msgs::msg::String>(\n      \"topic\", 10, std::bind(&MinimalSubscriber::topic_callback, this, _1));\n\nAs per my understanding, this is a ROS node to keep subscribing messages of type string from the Topic named \"topic\" and execute the topic_callback() whenever there is a new message. Coming from a very raw background, I wanted to ask why do we even need to use the bind() function? Can't we simply pass topic_callback function or a pointer to that, as an argument (Probably like Python) ?\nAnd why do we need to specify \"this\"? When we are referencing the topic_callback, it makes sense only if there exists an MinimalSubscriber object whose member function is topic_callback, so again specifying this seems to be redundant. Same for _1, there's only 1 argument being passed, i.e. String. According to me instead of bind, this->topic_callback could have been passed.\nI am probably wrong at several fronts. I did look at this excellent answer:-\nstd::bind(), but couldn't grasp it completely."], "question_code": ["#include &lt;memory&gt;\n\n#include &quot;rclcpp/rclcpp.hpp&quot;\n#include &quot;std_msgs/msg/string.hpp&quot;\nusing std::placeholders::_1;\n\nclass MinimalSubscriber : public rclcpp::Node\n{\npublic:\n  MinimalSubscriber()\n  : Node(&quot;minimal_subscriber&quot;)\n  {\n    subscription_ = this-&gt;create_subscription&lt;std_msgs::msg::String&gt;(\n      &quot;topic&quot;, 10, std::bind(&amp;MinimalSubscriber::topic_callback, this, _1));\n  }\n\nprivate:\n  void topic_callback(const std_msgs::msg::String::SharedPtr msg) const\n  {\n    RCLCPP_INFO(this-&gt;get_logger(), &quot;I heard: '%s'&quot;, msg-&gt;data.c_str());\n  }\n  rclcpp::Subscription&lt;std_msgs::msg::String&gt;::SharedPtr subscription_;\n};\n\nint main(int argc, char * argv[])\n{\n  rclcpp::init(argc, argv);\n  rclcpp::spin(std::make_shared&lt;MinimalSubscriber&gt;());\n  rclcpp::shutdown();\n  return 0;\n}\n", "subscription_ = this-&gt;create_subscription&lt;std_msgs::msg::String&gt;(\n      &quot;topic&quot;, 10, std::bind(&amp;MinimalSubscriber::topic_callback, this, _1));\n"], "quote": [], "url": "https://stackoverflow.com/questions/79021258/why-do-we-need-to-specify-the-object-in-stdbind-to-describe-it-as-a-functor", "answer": ["This problem is not ROS specific. Consider that you have a function that accepts a callback returning void and taking 1 std::string argument:\nvoid foo(std::function<void(std::string)> callback) {\n    if (callback) {\n        callback(\"foo\");\n    }\n}\n\nIf you have a free function void freeFun(std::string), you can pass it directly foo(freeFun);, however if you have a class or struct:\nstruct Foo {\n    void bar(std::string str) {\n        std::cout << \"bar str = \" << str << \"\\n\";\n    }\n    static void baz(std::string str) {\n        std::cout << \"baz str = \" << str << \"\\n\";\n    }\n    void registerCallback();\n};\n\nthen you cannot simply use bar as argument, because bar needs an object of type Foo to be called on. So:\nusing namespace std::placeholders;\nint main() {\n    // foo(&Foo::bar);  // nope\n    foo(&Foo::baz); // ok, because static method doesn't need associated object\n    Foo myFoo;\n    foo(std::bind(&Foo::bar, &myFoo, _1));  // ok, but rarely used for practical reasons\n}\n\nvoid Foo::registerCallback() {\n    foo(std::bind(&Foo::bar, this, _1));  // ok, typical use-case\n}\n\nstd::bind transforms function bar that (informally) has a signature void bar(Foo*, std::string) to an object that internally holds \"bound\" arguments, and that can be called like a function with signature void f(std::string).\nThe same could be achieved using lambda expression\nfoo([this](std::string str) { bar(str); });\n\nor a generic lambda if you don't want to be bothered with argument type:\nfoo([this](auto str) { bar(str); });"], "answer_code": ["void", "std::string", "void foo(std::function&lt;void(std::string)&gt; callback) {\n    if (callback) {\n        callback(&quot;foo&quot;);\n    }\n}\n", "void freeFun(std::string)", "foo(freeFun);", "struct Foo {\n    void bar(std::string str) {\n        std::cout &lt;&lt; &quot;bar str = &quot; &lt;&lt; str &lt;&lt; &quot;\\n&quot;;\n    }\n    static void baz(std::string str) {\n        std::cout &lt;&lt; &quot;baz str = &quot; &lt;&lt; str &lt;&lt; &quot;\\n&quot;;\n    }\n    void registerCallback();\n};\n", "bar", "bar", "Foo", "using namespace std::placeholders;\nint main() {\n    // foo(&amp;Foo::bar);  // nope\n    foo(&amp;Foo::baz); // ok, because static method doesn't need associated object\n    Foo myFoo;\n    foo(std::bind(&amp;Foo::bar, &amp;myFoo, _1));  // ok, but rarely used for practical reasons\n}\n\nvoid Foo::registerCallback() {\n    foo(std::bind(&amp;Foo::bar, this, _1));  // ok, typical use-case\n}\n", "std::bind", "bar", "void bar(Foo*, std::string)", "void f(std::string)", "foo([this](std::string str) { bar(str); });\n", "foo([this](auto str) { bar(str); });\n"]},
{"title": "Use ROS to connect raspberry pi 5 with ubuntu24 and laptop with ubuntu20", "time": 1727599936, "post_content": ["I would appreciate for the advice about real right platform to ask!\nSo the scenario is like this:\nI have installed Ubuntu24 on a Raspberry Pi 5, in order to run ROS2 (not yet ready). And my laptop has Ubuntu20 installed as well as ROS Noetic. I would like to know whether and how I can connect these 2 devices through ROS, although both the OS and ROS versions are different.\nLet's say,for example, just simple communication, e.g. RPi with ROS2 publishes a message, and laptop with ROS Noetic subscribes it.\nI haven't found any helpful posts or instructions about how to do this, so I would be grateful for any advice to have a try."], "question_code": [], "quote": [], "url": "https://stackoverflow.com/questions/79035981/use-ros-to-connect-raspberry-pi-5-with-ubuntu24-and-laptop-with-ubuntu20", "answer": ["The only (standard) supported way to do communication between ROS1 and ROS2 is to use the ROS2 bridge. You will need to follow the build and deploy instructions in the README.\nGenerally speaking this is more of a stopgap solution. It works for small projects, but in my experience can introduce a lot of overhead, especially when using the dynamic bridge for a large number of topics. Trying to be consistent on ros version and distros will always give you the best performance."], "answer_code": []},
{"title": "ROS2 launch error when installing my package", "time": 1729502863, "post_content": ["I tested both foxy and humble on Ubuntu 20.04, 22.04 and got the same error.\nWhen I build my package and type the source command, source /home/ws/ros2_ws/install/setup.bash, I get the following error.\nERROR\n$> ros2 launch\nFailed to load entry point 'launch': No module named 'launch.launch_description_sources'\nTraceback (most recent call last):\n  File \"/opt/ros/foxy/bin/ros2\", line 11, in <module>\n    load_entry_point('ros2cli==0.9.13', 'console_scripts', 'ros2')()\n  File \"/opt/ros/foxy/lib/python3.8/site-packages/ros2cli/cli.py\", line 39, in main\n    add_subparsers_on_demand(\n  File \"/opt/ros/foxy/lib/python3.8/site-packages/ros2cli/command/__init__.py\", line 237, in add_subparsers_on_demand\n    extension = command_extensions[name]\nKeyError: 'launch'\n\nThe only solution I've found so far is to delete the launch folder. What could be the problem?\npackage tree\n\u251c\u2500\u2500 config\n\u2502   \u2514\u2500\u2500 params_app.yaml\n\u251c\u2500\u2500 face_pose_estimation\n\u2502   \u251c\u2500\u2500 app_for_1.py\n\u2502   \u251c\u2500\u2500 components\n\u2502   \u2502   \u251c\u2500\u2500 main_component.py\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 utils\n\u2502   \u2502       \u251c\u2500\u2500 common.py\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2514\u2500\u2500 play_voice.py\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 save_service_server.py\n\u251c\u2500\u2500 launch\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 app_1.launch.py\n\u251c\u2500\u2500 log\n\u2502   \u2514\u2500\u2500 20241011_1114.txt\n\u251c\u2500\u2500 package.xml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 resource\n\u2502   \u251c\u2500\u2500 ros_app.service\n\u2502   \u2514\u2500\u2500 weights\n\u251c\u2500\u2500 script\n\u2502   \u251c\u2500\u2500 all.sh\n\u2502   \u251c\u2500\u2500 micro_ros.sh\n\u2502   \u2514\u2500\u2500 usbcam_open.sh\n\u251c\u2500\u2500 setup.cfg\n\u251c\u2500\u2500 setup.py\n\napp.launch.py\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\nfrom ament_index_python.packages import get_package_share_directory\nimport os\n\n\ndef generate_launch_description():\n    package_share_dir = get_package_share_directory(\"my_package\")\n    cam_params_file = os.path.join(package_share_dir, \"config\", \"params_usbcam.yaml\")\n    app_params_file = os.path.join(package_share_dir, \"config\", \"params_app.yaml\")\n\n    return LaunchDescription(\n        [\n            # Node(\n            #     package=\"micro_ros_agent\",\n            #     execuable=\"micro_ros_agent\",\n            #     name=\"micro_ros\",\n            #     arguments=[\n            #         \"serial\",\n            #         \"--dev\",\n            #         \"/dev/ttyUSB0\",\n            #         \"-b\",\n            #         \"115200\",\n            #     ],\n            # ),\n            Node(\n                package=\"usb_cam\",\n                executable=\"usb_cam_node_exe\",\n                name=\"app_cam\",\n                # parameters=[cam_params_file],\n            ),\n            Node(\n                package=\"my_package\",\n                executable=\"app_for_1\",\n                name=\"app\",\n                parameters=[app_params_file],\n            ),\n        ]\n\nsetup.py\nimport os\nfrom setuptools import setup, find_packages\n\npackage_name = \"my_package\"\n\ndata_files = [\n    (\"share/ament_index/resource_index/packages\", [\"resource/\" + package_name]),\n    (\"share/\" + package_name, [\"package.xml\"]),\n]\n\n\ndef package_files(data_files, directory_list):\n    paths_dict = {}\n    for directory in directory_list:\n        for path, directories, filenames in os.walk(directory):\n            for filename in filenames:\n                if filename == \"__init__.py\":\n                    continue\n                file_path = os.path.join(path, filename)\n                install_path = os.path.join(\"share\", package_name, path)\n                if install_path in paths_dict.keys():\n                    paths_dict[install_path].append(file_path)\n                else:\n                    paths_dict[install_path] = [file_path]\n    for key in paths_dict.keys():\n        data_files.append((key, paths_dict[key]))\n    return data_files\n\n\n\n\ndef copy_weights_to_home():\n    home_dir = os.path.expanduser(\"~\")\n    dest_dir = os.path.join(home_dir, \".temp\", \"weights\")\n    os.makedirs(dest_dir, exist_ok=True)\n\n    src_dir = os.path.abspath(\n        os.path.join(os.path.dirname(__file__), \"resource\", \"weights\")\n    )\n    for path, directories, filenames in os.walk(src_dir):\n        for filename in filenames:\n            src_file = os.path.join(path, filename)\n            dest_file = os.path.join(dest_dir, filename)\n            if not os.path.exists(dest_file):\n                os.symlink(src_file, dest_file)\n            elif os.path.islink(dest_file) and os.readlink(dest_file) != src_file:\n                os.remove(dest_file)\n                os.symlink(src_file, dest_file)\n\n\nsetup(\n    name=package_name,\n    version=\"0.0.0\",\n    packages=find_packages(exclude=[\"test\"]),\n    data_files=package_files(data_files, [\"launch\", \"config\", \"resource\"]),\n    install_requires=[\"setuptools\"],\n    zip_safe=True,\n    maintainer=\"foo\",\n    maintainer_email=\"foo@foo.com\",\n    description=\"TODO: Package description\",\n    license=\"TODO: License declaration\",\n    tests_require=[\"pytest\"],\n    entry_points={\n        \"console_scripts\": [\n            \"app_for_1 = my_package.app_for_1:main\",\n        ],\n    },\n)\n\ncopy_weights_to_home()\n\npackage.xml\n<?xml version=\"1.0\"?>\n<?xml-model href=\"http://download.ros.org/schema/package_format3.xsd\" schematypens=\"http://www.w3.org/2001/XMLSchema\"?>\n<package format=\"3\">\n  <name>my_package</name>\n  <version>0.0.0</version>\n  <description>ROS package</description>\n  <maintainer email=\"foo@foo.com\">foo</maintainer>\n  <license>TODO: License declaration</license>\n\n  <buildtool_depend>ament_python</buildtool_depend>\n\n  <exec_depend>rclpy</exec_depend>\n  <exec_depend>launch</exec_depend>\n  <exec_depend>launch_ros</exec_depend>\n\n  <depend>std_msgs</depend>\n  <depend>sensor_msgs</depend>\n  <depend>cv_bridge</depend>\n  <depend>usb_cam</depend>\n  <depend>v4l-utils</depend>\n  <depend>ffmpeg</depend>\n  <depend>ament_index_python</depend>\n\n  <test_depend>ament_copyright</test_depend>\n  <test_depend>ament_flake8</test_depend>\n  <test_depend>ament_pep257</test_depend>\n  <test_depend>python3-pytest</test_depend>\n\n  <export>\n    <build_type>ament_python</build_type>\n  </export>\n</package>"], "question_code": ["source /home/ws/ros2_ws/install/setup.bash", "$&gt; ros2 launch\nFailed to load entry point 'launch': No module named 'launch.launch_description_sources'\nTraceback (most recent call last):\n  File &quot;/opt/ros/foxy/bin/ros2&quot;, line 11, in &lt;module&gt;\n    load_entry_point('ros2cli==0.9.13', 'console_scripts', 'ros2')()\n  File &quot;/opt/ros/foxy/lib/python3.8/site-packages/ros2cli/cli.py&quot;, line 39, in main\n    add_subparsers_on_demand(\n  File &quot;/opt/ros/foxy/lib/python3.8/site-packages/ros2cli/command/__init__.py&quot;, line 237, in add_subparsers_on_demand\n    extension = command_extensions[name]\nKeyError: 'launch'\n", "\u251c\u2500\u2500 config\n\u2502   \u2514\u2500\u2500 params_app.yaml\n\u251c\u2500\u2500 face_pose_estimation\n\u2502   \u251c\u2500\u2500 app_for_1.py\n\u2502   \u251c\u2500\u2500 components\n\u2502   \u2502   \u251c\u2500\u2500 main_component.py\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 utils\n\u2502   \u2502       \u251c\u2500\u2500 common.py\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2514\u2500\u2500 play_voice.py\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 save_service_server.py\n\u251c\u2500\u2500 launch\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 app_1.launch.py\n\u251c\u2500\u2500 log\n\u2502   \u2514\u2500\u2500 20241011_1114.txt\n\u251c\u2500\u2500 package.xml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 resource\n\u2502   \u251c\u2500\u2500 ros_app.service\n\u2502   \u2514\u2500\u2500 weights\n\u251c\u2500\u2500 script\n\u2502   \u251c\u2500\u2500 all.sh\n\u2502   \u251c\u2500\u2500 micro_ros.sh\n\u2502   \u2514\u2500\u2500 usbcam_open.sh\n\u251c\u2500\u2500 setup.cfg\n\u251c\u2500\u2500 setup.py\n", "from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\nfrom ament_index_python.packages import get_package_share_directory\nimport os\n\n\ndef generate_launch_description():\n    package_share_dir = get_package_share_directory(&quot;my_package&quot;)\n    cam_params_file = os.path.join(package_share_dir, &quot;config&quot;, &quot;params_usbcam.yaml&quot;)\n    app_params_file = os.path.join(package_share_dir, &quot;config&quot;, &quot;params_app.yaml&quot;)\n\n    return LaunchDescription(\n        [\n            # Node(\n            #     package=&quot;micro_ros_agent&quot;,\n            #     execuable=&quot;micro_ros_agent&quot;,\n            #     name=&quot;micro_ros&quot;,\n            #     arguments=[\n            #         &quot;serial&quot;,\n            #         &quot;--dev&quot;,\n            #         &quot;/dev/ttyUSB0&quot;,\n            #         &quot;-b&quot;,\n            #         &quot;115200&quot;,\n            #     ],\n            # ),\n            Node(\n                package=&quot;usb_cam&quot;,\n                executable=&quot;usb_cam_node_exe&quot;,\n                name=&quot;app_cam&quot;,\n                # parameters=[cam_params_file],\n            ),\n            Node(\n                package=&quot;my_package&quot;,\n                executable=&quot;app_for_1&quot;,\n                name=&quot;app&quot;,\n                parameters=[app_params_file],\n            ),\n        ]\n", "import os\nfrom setuptools import setup, find_packages\n\npackage_name = &quot;my_package&quot;\n\ndata_files = [\n    (&quot;share/ament_index/resource_index/packages&quot;, [&quot;resource/&quot; + package_name]),\n    (&quot;share/&quot; + package_name, [&quot;package.xml&quot;]),\n]\n\n\ndef package_files(data_files, directory_list):\n    paths_dict = {}\n    for directory in directory_list:\n        for path, directories, filenames in os.walk(directory):\n            for filename in filenames:\n                if filename == &quot;__init__.py&quot;:\n                    continue\n                file_path = os.path.join(path, filename)\n                install_path = os.path.join(&quot;share&quot;, package_name, path)\n                if install_path in paths_dict.keys():\n                    paths_dict[install_path].append(file_path)\n                else:\n                    paths_dict[install_path] = [file_path]\n    for key in paths_dict.keys():\n        data_files.append((key, paths_dict[key]))\n    return data_files\n\n\n\n\ndef copy_weights_to_home():\n    home_dir = os.path.expanduser(&quot;~&quot;)\n    dest_dir = os.path.join(home_dir, &quot;.temp&quot;, &quot;weights&quot;)\n    os.makedirs(dest_dir, exist_ok=True)\n\n    src_dir = os.path.abspath(\n        os.path.join(os.path.dirname(__file__), &quot;resource&quot;, &quot;weights&quot;)\n    )\n    for path, directories, filenames in os.walk(src_dir):\n        for filename in filenames:\n            src_file = os.path.join(path, filename)\n            dest_file = os.path.join(dest_dir, filename)\n            if not os.path.exists(dest_file):\n                os.symlink(src_file, dest_file)\n            elif os.path.islink(dest_file) and os.readlink(dest_file) != src_file:\n                os.remove(dest_file)\n                os.symlink(src_file, dest_file)\n\n\nsetup(\n    name=package_name,\n    version=&quot;0.0.0&quot;,\n    packages=find_packages(exclude=[&quot;test&quot;]),\n    data_files=package_files(data_files, [&quot;launch&quot;, &quot;config&quot;, &quot;resource&quot;]),\n    install_requires=[&quot;setuptools&quot;],\n    zip_safe=True,\n    maintainer=&quot;foo&quot;,\n    maintainer_email=&quot;foo@foo.com&quot;,\n    description=&quot;TODO: Package description&quot;,\n    license=&quot;TODO: License declaration&quot;,\n    tests_require=[&quot;pytest&quot;],\n    entry_points={\n        &quot;console_scripts&quot;: [\n            &quot;app_for_1 = my_package.app_for_1:main&quot;,\n        ],\n    },\n)\n\ncopy_weights_to_home()\n", "&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-model href=&quot;http://download.ros.org/schema/package_format3.xsd&quot; schematypens=&quot;http://www.w3.org/2001/XMLSchema&quot;?&gt;\n&lt;package format=&quot;3&quot;&gt;\n  &lt;name&gt;my_package&lt;/name&gt;\n  &lt;version&gt;0.0.0&lt;/version&gt;\n  &lt;description&gt;ROS package&lt;/description&gt;\n  &lt;maintainer email=&quot;foo@foo.com&quot;&gt;foo&lt;/maintainer&gt;\n  &lt;license&gt;TODO: License declaration&lt;/license&gt;\n\n  &lt;buildtool_depend&gt;ament_python&lt;/buildtool_depend&gt;\n\n  &lt;exec_depend&gt;rclpy&lt;/exec_depend&gt;\n  &lt;exec_depend&gt;launch&lt;/exec_depend&gt;\n  &lt;exec_depend&gt;launch_ros&lt;/exec_depend&gt;\n\n  &lt;depend&gt;std_msgs&lt;/depend&gt;\n  &lt;depend&gt;sensor_msgs&lt;/depend&gt;\n  &lt;depend&gt;cv_bridge&lt;/depend&gt;\n  &lt;depend&gt;usb_cam&lt;/depend&gt;\n  &lt;depend&gt;v4l-utils&lt;/depend&gt;\n  &lt;depend&gt;ffmpeg&lt;/depend&gt;\n  &lt;depend&gt;ament_index_python&lt;/depend&gt;\n\n  &lt;test_depend&gt;ament_copyright&lt;/test_depend&gt;\n  &lt;test_depend&gt;ament_flake8&lt;/test_depend&gt;\n  &lt;test_depend&gt;ament_pep257&lt;/test_depend&gt;\n  &lt;test_depend&gt;python3-pytest&lt;/test_depend&gt;\n\n  &lt;export&gt;\n    &lt;build_type&gt;ament_python&lt;/build_type&gt;\n  &lt;/export&gt;\n&lt;/package&gt;\n"], "quote": [], "url": "https://stackoverflow.com/questions/79109423/ros2-launch-error-when-installing-my-package", "answer": ["You might want to check out: RoboticsBackend - Create a Python Package\n\nLaunch files\nCreate a launch/ folder at the root of your package. You\u2019ll put all\nyour launch files inside this folder.\n$ cd ~/ros2_ws/src/my_python_pkg/\n$ mkdir launch\nNow, to install those launch files, you need to modify setup.py.\nimport os \nfrom glob import glob \nfrom setuptools import setup \n... \ndata_files=[\n   ('share/ament_index/resource_index/packages',\n       ['resource/' + package_name]),\n   ('share/' + package_name, ['package.xml']),\n   (os.path.join('share', package_name, 'launch'), glob('launch/*.launch.py')), \n], \n...\n\nFor our example, with package name \u201cmy_python_pkg\u201d, this will install\nall launch files from the launch/ folder, into\n~/ros2_ws/install/my_python_pkg/share/my_python_pkg/launch/.\nNote: you only need to modify setup.py once. After that, every time\nyou add a launch file you\u2019ll just need to compile your package so that\nthe file is installed, that\u2019s it.\nThen, to start a launch file: ros2 launch package_name launch_file_name"], "answer_code": ["launch/", "$ cd ~/ros2_ws/src/my_python_pkg/", "$ mkdir launch", "import os \nfrom glob import glob \nfrom setuptools import setup \n... \ndata_files=[\n   ('share/ament_index/resource_index/packages',\n       ['resource/' + package_name]),\n   ('share/' + package_name, ['package.xml']),\n   (os.path.join('share', package_name, 'launch'), glob('launch/*.launch.py')), \n], \n...\n", "ros2 launch package_name launch_file_name"]},
{"title": "ROS2 Node runs using python3 command but not with ros2 run", "time": 1728330110, "post_content": ["I am using a YOLOv5 package I found online (https://drive.google.com/drive/folders/1xC-gFmWQybQGagxtu8WxGqpFS-1Ek-V2) for my project. The thing is, the tutorial says to run the detection code by going to its location  and running python3 ros_recognition_yolo.py, but I want to make the node executable from ros2 run.\nI made the node executable, but when I run it, it doesn't work. The strange is that running like before works, only not with ros2 run. When I run, it gives me this error:\nTraceback (most recent call last):\n  File \"/home/gabriel_pogo/at_work/install/yolobot_recognition/lib/yolobot_recognition/ros_recognition_yolo.py\", line 20, in <module>\n    from models.experimental import attempt_load\nModuleNotFoundError: No module named 'models'\n\nModels is a folder with lots of important scripts. Like the code I want to run, it is inside the scripts folder in the yolobot_recognition pkg.\nIf it helps, here is my CMake and my package.xml:\ncmake_minimum_required(VERSION 3.5)\nproject(yolobot_recognition)\n\n# Default to C99\nif(NOT CMAKE_C_STANDARD)\n  set(CMAKE_C_STANDARD 99)\nendif()\n\n# Default to C++14\nif(NOT CMAKE_CXX_STANDARD)\n  set(CMAKE_CXX_STANDARD 14)\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n  add_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\n# find dependencies\nfind_package(ament_cmake REQUIRED)\nfind_package(ament_cmake_python REQUIRED)\nfind_package(rclcpp REQUIRED)\nfind_package(rclpy REQUIRED)\n\nset(dependencies\n  \"rclpy\"\n  \"rclcpp\"\n)\n\ninstall(\n  DIRECTORY scripts/models scripts/utils\n  DESTINATION share/${PROJECT_NAME}\n)\n\ninstall(PROGRAMS\n  scripts/ros_recognition_yolo.py\n  DESTINATION lib/${PROJECT_NAME}\n)\n\nif(BUILD_TESTING)\n  find_package(ament_lint_auto REQUIRED)\n  # the following line skips the linter which checks for copyrights\n  # uncomment the line when a copyright and license is not present in all source files\n  #set(ament_cmake_copyright_FOUND TRUE)\n  # the following line skips cpplint (only works in a git repo)\n  # uncomment the line when this package is not in a git repo\n  #set(ament_cmake_cpplint_FOUND TRUE)\n  ament_lint_auto_find_test_dependencies()\nendif()\n\nament_export_dependencies(${dependencies})\nament_package()\n\n<?xml version=\"1.0\"?>\n<?xml-model href=\"http://download.ros.org/schema/package_format3.xsd\" schematypens=\"http://www.w3.org/2001/XMLSchema\"?>\n<package format=\"3\">\n  <name>yolobot_recognition</name>\n  <version>0.0.0</version>\n  <description>TODO: Package description</description>\n  <maintainer email=\"robotmania@todo.todo\">robotmania</maintainer>\n  <license>TODO: License declaration</license>\n\n  <buildtool_depend>ament_cmake</buildtool_depend>\n  <buildtool_depend>ament_cmake_python</buildtool_depend>\n\n\n  <test_depend>ament_lint_auto</test_depend>\n  <test_depend>ament_lint_common</test_depend>\n  <exec_depend>rclpy</exec_depend>\n  <exec_depend>models</exec_depend>\n  <build_depend>models</build_depend>\n\n  <export>\n    <build_type>ament_cmake</build_type>\n  </export>\n</package>"], "question_code": ["python3 ros_recognition_yolo.py", "Traceback (most recent call last):\n  File &quot;/home/gabriel_pogo/at_work/install/yolobot_recognition/lib/yolobot_recognition/ros_recognition_yolo.py&quot;, line 20, in &lt;module&gt;\n    from models.experimental import attempt_load\nModuleNotFoundError: No module named 'models'\n", "cmake_minimum_required(VERSION 3.5)\nproject(yolobot_recognition)\n\n# Default to C99\nif(NOT CMAKE_C_STANDARD)\n  set(CMAKE_C_STANDARD 99)\nendif()\n\n# Default to C++14\nif(NOT CMAKE_CXX_STANDARD)\n  set(CMAKE_CXX_STANDARD 14)\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES &quot;Clang&quot;)\n  add_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\n# find dependencies\nfind_package(ament_cmake REQUIRED)\nfind_package(ament_cmake_python REQUIRED)\nfind_package(rclcpp REQUIRED)\nfind_package(rclpy REQUIRED)\n\nset(dependencies\n  &quot;rclpy&quot;\n  &quot;rclcpp&quot;\n)\n\ninstall(\n  DIRECTORY scripts/models scripts/utils\n  DESTINATION share/${PROJECT_NAME}\n)\n\ninstall(PROGRAMS\n  scripts/ros_recognition_yolo.py\n  DESTINATION lib/${PROJECT_NAME}\n)\n\nif(BUILD_TESTING)\n  find_package(ament_lint_auto REQUIRED)\n  # the following line skips the linter which checks for copyrights\n  # uncomment the line when a copyright and license is not present in all source files\n  #set(ament_cmake_copyright_FOUND TRUE)\n  # the following line skips cpplint (only works in a git repo)\n  # uncomment the line when this package is not in a git repo\n  #set(ament_cmake_cpplint_FOUND TRUE)\n  ament_lint_auto_find_test_dependencies()\nendif()\n\nament_export_dependencies(${dependencies})\nament_package()\n", "&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-model href=&quot;http://download.ros.org/schema/package_format3.xsd&quot; schematypens=&quot;http://www.w3.org/2001/XMLSchema&quot;?&gt;\n&lt;package format=&quot;3&quot;&gt;\n  &lt;name&gt;yolobot_recognition&lt;/name&gt;\n  &lt;version&gt;0.0.0&lt;/version&gt;\n  &lt;description&gt;TODO: Package description&lt;/description&gt;\n  &lt;maintainer email=&quot;robotmania@todo.todo&quot;&gt;robotmania&lt;/maintainer&gt;\n  &lt;license&gt;TODO: License declaration&lt;/license&gt;\n\n  &lt;buildtool_depend&gt;ament_cmake&lt;/buildtool_depend&gt;\n  &lt;buildtool_depend&gt;ament_cmake_python&lt;/buildtool_depend&gt;\n\n\n  &lt;test_depend&gt;ament_lint_auto&lt;/test_depend&gt;\n  &lt;test_depend&gt;ament_lint_common&lt;/test_depend&gt;\n  &lt;exec_depend&gt;rclpy&lt;/exec_depend&gt;\n  &lt;exec_depend&gt;models&lt;/exec_depend&gt;\n  &lt;build_depend&gt;models&lt;/build_depend&gt;\n\n  &lt;export&gt;\n    &lt;build_type&gt;ament_cmake&lt;/build_type&gt;\n  &lt;/export&gt;\n&lt;/package&gt;\n"], "quote": [], "url": "https://stackoverflow.com/questions/79063442/ros2-node-runs-using-python3-command-but-not-with-ros2-run", "answer": ["It's because you're installing the modules in a different location than your script. As such your PYTHONPATH and import paths won't line up. You should be able to make this change:\ninstall(\n    DIRECTORY scripts/models scripts/utils\n    DESTINATION lib/${PROJECT_NAME}\n)\n\nI also generally recommend that pure python ROS packages are created as a Python ROS package"], "answer_code": ["PYTHONPATH", "install(\n    DIRECTORY scripts/models scripts/utils\n    DESTINATION lib/${PROJECT_NAME}\n)\n"]}
]